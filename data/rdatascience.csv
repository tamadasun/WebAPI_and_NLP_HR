approved_at_utc,subreddit,selftext,author_fullname,saved,mod_reason_title,gilded,clicked,title,link_flair_richtext,subreddit_name_prefixed,hidden,pwls,link_flair_css_class,downs,thumbnail_height,top_awarded_type,hide_score,name,quarantine,link_flair_text_color,upvote_ratio,author_flair_background_color,subreddit_type,ups,total_awards_received,media_embed,thumbnail_width,author_flair_template_id,is_original_content,user_reports,secure_media,is_reddit_media_domain,is_meta,category,secure_media_embed,link_flair_text,can_mod_post,score,approved_by,is_created_from_ads_ui,author_premium,thumbnail,edited,author_flair_css_class,author_flair_richtext,gildings,content_categories,is_self,mod_note,created,link_flair_type,wls,removed_by_category,banned_by,author_flair_type,domain,allow_live_comments,selftext_html,likes,suggested_sort,banned_at_utc,view_count,archived,no_follow,is_crosspostable,pinned,over_18,all_awardings,awarders,media_only,link_flair_template_id,can_gild,spoiler,locked,author_flair_text,treatment_tags,visited,removed_by,num_reports,distinguished,subreddit_id,author_is_blocked,mod_reason_by,removal_reason,link_flair_background_color,id,is_robot_indexable,report_reasons,author,discussion_type,num_comments,send_replies,whitelist_status,contest_mode,mod_reports,author_patreon_flair,author_flair_text_color,permalink,parent_whitelist_status,stickied,url,subreddit_subscribers,created_utc,num_crossposts,media,is_video,media_metadata,post_hint,preview,author_cakeday,url_overridden_by_dest,crosspost_parent_list,crosspost_parent,is_gallery,gallery_data,selftext_length,selftext_word_count
,datascience," Hi I wanted to get some takes from actual statisticians/people in the field

I'm a math graduate and I've done some self learning on statistics off and on the last two years. I've bounced back and forth considering grad school but the costs are very high (MS programs) both in person and online and I doubt I could swing it. Jobs want professional experience which I don't have. I'm very wary of bootcamps and the like. I do not have the expertise to make things I'd like to make on my own and it does not help that I get very hung up on the nitty gritty math details on why things work and where they come from.

How did you get started. Where did you end up and what might be your take for someone like myself. Thanks",t2_4ffvev5v,False,,0,False,Interested in statistics not sure how to proceed,[],r/datascience,False,6,fun,0,,,False,t3_18rxvx4,False,dark,0.86,,public,24,0,{},,,False,[],,False,False,,{},Career Discussion,False,24,,False,False,self,False,,[],{},,True,,1703673543.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi I wanted to get some takes from actual statisticians/people in the field&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a math graduate and I&amp;#39;ve done some self learning on statistics off and on the last two years. I&amp;#39;ve bounced back and forth considering grad school but the costs are very high (MS programs) both in person and online and I doubt I could swing it. Jobs want professional experience which I don&amp;#39;t have. I&amp;#39;m very wary of bootcamps and the like. I do not have the expertise to make things I&amp;#39;d like to make on my own and it does not help that I get very hung up on the nitty gritty math details on why things work and where they come from.&lt;/p&gt;

&lt;p&gt;How did you get started. Where did you end up and what might be your take for someone like myself. Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18rxvx4,True,,Tannir48,,17,True,all_ads,False,[],False,,/r/datascience/comments/18rxvx4/interested_in_statistics_not_sure_how_to_proceed/,all_ads,False,https://www.reddit.com/r/datascience/comments/18rxvx4/interested_in_statistics_not_sure_how_to_proceed/,1209065,1703673543.0,0,,False,,,,,,,,,,720,139
,datascience,"I'm a statistician looking for work after a layoff in November and getting a lot of rejections.

Would having a Github repository make my resume more competitive?

If so, which code should I include? I can't disclose past work examples without violating intellectual property agreements. 

Or do recruiters not look at applicant's Github repos?",t2_6cjiszgb,False,,0,False,Create Github repository?,[],r/datascience,False,6,fun,0,,,False,t3_18rn5j2,False,dark,0.9,,public,65,0,{},,,False,[],,False,False,,{},Career Discussion,False,65,,False,False,self,False,,[],{},,True,,1703637710.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a statistician looking for work after a layoff in November and getting a lot of rejections.&lt;/p&gt;

&lt;p&gt;Would having a Github repository make my resume more competitive?&lt;/p&gt;

&lt;p&gt;If so, which code should I include? I can&amp;#39;t disclose past work examples without violating intellectual property agreements. &lt;/p&gt;

&lt;p&gt;Or do recruiters not look at applicant&amp;#39;s Github repos?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18rn5j2,True,,RobertWF_47,,43,True,all_ads,False,[],False,,/r/datascience/comments/18rn5j2/create_github_repository/,all_ads,False,https://www.reddit.com/r/datascience/comments/18rn5j2/create_github_repository/,1209065,1703637710.0,0,,False,,,,,,,,,,344,54
,datascience,"My upcoming course is focused on programming a number of machine learning algorithms from scratch and requires a lot of demonstrated understanding of the related formulas and proofs. 

I have taken both linear algebra and multivariate calculus. Although I got good marks, I don't feel fluent in either topic. 

As an example, I struggle to map summations to matrix equations and vice versa. I might be able to do it if I work very slowly, but I am heavily reliant on worked examples or solutions being available. 

I expect to need some fluency in converting between the different forms and gradients. 

Can anyone point to resources that helped things ""click"" for them?   
Any general advice? Maybe a big library of worked examples?",t2_3puwn,False,,0,False,Linear Algebra and Multivariate Calculus,[],r/datascience,False,6,,0,,,False,t3_18rg70s,False,dark,0.96,,public,72,0,{},,,False,[],,False,False,,{},Challenges,False,72,,False,False,self,False,,[],{},,True,,1703619346.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My upcoming course is focused on programming a number of machine learning algorithms from scratch and requires a lot of demonstrated understanding of the related formulas and proofs. &lt;/p&gt;

&lt;p&gt;I have taken both linear algebra and multivariate calculus. Although I got good marks, I don&amp;#39;t feel fluent in either topic. &lt;/p&gt;

&lt;p&gt;As an example, I struggle to map summations to matrix equations and vice versa. I might be able to do it if I work very slowly, but I am heavily reliant on worked examples or solutions being available. &lt;/p&gt;

&lt;p&gt;I expect to need some fluency in converting between the different forms and gradients. &lt;/p&gt;

&lt;p&gt;Can anyone point to resources that helped things &amp;quot;click&amp;quot; for them?&lt;br/&gt;
Any general advice? Maybe a big library of worked examples?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,18rg70s,True,,joshred,,31,False,all_ads,False,[],False,,/r/datascience/comments/18rg70s/linear_algebra_and_multivariate_calculus/,all_ads,False,https://www.reddit.com/r/datascience/comments/18rg70s/linear_algebra_and_multivariate_calculus/,1209065,1703619346.0,2,,False,,,,,,,,,,733,122
,datascience,"Our company has 1000 ish headcount with 3 distinct business divisions, and has 2 DS teams, there are some chatters to merge the 2 teams into 1. I can see pros and cons to both merge and keep separate. Wondering how are other companies handling such situations? For smaller companies is it better to be centralized or decentralized??",t2_16kgog,False,,0,False,"DS org, decentralized or centralized?",[],r/datascience,False,6,fun,0,,,False,t3_18r48mp,False,dark,1.0,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1703582120.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Our company has 1000 ish headcount with 3 distinct business divisions, and has 2 DS teams, there are some chatters to merge the 2 teams into 1. I can see pros and cons to both merge and keep separate. Wondering how are other companies handling such situations? For smaller companies is it better to be centralized or decentralized??&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18r48mp,True,,balpby1989,,8,True,all_ads,False,[],False,,/r/datascience/comments/18r48mp/ds_org_decentralized_or_centralized/,all_ads,False,https://www.reddit.com/r/datascience/comments/18r48mp/ds_org_decentralized_or_centralized/,1209065,1703582120.0,0,,False,,,,,,,,,,332,58
,datascience,"Hi all, I'd like to rehash my understanding of the fundamentals of probability theory. I'm trying to find a probability book that meets the following criteria:
- Motivates different concepts and does not just show definition-proof-definition-proof
- Is complete in that it covers all the fundamentals of probability
- Is not overtly pro/anti bayesian
- Suitable for a data science professional with a mathematics undergrad but hasn't studied in several years
- Is suitable for self-study (problem solutions must be available in the book or online)

I skimmed across Probability by Shiryaev but it was a bit too definition-proof for my liking and too abstract. I am looking for a dedicated probability book and will then move to a dedicated statistics reference book. Cheers",t2_xfx8ms4,False,,0,False,Probability reference book for data science professionals,[],r/datascience,False,6,discussion,0,,,False,t3_18qtaid,False,dark,0.93,,public,106,0,{},,,False,[],,False,False,,{},Discussion,False,106,,False,False,self,1703556422.0,,[],{},,True,,1703545051.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;d like to rehash my understanding of the fundamentals of probability theory. I&amp;#39;m trying to find a probability book that meets the following criteria:
- Motivates different concepts and does not just show definition-proof-definition-proof
- Is complete in that it covers all the fundamentals of probability
- Is not overtly pro/anti bayesian
- Suitable for a data science professional with a mathematics undergrad but hasn&amp;#39;t studied in several years
- Is suitable for self-study (problem solutions must be available in the book or online)&lt;/p&gt;

&lt;p&gt;I skimmed across Probability by Shiryaev but it was a bit too definition-proof for my liking and too abstract. I am looking for a dedicated probability book and will then move to a dedicated statistics reference book. Cheers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18qtaid,True,,HStuart18,,37,True,all_ads,False,[],False,,/r/datascience/comments/18qtaid/probability_reference_book_for_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/18qtaid/probability_reference_book_for_data_science/,1209065,1703545051.0,0,,False,,,,,,,,,,773,124
,datascience," 

Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_6l4z3,False,,0,False,"Weekly Entering &amp; Transitioning - Thread 25 Dec, 2023 - 01 Jan, 2024",[],r/datascience,False,6,,0,,,False,t3_18qbsme,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,True,self,False,,[],{},,True,,1703480484.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,new,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_2sptq,False,,,,18qbsme,True,,AutoModerator,,32,False,all_ads,False,[],False,,/r/datascience/comments/18qbsme/weekly_entering_transitioning_thread_25_dec_2023/,all_ads,True,https://www.reddit.com/r/datascience/comments/18qbsme/weekly_entering_transitioning_thread_25_dec_2023/,1209065,1703480484.0,0,,False,,,,,,,,,,805,94
,datascience,"Does anyone have a good resource or example project doing this? Most things I find only do one step ahead prediction and I want to find some information on how to properly do multi step autoregressive forecasts. 

If it also has information on how to do Teacher Forcing and no Teacher Forcing that would be useful to me as well. 

Thank you for the help!",t2_44oxrfns,False,,0,False,PyTorch LSTM for time series,[],r/datascience,False,6,projects,0,,,False,t3_18q5vq6,False,dark,0.87,,public,18,0,{},,,False,[],,False,False,,{},ML,False,18,,False,False,self,False,,[],{},,True,,1703458494.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have a good resource or example project doing this? Most things I find only do one step ahead prediction and I want to find some information on how to properly do multi step autoregressive forecasts. &lt;/p&gt;

&lt;p&gt;If it also has information on how to do Teacher Forcing and no Teacher Forcing that would be useful to me as well. &lt;/p&gt;

&lt;p&gt;Thank you for the help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18q5vq6,True,,medylan,,32,True,all_ads,False,[],False,,/r/datascience/comments/18q5vq6/pytorch_lstm_for_time_series/,all_ads,False,https://www.reddit.com/r/datascience/comments/18q5vq6/pytorch_lstm_for_time_series/,1209065,1703458494.0,0,,False,,,,,,,,,,354,65
,datascience,"I see LLM's are all the rage these days. Learning and applying NLP projects seem redundant when you can fine tune a LLM model and get equally better results.

I want to learn what domain of DS/AI would you recommend investing my time in and why from future job scope perspective:
Classical ML
NLP
CV
Other (please specify)


Thank you! Happy holidays everyone🎅!",t2_a0h39pj0,False,,0,False,What Domain of DS will have most jobs in the future? And what skills to pursue?,[],r/datascience,False,6,fun,0,,,False,t3_18pytja,False,dark,0.8,,public,64,0,{},,,False,[],,False,False,,{},Career Discussion,False,64,,False,False,self,False,,[],{},,True,,1703436464.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see LLM&amp;#39;s are all the rage these days. Learning and applying NLP projects seem redundant when you can fine tune a LLM model and get equally better results.&lt;/p&gt;

&lt;p&gt;I want to learn what domain of DS/AI would you recommend investing my time in and why from future job scope perspective:
Classical ML
NLP
CV
Other (please specify)&lt;/p&gt;

&lt;p&gt;Thank you! Happy holidays everyone🎅!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18pytja,True,,wealthyinvestor999,,56,True,all_ads,False,[],False,,/r/datascience/comments/18pytja/what_domain_of_ds_will_have_most_jobs_in_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/18pytja/what_domain_of_ds_will_have_most_jobs_in_the/,1209065,1703436464.0,0,,False,,,,,,,,,,361,63
,datascience,"Hey folks, I am learning Time series Forecasting, and currently at topic of Model building and cross validation. I came up at topic of Walk forward validation of model. I didn't understand it well from my ongoing course, I searched it on internet but didn't helped.

Can someone explain it in easy way with example.",t2_agvtvokn,False,,0,False,Walk forward validation,[],r/datascience,False,6,,0,,,False,t3_18pxc6x,False,dark,0.67,,public,5,0,{},,,True,[],,False,False,,{},Education,False,5,,False,False,self,False,,[],{},,True,,1703431724.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks, I am learning Time series Forecasting, and currently at topic of Model building and cross validation. I came up at topic of Walk forward validation of model. I didn&amp;#39;t understand it well from my ongoing course, I searched it on internet but didn&amp;#39;t helped.&lt;/p&gt;

&lt;p&gt;Can someone explain it in easy way with example.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,18pxc6x,True,,chilly_tomato,,2,True,all_ads,False,[],False,,/r/datascience/comments/18pxc6x/walk_forward_validation/,all_ads,False,https://www.reddit.com/r/datascience/comments/18pxc6x/walk_forward_validation/,1209065,1703431724.0,0,,False,,,,,,,,,,315,55
,datascience,"How do you land a data job when you’re a physics masters with self-driven software experience?

Applied to over 1300 DS, DA, and MLE jobs without luck, feeling pretty defeated. 

My experience includes three major kaggle competitions, one in which I got a bronze medal, and a few entrepreneurial projects including a full stack application running a deep learning model on AWS cloud. I also have been developing software for a research group at CERN.

I understand that not having a CS degree or no corporate experience sets me back, but is it really that hard to land a job?? I’ve been trying for over two years. Sometimes I feel like recruiters don’t even open my resume.

I mainly apply on linkedin, but also on company websites especially Microsoft. 

Any advice is appreciated.",t2_u58v9e5m,False,,0,False,Job hunt status: feeling defeated,[],r/datascience,False,6,fun,0,,,False,t3_18ppfrh,False,dark,0.83,,public,72,0,{},,,False,[],,False,False,,{},Career Discussion,False,72,,False,False,self,False,,[],{},,True,,1703399541.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How do you land a data job when you’re a physics masters with self-driven software experience?&lt;/p&gt;

&lt;p&gt;Applied to over 1300 DS, DA, and MLE jobs without luck, feeling pretty defeated. &lt;/p&gt;

&lt;p&gt;My experience includes three major kaggle competitions, one in which I got a bronze medal, and a few entrepreneurial projects including a full stack application running a deep learning model on AWS cloud. I also have been developing software for a research group at CERN.&lt;/p&gt;

&lt;p&gt;I understand that not having a CS degree or no corporate experience sets me back, but is it really that hard to land a job?? I’ve been trying for over two years. Sometimes I feel like recruiters don’t even open my resume.&lt;/p&gt;

&lt;p&gt;I mainly apply on linkedin, but also on company websites especially Microsoft. &lt;/p&gt;

&lt;p&gt;Any advice is appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ppfrh,True,,abdoughnut,,103,True,all_ads,False,[],False,,/r/datascience/comments/18ppfrh/job_hunt_status_feeling_defeated/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ppfrh/job_hunt_status_feeling_defeated/,1209065,1703399541.0,0,,False,,,,,,,,,,782,133
,datascience,"I have an MS in data science, working as a data analyst and considering getting an MBA. I'm not sure if I should do the concentration in data analytics or business analytics I see some programs offer. My MS program was focused on computer science and statistics courses, not really presenting or dealing with a client. 

Has anyone gone through a similar MS and done a data/business analytics focused MBA? Were the data classes helpful or do you feel a general MBA would have been better? Thanks.


Edit: My employer offers tuition reimbursement but it's not much. Only $1,500 per term with a max of $3,000 a year. So I'll be paying some out of my own pocket. ",t2_lpb6f4wr,False,,0,False,MBA with Data Analytics Concentration after MS in Data Science?,[],r/datascience,False,6,fun,0,,,False,t3_18ponyx,False,dark,0.48,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,1703399504.0,,[],{},,True,,1703396555.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an MS in data science, working as a data analyst and considering getting an MBA. I&amp;#39;m not sure if I should do the concentration in data analytics or business analytics I see some programs offer. My MS program was focused on computer science and statistics courses, not really presenting or dealing with a client. &lt;/p&gt;

&lt;p&gt;Has anyone gone through a similar MS and done a data/business analytics focused MBA? Were the data classes helpful or do you feel a general MBA would have been better? Thanks.&lt;/p&gt;

&lt;p&gt;Edit: My employer offers tuition reimbursement but it&amp;#39;s not much. Only $1,500 per term with a max of $3,000 a year. So I&amp;#39;ll be paying some out of my own pocket. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ponyx,True,,livingwithnostalgia,,37,True,all_ads,False,[],False,,/r/datascience/comments/18ponyx/mba_with_data_analytics_concentration_after_ms_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ponyx/mba_with_data_analytics_concentration_after_ms_in/,1209065,1703396555.0,0,,False,,,,,,,,,,660,118
,datascience,"I've been trying very hard recently to learn some practical stuff and put it on my resume, but I still don't get any call-back from companies. I've been applying for a role as data scientist, data analyst, financial analyst, business analyst, quant trader, quant researcher, etc. Can you give me any constructive feedback for me based on my resume?

https://preview.redd.it/qjk5q1fnv58c1.png?width=612&amp;format=png&amp;auto=webp&amp;s=97cf4f58d4bac3f4bb3f8b5a0f24f9d20b0d335e",t2_gag9vq5a8,False,,0,False,Math major struggling to get an interview for an entry level position.. any advice would be appreciated!,[],r/datascience,False,6,fun,0,140.0,,False,t3_18pmbih,False,dark,0.87,,public,90,0,{},140.0,,False,[],,False,False,,{},Career Discussion,False,90,,False,False,https://b.thumbs.redditmedia.com/O2DJqLrsjvDzUYosCJHQoxtdagsL4edX6PjJSsxD1Ow.jpg,False,,[],{},,True,,1703388202.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been trying very hard recently to learn some practical stuff and put it on my resume, but I still don&amp;#39;t get any call-back from companies. I&amp;#39;ve been applying for a role as data scientist, data analyst, financial analyst, business analyst, quant trader, quant researcher, etc. Can you give me any constructive feedback for me based on my resume?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/qjk5q1fnv58c1.png?width=612&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=97cf4f58d4bac3f4bb3f8b5a0f24f9d20b0d335e""&gt;https://preview.redd.it/qjk5q1fnv58c1.png?width=612&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=97cf4f58d4bac3f4bb3f8b5a0f24f9d20b0d335e&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18pmbih,True,,Glad-Description2525,,106,True,all_ads,False,[],False,,/r/datascience/comments/18pmbih/math_major_struggling_to_get_an_interview_for_an/,all_ads,False,https://www.reddit.com/r/datascience/comments/18pmbih/math_major_struggling_to_get_an_interview_for_an/,1209065,1703388202.0,1,,False,"{'qjk5q1fnv58c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 139, 'x': 108, 'u': 'https://preview.redd.it/qjk5q1fnv58c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff14066f794d66866a885f03f9e77b74eb6e3cde'}, {'y': 279, 'x': 216, 'u': 'https://preview.redd.it/qjk5q1fnv58c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f90b181e950fe9fdd48b9a442fbb3339b4dde930'}, {'y': 414, 'x': 320, 'u': 'https://preview.redd.it/qjk5q1fnv58c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=117e10f4db04f9a940ec16a150138d760d2f4d6b'}], 's': {'y': 792, 'x': 612, 'u': 'https://preview.redd.it/qjk5q1fnv58c1.png?width=612&amp;format=png&amp;auto=webp&amp;s=97cf4f58d4bac3f4bb3f8b5a0f24f9d20b0d335e'}, 'id': 'qjk5q1fnv58c1'}}",,,,,,,,,477,60
,datascience,"Or Patreon, Snap, Dropbox or Notion.

I am in the loop with all of these companies, but furthest along with Figma and Patreon - I would love to know any insights if anyone's been through it before. Feel free to DM if you don't want to share publicly.",t2_18iah7mg,False,,0,False,Has anyone interviewed with Figma?,[],r/datascience,False,6,fun,0,,,False,t3_18pa61g,False,dark,0.72,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1703351536.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Or Patreon, Snap, Dropbox or Notion.&lt;/p&gt;

&lt;p&gt;I am in the loop with all of these companies, but furthest along with Figma and Patreon - I would love to know any insights if anyone&amp;#39;s been through it before. Feel free to DM if you don&amp;#39;t want to share publicly.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18pa61g,True,,myfriendscode,,8,True,all_ads,False,[],False,,/r/datascience/comments/18pa61g/has_anyone_interviewed_with_figma/,all_ads,False,https://www.reddit.com/r/datascience/comments/18pa61g/has_anyone_interviewed_with_figma/,1209065,1703351536.0,0,,False,,,,,,,,,,250,48
,datascience," Suppose I have records of the number of fishes that each fisherman caught from a particular lake within the year. The distribution peaks at count = 1 (i.e. most fishermen caught just one fish from the lake in the year), tapers off after that, and has a long right-tail (a very small number of fishermen caught over 100 fishes).

Such a data could possibly fit either a Poisson Distribution or a Negative Binomial Distribution. However, both of these distributions have a non-zero probability at count = 0, whereas for our data, fishermen who caught no fishes were not captured as a data point.

Why is it not correct to transform our original data by just deducting 1 from all counts, and therefore shifting our distribution to the left by 1 such that there is now a non-zero probability at count = 0?

(Context: this question came up to me during an interview for a data science job. The interviewer asked me how to deal with the non-zero probability at count = 0 for poisson or negative binomial distribution, and I suggested transforming the data by deducting 1 from all counts which apparently was wrong. I think the correct answer to how to deal with the absence of count = 0 is to use a zero-trauncated distribution instead)",t2_amc46yj2,False,,0,False,Why can't I transform a distribution by deducting one from all counts?,[],r/datascience,False,6,,0,,,False,t3_18p8uz5,False,dark,0.86,,public,52,0,{},,,False,[],,False,False,,{},Statistics,False,52,,False,False,self,False,,[],{},,True,,1703347779.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Suppose I have records of the number of fishes that each fisherman caught from a particular lake within the year. The distribution peaks at count = 1 (i.e. most fishermen caught just one fish from the lake in the year), tapers off after that, and has a long right-tail (a very small number of fishermen caught over 100 fishes).&lt;/p&gt;

&lt;p&gt;Such a data could possibly fit either a Poisson Distribution or a Negative Binomial Distribution. However, both of these distributions have a non-zero probability at count = 0, whereas for our data, fishermen who caught no fishes were not captured as a data point.&lt;/p&gt;

&lt;p&gt;Why is it not correct to transform our original data by just deducting 1 from all counts, and therefore shifting our distribution to the left by 1 such that there is now a non-zero probability at count = 0?&lt;/p&gt;

&lt;p&gt;(Context: this question came up to me during an interview for a data science job. The interviewer asked me how to deal with the non-zero probability at count = 0 for poisson or negative binomial distribution, and I suggested transforming the data by deducting 1 from all counts which apparently was wrong. I think the correct answer to how to deal with the absence of count = 0 is to use a zero-trauncated distribution instead)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,18p8uz5,True,,wanderingcatto,,23,True,all_ads,False,[],False,,/r/datascience/comments/18p8uz5/why_cant_i_transform_a_distribution_by_deducting/,all_ads,False,https://www.reddit.com/r/datascience/comments/18p8uz5/why_cant_i_transform_a_distribution_by_deducting/,1209065,1703347779.0,0,,False,,,,,,,,,,1231,217
,datascience,"I had a PM of a project where i was a DS where my job was to come up with the experiments and build the models, call me out on my coding skills. I do all my work in notebooks and he dint like that, he told me I had to improve my code. 

I told him I dont have much experience as a software engineer, he said thats not an excuse. 

I replied, isnt that like telling the devs to fix the server if it goes down. Its like expecting a software engineer to have sys admin skills.

He did not like my response very much. 

I was wonder whats everyone thought on being a DS and being required to have software engineering skills at the same time?",t2_5shgp83w,False,,0,False,In your opinion how important is dev skills in DS?,[],r/datascience,False,6,discussion,0,,,False,t3_18ow108,False,dark,0.91,,public,100,0,{},,,False,[],,False,False,,{},Discussion,False,100,,False,False,self,False,,[],{},,True,,1703300329.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I had a PM of a project where i was a DS where my job was to come up with the experiments and build the models, call me out on my coding skills. I do all my work in notebooks and he dint like that, he told me I had to improve my code. &lt;/p&gt;

&lt;p&gt;I told him I dont have much experience as a software engineer, he said thats not an excuse. &lt;/p&gt;

&lt;p&gt;I replied, isnt that like telling the devs to fix the server if it goes down. Its like expecting a software engineer to have sys admin skills.&lt;/p&gt;

&lt;p&gt;He did not like my response very much. &lt;/p&gt;

&lt;p&gt;I was wonder whats everyone thought on being a DS and being required to have software engineering skills at the same time?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18ow108,True,,ds_account_,,60,True,all_ads,False,[],False,,/r/datascience/comments/18ow108/in_your_opinion_how_important_is_dev_skills_in_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ow108/in_your_opinion_how_important_is_dev_skills_in_ds/,1209065,1703300329.0,0,,False,,,,,,,,,,638,129
,datascience,"I come from a computer science background and I was discussing with a friend who comes from a math background and he was telling me that if a person dosent know why we use kl divergence instead of other divergence metrics or why we divide square root of d in the softmax for the attention paper , we shouldn't hire him , while I myself didn't know the answer and fell into a existential crisis and kinda had an imposter syndrome after that. Currently we both are also working together on a project so now I question every thing I do.

Wanted to know ur thoughts on that",t2_py4qwirz,False,,0,False,Is Everyone in data science a mathematician,[],r/datascience,False,6,discussion,0,,,False,t3_18o7sqd,False,dark,0.93,,public,370,0,{},,,False,[],,False,False,,{},Discussion,False,370,,False,False,self,False,,[],{},,True,,1703224065.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I come from a computer science background and I was discussing with a friend who comes from a math background and he was telling me that if a person dosent know why we use kl divergence instead of other divergence metrics or why we divide square root of d in the softmax for the attention paper , we shouldn&amp;#39;t hire him , while I myself didn&amp;#39;t know the answer and fell into a existential crisis and kinda had an imposter syndrome after that. Currently we both are also working together on a project so now I question every thing I do.&lt;/p&gt;

&lt;p&gt;Wanted to know ur thoughts on that&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18o7sqd,True,,skeletons_of_closet,,197,True,all_ads,False,[],False,,/r/datascience/comments/18o7sqd/is_everyone_in_data_science_a_mathematician/,all_ads,False,https://www.reddit.com/r/datascience/comments/18o7sqd/is_everyone_in_data_science_a_mathematician/,1209065,1703224065.0,0,,False,,,,,,,,,,569,108
,datascience,Just curious what people are doing on this front... is it worth going down the deployment rabbit hole or do you just pay for a service?,t2_anwr3x7ou,False,,0,False,Have any of you ever paid for Streamlit/Dash (or equivalent) either personally or professionally?,[],r/datascience,False,6,discussion,0,,,False,t3_18o42gh,False,dark,0.94,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,False,self,False,,[],{},,True,,1703211559.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just curious what people are doing on this front... is it worth going down the deployment rabbit hole or do you just pay for a service?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18o42gh,True,,zero-true,,14,True,all_ads,False,[],False,,/r/datascience/comments/18o42gh/have_any_of_you_ever_paid_for_streamlitdash_or/,all_ads,False,https://www.reddit.com/r/datascience/comments/18o42gh/have_any_of_you_ever_paid_for_streamlitdash_or/,1209065,1703211559.0,0,,False,,,,,,,,,,135,26
,datascience,"I’m divided myself on this topic because I get that it’s more for data exploration. But at the same time, the code will eventually be put into production even if it’s not the current iteration.",t2_soqhf,False,,0,False,Should notebooks follow software engineering best practices?,[],r/datascience,False,6,discussion,0,,,False,t3_18nulu1,False,dark,0.92,,public,65,0,{},,,False,[],,False,False,,{},Discussion,False,65,,False,False,self,False,,[],{},,True,,1703185709.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m divided myself on this topic because I get that it’s more for data exploration. But at the same time, the code will eventually be put into production even if it’s not the current iteration.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18nulu1,True,,n1k0h1k0,,55,False,all_ads,False,[],False,,/r/datascience/comments/18nulu1/should_notebooks_follow_software_engineering_best/,all_ads,False,https://www.reddit.com/r/datascience/comments/18nulu1/should_notebooks_follow_software_engineering_best/,1209065,1703185709.0,1,,False,,,,,,,,,,193,35
,datascience,"I’ve written a couple of times about my manager and how toxic it has been on the team. I had a chance to re-org to a different team, but he made it difficult to change and kept putting so many hoops.

And then he became interim AVP because AVP got fed up and left, which meant that I wasn’t switching teams.

However, I had a random chance meeting with the someone higher and I spoke to them about everything, which he wasn’t aware of. They have a brand new team that I’ll be a part of. 

And best of all, my current manager can’t say anything and I’ll be leaving! However, since it’s internal, there’ll be transition time since there is no team. There’s no one to replace me on my team, unfortunately.

However, the new role comes with a promotion and a 20% salary increase, so this is truly the best Christmas gift ever! The projects won’t be as interesting, but I want to take a break from LLMs and stick to classification. LLMs in a corporation is really… political and the data sucks.

And then I can look for a new role externally with the title change, so definitely excited! I definitely have imposter syndrome about the new role, but very excited to start having more than 4 hours of sleep and not waking up to a million rude messages from my manager. It’s ridiculously hard to prepare for a new job when your current job is so toxic and you’re so burnt out.

Thanks so much for the advice and encouragement!!",t2_6lukipdd,False,,0,False,Thank you for the advice on my manager! I’m finally switching teams!,[],r/datascience,False,6,fun,0,,,False,t3_18ns3lu,False,dark,0.91,,public,31,0,{},,,False,[],,False,False,,{},Career Discussion,False,31,,False,False,self,1703183371.0,,[],{},,True,,1703179234.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve written a couple of times about my manager and how toxic it has been on the team. I had a chance to re-org to a different team, but he made it difficult to change and kept putting so many hoops.&lt;/p&gt;

&lt;p&gt;And then he became interim AVP because AVP got fed up and left, which meant that I wasn’t switching teams.&lt;/p&gt;

&lt;p&gt;However, I had a random chance meeting with the someone higher and I spoke to them about everything, which he wasn’t aware of. They have a brand new team that I’ll be a part of. &lt;/p&gt;

&lt;p&gt;And best of all, my current manager can’t say anything and I’ll be leaving! However, since it’s internal, there’ll be transition time since there is no team. There’s no one to replace me on my team, unfortunately.&lt;/p&gt;

&lt;p&gt;However, the new role comes with a promotion and a 20% salary increase, so this is truly the best Christmas gift ever! The projects won’t be as interesting, but I want to take a break from LLMs and stick to classification. LLMs in a corporation is really… political and the data sucks.&lt;/p&gt;

&lt;p&gt;And then I can look for a new role externally with the title change, so definitely excited! I definitely have imposter syndrome about the new role, but very excited to start having more than 4 hours of sleep and not waking up to a million rude messages from my manager. It’s ridiculously hard to prepare for a new job when your current job is so toxic and you’re so burnt out.&lt;/p&gt;

&lt;p&gt;Thanks so much for the advice and encouragement!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ns3lu,True,,Much-Focus-1408,,7,True,all_ads,False,[],False,,/r/datascience/comments/18ns3lu/thank_you_for_the_advice_on_my_manager_im_finally/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ns3lu/thank_you_for_the_advice_on_my_manager_im_finally/,1209065,1703179234.0,0,,False,,,,,,,,,,1418,264
,datascience,"  This article will explain how to use [Pipeline](https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com) and [Transformers](https://scikit-learn.org/stable/data_transforms.html?ref=dataleadsfuture.com) correctly in Scikit-Learn (sklearn) projects to speed up and reuse our model training process.

This piece complements and clarifies the official documentation on Pipeline examples and some common misunderstandings.

I hope that after reading this, you'll be able to use the Pipeline, an excellent design, to better complete your machine learning tasks.

 This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/ensuring-correct-use-of-transformers-in-scikit-learn-pipeline/) 

### Why use a Pipeline

As mentioned earlier, in a machine learning task, we often need to use various Transformers for data scaling and feature dimensionality reduction before training a model.

This presents several challenges:

* **Code complexity**: For each use of a Transformer, we have to go through initialization, `fit_transform`, and `transform` steps. Missing one step during a transformation could derail the entire training process.
* **Data leakage**: As we discussed, for each Transformer, we fit with train data and then transform both train and test data. We must avoid letting the distribution of the test data leak into the train data.
* **Code reusability**: A machine learning model includes not only the trained Estimator for prediction but also the data preprocessing steps. Therefore, a machine learning task comprising Transformers and an Estimator should be atomic and indivisible.
* **Hyperparameter tuning**: After setting up the steps of machine learning, we need to adjust hyperparameters to find the best combination of Transformer parameter values.

Scikit-Learn introduced the `Pipeline` module to solve these issues.

### What is a Pipeline

A `Pipeline` is a module in Scikit-Learn that implements the chain of responsibility design pattern.

When creating a Pipeline, we use the `steps` parameter to chain together multiple Transformers for initialization:

    from sklearn.pipeline import Pipeline
    from sklearn.decomposition import PCA
    from sklearn.ensemble import RandomForestClassifier
    
    pipeline = Pipeline(steps=[('scaler', StandardScaler()),
                               ('pca', PCA(n_components=2, random_state=42)),
                               ('estimator', RandomForestClassifier(n_estimators=3, max_depth=5))])

The [official documentation](https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com#pipeline) points out that the last Transformer must be an Estimator.

If you don't need to specify each Transformer's name, you can simplify the creation of a Pipeline with `make_pipeline`:

    from sklearn.pipeline import make_pipeline
    
    pipeline_2 = make_pipeline(StandardScaler(),
                               PCA(n_components=2, random_state=42),
                               RandomForestClassifier(n_estimators=3, max_depth=5))

 Understanding the Pipeline's mechanism from the source code

We've mentioned the importance of not letting test data variables leak into training data when using each Transformer.

This principle is relatively easy to ensure when each data preprocessing step is independent.

But what if we integrate these steps using a Pipeline?

If we look at the [official documentation](https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com#pipeline), we find it simply uses the fit  
 method on the entire dataset without explaining how to handle train and test data separately.

With this question in mind, I dived into the Pipeline's source code to find the answer.

Reading the source code revealed that although Pipeline implements `fit`, `fit_transform`, and `predict` methods, they work differently from regular Transformers.

Take the following Pipeline creation process as an example:

    from sklearn.pipeline import Pipeline
    from sklearn.decomposition import PCA
    from sklearn.ensemble import RandomForestClassifier
    
    pipeline = Pipeline(steps=[('scaler', StandardScaler()),
                               ('pca', PCA(n_components=2, random_state=42)),
                               ('estimator', RandomForestClassifier(n_estimators=3, max_depth=5))])

 The internal implementation can be represented by the following diagram: 

[ Internal implementation of the fit and predict methods when called. Image by Author ](https://preview.redd.it/okhwyg75gl7c1.png?width=684&amp;format=png&amp;auto=webp&amp;s=8106360fcaeb17deea2adf04fc34228dd31a9fd7)

As you can see, when we call the `fit` method, Pipeline first separates Transformers from the Estimator.

For each Transformer, Pipeline checks if there's a `fit_transform` method; if so, it calls it; otherwise, it calls `fit`.

For the Estimator, it calls `fit` directly.

For the `predict` method, Pipeline separates Transformers from the Estimator.

Pipeline calls each Transformer's `transform` method in sequence, followed by the Estimator's `predict`  
 method.

Therefore, when using a Pipeline, we still need to split train and test data. Then we simply call `fit` on the train data and `predict` on the test data.

There's a special case when combining Pipeline with `GridSearchCV` for hyperparameter tuning: you don't need to manually split train and test data. I'll explain this in more detail in the best practices section.

## Best Practices for Using Transformers and Pipeline in Actual Applications

Now that we've discussed the working principles of Transformers and Pipeline, it's time to fulfill the promise made in the title and talk about the best practices when combining Transformers with Pipeline in real projects.

### Combining Pipeline with GridSearchCV for hyperparameter tuning

In a machine learning project, selecting the right dataset processing and algorithm is one aspect. After debugging the initial steps, it's time for parameter optimization.

Using `GridSearchCV` or `RandomizedSearchCV`, you can try different parameters for the Estimator to find the best fit:

    import time
    
    from sklearn.model_selection import GridSearchCV
    
    pipeline = Pipeline(steps=[('scaler', StandardScaler()),
                               ('pca', PCA()),
                               ('estimator', RandomForestClassifier())])
    param_grid = {'pca__n_components': [2, 'mle'],
                  'estimator__n_estimators': [3, 5, 7],
                  'estimator__max_depth': [3, 5]}
    
    start = time.perf_counter()
    clf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)
    clf.fit(X, y)
    
    # It takes 2.39 seconds to finish the search on my laptop.
    print(f""It takes {time.perf_counter() - start} seconds to finish the search."")

 But in machine learning, hyperparameter tuning is not limited to Estimator parameters; it also involves combinations of Transformer parameters.

Integrating all steps with Pipeline allows for hyperparameter tuning of every element with different parameter combinations.

Note that during hyperparameter tuning, we no longer need to manually split train and test data. `GridSearchCV` will split the data into training and validation sets using [StratifiedKFold](https://scikit-learn.org/stable/modules/cross_validation.html?ref=dataleadsfuture.com#stratified-k-fold), which implemented a k-fold cross validation mechanism.

[ StratifiedKFold iterative process of splitting train data and test data. Image by Author ](https://preview.redd.it/uqnuo8fpgl7c1.png?width=681&amp;format=png&amp;auto=webp&amp;s=bd6b5f7edb2d4f5e71786fd6c0f45745ea2095d9)

 We can also set the number of folds for cross-validation and choose how many workers to use. The tuning process is illustrated in the following diagram: 

[ Internal implementation of GridSearchCV hyperparameter tuning. Image by Author ](https://preview.redd.it/piqqv9nrgl7c1.png?width=699&amp;format=png&amp;auto=webp&amp;s=1bb2a2d4739e8100e71559fb9f9e0cfaa4846803)

 Due to space constraints, I won't go into detail about `GridSearchCV` and `RandomizedSearchCV` here. If you're interested, I can write another article explaining them next time. 

### Using the memory parameter to cache Transformer outputs

Of course, hyperparameter tuning with `GridSearchCV` can be slow, but that's no worry, Pipeline provides a caching mechanism to speed up the tuning efficiency by caching the results of intermediate steps.

When initializing a Pipeline, you can pass in a memory parameter, which will cache the results after the first call to `fit` and `transform` for each transformer.

If subsequent calls to fit and `transform` use the same parameters, which is very likely during hyperparameter tuning, these steps will directly read the results from the cache instead of recalculating, significantly speeding up the efficiency when running the same Transformer repeatedly.

The `memory` parameter can accept the following values:

* The default is None: caching is not used.
* A string: providing a path to store the cached results.
* A `joblib.Memory` object: allows for finer-grained control, such as configuring the storage backend for the cache.

Next, let's use the previous `GridSearchCV` example, this time adding `memory` to the Pipeline to see how much speed can be improved:

    pipeline_m = Pipeline(steps=[('scaler', StandardScaler()),
                               ('pca', PCA()),
                               ('estimator', RandomForestClassifier())],
                          memory='./cache')
    start = time.perf_counter()
    clf_m = GridSearchCV(pipeline_m, param_grid=param_grid, cv=5, n_jobs=4)
    clf_m.fit(X, y)
    
    # It takes 0.22 seconds to finish the search with memory parameter.
    print(f""It takes {time.perf_counter() - start} seconds to finish the search with memory."")

As shown, with caching, the tuning process only takes 0.2 seconds, a significant speed increase from the previous 2.4 seconds.

### How to debug Scikit-Learn Pipeline

After integrating Transformers into a Pipeline, the entire preprocessing and transformation process becomes a black box. It can be difficult to understand which step the process is currently on.

Fortunately, we can solve this problem by adding logging to the Pipeline.  
We need to create custom transformers to add logging at each step of data transformation.

Here's an example of adding logging with Python's standard logging library:

First, you need to configure a logger:

    import logging
    
    from sklearn.base import BaseEstimator, TransformerMixin
    
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger()

 Next, you can create a custom Transformer and add logging within its methods: 

    class LoggingTransformer(BaseEstimator, TransformerMixin):
        def __init__(self, transformer):
            self.transformer = transformer
            self.real_name = self.transformer.__class__.__name__
    
        def fit(self, X, y=None):
            logging.info(f""Begin fit: {self.real_name}"")
            self.transformer.fit(X, y)
            logging.info(f""End fit: {self.real_name}"")
            return self
    
        def fit_transform(self, X, y=None):
            logging.info(f""Begin fit_transform: {self.real_name}"")
            X_fit_transformed = self.transformer.fit_transform(X, y)
            logging.info(f""End fit_transform: {self.real_name}"")
            return X_fit_transformed
    
        def transform(self, X):
            logging.info(f""Begin transform: {self.real_name}"")
            X_transformed = self.transformer.transform(X)
            logging.info(f""End transform: {self.real_name}"")
            return X_transformed

 Then you can use this `LoggingTransformer` when creating your Pipeline: 

    pipeline_logging = Pipeline(steps=[('scaler', LoggingTransformer(StandardScaler())),
                                 ('pca', LoggingTransformer(PCA(n_components=2))),
                                 ('estimator', RandomForestClassifier(n_estimators=5, max_depth=3))])
    pipeline_logging.fit(X_train, y_train)

[ The effect after adding the LoggingTransformer. Image by Author ](https://preview.redd.it/53kl3padhl7c1.png?width=664&amp;format=png&amp;auto=webp&amp;s=a3e3d9dcf25f0ee8dc7234e1db9280ce1cd15b0d)

When you use `pipeline.fit`, it will call the `fit` and `transform` methods for each step in turn and log the appropriate messages.

### Use passthrough in Scikit-Learn Pipeline

In a Pipeline, a step can be set to `'passthrough`', which means that for this specific step, the input data will pass through unchanged to the next step.

This is useful when you want to selectively enable/disable certain steps in a complex pipeline.

Taking the code example above, we know that when using `DecisionTree` or `RandomForest`, standardizing the data is unnecessary, so we can use `passthrough` to skip this step.

An example would be as follows:

    param_grid = {'scaler': ['passthrough'],
                  'pca__n_components': [2, 'mle'],
                  'estimator__n_estimators': [3, 5, 7],
                  'estimator__max_depth': [3, 5]}
    clf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)
    clf.fit(X, y)

 Reusing the Pipeline

After a journey of trials and tribulations, we finally have a well-performing machine learning model.

Now, you might consider how to reuse this model, share it with colleagues, or deploy it in a production environment.

However, the result of a model's training includes not only the model itself but also the various data processing steps, which all need to be saved.

Using `joblib` and Pipeline, we can save the entire training process for later use. The following code provides a simple example:

    from joblib import dump, load
    
    # save pipeline
    dump(pipeline, 'model_pipeline.joblib')
    
    # load pipeline
    loaded_pipeline = load('model_pipeline.joblib')
    
    # predict with loaded pipeline
    loaded_predictions = loaded_pipeline.predict(X_test)

 This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/ensuring-correct-use-of-transformers-in-scikit-learn-pipeline/) 

&amp;#x200B;",t2_9r8ft2a0,False,,0,False,How to correctly use sklearn Transformers in a Pipeline,[],r/datascience,False,6,,0,50.0,,False,t3_18ngsgv,False,dark,0.94,,public,95,0,{},140.0,,False,[],,False,False,,{},Coding,False,95,,False,False,https://b.thumbs.redditmedia.com/R6xMJtVPodH3aN_i-OC2a0zZZJv0utQLFd8yB5_cBeU.jpg,False,,[],{},,True,,1703141418.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This article will explain how to use &lt;a href=""https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com""&gt;Pipeline&lt;/a&gt; and &lt;a href=""https://scikit-learn.org/stable/data_transforms.html?ref=dataleadsfuture.com""&gt;Transformers&lt;/a&gt; correctly in Scikit-Learn (sklearn) projects to speed up and reuse our model training process.&lt;/p&gt;

&lt;p&gt;This piece complements and clarifies the official documentation on Pipeline examples and some common misunderstandings.&lt;/p&gt;

&lt;p&gt;I hope that after reading this, you&amp;#39;ll be able to use the Pipeline, an excellent design, to better complete your machine learning tasks.&lt;/p&gt;

&lt;p&gt;This article was originally published on my personal blog &lt;a href=""https://www.dataleadsfuture.com/ensuring-correct-use-of-transformers-in-scikit-learn-pipeline/""&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;

&lt;h3&gt;Why use a Pipeline&lt;/h3&gt;

&lt;p&gt;As mentioned earlier, in a machine learning task, we often need to use various Transformers for data scaling and feature dimensionality reduction before training a model.&lt;/p&gt;

&lt;p&gt;This presents several challenges:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Code complexity&lt;/strong&gt;: For each use of a Transformer, we have to go through initialization, &lt;code&gt;fit_transform&lt;/code&gt;, and &lt;code&gt;transform&lt;/code&gt; steps. Missing one step during a transformation could derail the entire training process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data leakage&lt;/strong&gt;: As we discussed, for each Transformer, we fit with train data and then transform both train and test data. We must avoid letting the distribution of the test data leak into the train data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code reusability&lt;/strong&gt;: A machine learning model includes not only the trained Estimator for prediction but also the data preprocessing steps. Therefore, a machine learning task comprising Transformers and an Estimator should be atomic and indivisible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hyperparameter tuning&lt;/strong&gt;: After setting up the steps of machine learning, we need to adjust hyperparameters to find the best combination of Transformer parameter values.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Scikit-Learn introduced the &lt;code&gt;Pipeline&lt;/code&gt; module to solve these issues.&lt;/p&gt;

&lt;h3&gt;What is a Pipeline&lt;/h3&gt;

&lt;p&gt;A &lt;code&gt;Pipeline&lt;/code&gt; is a module in Scikit-Learn that implements the chain of responsibility design pattern.&lt;/p&gt;

&lt;p&gt;When creating a Pipeline, we use the &lt;code&gt;steps&lt;/code&gt; parameter to chain together multiple Transformers for initialization:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

pipeline = Pipeline(steps=[(&amp;#39;scaler&amp;#39;, StandardScaler()),
                           (&amp;#39;pca&amp;#39;, PCA(n_components=2, random_state=42)),
                           (&amp;#39;estimator&amp;#39;, RandomForestClassifier(n_estimators=3, max_depth=5))])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=""https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com#pipeline""&gt;official documentation&lt;/a&gt; points out that the last Transformer must be an Estimator.&lt;/p&gt;

&lt;p&gt;If you don&amp;#39;t need to specify each Transformer&amp;#39;s name, you can simplify the creation of a Pipeline with &lt;code&gt;make_pipeline&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.pipeline import make_pipeline

pipeline_2 = make_pipeline(StandardScaler(),
                           PCA(n_components=2, random_state=42),
                           RandomForestClassifier(n_estimators=3, max_depth=5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Understanding the Pipeline&amp;#39;s mechanism from the source code&lt;/p&gt;

&lt;p&gt;We&amp;#39;ve mentioned the importance of not letting test data variables leak into training data when using each Transformer.&lt;/p&gt;

&lt;p&gt;This principle is relatively easy to ensure when each data preprocessing step is independent.&lt;/p&gt;

&lt;p&gt;But what if we integrate these steps using a Pipeline?&lt;/p&gt;

&lt;p&gt;If we look at the &lt;a href=""https://scikit-learn.org/stable/modules/compose.html?ref=dataleadsfuture.com#pipeline""&gt;official documentation&lt;/a&gt;, we find it simply uses the fit&lt;br/&gt;
 method on the entire dataset without explaining how to handle train and test data separately.&lt;/p&gt;

&lt;p&gt;With this question in mind, I dived into the Pipeline&amp;#39;s source code to find the answer.&lt;/p&gt;

&lt;p&gt;Reading the source code revealed that although Pipeline implements &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;fit_transform&lt;/code&gt;, and &lt;code&gt;predict&lt;/code&gt; methods, they work differently from regular Transformers.&lt;/p&gt;

&lt;p&gt;Take the following Pipeline creation process as an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

pipeline = Pipeline(steps=[(&amp;#39;scaler&amp;#39;, StandardScaler()),
                           (&amp;#39;pca&amp;#39;, PCA(n_components=2, random_state=42)),
                           (&amp;#39;estimator&amp;#39;, RandomForestClassifier(n_estimators=3, max_depth=5))])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The internal implementation can be represented by the following diagram: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/okhwyg75gl7c1.png?width=684&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8106360fcaeb17deea2adf04fc34228dd31a9fd7""&gt; Internal implementation of the fit and predict methods when called. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see, when we call the &lt;code&gt;fit&lt;/code&gt; method, Pipeline first separates Transformers from the Estimator.&lt;/p&gt;

&lt;p&gt;For each Transformer, Pipeline checks if there&amp;#39;s a &lt;code&gt;fit_transform&lt;/code&gt; method; if so, it calls it; otherwise, it calls &lt;code&gt;fit&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For the Estimator, it calls &lt;code&gt;fit&lt;/code&gt; directly.&lt;/p&gt;

&lt;p&gt;For the &lt;code&gt;predict&lt;/code&gt; method, Pipeline separates Transformers from the Estimator.&lt;/p&gt;

&lt;p&gt;Pipeline calls each Transformer&amp;#39;s &lt;code&gt;transform&lt;/code&gt; method in sequence, followed by the Estimator&amp;#39;s &lt;code&gt;predict&lt;/code&gt;&lt;br/&gt;
 method.&lt;/p&gt;

&lt;p&gt;Therefore, when using a Pipeline, we still need to split train and test data. Then we simply call &lt;code&gt;fit&lt;/code&gt; on the train data and &lt;code&gt;predict&lt;/code&gt; on the test data.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s a special case when combining Pipeline with &lt;code&gt;GridSearchCV&lt;/code&gt; for hyperparameter tuning: you don&amp;#39;t need to manually split train and test data. I&amp;#39;ll explain this in more detail in the best practices section.&lt;/p&gt;

&lt;h2&gt;Best Practices for Using Transformers and Pipeline in Actual Applications&lt;/h2&gt;

&lt;p&gt;Now that we&amp;#39;ve discussed the working principles of Transformers and Pipeline, it&amp;#39;s time to fulfill the promise made in the title and talk about the best practices when combining Transformers with Pipeline in real projects.&lt;/p&gt;

&lt;h3&gt;Combining Pipeline with GridSearchCV for hyperparameter tuning&lt;/h3&gt;

&lt;p&gt;In a machine learning project, selecting the right dataset processing and algorithm is one aspect. After debugging the initial steps, it&amp;#39;s time for parameter optimization.&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;GridSearchCV&lt;/code&gt; or &lt;code&gt;RandomizedSearchCV&lt;/code&gt;, you can try different parameters for the Estimator to find the best fit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import time

from sklearn.model_selection import GridSearchCV

pipeline = Pipeline(steps=[(&amp;#39;scaler&amp;#39;, StandardScaler()),
                           (&amp;#39;pca&amp;#39;, PCA()),
                           (&amp;#39;estimator&amp;#39;, RandomForestClassifier())])
param_grid = {&amp;#39;pca__n_components&amp;#39;: [2, &amp;#39;mle&amp;#39;],
              &amp;#39;estimator__n_estimators&amp;#39;: [3, 5, 7],
              &amp;#39;estimator__max_depth&amp;#39;: [3, 5]}

start = time.perf_counter()
clf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)
clf.fit(X, y)

# It takes 2.39 seconds to finish the search on my laptop.
print(f&amp;quot;It takes {time.perf_counter() - start} seconds to finish the search.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But in machine learning, hyperparameter tuning is not limited to Estimator parameters; it also involves combinations of Transformer parameters.&lt;/p&gt;

&lt;p&gt;Integrating all steps with Pipeline allows for hyperparameter tuning of every element with different parameter combinations.&lt;/p&gt;

&lt;p&gt;Note that during hyperparameter tuning, we no longer need to manually split train and test data. &lt;code&gt;GridSearchCV&lt;/code&gt; will split the data into training and validation sets using &lt;a href=""https://scikit-learn.org/stable/modules/cross_validation.html?ref=dataleadsfuture.com#stratified-k-fold""&gt;StratifiedKFold&lt;/a&gt;, which implemented a k-fold cross validation mechanism.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/uqnuo8fpgl7c1.png?width=681&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bd6b5f7edb2d4f5e71786fd6c0f45745ea2095d9""&gt; StratifiedKFold iterative process of splitting train data and test data. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We can also set the number of folds for cross-validation and choose how many workers to use. The tuning process is illustrated in the following diagram: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/piqqv9nrgl7c1.png?width=699&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1bb2a2d4739e8100e71559fb9f9e0cfaa4846803""&gt; Internal implementation of GridSearchCV hyperparameter tuning. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Due to space constraints, I won&amp;#39;t go into detail about &lt;code&gt;GridSearchCV&lt;/code&gt; and &lt;code&gt;RandomizedSearchCV&lt;/code&gt; here. If you&amp;#39;re interested, I can write another article explaining them next time. &lt;/p&gt;

&lt;h3&gt;Using the memory parameter to cache Transformer outputs&lt;/h3&gt;

&lt;p&gt;Of course, hyperparameter tuning with &lt;code&gt;GridSearchCV&lt;/code&gt; can be slow, but that&amp;#39;s no worry, Pipeline provides a caching mechanism to speed up the tuning efficiency by caching the results of intermediate steps.&lt;/p&gt;

&lt;p&gt;When initializing a Pipeline, you can pass in a memory parameter, which will cache the results after the first call to &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; for each transformer.&lt;/p&gt;

&lt;p&gt;If subsequent calls to fit and &lt;code&gt;transform&lt;/code&gt; use the same parameters, which is very likely during hyperparameter tuning, these steps will directly read the results from the cache instead of recalculating, significantly speeding up the efficiency when running the same Transformer repeatedly.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;memory&lt;/code&gt; parameter can accept the following values:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The default is None: caching is not used.&lt;/li&gt;
&lt;li&gt;A string: providing a path to store the cached results.&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;joblib.Memory&lt;/code&gt; object: allows for finer-grained control, such as configuring the storage backend for the cache.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, let&amp;#39;s use the previous &lt;code&gt;GridSearchCV&lt;/code&gt; example, this time adding &lt;code&gt;memory&lt;/code&gt; to the Pipeline to see how much speed can be improved:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pipeline_m = Pipeline(steps=[(&amp;#39;scaler&amp;#39;, StandardScaler()),
                           (&amp;#39;pca&amp;#39;, PCA()),
                           (&amp;#39;estimator&amp;#39;, RandomForestClassifier())],
                      memory=&amp;#39;./cache&amp;#39;)
start = time.perf_counter()
clf_m = GridSearchCV(pipeline_m, param_grid=param_grid, cv=5, n_jobs=4)
clf_m.fit(X, y)

# It takes 0.22 seconds to finish the search with memory parameter.
print(f&amp;quot;It takes {time.perf_counter() - start} seconds to finish the search with memory.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As shown, with caching, the tuning process only takes 0.2 seconds, a significant speed increase from the previous 2.4 seconds.&lt;/p&gt;

&lt;h3&gt;How to debug Scikit-Learn Pipeline&lt;/h3&gt;

&lt;p&gt;After integrating Transformers into a Pipeline, the entire preprocessing and transformation process becomes a black box. It can be difficult to understand which step the process is currently on.&lt;/p&gt;

&lt;p&gt;Fortunately, we can solve this problem by adding logging to the Pipeline.&lt;br/&gt;
We need to create custom transformers to add logging at each step of data transformation.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s an example of adding logging with Python&amp;#39;s standard logging library:&lt;/p&gt;

&lt;p&gt;First, you need to configure a logger:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import logging

from sklearn.base import BaseEstimator, TransformerMixin

logging.basicConfig(level=logging.INFO, format=&amp;#39;%(asctime)s - %(levelname)s - %(message)s&amp;#39;)
logger = logging.getLogger()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, you can create a custom Transformer and add logging within its methods: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class LoggingTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, transformer):
        self.transformer = transformer
        self.real_name = self.transformer.__class__.__name__

    def fit(self, X, y=None):
        logging.info(f&amp;quot;Begin fit: {self.real_name}&amp;quot;)
        self.transformer.fit(X, y)
        logging.info(f&amp;quot;End fit: {self.real_name}&amp;quot;)
        return self

    def fit_transform(self, X, y=None):
        logging.info(f&amp;quot;Begin fit_transform: {self.real_name}&amp;quot;)
        X_fit_transformed = self.transformer.fit_transform(X, y)
        logging.info(f&amp;quot;End fit_transform: {self.real_name}&amp;quot;)
        return X_fit_transformed

    def transform(self, X):
        logging.info(f&amp;quot;Begin transform: {self.real_name}&amp;quot;)
        X_transformed = self.transformer.transform(X)
        logging.info(f&amp;quot;End transform: {self.real_name}&amp;quot;)
        return X_transformed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you can use this &lt;code&gt;LoggingTransformer&lt;/code&gt; when creating your Pipeline: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pipeline_logging = Pipeline(steps=[(&amp;#39;scaler&amp;#39;, LoggingTransformer(StandardScaler())),
                             (&amp;#39;pca&amp;#39;, LoggingTransformer(PCA(n_components=2))),
                             (&amp;#39;estimator&amp;#39;, RandomForestClassifier(n_estimators=5, max_depth=3))])
pipeline_logging.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/53kl3padhl7c1.png?width=664&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3e3d9dcf25f0ee8dc7234e1db9280ce1cd15b0d""&gt; The effect after adding the LoggingTransformer. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When you use &lt;code&gt;pipeline.fit&lt;/code&gt;, it will call the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; methods for each step in turn and log the appropriate messages.&lt;/p&gt;

&lt;h3&gt;Use passthrough in Scikit-Learn Pipeline&lt;/h3&gt;

&lt;p&gt;In a Pipeline, a step can be set to &lt;code&gt;&amp;#39;passthrough&lt;/code&gt;&amp;#39;, which means that for this specific step, the input data will pass through unchanged to the next step.&lt;/p&gt;

&lt;p&gt;This is useful when you want to selectively enable/disable certain steps in a complex pipeline.&lt;/p&gt;

&lt;p&gt;Taking the code example above, we know that when using &lt;code&gt;DecisionTree&lt;/code&gt; or &lt;code&gt;RandomForest&lt;/code&gt;, standardizing the data is unnecessary, so we can use &lt;code&gt;passthrough&lt;/code&gt; to skip this step.&lt;/p&gt;

&lt;p&gt;An example would be as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;param_grid = {&amp;#39;scaler&amp;#39;: [&amp;#39;passthrough&amp;#39;],
              &amp;#39;pca__n_components&amp;#39;: [2, &amp;#39;mle&amp;#39;],
              &amp;#39;estimator__n_estimators&amp;#39;: [3, 5, 7],
              &amp;#39;estimator__max_depth&amp;#39;: [3, 5]}
clf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)
clf.fit(X, y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reusing the Pipeline&lt;/p&gt;

&lt;p&gt;After a journey of trials and tribulations, we finally have a well-performing machine learning model.&lt;/p&gt;

&lt;p&gt;Now, you might consider how to reuse this model, share it with colleagues, or deploy it in a production environment.&lt;/p&gt;

&lt;p&gt;However, the result of a model&amp;#39;s training includes not only the model itself but also the various data processing steps, which all need to be saved.&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;joblib&lt;/code&gt; and Pipeline, we can save the entire training process for later use. The following code provides a simple example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from joblib import dump, load

# save pipeline
dump(pipeline, &amp;#39;model_pipeline.joblib&amp;#39;)

# load pipeline
loaded_pipeline = load(&amp;#39;model_pipeline.joblib&amp;#39;)

# predict with loaded pipeline
loaded_predictions = loaded_pipeline.predict(X_test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This article was originally published on my personal blog &lt;a href=""https://www.dataleadsfuture.com/ensuring-correct-use-of-transformers-in-scikit-learn-pipeline/""&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,18ngsgv,True,,qtalen,,31,True,all_ads,False,[],False,,/r/datascience/comments/18ngsgv/how_to_correctly_use_sklearn_transformers_in_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ngsgv/how_to_correctly_use_sklearn_transformers_in_a/,1209065,1703141418.0,0,,False,"{'piqqv9nrgl7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 97, 'x': 108, 'u': 'https://preview.redd.it/piqqv9nrgl7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc712dc1ff6400f697a3881d51f8d3570f829238'}, {'y': 194, 'x': 216, 'u': 'https://preview.redd.it/piqqv9nrgl7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c3a36b89acd98a75d521128b625e47005add048a'}, {'y': 288, 'x': 320, 'u': 'https://preview.redd.it/piqqv9nrgl7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=03780e7cf2e0d41698ce9f4e0ce50d301171ebb0'}, {'y': 577, 'x': 640, 'u': 'https://preview.redd.it/piqqv9nrgl7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f33f9a7028cf3468f80742501736390b58e76681'}], 's': {'y': 631, 'x': 699, 'u': 'https://preview.redd.it/piqqv9nrgl7c1.png?width=699&amp;format=png&amp;auto=webp&amp;s=1bb2a2d4739e8100e71559fb9f9e0cfaa4846803'}, 'id': 'piqqv9nrgl7c1'}, 'uqnuo8fpgl7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 54, 'x': 108, 'u': 'https://preview.redd.it/uqnuo8fpgl7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1b370e612070428374a207b597a92aff82d8a147'}, {'y': 108, 'x': 216, 'u': 'https://preview.redd.it/uqnuo8fpgl7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94c2adf95ce18b60f16bc2cc8abc2a6c14563d8f'}, {'y': 160, 'x': 320, 'u': 'https://preview.redd.it/uqnuo8fpgl7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=84db99e434cb5e4d32032a6ae0d7446b5193e10a'}, {'y': 320, 'x': 640, 'u': 'https://preview.redd.it/uqnuo8fpgl7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad714328a71791ed1f8ded1f1e5f63e03f1ccbaa'}], 's': {'y': 341, 'x': 681, 'u': 'https://preview.redd.it/uqnuo8fpgl7c1.png?width=681&amp;format=png&amp;auto=webp&amp;s=bd6b5f7edb2d4f5e71786fd6c0f45745ea2095d9'}, 'id': 'uqnuo8fpgl7c1'}, 'okhwyg75gl7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/okhwyg75gl7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a3723b91df001b47a713b573280c2632814bff9'}, {'y': 132, 'x': 216, 'u': 'https://preview.redd.it/okhwyg75gl7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=318fb9cf0ea6f735eaa74c3ee9f46c0a1a31d5d1'}, {'y': 196, 'x': 320, 'u': 'https://preview.redd.it/okhwyg75gl7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8a9cd4c403b9f61f1ee9176cdfdb693a946dbe2b'}, {'y': 393, 'x': 640, 'u': 'https://preview.redd.it/okhwyg75gl7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1eac9f48da6a1da4c9a130d67dbc6580769e103e'}], 's': {'y': 421, 'x': 684, 'u': 'https://preview.redd.it/okhwyg75gl7c1.png?width=684&amp;format=png&amp;auto=webp&amp;s=8106360fcaeb17deea2adf04fc34228dd31a9fd7'}, 'id': 'okhwyg75gl7c1'}, '53kl3padhl7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/53kl3padhl7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ccc85545041b723d70529bd68170283417122e9'}, {'y': 126, 'x': 216, 'u': 'https://preview.redd.it/53kl3padhl7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd832e4183f64bc5cb636ae98f3cf166d672ded4'}, {'y': 187, 'x': 320, 'u': 'https://preview.redd.it/53kl3padhl7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b39ac233ad51443069ed58202070dc9749e37e96'}, {'y': 375, 'x': 640, 'u': 'https://preview.redd.it/53kl3padhl7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dc09cc5b6c6fc6fd89507b8a1fbef3e85099e61'}], 's': {'y': 390, 'x': 664, 'u': 'https://preview.redd.it/53kl3padhl7c1.png?width=664&amp;format=png&amp;auto=webp&amp;s=a3e3d9dcf25f0ee8dc7234e1db9280ce1cd15b0d'}, 'id': '53kl3padhl7c1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3QeLrvmrkTlith0rWod1RvJb84uIyQ_ooxhR4GAxxyk.jpg?auto=webp&amp;s=0898caa546f8aacdf897f436bb227a3544bf2c83', 'width': 160, 'height': 58}, 'resolutions': [{'url': 'https://external-preview.redd.it/3QeLrvmrkTlith0rWod1RvJb84uIyQ_ooxhR4GAxxyk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54fa7103ac1fa7c5fa4f7488aed2f8f183533aa7', 'width': 108, 'height': 39}], 'variants': {}, 'id': 'aRDTtkw0_GBCGb9E7JLBzDXeEp2pWa53pBC0AILtbPw'}], 'enabled': False}",,,,,,,14363,1636
,datascience,"Hey data science people, 

I've been a data scientist now for several years, and am currently in somewhat of a leadership position. I work for a smaller company, for which I was their very first data scientist. Overall, I'd describe my situation as somewhat of a massive double-edged sword. I've developed all their infrastructure and have really set the scope of data science at the organization. This last year, I started a push into actual data products. In that sense, it's been very rewarding getting to experience multiple hats, mostly be my own boss, and to be able to create something across not only the modeling side, but also the infrastructure and product management sides. 

That said, the other side of the sword is all that comes with being the first data scientist at a smaller organization. The being a one-man startup within a company thing can definitely be a fair amount of exhausting and isolating. Hiring other positions itself has been very tricky. Company buy-in has been a weird mix... they definitely make me feel heavily valued, and I'm not afraid of losing my job. The last presentation I gave, the COO was practically salivating. Yet, I also feel like they haven't committed too much buy-in to data science in general. I've told my boss repeatedly how it all can feel really tenuous. Even scheduling meetings to go over data science success with various company stakeholders, feels like they really have to fit it in. 

With all that said, my boss has for a long time been very interested in scaling up data science at the organization. He recently informally offered me a title bump up to Director of Data Science, and I'm considering it. I've also been thinking about changing companies to experience how others do it, or else taking somewhat of a sabbatical to think out the next stage of my life, what direction I want to go in. Overall I'm torn about the limitations of my current company... had originally gotten into data science to do NLP, and now that LLMs are taking off, I feel like I'm falling farther and farther away from that working here. I'm also wondering on whether it would be smart to take on a director role from the first company I started my ds career with. I'm a little worried I would get shoehorned from now on into director roles, when I'm not sure I'm ready to give up a more raw position. That said, my company has overall treated me well, and it IS a director role, which essentially I'm already doing. 

So yeah, overall I think taking the director role would be an interesting experience and might play into my underlying motivations around creativity, BUT I'm also wary of the limitations of my own company in the field, and whether it overall aligns with my interests in things like LLMs. 

What do you guys think? :) ",t2_q91gszwod,False,,0,False,Taking a Director of Data Science Position from First Company,[],r/datascience,False,6,fun,0,,,False,t3_18nfk9b,False,dark,0.84,,public,9,0,{},,,False,[],,False,False,,{},Career Discussion,False,9,,False,False,self,False,,[],{},,True,,1703137081.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey data science people, &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been a data scientist now for several years, and am currently in somewhat of a leadership position. I work for a smaller company, for which I was their very first data scientist. Overall, I&amp;#39;d describe my situation as somewhat of a massive double-edged sword. I&amp;#39;ve developed all their infrastructure and have really set the scope of data science at the organization. This last year, I started a push into actual data products. In that sense, it&amp;#39;s been very rewarding getting to experience multiple hats, mostly be my own boss, and to be able to create something across not only the modeling side, but also the infrastructure and product management sides. &lt;/p&gt;

&lt;p&gt;That said, the other side of the sword is all that comes with being the first data scientist at a smaller organization. The being a one-man startup within a company thing can definitely be a fair amount of exhausting and isolating. Hiring other positions itself has been very tricky. Company buy-in has been a weird mix... they definitely make me feel heavily valued, and I&amp;#39;m not afraid of losing my job. The last presentation I gave, the COO was practically salivating. Yet, I also feel like they haven&amp;#39;t committed too much buy-in to data science in general. I&amp;#39;ve told my boss repeatedly how it all can feel really tenuous. Even scheduling meetings to go over data science success with various company stakeholders, feels like they really have to fit it in. &lt;/p&gt;

&lt;p&gt;With all that said, my boss has for a long time been very interested in scaling up data science at the organization. He recently informally offered me a title bump up to Director of Data Science, and I&amp;#39;m considering it. I&amp;#39;ve also been thinking about changing companies to experience how others do it, or else taking somewhat of a sabbatical to think out the next stage of my life, what direction I want to go in. Overall I&amp;#39;m torn about the limitations of my current company... had originally gotten into data science to do NLP, and now that LLMs are taking off, I feel like I&amp;#39;m falling farther and farther away from that working here. I&amp;#39;m also wondering on whether it would be smart to take on a director role from the first company I started my ds career with. I&amp;#39;m a little worried I would get shoehorned from now on into director roles, when I&amp;#39;m not sure I&amp;#39;m ready to give up a more raw position. That said, my company has overall treated me well, and it IS a director role, which essentially I&amp;#39;m already doing. &lt;/p&gt;

&lt;p&gt;So yeah, overall I think taking the director role would be an interesting experience and might play into my underlying motivations around creativity, BUT I&amp;#39;m also wary of the limitations of my own company in the field, and whether it overall aligns with my interests in things like LLMs. &lt;/p&gt;

&lt;p&gt;What do you guys think? :) &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18nfk9b,True,,dsthrowaway1337,,16,True,all_ads,False,[],False,,/r/datascience/comments/18nfk9b/taking_a_director_of_data_science_position_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/18nfk9b/taking_a_director_of_data_science_position_from/,1209065,1703137081.0,0,,False,,,,,,,,,,2782,488
,datascience,"Hi. I have the opportunity to define my own data role at a very very large company. I'm currently a Sr. DS and I manage a team at a startup. This seems like a trick - the company is tech and data heavy and they have data scientists on staff, in abundance - *I'm* not that great.    

 Is this a **trap**? ",t2_4ciy3,False,,0,False,"Advice needed, (not a humble brag, I swear)",[],r/datascience,False,6,fun,0,,,False,t3_18nccs1,False,dark,0.32,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,True,self,False,,[],{},,True,,1703126609.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I have the opportunity to define my own data role at a very very large company. I&amp;#39;m currently a Sr. DS and I manage a team at a startup. This seems like a trick - the company is tech and data heavy and they have data scientists on staff, in abundance - &lt;em&gt;I&amp;#39;m&lt;/em&gt; not that great.    &lt;/p&gt;

&lt;p&gt;Is this a &lt;strong&gt;trap&lt;/strong&gt;? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18nccs1,True,,tmotytmoty,,22,True,all_ads,False,[],False,,/r/datascience/comments/18nccs1/advice_needed_not_a_humble_brag_i_swear/,all_ads,False,https://www.reddit.com/r/datascience/comments/18nccs1/advice_needed_not_a_humble_brag_i_swear/,1209065,1703126609.0,0,,False,,,,,,,,,,305,61
,datascience,"UPDATE TO TITLE: I meant, “heading down the management path.” 

It’s been 6 months since starting a data science management role, and now have been laid off. 

The role was sold as a data science manager, yet ended up doing admin work and touched on very small amounts of actual data science projects. 

I was upset about the role but my boss assured me there were “big things” in the pipeline. 

I got my break and finally took responsibility for a project and coordinated with a team from the US. Things went smoothly, and as a native English speaker (I’m EU based), I sat in on more global meetings. 

Finally, things seemed to take off and work well… until I got fired today. 

The result was: “business wasn’t happy with your results.” (We acted as data science manager consultants for different Business Units within the company). I asked why, the only feedback was a comment about a presentation not working out. 

Business never communicated with me directly, only with my boss. There was a layer of reasoning missing. 

So, here I am: questions unanswered, out of a job, and feel like I’ve missed my chance at DS management. 

I have one week left. What could I best do with this time?

Thanks all :)",,False,,0,False,Just got laid off as I was heading the management path,[],r/datascience,False,6,fun,0,,,False,t3_18natsq,False,dark,0.91,,public,56,0,{},,,False,[],,False,False,,{},Career Discussion,False,56,,False,,self,False,,,{},,True,,1703121843.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;UPDATE TO TITLE: I meant, “heading down the management path.” &lt;/p&gt;

&lt;p&gt;It’s been 6 months since starting a data science management role, and now have been laid off. &lt;/p&gt;

&lt;p&gt;The role was sold as a data science manager, yet ended up doing admin work and touched on very small amounts of actual data science projects. &lt;/p&gt;

&lt;p&gt;I was upset about the role but my boss assured me there were “big things” in the pipeline. &lt;/p&gt;

&lt;p&gt;I got my break and finally took responsibility for a project and coordinated with a team from the US. Things went smoothly, and as a native English speaker (I’m EU based), I sat in on more global meetings. &lt;/p&gt;

&lt;p&gt;Finally, things seemed to take off and work well… until I got fired today. &lt;/p&gt;

&lt;p&gt;The result was: “business wasn’t happy with your results.” (We acted as data science manager consultants for different Business Units within the company). I asked why, the only feedback was a comment about a presentation not working out. &lt;/p&gt;

&lt;p&gt;Business never communicated with me directly, only with my boss. There was a layer of reasoning missing. &lt;/p&gt;

&lt;p&gt;So, here I am: questions unanswered, out of a job, and feel like I’ve missed my chance at DS management. &lt;/p&gt;

&lt;p&gt;I have one week left. What could I best do with this time?&lt;/p&gt;

&lt;p&gt;Thanks all :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18natsq,True,,[deleted],,52,True,all_ads,False,[],,dark,/r/datascience/comments/18natsq/just_got_laid_off_as_i_was_heading_the_management/,all_ads,False,https://www.reddit.com/r/datascience/comments/18natsq/just_got_laid_off_as_i_was_heading_the_management/,1209065,1703121843.0,0,,False,,,,,,,,,,1209,214
,datascience,"Hey all, looking at a career transition out of the implementation side and into the sales / pre-sales side.

Many folks here who are in that space? If so I'd love to ask some questions and get the vibe. I have done quite a bit of the analytics side of DS and been involved in projects to do with Gen AI.

Is this type of thing best left to pure tech sales folks? One of the commonalities I hear is that pure tech sales folks really struggle to understand or sell in the AI/ML space. So I figured I'd look at moving over.",t2_7jjayp3,False,,0,False,Looking at sales,[],r/datascience,False,6,fun,0,,,False,t3_18n9g8m,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1703117702.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all, looking at a career transition out of the implementation side and into the sales / pre-sales side.&lt;/p&gt;

&lt;p&gt;Many folks here who are in that space? If so I&amp;#39;d love to ask some questions and get the vibe. I have done quite a bit of the analytics side of DS and been involved in projects to do with Gen AI.&lt;/p&gt;

&lt;p&gt;Is this type of thing best left to pure tech sales folks? One of the commonalities I hear is that pure tech sales folks really struggle to understand or sell in the AI/ML space. So I figured I&amp;#39;d look at moving over.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18n9g8m,True,,quantpsychguy,,3,True,all_ads,False,[],False,,/r/datascience/comments/18n9g8m/looking_at_sales/,all_ads,False,https://www.reddit.com/r/datascience/comments/18n9g8m/looking_at_sales/,1209065,1703117702.0,0,,False,,,,,,,,,,520,103
,datascience,"I'm doing an excercise for an interview process and I'm no used to working on open source projects so I'm supposed to extract a csv and a Json and do some cleaning. I uploaded the files on a public github repository and did the extraction, cleaning and intial modeling on a jupyter notebook. so far so good.

The next step is to do some SQL queries to analize data but I'm wondering how can I set everything up so that the recruiter will be able to connect and run my queries?

1. Where and how should I output my jupyter created dataframes so that anyone can connect to them 
2. Which software could be used to query the data without having to set up a connection

&amp;#x200B;

Thanks a lot",t2_38po62bx,False,,0,False,Coding Excercise question,[],r/datascience,False,6,meta,0,,,False,t3_18n9928,False,dark,0.81,,public,13,0,{},,,False,[],,False,False,,{},Projects,False,13,,False,False,self,False,,[],{},,True,,1703117107.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m doing an excercise for an interview process and I&amp;#39;m no used to working on open source projects so I&amp;#39;m supposed to extract a csv and a Json and do some cleaning. I uploaded the files on a public github repository and did the extraction, cleaning and intial modeling on a jupyter notebook. so far so good.&lt;/p&gt;

&lt;p&gt;The next step is to do some SQL queries to analize data but I&amp;#39;m wondering how can I set everything up so that the recruiter will be able to connect and run my queries?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Where and how should I output my jupyter created dataframes so that anyone can connect to them &lt;/li&gt;
&lt;li&gt;Which software could be used to query the data without having to set up a connection&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks a lot&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18n9928,True,,Esteban_Rdz,,8,True,all_ads,False,[],False,,/r/datascience/comments/18n9928/coding_excercise_question/,all_ads,False,https://www.reddit.com/r/datascience/comments/18n9928/coding_excercise_question/,1209065,1703117107.0,0,,False,,,,,,,,,,692,130
,datascience,"Title says it all: why SQLAlchemy over traditional SQL?

edit: did not realize I would get so much backlash for asking a question. I am great with SQL, was recently introed to SQLAlchemy, and was pretty much like… why? I kinda see if you’re querying multiple different kinds of databases that are all similar enough to use the same structure it would be useful…(I.e different hosts for databases that act as repos for same software family), but I struggle to understand how this could possibly be better or easier than just using SQL to the point where it seems like instead of teaching SQL a class would teach SQLAlchemy.  SQL is one of the easiest most human readable languages in the world, arguably even more so than python(definitely less versatile than it).  The point of using your own SQL is only with it can you truly make accommodations for the database structure and calculation schedules.  I get that you can write SQL in SQLAlchemy if called for, but that just makes it seem like an extra step.  

I got some of the answers, I like the SINGLE one where they argue for 3 different efficiencies, but I doubt… need to do more research ig on efficiency, but most responses seem more backlash for asking a vagueish Question than anything.",t2_14wbpk,False,,0,False,Why SQLAlchemy?,[],r/datascience,False,6,discussion,0,,,False,t3_18n5ylh,False,dark,0.57,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,1703133669.0,,[],{},,True,,1703108298.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Title says it all: why SQLAlchemy over traditional SQL?&lt;/p&gt;

&lt;p&gt;edit: did not realize I would get so much backlash for asking a question. I am great with SQL, was recently introed to SQLAlchemy, and was pretty much like… why? I kinda see if you’re querying multiple different kinds of databases that are all similar enough to use the same structure it would be useful…(I.e different hosts for databases that act as repos for same software family), but I struggle to understand how this could possibly be better or easier than just using SQL to the point where it seems like instead of teaching SQL a class would teach SQLAlchemy.  SQL is one of the easiest most human readable languages in the world, arguably even more so than python(definitely less versatile than it).  The point of using your own SQL is only with it can you truly make accommodations for the database structure and calculation schedules.  I get that you can write SQL in SQLAlchemy if called for, but that just makes it seem like an extra step.  &lt;/p&gt;

&lt;p&gt;I got some of the answers, I like the SINGLE one where they argue for 3 different efficiencies, but I doubt… need to do more research ig on efficiency, but most responses seem more backlash for asking a vagueish Question than anything.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18n5ylh,True,,kater543,,37,True,all_ads,False,[],False,,/r/datascience/comments/18n5ylh/why_sqlalchemy/,all_ads,False,https://www.reddit.com/r/datascience/comments/18n5ylh/why_sqlalchemy/,1209065,1703108298.0,0,,False,,,,,,,,,,1246,219
,datascience,"What would be the best practice to create a data warehouse out dataframes that were created in a juoyter notebook? 
Should I use some magic commands to run sql within the notebook itself or should I export the dataframes and import them to another software? 
The goal is to use the normalized tables in PBI",t2_38po62bx,False,,0,False,Juoyter notebook to SQL,[],r/datascience,False,6,meta,0,,,False,t3_18n3hij,False,dark,0.45,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1703101850.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What would be the best practice to create a data warehouse out dataframes that were created in a juoyter notebook? 
Should I use some magic commands to run sql within the notebook itself or should I export the dataframes and import them to another software? 
The goal is to use the normalized tables in PBI&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18n3hij,True,,Esteban_Rdz,,12,True,all_ads,False,[],False,,/r/datascience/comments/18n3hij/juoyter_notebook_to_sql/,all_ads,False,https://www.reddit.com/r/datascience/comments/18n3hij/juoyter_notebook_to_sql/,1209065,1703101850.0,0,,False,,,,,,,,,,306,55
,datascience,"Hi all, I'm looking for a crash course on the above, plus tensors, keras et al, and most of the tuts I see on YouTube are targeted at those with zero experience, and is quite a hassle to get through. 

I already use notebooks, pandas/numpy daily and have exposure to train testing, but am looking to learn more about deep learning and some modern frameworks. 

Are there some courses, books or YouTube vids you would recommend? I would very much prefer that they're NOT trying to explain what a notebook is, how to use pandas etc. Just jump right into the logic and the math of tensors and nn's",t2_xrizd,False,,0,False,Crash course on Tensorflow and Deep Learning?,[],r/datascience,False,6,discussion,0,,,False,t3_18myu6y,False,dark,0.84,,public,28,0,{},,,False,[],,False,False,,{},Discussion,False,28,,False,False,self,False,,[],{},,True,,1703090283.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m looking for a crash course on the above, plus tensors, keras et al, and most of the tuts I see on YouTube are targeted at those with zero experience, and is quite a hassle to get through. &lt;/p&gt;

&lt;p&gt;I already use notebooks, pandas/numpy daily and have exposure to train testing, but am looking to learn more about deep learning and some modern frameworks. &lt;/p&gt;

&lt;p&gt;Are there some courses, books or YouTube vids you would recommend? I would very much prefer that they&amp;#39;re NOT trying to explain what a notebook is, how to use pandas etc. Just jump right into the logic and the math of tensors and nn&amp;#39;s&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18myu6y,True,,ApocalypseAce,,37,True,all_ads,False,[],False,,/r/datascience/comments/18myu6y/crash_course_on_tensorflow_and_deep_learning/,all_ads,False,https://www.reddit.com/r/datascience/comments/18myu6y/crash_course_on_tensorflow_and_deep_learning/,1209065,1703090283.0,0,,False,,,,,,,,,,594,109
,datascience,"I'll not go into the details of the ML models I built. Here's the short story. 

I trained and built two models for two different tasks, got good results, beat the current benchmarks at my company (a startup), got good reviews by the CEO and the CTO (both of them are the co-founders of this company). Today morning, I got a phone call from one of them who told me my efforts aren't contributing anything to the company and I got fired. In my opinion, the company is out of funds. 

While I understand being fired, but I feel I've been stabbed in the back. It surely doesn't feel good. I have two questions 
1. Has anyone faced this in their career? 
2. How should I get my life back on track? I have a wife and a two year old daughter. I'm in India. Given the economy is bad, how can I maximize my chances of getting another job?

Edit: I was hired in September 2023 and fired today.",t2_7aj1qm5h,False,,0,False,Praised for building good models yesterday but got fired today.,[],r/datascience,False,6,fun,0,,,False,t3_18mp9az,False,dark,0.95,,public,258,0,{},,,False,[],,False,False,,{},Career Discussion,False,258,,False,False,self,1703067722.0,,[],{},,True,,1703058697.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ll not go into the details of the ML models I built. Here&amp;#39;s the short story. &lt;/p&gt;

&lt;p&gt;I trained and built two models for two different tasks, got good results, beat the current benchmarks at my company (a startup), got good reviews by the CEO and the CTO (both of them are the co-founders of this company). Today morning, I got a phone call from one of them who told me my efforts aren&amp;#39;t contributing anything to the company and I got fired. In my opinion, the company is out of funds. &lt;/p&gt;

&lt;p&gt;While I understand being fired, but I feel I&amp;#39;ve been stabbed in the back. It surely doesn&amp;#39;t feel good. I have two questions 
1. Has anyone faced this in their career? 
2. How should I get my life back on track? I have a wife and a two year old daughter. I&amp;#39;m in India. Given the economy is bad, how can I maximize my chances of getting another job?&lt;/p&gt;

&lt;p&gt;Edit: I was hired in September 2023 and fired today.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18mp9az,True,,madhav1113,,79,True,all_ads,False,[],False,,/r/datascience/comments/18mp9az/praised_for_building_good_models_yesterday_but/,all_ads,False,https://www.reddit.com/r/datascience/comments/18mp9az/praised_for_building_good_models_yesterday_but/,1209065,1703058697.0,0,,False,,,,,,,,,,884,170
,datascience,"Last year I set a goal for myself that I wanted to get a promotion at the end of 2023. I aimed to expand my responsibilities and visibility, and improve the overall quality and impact of my work. Come year-end review time I was really proud of what I had accomplished, so I requested a promotion from data scientist to Senior data scientist. Fast forward a month and a half, I was just told that I’ve been given the promotion. My peer and manager reviews were excellent and the company wanted to reward me with the promotion. Directly upwards, from P2 to P3. Pretty straightforward.

I’ve never received a straight promotion before, I was expecting it to come with a significant pay raise as well, ~10-15% maybe if a standard raise without a promotion is a few percent? Not too sure. So I got my reward letter: it’s a 6% raise.

Was I delusional? Is a double digit raise for a promotion just crazy? Or should I be concerned that the company’s actions aren’t lining up with their words? What’s a reasonable raise for a promotion to senior data scientist? In this economy should I just be thankful for not being laid off and keep quiet?

Additional details: this is a tech company, startup just turning profitable (200-250 employees), unicorn status, HCOL area.",t2_113tes,False,,0,False,Insulting promotion or should I be thankful?,[],r/datascience,False,6,fun,0,,,False,t3_18mmwfi,False,dark,0.87,,public,41,0,{},,,False,[],,False,False,,{},Career Discussion,False,41,,False,False,self,False,,[],{},,True,,1703049931.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Last year I set a goal for myself that I wanted to get a promotion at the end of 2023. I aimed to expand my responsibilities and visibility, and improve the overall quality and impact of my work. Come year-end review time I was really proud of what I had accomplished, so I requested a promotion from data scientist to Senior data scientist. Fast forward a month and a half, I was just told that I’ve been given the promotion. My peer and manager reviews were excellent and the company wanted to reward me with the promotion. Directly upwards, from P2 to P3. Pretty straightforward.&lt;/p&gt;

&lt;p&gt;I’ve never received a straight promotion before, I was expecting it to come with a significant pay raise as well, ~10-15% maybe if a standard raise without a promotion is a few percent? Not too sure. So I got my reward letter: it’s a 6% raise.&lt;/p&gt;

&lt;p&gt;Was I delusional? Is a double digit raise for a promotion just crazy? Or should I be concerned that the company’s actions aren’t lining up with their words? What’s a reasonable raise for a promotion to senior data scientist? In this economy should I just be thankful for not being laid off and keep quiet?&lt;/p&gt;

&lt;p&gt;Additional details: this is a tech company, startup just turning profitable (200-250 employees), unicorn status, HCOL area.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18mmwfi,True,,woodswims,,85,True,all_ads,False,[],False,,/r/datascience/comments/18mmwfi/insulting_promotion_or_should_i_be_thankful/,all_ads,False,https://www.reddit.com/r/datascience/comments/18mmwfi/insulting_promotion_or_should_i_be_thankful/,1209065,1703049931.0,0,,False,,,,,,,,,,1259,223
,datascience,"Hello everyone,

I'm reaching out for some guidance on submitting a python ETL and dashboard creation exercise for an interview process. I'm unsure of the preferred format for delivery. Should I simply share a Jupyter notebook link and the separate dashboard file, or is there another preferred method?

Given my prior experience solely working with our company's internal software, I haven't had the opportunity to send pipelines to externals.

&amp;#x200B;

Thanks!",t2_38po62bx,False,,0,False,Coding Excercise for Interview,[],r/datascience,False,6,meta,0,,,False,t3_18mezbc,False,dark,0.58,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1703026365.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m reaching out for some guidance on submitting a python ETL and dashboard creation exercise for an interview process. I&amp;#39;m unsure of the preferred format for delivery. Should I simply share a Jupyter notebook link and the separate dashboard file, or is there another preferred method?&lt;/p&gt;

&lt;p&gt;Given my prior experience solely working with our company&amp;#39;s internal software, I haven&amp;#39;t had the opportunity to send pipelines to externals.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18mezbc,True,,Esteban_Rdz,,7,True,all_ads,False,[],False,,/r/datascience/comments/18mezbc/coding_excercise_for_interview/,all_ads,False,https://www.reddit.com/r/datascience/comments/18mezbc/coding_excercise_for_interview/,1209065,1703026365.0,0,,False,,,,,,,,,,467,71
,datascience,"I work in the realm of marketing/advertising, and sometimes I find that the models described in biostatistics or medicine far more aligns with our inference models than any other model (including marketing/CLV models). 

Though, I've noticed that courses that utilize marketing examples for discrete data analysis, instead of medical examples, are far and few. So what I've been doing so far is going through a lot of Biostatistics documents and trying to replicate some of the examples in medicine into marketing which held promising result in terms of how we can infer some of our marketing practices (e.g. what's the likelihood of a customer purchasing again at time interval t after being exposed to a specific promotion). Of course, ensuring the appropriate conditions are met (test for independence, or ensuring the samples are separate entities and not dependent pairs - i.e. different customers and not same customers experiencing both states).

The challenge is how to translate those to Business lingo. Basically if I have a point estimate delta, and confidence interval of \[X, Y\], how would I translate that to something that business can digest? They'd be happier to know information provided in the given format:

Given our customer cohort (those who were exposed to Promo A vs. not exposed to Promo A), the probability of us seeing 25% of the customers returning is promo\_A\_prob vs. c\_promo\_A\_prob.",t2_48648,False,,0,False,Application of Discrete Data Analysis beyond Medicine,[],r/datascience,False,6,discussion,0,,,False,t3_18md7be,False,dark,0.67,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1703021685.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work in the realm of marketing/advertising, and sometimes I find that the models described in biostatistics or medicine far more aligns with our inference models than any other model (including marketing/CLV models). &lt;/p&gt;

&lt;p&gt;Though, I&amp;#39;ve noticed that courses that utilize marketing examples for discrete data analysis, instead of medical examples, are far and few. So what I&amp;#39;ve been doing so far is going through a lot of Biostatistics documents and trying to replicate some of the examples in medicine into marketing which held promising result in terms of how we can infer some of our marketing practices (e.g. what&amp;#39;s the likelihood of a customer purchasing again at time interval t after being exposed to a specific promotion). Of course, ensuring the appropriate conditions are met (test for independence, or ensuring the samples are separate entities and not dependent pairs - i.e. different customers and not same customers experiencing both states).&lt;/p&gt;

&lt;p&gt;The challenge is how to translate those to Business lingo. Basically if I have a point estimate delta, and confidence interval of [X, Y], how would I translate that to something that business can digest? They&amp;#39;d be happier to know information provided in the given format:&lt;/p&gt;

&lt;p&gt;Given our customer cohort (those who were exposed to Promo A vs. not exposed to Promo A), the probability of us seeing 25% of the customers returning is promo_A_prob vs. c_promo_A_prob.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18md7be,True,,forbiscuit,,1,True,all_ads,False,[],False,,/r/datascience/comments/18md7be/application_of_discrete_data_analysis_beyond/,all_ads,False,https://www.reddit.com/r/datascience/comments/18md7be/application_of_discrete_data_analysis_beyond/,1209065,1703021685.0,0,,False,,,,,,,,,,1419,227
,datascience,"I work at a company in the automotive industry, (dealership group not manufacturers).

For those of you familiar with the automotive industry, you know it’s a minefield when it comes to technology. We have hundreds of regulations we have to follow (both from federal law to private OEM regulations). This is handcuff #1 when it comes to dealing with technology. Often we have no choice when it comes to our technology stack. We use what the OEM says we are allowed to use.

Then comes the company itself. I can count on one hand the number of people who are truly technologically literate. This is out of hundreds of employees. I don’t mean people who don’t know how to program, or people who struggle to understand statistics or complex math. I mean we have maybe 5 people in the whole company who could sufficiently answer questions like:

“what is a PDF and how does it work?”

“what is a browser and how does it work?”

“what is the difference between client and server?”

“what is a CPU and how does it work?”

“what is RAM and how does it work?”

“what is a file path?”



Now, given the hype around AI, the company wants to do more advanced things like hosting their own ML models locally and using them for data analysis.

How do I tell the company this isn’t possible without significant investment? They want to put this project on my plate with very little resources.

For reference, they would balk at the idea of hiring a data scientist for $200-300k. They might offer $85-90k to a new college grad, and that would take heavy convincing.They would balk at the idea of hiring multiple data engineers, or a statistician. They would absolutely never hire someone solely for data visualization. 

All told. To do this project right would probably take around $500k and 1-2 years of labor (at a minimum, because our company moves at the speed of a snail).

And the grand cherry on top is they have no clue how software development works. They’ll want tangible results extremely rapidly or the risk of the project collapsing from funding being pulled is very high. they’ll also likely want to micro-manage everything, if they don’t try to outsource it to Indian contractors first.

How do I convince them that to do this project right, they have to be prepared to open their checkbook, and be completely hands off, while heavily re-structuring their organization’s processes to take advantage of this technology?

Should I cut bait and run? I’m trying to muddle through this but at the same time maybe I’m just in the wrong industry for building this sort of technology (which is what I came here to do, but I’m quickly realizing the private automotive industry is pretty much antithetical to technology innovation.)",t2_lg3qzih6,False,,0,False,"I work at a company that is technologically illiterate, how do I help them overcome this?",[],r/datascience,False,6,,0,,,False,t3_18mchjf,False,dark,0.83,,public,19,0,{},,,False,[],,False,False,,{},Challenges,False,19,,False,False,self,False,,[],{},,True,,1703019865.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work at a company in the automotive industry, (dealership group not manufacturers).&lt;/p&gt;

&lt;p&gt;For those of you familiar with the automotive industry, you know it’s a minefield when it comes to technology. We have hundreds of regulations we have to follow (both from federal law to private OEM regulations). This is handcuff #1 when it comes to dealing with technology. Often we have no choice when it comes to our technology stack. We use what the OEM says we are allowed to use.&lt;/p&gt;

&lt;p&gt;Then comes the company itself. I can count on one hand the number of people who are truly technologically literate. This is out of hundreds of employees. I don’t mean people who don’t know how to program, or people who struggle to understand statistics or complex math. I mean we have maybe 5 people in the whole company who could sufficiently answer questions like:&lt;/p&gt;

&lt;p&gt;“what is a PDF and how does it work?”&lt;/p&gt;

&lt;p&gt;“what is a browser and how does it work?”&lt;/p&gt;

&lt;p&gt;“what is the difference between client and server?”&lt;/p&gt;

&lt;p&gt;“what is a CPU and how does it work?”&lt;/p&gt;

&lt;p&gt;“what is RAM and how does it work?”&lt;/p&gt;

&lt;p&gt;“what is a file path?”&lt;/p&gt;

&lt;p&gt;Now, given the hype around AI, the company wants to do more advanced things like hosting their own ML models locally and using them for data analysis.&lt;/p&gt;

&lt;p&gt;How do I tell the company this isn’t possible without significant investment? They want to put this project on my plate with very little resources.&lt;/p&gt;

&lt;p&gt;For reference, they would balk at the idea of hiring a data scientist for $200-300k. They might offer $85-90k to a new college grad, and that would take heavy convincing.They would balk at the idea of hiring multiple data engineers, or a statistician. They would absolutely never hire someone solely for data visualization. &lt;/p&gt;

&lt;p&gt;All told. To do this project right would probably take around $500k and 1-2 years of labor (at a minimum, because our company moves at the speed of a snail).&lt;/p&gt;

&lt;p&gt;And the grand cherry on top is they have no clue how software development works. They’ll want tangible results extremely rapidly or the risk of the project collapsing from funding being pulled is very high. they’ll also likely want to micro-manage everything, if they don’t try to outsource it to Indian contractors first.&lt;/p&gt;

&lt;p&gt;How do I convince them that to do this project right, they have to be prepared to open their checkbook, and be completely hands off, while heavily re-structuring their organization’s processes to take advantage of this technology?&lt;/p&gt;

&lt;p&gt;Should I cut bait and run? I’m trying to muddle through this but at the same time maybe I’m just in the wrong industry for building this sort of technology (which is what I came here to do, but I’m quickly realizing the private automotive industry is pretty much antithetical to technology innovation.)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,18mchjf,True,,leroyyyyyjenkinsssss,,26,True,all_ads,False,[],False,,/r/datascience/comments/18mchjf/i_work_at_a_company_that_is_technologically/,all_ads,False,https://www.reddit.com/r/datascience/comments/18mchjf/i_work_at_a_company_that_is_technologically/,1209065,1703019865.0,0,,False,,,,,,,,,,2723,473
,datascience,"Is this a good choice? Can one transition towards the dev team ?

How much one can learn if this role is from a big cloud provider ?

Working with customer and dev team ?",t2_4ambd4mh,False,,0,False,What is meant by support engineer(AI-ML),[],r/datascience,False,6,fun,0,,,False,t3_18m8mn8,False,dark,0.56,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1703010180.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is this a good choice? Can one transition towards the dev team ?&lt;/p&gt;

&lt;p&gt;How much one can learn if this role is from a big cloud provider ?&lt;/p&gt;

&lt;p&gt;Working with customer and dev team ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18m8mn8,True,,Shah_geee,,9,True,all_ads,False,[],False,,/r/datascience/comments/18m8mn8/what_is_meant_by_support_engineeraiml/,all_ads,False,https://www.reddit.com/r/datascience/comments/18m8mn8/what_is_meant_by_support_engineeraiml/,1209065,1703010180.0,0,,False,,,,,,,,,,170,35
,datascience,"Hello!

I'm a huge fan of software best practices, and I believe that following them helps us to move faster and make more reliable projects. I'm currently working on a project and we have developed a Python package with all the logic to generate the data, train the model, and evaluate it. It follows the typical structure of a Python package

```
setup.py
requirements.txt
package/__init__.py
package/core.py
package/helpers.py
tests/test_basic.py
tests/test_advanced.py
```

and we even have CI/CD that runs tests every time a commit is pushed to main, and so on.

However, I don't know where to fit one-shot experiments and analysis in this structure. For example, let's say I run an experiment to determine which is the optimal training dataset size. To do so I have to write some code that I would like to keep track of, but this code doesn't naturally fit as part of the Python package since it's code that will be run only once.

I guess one option is to use Jupyter Notebooks, but every time I have used this approach I've ended up with dozens of poorly maintained notebooks in the repo.

I would like to know how you tackle this problem. How do you version control this kind of code?",t2_6nmywi2j,False,,0,False,How do you keep track of code used for one-shot experiments and analysis?,[],r/datascience,False,6,,0,,,False,t3_18m5kt9,False,dark,0.97,,public,26,0,{},,,False,[],,False,False,,{},Coding,False,26,,False,False,self,False,,[],{},,True,,1703002397.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a huge fan of software best practices, and I believe that following them helps us to move faster and make more reliable projects. I&amp;#39;m currently working on a project and we have developed a Python package with all the logic to generate the data, train the model, and evaluate it. It follows the typical structure of a Python package&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
setup.py
requirements.txt
package/__init__.py
package/core.py
package/helpers.py
tests/test_basic.py
tests/test_advanced.py
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and we even have CI/CD that runs tests every time a commit is pushed to main, and so on.&lt;/p&gt;

&lt;p&gt;However, I don&amp;#39;t know where to fit one-shot experiments and analysis in this structure. For example, let&amp;#39;s say I run an experiment to determine which is the optimal training dataset size. To do so I have to write some code that I would like to keep track of, but this code doesn&amp;#39;t naturally fit as part of the Python package since it&amp;#39;s code that will be run only once.&lt;/p&gt;

&lt;p&gt;I guess one option is to use Jupyter Notebooks, but every time I have used this approach I&amp;#39;ve ended up with dozens of poorly maintained notebooks in the repo.&lt;/p&gt;

&lt;p&gt;I would like to know how you tackle this problem. How do you version control this kind of code?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,18m5kt9,True,,AM_DS,,13,True,all_ads,False,[],False,,/r/datascience/comments/18m5kt9/how_do_you_keep_track_of_code_used_for_oneshot/,all_ads,False,https://www.reddit.com/r/datascience/comments/18m5kt9/how_do_you_keep_track_of_code_used_for_oneshot/,1209065,1703002397.0,0,,False,,,,,,,,,,1193,206
,datascience,"I was considering these internships offers: one at Qorvo and another at a New York FinTech company. I'm trying to gather information on Qorvo's recent data science position salary. While I couldn't find specific details, I heard they might offer return offers. Does anyone know how much data scientist, data science engineer at Qorvo typically earn for new graduates? Please note that location could vary, so feel free to state the location too. Thank you guys!",t2_mu1p09e1,False,,0,False,Qorvo Data Science Engineer Salary,[],r/datascience,False,6,fun,0,,,False,t3_18m05co,False,dark,0.46,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1702986872.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was considering these internships offers: one at Qorvo and another at a New York FinTech company. I&amp;#39;m trying to gather information on Qorvo&amp;#39;s recent data science position salary. While I couldn&amp;#39;t find specific details, I heard they might offer return offers. Does anyone know how much data scientist, data science engineer at Qorvo typically earn for new graduates? Please note that location could vary, so feel free to state the location too. Thank you guys!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18m05co,True,,Deep-Lab4690,,15,True,all_ads,False,[],False,,/r/datascience/comments/18m05co/qorvo_data_science_engineer_salary/,all_ads,False,https://www.reddit.com/r/datascience/comments/18m05co/qorvo_data_science_engineer_salary/,1209065,1702986872.0,0,,False,,,,,,,,,,461,76
,datascience,"I trained and initially worked in engineering simulation where complex numbers were a fairly commonly used concept. I haven’t seen a complex number since working in data science (working mostly with geospatial and environmental data).

Any data science buddies out there working with complex numbers in their data? Interested to know what projects you all are doing!",t2_9pfg6ruz,False,,0,False,Do you do data science work with complex numbers?,[],r/datascience,False,6,meta,0,,,False,t3_18lyzx5,False,dark,0.92,,public,68,0,{},,,False,[],,False,False,,{},Projects,False,68,,False,False,self,False,,[],{},,True,,1702982466.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I trained and initially worked in engineering simulation where complex numbers were a fairly commonly used concept. I haven’t seen a complex number since working in data science (working mostly with geospatial and environmental data).&lt;/p&gt;

&lt;p&gt;Any data science buddies out there working with complex numbers in their data? Interested to know what projects you all are doing!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18lyzx5,True,,No-Requirement-8723,,84,False,all_ads,False,[],False,,/r/datascience/comments/18lyzx5/do_you_do_data_science_work_with_complex_numbers/,all_ads,False,https://www.reddit.com/r/datascience/comments/18lyzx5/do_you_do_data_science_work_with_complex_numbers/,1209065,1702982466.0,0,,False,,,,,,,,,,366,57
,datascience,"Hi everyone,

I'm a 3rd year PhD student at a university and I'm thinking about starting a data science club here. I'm certainly no expert, but I have some decent python, Matlab, and SQL experience now and I'd love to find some like minded students. There currently are no active clubs in the data science and machine learning realm and I'd like to kcikstart it. 

What do you all think would be some ideas for group meetings, workshops, or club activities? I'm thinking we do some work on conceptual ideas before coding, but I really haven't fleshed it out yet. I guess another question is, what would you have wished for from this kind of club at your college? Thanks for any advice or discussion!",t2_pfd4h,False,,0,False,Creating a University Data Science Club,[],r/datascience,False,6,,0,,,False,t3_18lx1y9,False,dark,0.97,,public,30,0,{},,,False,[],,False,False,,{},Education,False,30,,False,False,self,False,,[],{},,True,,1702974370.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a 3rd year PhD student at a university and I&amp;#39;m thinking about starting a data science club here. I&amp;#39;m certainly no expert, but I have some decent python, Matlab, and SQL experience now and I&amp;#39;d love to find some like minded students. There currently are no active clubs in the data science and machine learning realm and I&amp;#39;d like to kcikstart it. &lt;/p&gt;

&lt;p&gt;What do you all think would be some ideas for group meetings, workshops, or club activities? I&amp;#39;m thinking we do some work on conceptual ideas before coding, but I really haven&amp;#39;t fleshed it out yet. I guess another question is, what would you have wished for from this kind of club at your college? Thanks for any advice or discussion!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,18lx1y9,True,,GreenFractal,,21,True,all_ads,False,[],False,,/r/datascience/comments/18lx1y9/creating_a_university_data_science_club/,all_ads,False,https://www.reddit.com/r/datascience/comments/18lx1y9/creating_a_university_data_science_club/,1209065,1702974370.0,0,,False,,,,,,,,,,699,125
,datascience,"Given that almost anyone can use RAG and build LLM-based chatbots with not much effort these days, what NLP project would truly be impressive?",t2_cs54hyd66,False,,0,False,"In this age of LLMs, what kind of side projects in NLP would you truly appreciate?",[],r/datascience,False,6,projects,0,,,False,t3_18lweey,False,dark,0.88,,public,57,0,{},,,False,[],,False,False,,{},ML,False,57,,False,False,self,False,,[],{},,True,,1702971633.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Given that almost anyone can use RAG and build LLM-based chatbots with not much effort these days, what NLP project would truly be impressive?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18lweey,True,,Mission-Language8789,,31,True,all_ads,False,[],False,,/r/datascience/comments/18lweey/in_this_age_of_llms_what_kind_of_side_projects_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/18lweey/in_this_age_of_llms_what_kind_of_side_projects_in/,1209065,1702971633.0,0,,False,,,,,,,,,,142,24
,datascience," I'm currently looking to transition into a data science or data management role at a company. I don't have much Linux experience, but I've heard it can be useful to learn.

For those working in data science, analytics, or data management positions - how beneficial do you find knowing Linux? Do you use it often in your day-to-day work?

I'm trying to prioritize what skills to focus my learning time on. Is Linux something that would give me an edge when applying for jobs or provide a lot of value on the job? Or are there other skills more worth my time investing in first?

Curious to hear perspectives especially from senior data scientists, analytics managers, data engineers etc. in industry roles on how useful Linux skills have been for you. Any advice is much appreciated!",t2_fspv649pr,False,,0,False,learning Linux beneficial for data science/data management roles?,[],r/datascience,False,6,fun,0,,,False,t3_18lrzpg,False,dark,0.76,,public,14,0,{},,,False,[],,False,False,,{},Career Discussion,False,14,,False,False,self,False,,[],{},,True,,1702956474.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently looking to transition into a data science or data management role at a company. I don&amp;#39;t have much Linux experience, but I&amp;#39;ve heard it can be useful to learn.&lt;/p&gt;

&lt;p&gt;For those working in data science, analytics, or data management positions - how beneficial do you find knowing Linux? Do you use it often in your day-to-day work?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to prioritize what skills to focus my learning time on. Is Linux something that would give me an edge when applying for jobs or provide a lot of value on the job? Or are there other skills more worth my time investing in first?&lt;/p&gt;

&lt;p&gt;Curious to hear perspectives especially from senior data scientists, analytics managers, data engineers etc. in industry roles on how useful Linux skills have been for you. Any advice is much appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18lrzpg,True,,theogswami,,24,True,all_ads,False,[],False,,/r/datascience/comments/18lrzpg/learning_linux_beneficial_for_data_sciencedata/,all_ads,False,https://www.reddit.com/r/datascience/comments/18lrzpg/learning_linux_beneficial_for_data_sciencedata/,1209065,1702956474.0,0,,False,,,,,,,,,,783,136
,datascience,"Hey r/datascience! We created a plugin to easily cache the results of functions in jupyter notebook cells. The intermediate results are stored in a pickle file in the same folder.

This helps solve a few common pains we've experienced:

\- **accidentally overwriting variables**: You can re-run a given cell and re-populate any variable (e.g. if you reassigned \`df\` to some other value)\_

\- **sharing notebooks for others to rerun / reproduce**: Many collaborators don't have access to all the same clients / tokens, or all the datasets. Using xetcache, notebook authors can cache any cells / functions that they know are painful for others to reproduce / recreate.

\- **speed up rerunning**: even in single player mode, being able to rerun through your entire notebooks in seconds instead of minutes or hours is really really fun

Let us know what you think and what feedback you have! Happy data scienc-ing

&amp;#x200B;

**Library + quick tutorial:** [https://about.xethub.com/blog/xetcache-cache-jupyter-notebook-cells-for-performance-reproducibility](https://about.xethub.com/blog/xetcache-cache-jupyter-notebook-cells-for-performance-reproducibility?utm_source=reddit)",t2_6khnrfh1,False,,0,False,Caching Jupyter Notebook Cells for Faster Reruns,[],r/datascience,False,6,tooling,0,,,False,t3_18lh3f4,False,dark,0.9,,public,32,0,{},,,False,[],,False,False,,{},Tools,False,32,,False,False,self,False,,[],{},,True,,1702927461.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;! We created a plugin to easily cache the results of functions in jupyter notebook cells. The intermediate results are stored in a pickle file in the same folder.&lt;/p&gt;

&lt;p&gt;This helps solve a few common pains we&amp;#39;ve experienced:&lt;/p&gt;

&lt;p&gt;- &lt;strong&gt;accidentally overwriting variables&lt;/strong&gt;: You can re-run a given cell and re-populate any variable (e.g. if you reassigned `df` to some other value)_&lt;/p&gt;

&lt;p&gt;- &lt;strong&gt;sharing notebooks for others to rerun / reproduce&lt;/strong&gt;: Many collaborators don&amp;#39;t have access to all the same clients / tokens, or all the datasets. Using xetcache, notebook authors can cache any cells / functions that they know are painful for others to reproduce / recreate.&lt;/p&gt;

&lt;p&gt;- &lt;strong&gt;speed up rerunning&lt;/strong&gt;: even in single player mode, being able to rerun through your entire notebooks in seconds instead of minutes or hours is really really fun&lt;/p&gt;

&lt;p&gt;Let us know what you think and what feedback you have! Happy data scienc-ing&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Library + quick tutorial:&lt;/strong&gt; &lt;a href=""https://about.xethub.com/blog/xetcache-cache-jupyter-notebook-cells-for-performance-reproducibility?utm_source=reddit""&gt;https://about.xethub.com/blog/xetcache-cache-jupyter-notebook-cells-for-performance-reproducibility&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18lh3f4,True,,semicausal,,10,True,all_ads,False,[],False,,/r/datascience/comments/18lh3f4/caching_jupyter_notebook_cells_for_faster_reruns/,all_ads,False,https://www.reddit.com/r/datascience/comments/18lh3f4/caching_jupyter_notebook_cells_for_faster_reruns/,1209065,1702927461.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?auto=webp&amp;s=fbfc7059e51e3c6d324686869fc8af98c953cd41', 'width': 2688, 'height': 1536}, 'resolutions': [{'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d900bcafe96090bff9ccebee9555cbddb9247acb', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98c8f60159d16e7b75ebd39007503da978adb537', 'width': 216, 'height': 123}, {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=33d6b4992d66681ff889a6d36d781bbce9905187', 'width': 320, 'height': 182}, {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=685dcbbb192edcdb1a4fa52db90033722bbf2bfb', 'width': 640, 'height': 365}, {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=323f83d46cabbb11c30f011a962d4bef2efe6c04', 'width': 960, 'height': 548}, {'url': 'https://external-preview.redd.it/sGNJmKKP7SwpZZ3MGnJL9FeeE0q4z2IEV-KfSKMhvO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d330774d00024a76d6984ae80a115d066d5212c4', 'width': 1080, 'height': 617}], 'variants': {}, 'id': 'hVM3oQxiObDL4IKJatt0Gj3nqg9Q-ZC5XQiinGgm_XI'}], 'enabled': False}",,,,,,,1179,156
,datascience,"I have a couple interesting topics I could work on for my MS thesis in Statistics. I want the methods in my thesis to be statistical topics that could be helpful/knowledgable when working as a DS in the industry. One professor works in causal inference and one works in Modern experimental design for industry settings. Doing a thesis in either topic gives me a chance to engage with a specific skillset within stats that I could leverage in solving problems. It’s just both seem interesting to me, and I can’t decide.

Topic 1: causal inference

The prof works in biomedical sciences and a lot of his methods research is causal inference. Essentially doing a thesis within this area could equip me with really great tool when needing to answer causal questions. A thesis in this area would allow me to really work closely with the methods and give me a chance to answer “what if” questions potentially on the industry. Would be an application within biostatistics or genomics since that is the profs specialty, but would get a good understanding of how to leverage causal inference methods in my work, and overall train me to think about causal questions.


Topic 2: Online Randomized Experiments 

Another prof works in “modern” experimental design methods for data science, within the realm of online randomized controlled experimentation, and adaptive experimentation specifically within the context of AB testing and data science.  Lots of heavy optimization on the math side, and could be practical for industry experimentation. This is also interesting to me because it is a huge area of stats which is somewhat neglected, and now it has become really crucial in many companies for making decisions. A thesis in this could allow me to really understand how experimentation works in a data science setting and could allow me to have a deeper knowledge on how to build, and implement experiments in the industry. Could be useful for experimentation focused DS roles.


My question is, which of these two thesis topics had the most “immediate impact” on my day to day working as a data scientist. I’m trying to use this thesis as a way to show employers that I have some “specialty” within my MS statistics that could make me useful in solving problems. What do you guys think? Causal inference or Modern Experimental Deign?",t2_uy28jztl,False,,0,False,"Which topic has more “immediate impact”, Stats MS thesis topics",[],r/datascience,False,6,meta,0,,,False,t3_18ldxym,False,dark,0.56,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1702919747.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a couple interesting topics I could work on for my MS thesis in Statistics. I want the methods in my thesis to be statistical topics that could be helpful/knowledgable when working as a DS in the industry. One professor works in causal inference and one works in Modern experimental design for industry settings. Doing a thesis in either topic gives me a chance to engage with a specific skillset within stats that I could leverage in solving problems. It’s just both seem interesting to me, and I can’t decide.&lt;/p&gt;

&lt;p&gt;Topic 1: causal inference&lt;/p&gt;

&lt;p&gt;The prof works in biomedical sciences and a lot of his methods research is causal inference. Essentially doing a thesis within this area could equip me with really great tool when needing to answer causal questions. A thesis in this area would allow me to really work closely with the methods and give me a chance to answer “what if” questions potentially on the industry. Would be an application within biostatistics or genomics since that is the profs specialty, but would get a good understanding of how to leverage causal inference methods in my work, and overall train me to think about causal questions.&lt;/p&gt;

&lt;p&gt;Topic 2: Online Randomized Experiments &lt;/p&gt;

&lt;p&gt;Another prof works in “modern” experimental design methods for data science, within the realm of online randomized controlled experimentation, and adaptive experimentation specifically within the context of AB testing and data science.  Lots of heavy optimization on the math side, and could be practical for industry experimentation. This is also interesting to me because it is a huge area of stats which is somewhat neglected, and now it has become really crucial in many companies for making decisions. A thesis in this could allow me to really understand how experimentation works in a data science setting and could allow me to have a deeper knowledge on how to build, and implement experiments in the industry. Could be useful for experimentation focused DS roles.&lt;/p&gt;

&lt;p&gt;My question is, which of these two thesis topics had the most “immediate impact” on my day to day working as a data scientist. I’m trying to use this thesis as a way to show employers that I have some “specialty” within my MS statistics that could make me useful in solving problems. What do you guys think? Causal inference or Modern Experimental Deign?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18ldxym,True,,Direct-Touch469,,7,True,all_ads,False,[],False,,/r/datascience/comments/18ldxym/which_topic_has_more_immediate_impact_stats_ms/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ldxym/which_topic_has_more_immediate_impact_stats_ms/,1209065,1702919747.0,0,,False,,,,,,,,,,2328,391
,datascience,"Hi All, Is there a good book that anyone can recommend to understand the landscape and architecture of AI/Ml that started shaping industry solutions from last decade and today’s LLMs ranging from logistics supply chain problems to customer churn, and in medicine industry to NLP also including computer vision and audio ANNs.

Thanks!",t2_ayqufd5k,False,,0,False,Data Science book for managers and C-suite,[],r/datascience,False,6,fun,0,,,False,t3_18l871d,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Career Discussion,False,3,,False,False,self,False,,[],{},,True,,1702904622.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All, Is there a good book that anyone can recommend to understand the landscape and architecture of AI/Ml that started shaping industry solutions from last decade and today’s LLMs ranging from logistics supply chain problems to customer churn, and in medicine industry to NLP also including computer vision and audio ANNs.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18l871d,True,,Dependent_Mushroom98,,5,True,all_ads,False,[],False,,/r/datascience/comments/18l871d/data_science_book_for_managers_and_csuite/,all_ads,False,https://www.reddit.com/r/datascience/comments/18l871d/data_science_book_for_managers_and_csuite/,1209065,1702904622.0,0,,False,,,,,,,,,,334,53
,datascience,I am currently working as an MLE in a company and I am thinking about the possibility of moving to freelance status but I don't know what service would work.  Because I have the impression that most of the tasks that an MLE performs are adapted to work within a company.  But at the moment I'm thinking about data visualization.  Do you think it is possible to have a career as a data visualization expert as a freelancer?  Or what service would you recommend?,t2_e9q7uu8d,False,,0,False,What service could an MLE offer as a freelancer?,[],r/datascience,False,6,fun,0,,,False,t3_18l6s94,False,dark,0.69,,public,9,0,{},,,False,[],,False,False,,{},Career Discussion,False,9,,False,False,self,False,,[],{},,True,,1702899909.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently working as an MLE in a company and I am thinking about the possibility of moving to freelance status but I don&amp;#39;t know what service would work.  Because I have the impression that most of the tasks that an MLE performs are adapted to work within a company.  But at the moment I&amp;#39;m thinking about data visualization.  Do you think it is possible to have a career as a data visualization expert as a freelancer?  Or what service would you recommend?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18l6s94,True,,Glad_Split_743,,14,True,all_ads,False,[],False,,/r/datascience/comments/18l6s94/what_service_could_an_mle_offer_as_a_freelancer/,all_ads,False,https://www.reddit.com/r/datascience/comments/18l6s94/what_service_could_an_mle_offer_as_a_freelancer/,1209065,1702899909.0,0,,False,,,,,,,,,,460,84
,datascience,"I was supposed to re-org to another team that would have been significantly less toxic than my current role. 

My manager and the other manager had been arguing to the VP on where I should go. I went through a formal HR process and passed. Then that VP left, and the interim VP who makes the decisions is…. My manager. Which means I’m staying on his team. 

I have a dead end career at this point. Internally, there’s no backfill/hiring, so there’s not much chance to go to another team. 

I’ve developed anxiety and insomnia after being on this team, and even with this company. I need to leave.

However, I’ve only ever worked at one company my entire career, and I’ve only been a DS for 1ish years. I was a DA who did DS work - can I just write that I was a data scientist for that role on my resume and make the changes on LinkedIn for external roles? 

I have friends who can give recommendations at other roles, but I think I’m at the point where I’m having a hard time mentally leaving my company. At this point it’s probably fear of the unknown/unable to leave. 

I’m confident that I’d get a more flexible job that pays more, but I’m terrified of the DS technical interview. I started preparing for my technical interview for the other role, but that interview was just a farce. I truly despise my company and am overworked on this team and complain nonstop about my manager, but I keep accepting even more shitty behavior that harms me because I’m terrified of leaving and doing horrible on a job interview. 

How do you prepare for interviews when you’re so burnt out?",t2_6lukipdd,False,,0,False,"Manager blocked internal transfer to another team. At this point, how do you leave your first company? How do you do it when you’re burnt out?",[],r/datascience,False,6,fun,0,,,False,t3_18l4l8a,False,dark,0.9,,public,79,0,{},,,False,[],,False,False,,{},Career Discussion,False,79,,False,False,self,False,,[],{},,True,,1702891092.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was supposed to re-org to another team that would have been significantly less toxic than my current role. &lt;/p&gt;

&lt;p&gt;My manager and the other manager had been arguing to the VP on where I should go. I went through a formal HR process and passed. Then that VP left, and the interim VP who makes the decisions is…. My manager. Which means I’m staying on his team. &lt;/p&gt;

&lt;p&gt;I have a dead end career at this point. Internally, there’s no backfill/hiring, so there’s not much chance to go to another team. &lt;/p&gt;

&lt;p&gt;I’ve developed anxiety and insomnia after being on this team, and even with this company. I need to leave.&lt;/p&gt;

&lt;p&gt;However, I’ve only ever worked at one company my entire career, and I’ve only been a DS for 1ish years. I was a DA who did DS work - can I just write that I was a data scientist for that role on my resume and make the changes on LinkedIn for external roles? &lt;/p&gt;

&lt;p&gt;I have friends who can give recommendations at other roles, but I think I’m at the point where I’m having a hard time mentally leaving my company. At this point it’s probably fear of the unknown/unable to leave. &lt;/p&gt;

&lt;p&gt;I’m confident that I’d get a more flexible job that pays more, but I’m terrified of the DS technical interview. I started preparing for my technical interview for the other role, but that interview was just a farce. I truly despise my company and am overworked on this team and complain nonstop about my manager, but I keep accepting even more shitty behavior that harms me because I’m terrified of leaving and doing horrible on a job interview. &lt;/p&gt;

&lt;p&gt;How do you prepare for interviews when you’re so burnt out?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18l4l8a,True,,Much-Focus-1408,,40,True,all_ads,False,[],False,,/r/datascience/comments/18l4l8a/manager_blocked_internal_transfer_to_another_team/,all_ads,False,https://www.reddit.com/r/datascience/comments/18l4l8a/manager_blocked_internal_transfer_to_another_team/,1209065,1702891092.0,0,,False,,,,,,,,,,1579,290
,datascience,"If Ljung-Box test, autocorrelation function and partial autocorrelation function all suggest that a time-series doesn't encompass autocorrelation, is using an ARIMA model unjustified or ""useless""?

Can the use of ARIMA be justified in a situation of low autocorrelation in the data?

Thank you for responding!",t2_tf1f2,False,,0,False,ARIMA models with no/low autocorrelation of time-series,[],r/datascience,False,6,,0,,,False,t3_18kytqr,False,dark,0.95,,public,15,0,{},,,False,[],,False,False,,{},Statistics,False,15,,False,False,self,False,,[],{},,True,,1702869287.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If Ljung-Box test, autocorrelation function and partial autocorrelation function all suggest that a time-series doesn&amp;#39;t encompass autocorrelation, is using an ARIMA model unjustified or &amp;quot;useless&amp;quot;?&lt;/p&gt;

&lt;p&gt;Can the use of ARIMA be justified in a situation of low autocorrelation in the data?&lt;/p&gt;

&lt;p&gt;Thank you for responding!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,18kytqr,True,,Fluxan,,15,True,all_ads,False,[],False,,/r/datascience/comments/18kytqr/arima_models_with_nolow_autocorrelation_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/18kytqr/arima_models_with_nolow_autocorrelation_of/,1209065,1702869287.0,0,,False,,,,,,,,,,309,45
,datascience,"Hi. I am a 15 year hedge fund professional. I’ve worked at large funds you have probably heard of where I regularly presented my research to firm leadership. I even led a team of analysts for a few years. I have 10 years of python experience, have built production ML models, and helped new funds build their data, analytics and other infrastructure from ground up, allowing them to get to &gt;1bn in assets. So that’s my background.

My question is, I am looking to get out of the market stress of HFs and into a data science role at a different firm. I’m having a bit of trouble getting an interview. I admit I’ve only been trying for a couple weeks. Any advice for an experienced data-focused professional trying to transition out of finance into a data science role?

Edit - if anyone wants to connect please dm me.",t2_q5p499d80,False,,0,False,Advice for an experienced hedge funder,[],r/datascience,False,6,fun,0,,,False,t3_18kxuj7,False,dark,0.69,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,False,self,1702915603.0,,[],{},,True,,1702866090.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I am a 15 year hedge fund professional. I’ve worked at large funds you have probably heard of where I regularly presented my research to firm leadership. I even led a team of analysts for a few years. I have 10 years of python experience, have built production ML models, and helped new funds build their data, analytics and other infrastructure from ground up, allowing them to get to &amp;gt;1bn in assets. So that’s my background.&lt;/p&gt;

&lt;p&gt;My question is, I am looking to get out of the market stress of HFs and into a data science role at a different firm. I’m having a bit of trouble getting an interview. I admit I’ve only been trying for a couple weeks. Any advice for an experienced data-focused professional trying to transition out of finance into a data science role?&lt;/p&gt;

&lt;p&gt;Edit - if anyone wants to connect please dm me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18kxuj7,True,,hfguy23,,13,True,all_ads,False,[],False,,/r/datascience/comments/18kxuj7/advice_for_an_experienced_hedge_funder/,all_ads,False,https://www.reddit.com/r/datascience/comments/18kxuj7/advice_for_an_experienced_hedge_funder/,1209065,1702866090.0,0,,False,,,,,,,,,,819,149
,datascience,"After finishing my masters degree in Data Science, I would love to get into ML-Research. I know that the majority of research positions do require a PHD so I am thinking about pursuing one after graduation. 

Now what I am concerned about is that I start to write my dissertation on something which builds on the state of the art but will eventually become completely irrelevant after a year or two because the state of the art has progressed massively and achieves better results than my approach could ever imagine. I imagine it to be frustrating to still having to finish something which won’t really provide any scientific value. 

Do I think a too one-dimensional or is this a valid consideration?",t2_ed1zitv0q,False,,0,False,"Does a PHD thesis in Machine Learning even make sense, given how fast the field develops",[],r/datascience,False,6,discussion,0,,,False,t3_18ktx2o,False,dark,0.87,,public,129,0,{},,,False,[],,False,False,,{},Discussion,False,129,,False,False,self,False,,[],{},,True,,1702854289.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;After finishing my masters degree in Data Science, I would love to get into ML-Research. I know that the majority of research positions do require a PHD so I am thinking about pursuing one after graduation. &lt;/p&gt;

&lt;p&gt;Now what I am concerned about is that I start to write my dissertation on something which builds on the state of the art but will eventually become completely irrelevant after a year or two because the state of the art has progressed massively and achieves better results than my approach could ever imagine. I imagine it to be frustrating to still having to finish something which won’t really provide any scientific value. &lt;/p&gt;

&lt;p&gt;Do I think a too one-dimensional or is this a valid consideration?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18ktx2o,True,,Substantial-Guava-64,,60,True,all_ads,False,[],False,,/r/datascience/comments/18ktx2o/does_a_phd_thesis_in_machine_learning_even_make/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ktx2o/does_a_phd_thesis_in_machine_learning_even_make/,1209065,1702854289.0,1,,False,,,,,,,,,,702,121
,datascience,So Ive worked in healthcare for 10yrs now in various positions. Over the past 3 years I decided I wanted to really get into data and operational management. So I went and got an associates in Business management with a focus in Data Science and am in the middle of completing a Masters in Data Science. This resulted in me landing a position as the Data Manager for a large clinical operation in a hospital that I started 2 weeks ago. And now I have a small problem. I've been using python and R for the past 3 years and the job itself only allows use of excel. I used to be a amazing at excel but I am super rusty at it after not using for 3 years. I will primarily doing basic descriptives and pivot tables. Does anyone have some good reccomendations for like youtube videos or any other resources for a quick crash course so I get back to being an excel overlord?,t2_khadnffg,False,,0,False,Got a new data job but need a refresher.,[],r/datascience,False,6,tooling,0,,,False,t3_18ktp2j,False,dark,0.88,,public,32,0,{},,,False,[],,False,False,,{},Tools,False,32,,False,False,self,False,,[],{},,True,,1702853712.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So Ive worked in healthcare for 10yrs now in various positions. Over the past 3 years I decided I wanted to really get into data and operational management. So I went and got an associates in Business management with a focus in Data Science and am in the middle of completing a Masters in Data Science. This resulted in me landing a position as the Data Manager for a large clinical operation in a hospital that I started 2 weeks ago. And now I have a small problem. I&amp;#39;ve been using python and R for the past 3 years and the job itself only allows use of excel. I used to be a amazing at excel but I am super rusty at it after not using for 3 years. I will primarily doing basic descriptives and pivot tables. Does anyone have some good reccomendations for like youtube videos or any other resources for a quick crash course so I get back to being an excel overlord?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18ktp2j,True,,HamsterCultural3081,,15,True,all_ads,False,[],False,,/r/datascience/comments/18ktp2j/got_a_new_data_job_but_need_a_refresher/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ktp2j/got_a_new_data_job_but_need_a_refresher/,1209065,1702853712.0,0,,False,,,,,,,,,,866,166
,datascience,"Hi everyone,

I just trained a pytorch GNN Model (GAT based ) that performs pretty well. What's you experience with interpretable tools for GNN? Any suggestions on which one to use or not use? There are so many out there, I can't test them all.. My inputs are small graphs made of 10-50 proteins. Thanks for your help. G. ",t2_87xxasa2,False,,0,False,GNN Model prediction interpretation,[],r/datascience,False,6,tooling,0,,,False,t3_18ksy1b,False,dark,0.8,,public,6,0,{},,,False,[],,False,False,,{},Tools,False,6,,False,False,self,False,,[],{},,True,,1702851673.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I just trained a pytorch GNN Model (GAT based ) that performs pretty well. What&amp;#39;s you experience with interpretable tools for GNN? Any suggestions on which one to use or not use? There are so many out there, I can&amp;#39;t test them all.. My inputs are small graphs made of 10-50 proteins. Thanks for your help. G. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18ksy1b,True,,Amazing_Alarm6130,,5,True,all_ads,False,[],False,,/r/datascience/comments/18ksy1b/gnn_model_prediction_interpretation/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ksy1b/gnn_model_prediction_interpretation/,1209065,1702851673.0,0,,False,,,,,,,,,,322,59
,datascience,"Hi Everyone, I wanted to ask you for suggestions on how to organize work in my data science team. We're a team of internal consultants in a bigger company, we usually help other teams understand their data/find anomalies, sometimes we develop models for automatic anomaly detection or prediction, we also develop llms sometimes. We're a team of 8-10 people. What are your weekly/monthly customs, things you do to stay organized?",t2_viw38w9,False,,0,False,Soon to be a team manager. What's your team setup/workflow? How do you organize your work as a team?,[],r/datascience,False,6,fun,0,,,False,t3_18kphif,False,dark,0.81,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,False,self,False,,[],{},,True,,1702842500.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Everyone, I wanted to ask you for suggestions on how to organize work in my data science team. We&amp;#39;re a team of internal consultants in a bigger company, we usually help other teams understand their data/find anomalies, sometimes we develop models for automatic anomaly detection or prediction, we also develop llms sometimes. We&amp;#39;re a team of 8-10 people. What are your weekly/monthly customs, things you do to stay organized?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18kphif,True,,johndatavizwiz,,30,True,all_ads,False,[],False,,/r/datascience/comments/18kphif/soon_to_be_a_team_manager_whats_your_team/,all_ads,False,https://www.reddit.com/r/datascience/comments/18kphif/soon_to_be_a_team_manager_whats_your_team/,1209065,1702842500.0,0,,False,,,,,,,,,,428,70
,datascience,"Hey there! I'm keen to considering switching to a DS/DA role. As part of the process of trying to better understand the role, Would you mind briefly share how you divide your day? Also, mentioning your industry and company size would be really helpful. Bonus: what part do you hate the most :) ?

Something like:

* **30% Identifying Problems with Stakeholders**
* **20% Data Processing**
* **20% Feature Engineering**
* **10% Model Building**
* **20% Explaining Results to Stakeholders**

Looking forward to your insights! :)",t2_bhsqog3,False,,0,False,Day to day task of a data scientist / analyst?,[],r/datascience,False,6,discussion,0,,,False,t3_18k5duf,False,dark,0.79,,public,38,0,{},,,False,[],,False,False,,{},Discussion,False,38,,False,False,self,False,,[],{},,True,,1702774742.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there! I&amp;#39;m keen to considering switching to a DS/DA role. As part of the process of trying to better understand the role, Would you mind briefly share how you divide your day? Also, mentioning your industry and company size would be really helpful. Bonus: what part do you hate the most :) ?&lt;/p&gt;

&lt;p&gt;Something like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;30% Identifying Problems with Stakeholders&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;20% Data Processing&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;20% Feature Engineering&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;10% Model Building&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;20% Explaining Results to Stakeholders&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Looking forward to your insights! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18k5duf,True,,deanlee805,,49,True,all_ads,False,[],False,,/r/datascience/comments/18k5duf/day_to_day_task_of_a_data_scientist_analyst/,all_ads,False,https://www.reddit.com/r/datascience/comments/18k5duf/day_to_day_task_of_a_data_scientist_analyst/,1209065,1702774742.0,0,,False,,,,,,,,,,526,86
,datascience,"Hi everyone,

Note - I do not want to be trolled so please don't.

I am currently in my early 30s working as actuarial analyst in the pension valuation for past 8 years in the same company. I had to drop out of my college due to personal reasons but 3 years ago I got the opportunity to pursue a Bachelor's degree in data science from the top college in my country and I am about to finish it soon. I have studied about various ML algorithms (theoretically/mathematically with one Kaggle project in college), statistics, linear algebra, basics of SQL, made a simple activity tracking web app using python and flask ( I loved creating it)

My career is currently stagnant and I wish to change that. Before this degree I would have not thought of working with top tech companies but now I have built some confidence to think about it. I want to better my life and how I think of myself. People who started working with me 8 years ago are now earning twice as much and it hurts that I am stuck. I have decided to prepare for Amazon, Google, and Optiver since HFT is intriguing. The thought of preparing for the interviews is overwhelms me.

I read a lot of posts here which tell me that DSA is important to go through initial rounds of interview, but then I could not find any answers on how to prepare for the Data Science (especially at Google and Amazon) round who is looking to switch career.

Query 1 - Ideally I would like to work in a MLOps role because I have learnt that it is a mix of software engineering and machine learning and I understand I might not get a similar role as my first data science job so should I aim at any data analytics role in the beginning?

Query 2 - Should I work on some Kaggle competitions where data is provided by companies, build web apps as personal project and put it on my resume/Github to get a call for interview?

Query 3-  Should I rely on the posts on Glassdoor to prepare for interviews? There are so many algorithms - do I need to remember all of them? And since I have no prior experience in similar roles - what are they going to ask me about?

Thank you so much!

&amp;#x200B;",t2_9gccb5lr,False,,0,False,"In early 30s, want to switch my career from Actuarial Science to DS/MLOps and want to better my life",[],r/datascience,False,6,fun,0,,,False,t3_18k2z8y,False,dark,0.69,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,1702768755.0,,[],{},,True,,1702767560.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;Note - I do not want to be trolled so please don&amp;#39;t.&lt;/p&gt;

&lt;p&gt;I am currently in my early 30s working as actuarial analyst in the pension valuation for past 8 years in the same company. I had to drop out of my college due to personal reasons but 3 years ago I got the opportunity to pursue a Bachelor&amp;#39;s degree in data science from the top college in my country and I am about to finish it soon. I have studied about various ML algorithms (theoretically/mathematically with one Kaggle project in college), statistics, linear algebra, basics of SQL, made a simple activity tracking web app using python and flask ( I loved creating it)&lt;/p&gt;

&lt;p&gt;My career is currently stagnant and I wish to change that. Before this degree I would have not thought of working with top tech companies but now I have built some confidence to think about it. I want to better my life and how I think of myself. People who started working with me 8 years ago are now earning twice as much and it hurts that I am stuck. I have decided to prepare for Amazon, Google, and Optiver since HFT is intriguing. The thought of preparing for the interviews is overwhelms me.&lt;/p&gt;

&lt;p&gt;I read a lot of posts here which tell me that DSA is important to go through initial rounds of interview, but then I could not find any answers on how to prepare for the Data Science (especially at Google and Amazon) round who is looking to switch career.&lt;/p&gt;

&lt;p&gt;Query 1 - Ideally I would like to work in a MLOps role because I have learnt that it is a mix of software engineering and machine learning and I understand I might not get a similar role as my first data science job so should I aim at any data analytics role in the beginning?&lt;/p&gt;

&lt;p&gt;Query 2 - Should I work on some Kaggle competitions where data is provided by companies, build web apps as personal project and put it on my resume/Github to get a call for interview?&lt;/p&gt;

&lt;p&gt;Query 3-  Should I rely on the posts on Glassdoor to prepare for interviews? There are so many algorithms - do I need to remember all of them? And since I have no prior experience in similar roles - what are they going to ask me about?&lt;/p&gt;

&lt;p&gt;Thank you so much!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18k2z8y,True,,Own-Foot7556,,25,True,all_ads,False,[],False,,/r/datascience/comments/18k2z8y/in_early_30s_want_to_switch_my_career_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/18k2z8y/in_early_30s_want_to_switch_my_career_from/,1209065,1702767560.0,0,,False,,,,,,,,,,2127,401
,datascience,"The workflow for a data scientist is typically broken down into the following steps at a high level:

1. Define the problem statement
2. Data gathering/cleansing
3. Data exploration
4. Data modeling
5. Presenting results

If I had to rank them in order of importance (1 being the most important):

1. Data gathering/cleansing
2. Define the problem statement
3. Data exploration
4. Presenting results
5. Data modeling

I’m content with the current state of data gathering/cleansing (or perhaps I’ve given up on this area) as well as defining the problem statement. However, I’ve found data exploration as my biggest problem area, specifically because I wait for hours on end to query massive data sets / need to iterate on something that takes 30 minutes to run.

Is this a problem that resonates with others? How have you tried to solve this problem today? 

If not, what’s a problem that you believe to be more important?",t2_soqhf,False,,0,False,Data Science Workflow Challenges,[],r/datascience,False,6,discussion,0,,,False,t3_18k0s8z,False,dark,0.9,,public,22,0,{},,,False,[],,False,False,,{},Discussion,False,22,,False,False,self,False,,[],{},,True,,1702761167.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The workflow for a data scientist is typically broken down into the following steps at a high level:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Define the problem statement&lt;/li&gt;
&lt;li&gt;Data gathering/cleansing&lt;/li&gt;
&lt;li&gt;Data exploration&lt;/li&gt;
&lt;li&gt;Data modeling&lt;/li&gt;
&lt;li&gt;Presenting results&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If I had to rank them in order of importance (1 being the most important):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Data gathering/cleansing&lt;/li&gt;
&lt;li&gt;Define the problem statement&lt;/li&gt;
&lt;li&gt;Data exploration&lt;/li&gt;
&lt;li&gt;Presenting results&lt;/li&gt;
&lt;li&gt;Data modeling&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m content with the current state of data gathering/cleansing (or perhaps I’ve given up on this area) as well as defining the problem statement. However, I’ve found data exploration as my biggest problem area, specifically because I wait for hours on end to query massive data sets / need to iterate on something that takes 30 minutes to run.&lt;/p&gt;

&lt;p&gt;Is this a problem that resonates with others? How have you tried to solve this problem today? &lt;/p&gt;

&lt;p&gt;If not, what’s a problem that you believe to be more important?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18k0s8z,True,,n1k0h1k0,,16,True,all_ads,False,[],False,,/r/datascience/comments/18k0s8z/data_science_workflow_challenges/,all_ads,False,https://www.reddit.com/r/datascience/comments/18k0s8z/data_science_workflow_challenges/,1209065,1702761167.0,0,,False,,,,,,,,,,922,155
,datascience,"I'm not sure if I'm posting this in the most appropriate subreddit, but I got to thinking about a project at work.

My job role is somewhere between data analyst and software engineer for a big aerospace manufacturing company, but digital processes here are a bit antiquated. A manager proposed a project to me in which financial calculations and forecasts are done in an Excel sheet using a VBA macro - and when I say huge I mean this thing is 180mb of aggregated financial data. To produce forecasts for monthly data someone quite literally runs this macro and leaves their laptop on for 12 hours overnight to run it.

I say this company's processes are antiquated because we have no ML processes, Azure, AWS or any Python or R libraries - just a base 3.11 installation of Python is all I have available.

Do you guys have any ideas for a more efficient way to go about this huge financial calculation?",t2_c4tdx,False,,0,False,Efficient alternatives to a cumbersome VBA macro,[],r/datascience,False,6,network,0,,,False,t3_18jy1dy,False,dark,0.81,,public,32,0,{},,,False,[],,False,False,,{},Analysis,False,32,,False,False,self,False,,[],{},,True,,1702753279.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m not sure if I&amp;#39;m posting this in the most appropriate subreddit, but I got to thinking about a project at work.&lt;/p&gt;

&lt;p&gt;My job role is somewhere between data analyst and software engineer for a big aerospace manufacturing company, but digital processes here are a bit antiquated. A manager proposed a project to me in which financial calculations and forecasts are done in an Excel sheet using a VBA macro - and when I say huge I mean this thing is 180mb of aggregated financial data. To produce forecasts for monthly data someone quite literally runs this macro and leaves their laptop on for 12 hours overnight to run it.&lt;/p&gt;

&lt;p&gt;I say this company&amp;#39;s processes are antiquated because we have no ML processes, Azure, AWS or any Python or R libraries - just a base 3.11 installation of Python is all I have available.&lt;/p&gt;

&lt;p&gt;Do you guys have any ideas for a more efficient way to go about this huge financial calculation?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18jy1dy,True,,EncryptedMyst,,85,True,all_ads,False,[],False,,/r/datascience/comments/18jy1dy/efficient_alternatives_to_a_cumbersome_vba_macro/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jy1dy/efficient_alternatives_to_a_cumbersome_vba_macro/,1209065,1702753279.0,0,,False,,,,,,,,,,904,162
,datascience,"I have 4 YOE (with an additional 3 in academia but it was all research related). Recently got an offer for a role which matches my current job title Senior MLE but it seems more advanced than my current role, based on the way the folks I interviewed with described the team's work. I was surprised I even got an offer for this role because while I didn't do too bad on the interviews, my performance wasn't exactly stellar. It's a very nice offer that aligns well with my future career goals but I feel overwhelmed thinking of the responsibility of such an advanced role. Some might say if they chose to hire me then they know I can do the job, or that this is just impostor's syndrome but I'm not sure, I'm a member of a group that is very underrepresented in the field, and I have a gloomy suspicion that maybe that's why they want to hire me? I felt intimidated by the interviewers, particularly the one who was junior to the position to which I'm applying, he seemed extremely competent, more so than I (although perhaps it's because he already knew the solution to the programming problem he had me solve); has anyone felt that sort of vibe when interviewing, the feeling that you aren't as competent as the people you'll be working with? That the people offering you a job made a mistake, or have some ulterior motive for hiring you? How did it go? What did you do?",t2_7dpje88o,False,,0,False,Feeling underqualified for job offer?,[],r/datascience,False,6,fun,0,,,False,t3_18jsjqv,False,dark,0.75,,public,8,0,{},,,False,[],,False,False,,{},Career Discussion,False,8,,False,False,self,False,,[],{},,True,,1702737510.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have 4 YOE (with an additional 3 in academia but it was all research related). Recently got an offer for a role which matches my current job title Senior MLE but it seems more advanced than my current role, based on the way the folks I interviewed with described the team&amp;#39;s work. I was surprised I even got an offer for this role because while I didn&amp;#39;t do too bad on the interviews, my performance wasn&amp;#39;t exactly stellar. It&amp;#39;s a very nice offer that aligns well with my future career goals but I feel overwhelmed thinking of the responsibility of such an advanced role. Some might say if they chose to hire me then they know I can do the job, or that this is just impostor&amp;#39;s syndrome but I&amp;#39;m not sure, I&amp;#39;m a member of a group that is very underrepresented in the field, and I have a gloomy suspicion that maybe that&amp;#39;s why they want to hire me? I felt intimidated by the interviewers, particularly the one who was junior to the position to which I&amp;#39;m applying, he seemed extremely competent, more so than I (although perhaps it&amp;#39;s because he already knew the solution to the programming problem he had me solve); has anyone felt that sort of vibe when interviewing, the feeling that you aren&amp;#39;t as competent as the people you&amp;#39;ll be working with? That the people offering you a job made a mistake, or have some ulterior motive for hiring you? How did it go? What did you do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18jsjqv,True,,neelankatan,,16,True,all_ads,False,[],False,,/r/datascience/comments/18jsjqv/feeling_underqualified_for_job_offer/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jsjqv/feeling_underqualified_for_job_offer/,1209065,1702737510.0,0,,False,,,,,,,,,,1371,254
,datascience,"I've just started as a data analyst but I have a research background so I understand all the stats for data science. I know R and I've been getting really good at SQL recently.

Money in the public sector is crap. I'm only on £30k atm and I'm the sole earner due to having a child. I'd love to go into the private sector but I'm scared, I have impostor syndrome due to being so new and my boss didn't give me much training then got grumpy when I made a mistake in a process only he knows about. He commented if I was in the private sector I'd still be on probation, felt a bit weird to say that to me. Should I avoid the private sector? My plan was to stay in the safety of public sector until I get really good then I'll have more value to the private sector.",t2_d51zenrcx,False,,0,False,"I've never worked for a private company, I've always worked public sector and have only just broken into data. I'm scared of being fired if I worked for a private company, is that a realistic fear in the UK?",[],r/datascience,False,6,discussion,0,,,False,t3_18jotcg,False,dark,0.53,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1702723942.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve just started as a data analyst but I have a research background so I understand all the stats for data science. I know R and I&amp;#39;ve been getting really good at SQL recently.&lt;/p&gt;

&lt;p&gt;Money in the public sector is crap. I&amp;#39;m only on £30k atm and I&amp;#39;m the sole earner due to having a child. I&amp;#39;d love to go into the private sector but I&amp;#39;m scared, I have impostor syndrome due to being so new and my boss didn&amp;#39;t give me much training then got grumpy when I made a mistake in a process only he knows about. He commented if I was in the private sector I&amp;#39;d still be on probation, felt a bit weird to say that to me. Should I avoid the private sector? My plan was to stay in the safety of public sector until I get really good then I&amp;#39;ll have more value to the private sector.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18jotcg,True,,InsightSeeker99,,18,True,all_ads,False,[],False,,/r/datascience/comments/18jotcg/ive_never_worked_for_a_private_company_ive_always/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jotcg/ive_never_worked_for_a_private_company_ive_always/,1209065,1702723942.0,0,,False,,,,,,,,,,760,153
,datascience,"Hello guys I'm doing a 2 years master's in data science, i'm in my first year. Any suggestions on some graduation projects to keep in mind cuz i wanna be ready and match my skills to the potential projects.",t2_j0wuczrp,False,,0,False,Graduation project,[],r/datascience,False,6,meta,0,,,False,t3_18jnmcf,False,dark,0.84,,public,12,0,{},,,False,[],,False,False,,{},Projects,False,12,,False,False,self,False,,[],{},,True,,1702718688.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys I&amp;#39;m doing a 2 years master&amp;#39;s in data science, i&amp;#39;m in my first year. Any suggestions on some graduation projects to keep in mind cuz i wanna be ready and match my skills to the potential projects.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18jnmcf,True,,Gold-Artichoke-9288,,38,True,all_ads,False,[],False,,/r/datascience/comments/18jnmcf/graduation_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jnmcf/graduation_project/,1209065,1702718688.0,0,,False,,,,,,,,,,206,39
,datascience,Just curious what everyone's working on.,t2_d51zenrcx,False,,0,False,What statistical analysis are you currently doing in work?,[],r/datascience,False,6,,0,,,False,t3_18jn66v,False,dark,0.98,,public,126,0,{},,,False,[],,False,False,,{},Statistics,False,126,,False,False,self,False,,[],{},,True,,1702716732.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just curious what everyone&amp;#39;s working on.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,18jn66v,True,,InsightSeeker99,,123,True,all_ads,False,[],False,,/r/datascience/comments/18jn66v/what_statistical_analysis_are_you_currently_doing/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jn66v/what_statistical_analysis_are_you_currently_doing/,1209065,1702716732.0,1,,False,,,,,,,,,,40,6
,datascience,"I'm a data scientist with an interest in online gaming. I want to create a project on sentiment analysis for toxic chats in online multiplayer gaming.

I was thinking of creating a public Google sheets and requesting people in the respective subreddits to help if anyone is interested.

But how can I prevent it from being tampered? 

Can I get any tips on how to go about collecting and building this dataset?
Is there anything else I should be aware of?",t2_736ioria,False,,0,False,Trying to create a data set using inputs from redditors,[],r/datascience,False,6,meta,0,,,False,t3_18jl2im,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1702707876.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a data scientist with an interest in online gaming. I want to create a project on sentiment analysis for toxic chats in online multiplayer gaming.&lt;/p&gt;

&lt;p&gt;I was thinking of creating a public Google sheets and requesting people in the respective subreddits to help if anyone is interested.&lt;/p&gt;

&lt;p&gt;But how can I prevent it from being tampered? &lt;/p&gt;

&lt;p&gt;Can I get any tips on how to go about collecting and building this dataset?
Is there anything else I should be aware of?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18jl2im,True,,jaegarbong,,7,True,all_ads,False,[],False,,/r/datascience/comments/18jl2im/trying_to_create_a_data_set_using_inputs_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jl2im/trying_to_create_a_data_set_using_inputs_from/,1209065,1702707876.0,0,,False,,,,,,,,,,455,81
,datascience,Does anyone here do this? I always felt like my career trajectory should be trying to switch companies every 2-3 years to work on cooler problems and get paid more. Especially with remote options being a thing it’s even more possible now. Do any DS do this now? How does it feel? Do you guys feel like you are really growing by hopping every few years for higher pay?,t2_i69qgpqa,False,,0,False,Job hopping for higher pay in this field,[],r/datascience,False,6,fun,0,,,False,t3_18ji1ig,False,dark,0.89,,public,40,0,{},,,False,[],,False,False,,{},Career Discussion,False,40,,False,False,self,False,,[],{},,True,,1702697203.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone here do this? I always felt like my career trajectory should be trying to switch companies every 2-3 years to work on cooler problems and get paid more. Especially with remote options being a thing it’s even more possible now. Do any DS do this now? How does it feel? Do you guys feel like you are really growing by hopping every few years for higher pay?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ji1ig,True,,AdFew4357,,62,True,all_ads,False,[],False,,/r/datascience/comments/18ji1ig/job_hopping_for_higher_pay_in_this_field/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ji1ig/job_hopping_for_higher_pay_in_this_field/,1209065,1702697203.0,0,,False,,,,,,,,,,367,69
,datascience,"Does anyone here work in a role where the theory in the former book is actually *needed* for their job? I finished the ISL book in my undergrad and picked up ESL at one point during grad school and the theory is quite fascinating. I know it’s probably not gonna be useful to me since it’s not as practical as ISL, but, curious if anyone here actually needs to use ESL for their work at all, or has needed to go into the theory a bit.",t2_uy28jztl,False,,0,False,Elements of statistical learning vs introduction to statistical learning,[],r/datascience,False,6,discussion,0,,,False,t3_18jfqz2,False,dark,0.84,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,False,self,False,,[],{},,True,,1702689711.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone here work in a role where the theory in the former book is actually &lt;em&gt;needed&lt;/em&gt; for their job? I finished the ISL book in my undergrad and picked up ESL at one point during grad school and the theory is quite fascinating. I know it’s probably not gonna be useful to me since it’s not as practical as ISL, but, curious if anyone here actually needs to use ESL for their work at all, or has needed to go into the theory a bit.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18jfqz2,True,,Direct-Touch469,,18,True,all_ads,False,[],False,,/r/datascience/comments/18jfqz2/elements_of_statistical_learning_vs_introduction/,all_ads,False,https://www.reddit.com/r/datascience/comments/18jfqz2/elements_of_statistical_learning_vs_introduction/,1209065,1702689711.0,0,,False,,,,,,,,,,433,86
,datascience,"Would be interesting to see what situations people prefer to drop NA’s or to interpolate (linear, spline ?). 

If people have any war stories about interpolating data leading to a massively different outcome I’d love to hear it!",t2_j3ti74md,False,,0,False,Has anyone done a deep dive on the impacts of different Data Interpolations / Missing Data Handling on Analysis Results?,[],r/datascience,False,6,network,0,,,False,t3_18je1qt,False,dark,0.85,,public,9,0,{},,,False,[],,False,False,,{},Analysis,False,9,,False,False,self,False,,[],{},,True,,1702684707.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Would be interesting to see what situations people prefer to drop NA’s or to interpolate (linear, spline ?). &lt;/p&gt;

&lt;p&gt;If people have any war stories about interpolating data leading to a massively different outcome I’d love to hear it!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18je1qt,True,,deonvin,,1,True,all_ads,False,[],False,,/r/datascience/comments/18je1qt/has_anyone_done_a_deep_dive_on_the_impacts_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/18je1qt/has_anyone_done_a_deep_dive_on_the_impacts_of/,1209065,1702684707.0,0,,False,,,,,,,,,,228,38
,datascience,"Hi everyone.

I'm trying to gather and increase the amount of tips and material related to get a job in sports analytics.

I started creating some articles about it. Some will be tips and experiences, others cool and useful material, curated content etc. It was already hard to get good information about this niche, now with more garbage content on the internet it's harder. I'm trying to put together a source of truth that can be trusted.

This is [the first post.](https://www.sportsjobs.online/blog-post/1how%2520to%2520start%2520your%2520sports%2520analytics%2520career%253f/r/recdeWmEztJQB7TfN)

I run a job board for sports analytics positions and this content will be integrated there.

Your support and feedback is highly appreciated.

Thanks!

&amp;#x200B;",t2_24mvheq,False,,0,False,Helping people get a job in sports analytics!,[],r/datascience,False,6,meta,0,,,False,t3_18j8fbl,False,dark,0.92,,public,112,0,{},,,False,[],,False,False,,{},Projects,False,112,,False,False,self,False,,[],{},,True,,1702669344.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to gather and increase the amount of tips and material related to get a job in sports analytics.&lt;/p&gt;

&lt;p&gt;I started creating some articles about it. Some will be tips and experiences, others cool and useful material, curated content etc. It was already hard to get good information about this niche, now with more garbage content on the internet it&amp;#39;s harder. I&amp;#39;m trying to put together a source of truth that can be trusted.&lt;/p&gt;

&lt;p&gt;This is &lt;a href=""https://www.sportsjobs.online/blog-post/1how%2520to%2520start%2520your%2520sports%2520analytics%2520career%253f/r/recdeWmEztJQB7TfN""&gt;the first post.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I run a job board for sports analytics positions and this content will be integrated there.&lt;/p&gt;

&lt;p&gt;Your support and feedback is highly appreciated.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18j8fbl,True,,fark13,,34,True,all_ads,False,[],False,,/r/datascience/comments/18j8fbl/helping_people_get_a_job_in_sports_analytics/,all_ads,False,https://www.reddit.com/r/datascience/comments/18j8fbl/helping_people_get_a_job_in_sports_analytics/,1209065,1702669344.0,0,,False,,,,,,,,,,767,107
,datascience,"Whenever I build a stacking ensemble (be it for classification or regression), a support vector machine nearly always has the lowest error. Quite often, its error will even be lower or equivalent to the entire ensemble with averaged predictions from various models (LDA, GLMs, trees/random forests, KNN, splines, etc.). Yet, I rarely see SMVs used by other people. Is this just because you strip away interpretation for prediction accuracy in SMVs? Is anyone else experiencing this, or am I just having dumb luck with SVMs?",t2_h2dycfv3,False,,0,False,Support vector machines dominate my prediction modeling nearly every time,[],r/datascience,False,6,projects,0,,,False,t3_18j8107,False,dark,0.97,,public,143,0,{},,,False,[],,False,False,,{},ML,False,143,,False,False,self,False,,[],{},,True,,1702668233.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Whenever I build a stacking ensemble (be it for classification or regression), a support vector machine nearly always has the lowest error. Quite often, its error will even be lower or equivalent to the entire ensemble with averaged predictions from various models (LDA, GLMs, trees/random forests, KNN, splines, etc.). Yet, I rarely see SMVs used by other people. Is this just because you strip away interpretation for prediction accuracy in SMVs? Is anyone else experiencing this, or am I just having dumb luck with SVMs?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18j8107,True,,Every-Eggplant9205,,35,True,all_ads,False,[],False,,/r/datascience/comments/18j8107/support_vector_machines_dominate_my_prediction/,all_ads,False,https://www.reddit.com/r/datascience/comments/18j8107/support_vector_machines_dominate_my_prediction/,1209065,1702668233.0,0,,False,,,,,,,,,,523,85
,datascience,"I enjoy LC, and want to get good eventually at working with more advanced data structures and techniques like graphs and dynamic programming, however, I also want to start working on other elements of the interview as well.

I mostly do LC mediums, is that also what is consistent with coding rounds during interviews? Is there a need to go beyond the basic data structures? (Lists, hash map, stacks, and linked lists)

What has been your guys experience overall with LC in data science/data analysis/whatever interviews?",t2_gjagx21e,False,,0,False,How much leetcode for DS Interviews?,[],r/datascience,False,6,fun,0,,,False,t3_18j6oce,False,dark,0.81,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1702664744.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I enjoy LC, and want to get good eventually at working with more advanced data structures and techniques like graphs and dynamic programming, however, I also want to start working on other elements of the interview as well.&lt;/p&gt;

&lt;p&gt;I mostly do LC mediums, is that also what is consistent with coding rounds during interviews? Is there a need to go beyond the basic data structures? (Lists, hash map, stacks, and linked lists)&lt;/p&gt;

&lt;p&gt;What has been your guys experience overall with LC in data science/data analysis/whatever interviews?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18j6oce,True,,Complete_Bag_1192,,12,True,all_ads,False,[],False,,/r/datascience/comments/18j6oce/how_much_leetcode_for_ds_interviews/,all_ads,False,https://www.reddit.com/r/datascience/comments/18j6oce/how_much_leetcode_for_ds_interviews/,1209065,1702664744.0,0,,False,,,,,,,,,,521,86
,datascience,Got this initial numbers from recruiter. Trying to understand how additional I should ask. The initial ranges given were 135-150k + 10-20k.,t2_viwwhp0m,False,,0,False,"How is this salary for Sr. Associate - DS in Plano, TX: 135k + 10k (base + bonus)?",[],r/datascience,False,6,fun,0,,,False,t3_18j6f5s,False,dark,0.81,,public,37,0,{},,,False,[],,False,False,,{},Career Discussion,False,37,,False,False,self,False,,[],{},,True,,1702664077.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Got this initial numbers from recruiter. Trying to understand how additional I should ask. The initial ranges given were 135-150k + 10-20k.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18j6f5s,True,,Abject-Bumblebee4881,,54,True,all_ads,False,[],False,,/r/datascience/comments/18j6f5s/how_is_this_salary_for_sr_associate_ds_in_plano/,all_ads,False,https://www.reddit.com/r/datascience/comments/18j6f5s/how_is_this_salary_for_sr_associate_ds_in_plano/,1209065,1702664077.0,0,,False,,,,,,,,,,139,22
,datascience,"As title indicates, I work as a Data Scientist, but am looking to improve position . I  daily use  Pyton/R/Git/SQL/Excel/Tableau , hold  PhD in comp. sci. and am confident in ML.

Due to the nature of my work, there is very little deploying of the ML models, and cloud use (I do have AWS and Azure Certifications). How can I strengthen my profile? I have been looking at technologies such as: containerization (kubernetes), deployment (gradio/streamlit/dash/flask), ML version control (mlflow / clear ml). Is there something else I should keep in mind/ look into?

If it helps, I am UK based.

Thank you",t2_2jaddzio,False,,0,False,Stack necessary to transition to Senior DS,[],r/datascience,False,6,fun,0,,,False,t3_18iz4kj,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Career Discussion,False,4,,False,False,self,False,,[],{},,True,,1702643816.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As title indicates, I work as a Data Scientist, but am looking to improve position . I  daily use  Pyton/R/Git/SQL/Excel/Tableau , hold  PhD in comp. sci. and am confident in ML.&lt;/p&gt;

&lt;p&gt;Due to the nature of my work, there is very little deploying of the ML models, and cloud use (I do have AWS and Azure Certifications). How can I strengthen my profile? I have been looking at technologies such as: containerization (kubernetes), deployment (gradio/streamlit/dash/flask), ML version control (mlflow / clear ml). Is there something else I should keep in mind/ look into?&lt;/p&gt;

&lt;p&gt;If it helps, I am UK based.&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18iz4kj,True,,citizenofme,,11,True,all_ads,False,[],False,,/r/datascience/comments/18iz4kj/stack_necessary_to_transition_to_senior_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/18iz4kj/stack_necessary_to_transition_to_senior_ds/,1209065,1702643816.0,0,,False,,,,,,,,,,603,102
,datascience,"And do you see that changing? 
",t2_b3hvfhlp,False,,0,False,Why are Software Engineers paid higher than Data Scientists?,[],r/datascience,False,6,fun,0,,,False,t3_18iv880,False,dark,0.79,,public,120,0,{},,,False,[],,False,False,,{},Career Discussion,False,120,,False,False,self,1702630251.0,,[],{},,True,,1702627799.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;And do you see that changing? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18iv880,True,,Exotic_Avocado6164,,247,True,all_ads,False,[],False,,/r/datascience/comments/18iv880/why_are_software_engineers_paid_higher_than_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/18iv880/why_are_software_engineers_paid_higher_than_data/,1209065,1702627799.0,0,,False,,,,,,,,,,31,6
,datascience,"I've been doing some scraping and the website in question seems, let's say less than happy with it. I'm in the process of transitioning to a different data source but for the time being I kinda need the data for a tool I built and am using. Does anyone have any tricks for making the process look less programmatic on their side? I'm going very slowly, have random sleeps built in, recently started visiting other random websites at specified intervals and also at specified intervals visit different portions of their website so it doesn't appear I'm focused solely on this one thing. Any other ideas?",t2_9wge0haf,False,,0,False,What are some scraping tricks to make the process not look so programmatic?,[],r/datascience,False,6,meta,0,,,False,t3_18itp2h,False,dark,0.73,,public,24,0,{},,,False,[],,False,False,,{},Projects,False,24,,False,False,self,False,,[],{},,True,,1702621509.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been doing some scraping and the website in question seems, let&amp;#39;s say less than happy with it. I&amp;#39;m in the process of transitioning to a different data source but for the time being I kinda need the data for a tool I built and am using. Does anyone have any tricks for making the process look less programmatic on their side? I&amp;#39;m going very slowly, have random sleeps built in, recently started visiting other random websites at specified intervals and also at specified intervals visit different portions of their website so it doesn&amp;#39;t appear I&amp;#39;m focused solely on this one thing. Any other ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18itp2h,True,,Tamalelulu,,26,True,all_ads,False,[],False,,/r/datascience/comments/18itp2h/what_are_some_scraping_tricks_to_make_the_process/,all_ads,False,https://www.reddit.com/r/datascience/comments/18itp2h/what_are_some_scraping_tricks_to_make_the_process/,1209065,1702621509.0,0,,False,,,,,,,,,,602,105
,datascience,"Finally moving into a data science oriented role where before I was not doing what I went to school for (financial software testing and consulting). I put in my two weeks, and man idk. I just feel guilty for it. I know it’s for the best for my career, and if sucks because my manager was the best manager I’ve had. Is this normal?",t2_13fee6,False,,0,False,Making first ever career company switch; is it normal to feel “guilty” about it?,[],r/datascience,False,6,fun,0,,,False,t3_18iq06r,False,dark,0.88,,public,63,0,{},,,False,[],,False,False,,{},Career Discussion,False,63,,False,False,self,False,,[],{},,True,,1702608804.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Finally moving into a data science oriented role where before I was not doing what I went to school for (financial software testing and consulting). I put in my two weeks, and man idk. I just feel guilty for it. I know it’s for the best for my career, and if sucks because my manager was the best manager I’ve had. Is this normal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18iq06r,True,,andrew2018022,,31,True,all_ads,False,[],False,,/r/datascience/comments/18iq06r/making_first_ever_career_company_switch_is_it/,all_ads,False,https://www.reddit.com/r/datascience/comments/18iq06r/making_first_ever_career_company_switch_is_it/,1209065,1702608804.0,0,,False,,,,,,,,,,330,64
,datascience,"Hi everyone, this post is regarding team project tracking, transparency and taking responsibility.

Context: I am a senior data scientist in a large MNC in a relatively young DS team with 4 other DS. I'm not a team lead so I do not have anyone under me. Recently my team lead has asked me to become the contact person for him to look for when he needs to know projects’ progress. He’s the one doing it right now.

Constraints:
- I'm located &gt;=12 hours away from my entire team. Unless I want to do 16 hours days and work myself to death, I need the individual team members to take responsibilities to make their progress visible.
- No Jira (I don't like it for DS projects anyway)
- We have confluence which I plan to make into our key platform for project management. 

Questions:
- How should I go about doing this? Please share the things that worked for you if you are in similar situation
- what are the key components in the confluence space for this purpose? Off the top of my head, I think there should be some way to document proj requirements, stakeholders, timeline, model details, progress. 
- Project progress is a big one. How do I make it such that the team runs on almost autopilot and most details are transparent? I do not want to chase people for updates

Thanks in advance!! Happy holidays!",t2_pnx7y1h,False,,0,False,Advice on DS project tracking for entire team,[],r/datascience,False,6,meta,0,,,False,t3_18iozfa,False,dark,0.93,,public,27,0,{},,,False,[],,False,False,,{},Projects,False,27,,False,False,self,False,,[],{},,True,,1702605603.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, this post is regarding team project tracking, transparency and taking responsibility.&lt;/p&gt;

&lt;p&gt;Context: I am a senior data scientist in a large MNC in a relatively young DS team with 4 other DS. I&amp;#39;m not a team lead so I do not have anyone under me. Recently my team lead has asked me to become the contact person for him to look for when he needs to know projects’ progress. He’s the one doing it right now.&lt;/p&gt;

&lt;p&gt;Constraints:
- I&amp;#39;m located &amp;gt;=12 hours away from my entire team. Unless I want to do 16 hours days and work myself to death, I need the individual team members to take responsibilities to make their progress visible.
- No Jira (I don&amp;#39;t like it for DS projects anyway)
- We have confluence which I plan to make into our key platform for project management. &lt;/p&gt;

&lt;p&gt;Questions:
- How should I go about doing this? Please share the things that worked for you if you are in similar situation
- what are the key components in the confluence space for this purpose? Off the top of my head, I think there should be some way to document proj requirements, stakeholders, timeline, model details, progress. 
- Project progress is a big one. How do I make it such that the team runs on almost autopilot and most details are transparent? I do not want to chase people for updates&lt;/p&gt;

&lt;p&gt;Thanks in advance!! Happy holidays!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18iozfa,True,,appleciderv,,29,True,all_ads,False,[],False,,/r/datascience/comments/18iozfa/advice_on_ds_project_tracking_for_entire_team/,all_ads,False,https://www.reddit.com/r/datascience/comments/18iozfa/advice_on_ds_project_tracking_for_entire_team/,1209065,1702605603.0,0,,False,,,,True,,,,,,1313,240
,datascience,"Currently Data Scientist at a legacy/ old school type of company. Good career path, likely to make senior DS very soon, but no culture and lots of technically inept people.

Enter opportunity to move to Senior Analyst role at a very desirable/growing public tech company. The role would have very similar responsibilities (still building models etc), almost same pay. Every review says the co is great to work at.

Given that pay and responsibilities are very similar, is the title change from Scientist to Analyst enough that I shouldn't do it? I worry how it could affect future career prospects

&amp;#x200B;",t2_7nuksarw,False,,0,False,Am I crazy to leave a DS role for an Analyst role as a more desirable company?,[],r/datascience,False,6,fun,0,,,False,t3_18im2fp,False,dark,0.89,,public,47,0,{},,,False,[],,False,False,,{},Career Discussion,False,47,,False,False,self,False,,[],{},,True,,1702596961.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently Data Scientist at a legacy/ old school type of company. Good career path, likely to make senior DS very soon, but no culture and lots of technically inept people.&lt;/p&gt;

&lt;p&gt;Enter opportunity to move to Senior Analyst role at a very desirable/growing public tech company. The role would have very similar responsibilities (still building models etc), almost same pay. Every review says the co is great to work at.&lt;/p&gt;

&lt;p&gt;Given that pay and responsibilities are very similar, is the title change from Scientist to Analyst enough that I shouldn&amp;#39;t do it? I worry how it could affect future career prospects&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18im2fp,True,,Agitated_Hedgehog_,,48,True,all_ads,False,[],False,,/r/datascience/comments/18im2fp/am_i_crazy_to_leave_a_ds_role_for_an_analyst_role/,all_ads,False,https://www.reddit.com/r/datascience/comments/18im2fp/am_i_crazy_to_leave_a_ds_role_for_an_analyst_role/,1209065,1702596961.0,0,,False,,,,,,,,,,611,101
,datascience,"Especially when referring to a Data Lake but also when working in massive databases sometimes as a Data Science/Analyst you collect some information or multiple datasets usually into a collection that’s easily accessible and reference-able without having to query over and over again. I learned it last summer.

I am trying to find the terminology to find a easy and reliable definition to use but also provide documentation on its stated benefits. But I just can’t remember the darn term, help!",t2_1tgq8rm3,False,,0,False,What’s the term….?,[],r/datascience,False,6,tooling,0,,,False,t3_18idjti,False,dark,0.86,,public,14,0,{},,,False,[],,False,False,,{},Tools,False,14,,False,False,self,False,,[],{},,True,,1702574328.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Especially when referring to a Data Lake but also when working in massive databases sometimes as a Data Science/Analyst you collect some information or multiple datasets usually into a collection that’s easily accessible and reference-able without having to query over and over again. I learned it last summer.&lt;/p&gt;

&lt;p&gt;I am trying to find the terminology to find a easy and reliable definition to use but also provide documentation on its stated benefits. But I just can’t remember the darn term, help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18idjti,True,,CleanDataDirtyMind,,10,True,all_ads,False,[],False,,/r/datascience/comments/18idjti/whats_the_term/,all_ads,False,https://www.reddit.com/r/datascience/comments/18idjti/whats_the_term/,1209065,1702574328.0,0,,False,,,,,,,,,,495,81
,datascience,"I've been seeing frequent posts on r/datascience about how many applicants a job posting can get (hundreds to low thousands), often with days or a week after the posting goes live. And I'm also seeing the same rough # of applicants on linkedin job postings themselves. I understand that many applicants may be unqualified / ineligible to work in that country etc and are just blasting CV's everywhere, but even after weeding out a large proportion of those individuals, there would still be quite a number of suitable candidates to wade through. 

  
So - how do hiring managers handle it from that point? if you've got 50 to 100 candidates that look good on paper at first glance, how do you decide who to go forward with for interviews? or is there an easy screening tool that's typically used to validate skills / ask basic questions etc (or is this an HR / recruitment task?)..? I see a lot of the perspective from those trying to find work, but am interested in hearing from the 'other side' too!

Thanks all!",t2_wsk2i,False,,0,False,Question for Hiring Managers,[],r/datascience,False,6,fun,0,,,False,t3_18iazcw,False,dark,0.89,,public,14,0,{},,,False,[],,False,False,,{},Career Discussion,False,14,,False,False,self,False,,[],{},,True,,1702567338.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been seeing frequent posts on &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt; about how many applicants a job posting can get (hundreds to low thousands), often with days or a week after the posting goes live. And I&amp;#39;m also seeing the same rough # of applicants on linkedin job postings themselves. I understand that many applicants may be unqualified / ineligible to work in that country etc and are just blasting CV&amp;#39;s everywhere, but even after weeding out a large proportion of those individuals, there would still be quite a number of suitable candidates to wade through. &lt;/p&gt;

&lt;p&gt;So - how do hiring managers handle it from that point? if you&amp;#39;ve got 50 to 100 candidates that look good on paper at first glance, how do you decide who to go forward with for interviews? or is there an easy screening tool that&amp;#39;s typically used to validate skills / ask basic questions etc (or is this an HR / recruitment task?)..? I see a lot of the perspective from those trying to find work, but am interested in hearing from the &amp;#39;other side&amp;#39; too!&lt;/p&gt;

&lt;p&gt;Thanks all!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18iazcw,True,,bennymac111,,34,True,all_ads,False,[],False,,/r/datascience/comments/18iazcw/question_for_hiring_managers/,all_ads,False,https://www.reddit.com/r/datascience/comments/18iazcw/question_for_hiring_managers/,1209065,1702567338.0,0,,False,,,,,,,,,,1014,180
,datascience,"I had an idea for applying logistic regression model coefficients. 

We have a certain data field that in theory is very valuable to have filled out on the front end for a specific problem, but in reality it is often not filled out (only about 3% of the time). 

Can I use a logistic regression model to show how “important” it is to have this data field filled out when trying to predict the outcome of our business problem?

I want to use the coefficient interpretation to say “When this data field is filled out, there is a 25% greater chance that **dependent variable outcome** occurs. Thus, we should fill it out.”

And I would the deal with the class imbalance the same way as with other ML problems. 

Thoughts?",t2_495cn7pm,False,,0,False,Using log odds to look at variable significance,[],r/datascience,False,6,network,0,,,False,t3_18i94vr,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Analysis,False,5,,False,False,self,False,,[],{},,True,,1702562137.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I had an idea for applying logistic regression model coefficients. &lt;/p&gt;

&lt;p&gt;We have a certain data field that in theory is very valuable to have filled out on the front end for a specific problem, but in reality it is often not filled out (only about 3% of the time). &lt;/p&gt;

&lt;p&gt;Can I use a logistic regression model to show how “important” it is to have this data field filled out when trying to predict the outcome of our business problem?&lt;/p&gt;

&lt;p&gt;I want to use the coefficient interpretation to say “When this data field is filled out, there is a 25% greater chance that &lt;strong&gt;dependent variable outcome&lt;/strong&gt; occurs. Thus, we should fill it out.”&lt;/p&gt;

&lt;p&gt;And I would the deal with the class imbalance the same way as with other ML problems. &lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18i94vr,True,,Throwawayforgainz99,,25,True,all_ads,False,[],False,,/r/datascience/comments/18i94vr/using_log_odds_to_look_at_variable_significance/,all_ads,False,https://www.reddit.com/r/datascience/comments/18i94vr/using_log_odds_to_look_at_variable_significance/,1209065,1702562137.0,0,,False,,,,,,,,,,718,130
,datascience,"As the title says, I'm looking for a multivariate time series anomaly detection dataset. I'd use it to studyand try some pre-processing techniques and different algorithms.

It doesn't specifically has to be for anomaly detection, some forecasting dataset could also de useful if it's for failure prediction or equivalent, with low occurency of events.I've done the tour and found some datasets, but most are univariate or not real use cases. The ideal use case would be data coming from sensors and/or IoT in a real environment.

Any references ? I'm desperately looking for this.

&amp;#x200B;

Thank you.",t2_nw83t,False,,0,False,Multivariate Time Series Anomaly Detection Dataset ?,[],r/datascience,False,6,meta,0,,,False,t3_18i6oir,False,dark,0.83,,public,7,0,{},,,False,[],,False,False,,{},Projects,False,7,,False,False,self,False,,[],{},,True,,1702553536.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As the title says, I&amp;#39;m looking for a multivariate time series anomaly detection dataset. I&amp;#39;d use it to studyand try some pre-processing techniques and different algorithms.&lt;/p&gt;

&lt;p&gt;It doesn&amp;#39;t specifically has to be for anomaly detection, some forecasting dataset could also de useful if it&amp;#39;s for failure prediction or equivalent, with low occurency of events.I&amp;#39;ve done the tour and found some datasets, but most are univariate or not real use cases. The ideal use case would be data coming from sensors and/or IoT in a real environment.&lt;/p&gt;

&lt;p&gt;Any references ? I&amp;#39;m desperately looking for this.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18i6oir,True,,chacalgamer,,11,True,all_ads,False,[],False,,/r/datascience/comments/18i6oir/multivariate_time_series_anomaly_detection_dataset/,all_ads,False,https://www.reddit.com/r/datascience/comments/18i6oir/multivariate_time_series_anomaly_detection_dataset/,1209065,1702553536.0,0,,False,,,,,,,,,,607,97
,datascience,"Long post, sorry!

As you all know the job market has been rough. I've been applying and interviewing for about 9 months. Just landed my 2nd offer (1st one was really low) and I could use some unbiased input. A bit of a background.

I have a career in manufacturing and currently working as such. I got an MSDS paid for by my employer. I do some DA and DS (SQL, Python, PowerBI) type work at my current positions which gives me things to talk about at interviews. Now onto the offer:

It's a Data Scientist position, on site at a large international company with a local HQ in a MCOL city. They gave me the base salary I asked for ($120k) but when I saw the rest of the comp package, I was underwhelmed:

1) They don't offer any bonuses. So whatever increase in salary I'd get, I'm losing about the same amount in bonuses from the current job so it's a wash. If this was it, I can live with that to get my foot in the door.

2) I'd be paying $5400/yr more than current employer for health care of a similar plan. 

3) Their 401k match is about half of what my current employer offers and vested after 3 yrs. I'm not likely to stay that long so basically no match. I'd be losing about $7k/yr + compound growth vs current job

4) If I leave now, I owe my employer \~$25k in tuition reimbursement (tapers down over the next 16 months). I negotiated a $10k (taxable so \~$6600) singing bonus to offset that but that's still \~$18.4k of my savings I'll have to lose to make the transition

I've explained this (w/out all the numbers) to the company, they responded with the singing bonus. I can ask for a $10k salary increase but they had to jump through hoops to get the current offer approved so I doubt it'll happen.

Financially, it doesn't make sense. I know. But my impression is that once I'm in a DS job, it'll be relatively easy to find a more senior, higher paying position.  Seems like people here are jumping ship (and salaries) every couple years. I'm also sick of applying/interviewing, it's been 9 months.  

Probably worth noting that although I don't love my current job, and sometimes dread it, I'm not totally miserable. I'm also expecting an annual raise next month (4% &amp; 5% last 2 yrs) which further increases the salary gap and there's a chance I can make a lateral move to keep things interesting.

So here are my thoughts. Any input is appreciated:

Option 1: Take the job and start looking for something better in 6 months

Option 2: Wait it out, keep looking for something better and keep my savings (Honestly, the more I type, the more I'm leaning toward this option)",t2_fhq8w,False,,0,False,Conflicted on DS offer,[],r/datascience,False,6,fun,0,,,False,t3_18i0gku,False,dark,0.53,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1702528358.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Long post, sorry!&lt;/p&gt;

&lt;p&gt;As you all know the job market has been rough. I&amp;#39;ve been applying and interviewing for about 9 months. Just landed my 2nd offer (1st one was really low) and I could use some unbiased input. A bit of a background.&lt;/p&gt;

&lt;p&gt;I have a career in manufacturing and currently working as such. I got an MSDS paid for by my employer. I do some DA and DS (SQL, Python, PowerBI) type work at my current positions which gives me things to talk about at interviews. Now onto the offer:&lt;/p&gt;

&lt;p&gt;It&amp;#39;s a Data Scientist position, on site at a large international company with a local HQ in a MCOL city. They gave me the base salary I asked for ($120k) but when I saw the rest of the comp package, I was underwhelmed:&lt;/p&gt;

&lt;p&gt;1) They don&amp;#39;t offer any bonuses. So whatever increase in salary I&amp;#39;d get, I&amp;#39;m losing about the same amount in bonuses from the current job so it&amp;#39;s a wash. If this was it, I can live with that to get my foot in the door.&lt;/p&gt;

&lt;p&gt;2) I&amp;#39;d be paying $5400/yr more than current employer for health care of a similar plan. &lt;/p&gt;

&lt;p&gt;3) Their 401k match is about half of what my current employer offers and vested after 3 yrs. I&amp;#39;m not likely to stay that long so basically no match. I&amp;#39;d be losing about $7k/yr + compound growth vs current job&lt;/p&gt;

&lt;p&gt;4) If I leave now, I owe my employer ~$25k in tuition reimbursement (tapers down over the next 16 months). I negotiated a $10k (taxable so ~$6600) singing bonus to offset that but that&amp;#39;s still ~$18.4k of my savings I&amp;#39;ll have to lose to make the transition&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve explained this (w/out all the numbers) to the company, they responded with the singing bonus. I can ask for a $10k salary increase but they had to jump through hoops to get the current offer approved so I doubt it&amp;#39;ll happen.&lt;/p&gt;

&lt;p&gt;Financially, it doesn&amp;#39;t make sense. I know. But my impression is that once I&amp;#39;m in a DS job, it&amp;#39;ll be relatively easy to find a more senior, higher paying position.  Seems like people here are jumping ship (and salaries) every couple years. I&amp;#39;m also sick of applying/interviewing, it&amp;#39;s been 9 months.  &lt;/p&gt;

&lt;p&gt;Probably worth noting that although I don&amp;#39;t love my current job, and sometimes dread it, I&amp;#39;m not totally miserable. I&amp;#39;m also expecting an annual raise next month (4% &amp;amp; 5% last 2 yrs) which further increases the salary gap and there&amp;#39;s a chance I can make a lateral move to keep things interesting.&lt;/p&gt;

&lt;p&gt;So here are my thoughts. Any input is appreciated:&lt;/p&gt;

&lt;p&gt;Option 1: Take the job and start looking for something better in 6 months&lt;/p&gt;

&lt;p&gt;Option 2: Wait it out, keep looking for something better and keep my savings (Honestly, the more I type, the more I&amp;#39;m leaning toward this option)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18i0gku,True,,naiq6236,,28,True,all_ads,False,[],False,,/r/datascience/comments/18i0gku/conflicted_on_ds_offer/,all_ads,False,https://www.reddit.com/r/datascience/comments/18i0gku/conflicted_on_ds_offer/,1209065,1702528358.0,0,,False,,,,,,,,,,2593,478
,datascience,"Hi ,

I'm looking for some book recommendations - I want to upskill before I start a new job-my first Data Scientist job - this one is EDA heavy - and ML too. its a start up so I want to perform well.

I'd like to know your recommendations for

1. Dealing with different kinds of data - for example - In the take home test I was given - there is a quantity - different kinds of capacitance - the range was very very small - and how to find outliers - the box plots could not show anything.  I want to get better at that kind of analysis and EDA.
2. Model Deployment - this area is new to me . I think they use AWS - any courses or primers that I can do.
3. Advanced visualization  - we're trying different kinds of visualization. I already know how to use matplotlib,seaborn and basic libraries - but the more interactive ones - from basic to advanced(Will tableau be useful?)
4. How to deal with massive amounts of data - we will be processing and creating files and sorting through 1 billion data points.

Please?",t2_3w8i6ry97,False,,0,False,Book recommendations,[],r/datascience,False,6,discussion,0,,,False,t3_18hvowg,False,dark,1.0,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,False,self,1702585420.0,,[],{},,True,,1702513505.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi ,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking for some book recommendations - I want to upskill before I start a new job-my first Data Scientist job - this one is EDA heavy - and ML too. its a start up so I want to perform well.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d like to know your recommendations for&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Dealing with different kinds of data - for example - In the take home test I was given - there is a quantity - different kinds of capacitance - the range was very very small - and how to find outliers - the box plots could not show anything.  I want to get better at that kind of analysis and EDA.&lt;/li&gt;
&lt;li&gt;Model Deployment - this area is new to me . I think they use AWS - any courses or primers that I can do.&lt;/li&gt;
&lt;li&gt;Advanced visualization  - we&amp;#39;re trying different kinds of visualization. I already know how to use matplotlib,seaborn and basic libraries - but the more interactive ones - from basic to advanced(Will tableau be useful?)&lt;/li&gt;
&lt;li&gt;How to deal with massive amounts of data - we will be processing and creating files and sorting through 1 billion data points.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Please?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18hvowg,True,,Fearless-Soup-2583,,6,True,all_ads,False,[],False,,/r/datascience/comments/18hvowg/book_recommendations/,all_ads,False,https://www.reddit.com/r/datascience/comments/18hvowg/book_recommendations/,1209065,1702513505.0,0,,False,,,,,,,,,,1015,196
,datascience," Looking at the job boards on LinkedIn - there is a Biostatistician  position with Orbis Clinical which has 1,697 applicants already. Saw another posting with over 500 applicants. Insane.  ",t2_6cjiszgb,False,,0,False,What's up with the data scientist/statistician job market?,[],r/datascience,False,6,discussion,0,,,False,t3_18hudn7,False,dark,0.84,,public,95,0,{},,,False,[],,False,False,,{},Discussion,False,95,,False,False,self,False,,[],{},,True,,1702509854.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Looking at the job boards on LinkedIn - there is a Biostatistician  position with Orbis Clinical which has 1,697 applicants already. Saw another posting with over 500 applicants. Insane.  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18hudn7,True,,RobertWF_47,,141,True,all_ads,False,[],False,,/r/datascience/comments/18hudn7/whats_up_with_the_data_scientiststatistician_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/18hudn7/whats_up_with_the_data_scientiststatistician_job/,1209065,1702509854.0,0,,False,,,,,,,,,,189,29
,datascience,"Hey there,

I am having trouble achieving what I would like for a POC gradio app to demonstrate what the top 5 predicted matching images are to go with an input and also display some associated text that explains the predictions at the same time. There are actually multiple pieces of text but I cant even get an example with just one text and one image for each of the top 5 results to work. 

My function find_top_n() currently returns a tuple of two lists - product_ids and product_images of length n (lets say n=5). I have an input drop down where they select the source product and then it should be able to show the top 5 matches and some associated data. 

I can get it to display the top 5 product_ids that match by returning a list and using `outputs=[gr.Textbox(label=f""Product {i+1}"") for i in range(5)]` to generate 5 Textboxes fine. I can also get it to return a single product with a single string and single image and display that ok by using blocks and a list for output in the listener `outputs=[product_name, product_image]`.

What I cannot find any way to do or any example for is those outputs to be two lists. I get AttributeError: 'list' object has no attribute '_id' error.",t2_nxbnl,False,,0,False,Gradio deployment Q: how to display lists of images and text as outputs,[],r/datascience,False,6,tooling,0,,,False,t3_18hlmvj,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1702487394.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;I am having trouble achieving what I would like for a POC gradio app to demonstrate what the top 5 predicted matching images are to go with an input and also display some associated text that explains the predictions at the same time. There are actually multiple pieces of text but I cant even get an example with just one text and one image for each of the top 5 results to work. &lt;/p&gt;

&lt;p&gt;My function find_top_n() currently returns a tuple of two lists - product_ids and product_images of length n (lets say n=5). I have an input drop down where they select the source product and then it should be able to show the top 5 matches and some associated data. &lt;/p&gt;

&lt;p&gt;I can get it to display the top 5 product_ids that match by returning a list and using &lt;code&gt;outputs=[gr.Textbox(label=f&amp;quot;Product {i+1}&amp;quot;) for i in range(5)]&lt;/code&gt; to generate 5 Textboxes fine. I can also get it to return a single product with a single string and single image and display that ok by using blocks and a list for output in the listener &lt;code&gt;outputs=[product_name, product_image]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;What I cannot find any way to do or any example for is those outputs to be two lists. I get AttributeError: &amp;#39;list&amp;#39; object has no attribute &amp;#39;_id&amp;#39; error.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18hlmvj,True,,And_Ends_Battle,,2,True,all_ads,False,[],False,,/r/datascience/comments/18hlmvj/gradio_deployment_q_how_to_display_lists_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/18hlmvj/gradio_deployment_q_how_to_display_lists_of/,1209065,1702487394.0,0,,False,,,,,,,,,,1196,215
,datascience,"Basically just interested in whether any of you have had any trouble with non compete clauses or with leaving a past role in general. I’m considering a career switch but I’m not entirely sure what would be fair grounds to enforce something like a non compete? As a data scientist you’re likely to recycle skills you applied across a number of roles, so I was particularly interested in a DS’s view on this.

Thanks in advance for proving any input!",t2_swkdetcu,False,,0,False,Non compete clause? (Europe),[],r/datascience,False,6,fun,0,,,False,t3_18hkw2z,False,dark,0.8,,public,6,0,{},,,False,[],,False,False,,{},Career Discussion,False,6,,False,False,self,False,,[],{},,True,,1702485555.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Basically just interested in whether any of you have had any trouble with non compete clauses or with leaving a past role in general. I’m considering a career switch but I’m not entirely sure what would be fair grounds to enforce something like a non compete? As a data scientist you’re likely to recycle skills you applied across a number of roles, so I was particularly interested in a DS’s view on this.&lt;/p&gt;

&lt;p&gt;Thanks in advance for proving any input!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18hkw2z,True,,StoicPanda5,,6,True,all_ads,False,[],False,,/r/datascience/comments/18hkw2z/non_compete_clause_europe/,all_ads,False,https://www.reddit.com/r/datascience/comments/18hkw2z/non_compete_clause_europe/,1209065,1702485555.0,0,,False,,,,,,,,,,448,80
,datascience,"I'm considering accepting a job with 3-month notice period (after probation), and this seems long. One concern is when applying for new jobs, would you be at a disadvantage if your notice period is a whopping 3 months? It's difficult enough to compete for roles in this tough market, but then you add the fact that you'll not be able to start for 3 months, wouldn't you be at a disadvantage relatively to those who can start sooner? I don't know, just beginning to second-guess myself here. For people here who are hiring, would you look differently at a candidate with a 3-month notice period?",t2_7dpje88o,False,,0,False,How common are jobs with 3 month notice period?,[],r/datascience,False,6,fun,0,,,False,t3_18hh551,False,dark,0.87,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,False,self,False,,[],{},,True,,1702475212.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m considering accepting a job with 3-month notice period (after probation), and this seems long. One concern is when applying for new jobs, would you be at a disadvantage if your notice period is a whopping 3 months? It&amp;#39;s difficult enough to compete for roles in this tough market, but then you add the fact that you&amp;#39;ll not be able to start for 3 months, wouldn&amp;#39;t you be at a disadvantage relatively to those who can start sooner? I don&amp;#39;t know, just beginning to second-guess myself here. For people here who are hiring, would you look differently at a candidate with a 3-month notice period?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18hh551,True,,neelankatan,,43,True,all_ads,False,[],False,,/r/datascience/comments/18hh551/how_common_are_jobs_with_3_month_notice_period/,all_ads,False,https://www.reddit.com/r/datascience/comments/18hh551/how_common_are_jobs_with_3_month_notice_period/,1209065,1702475212.0,0,,False,,,,,,,,,,594,105
,datascience,Is it possible to go from DS to MLE without a CS background but an adjacent stem degree? Did an MS in stats and wondering if swe skills learned from a DS job could transfer over to a MLE role. Any insights?,t2_uy28jztl,False,,0,False,DS to MLE/SWE with no CS degree,[],r/datascience,False,6,fun,0,,,False,t3_18h88e0,False,dark,0.81,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1702440683.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to go from DS to MLE without a CS background but an adjacent stem degree? Did an MS in stats and wondering if swe skills learned from a DS job could transfer over to a MLE role. Any insights?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18h88e0,True,,Direct-Touch469,,17,True,all_ads,False,[],False,,/r/datascience/comments/18h88e0/ds_to_mleswe_with_no_cs_degree/,all_ads,False,https://www.reddit.com/r/datascience/comments/18h88e0/ds_to_mleswe_with_no_cs_degree/,1209065,1702440683.0,0,,False,,,,,,,,,,206,42
,datascience,"In my day-to-day, I use R, Python, SQL, PowerBI, Excel, but I’m most familiar with R. Today I was struggling with DAX in creating a measure in PowerBI. I’m still new to it so I couldn’t really find a solution, not even a complicated one, so I resorted back to R, to manipulate my data so that I don’t have to mess with the DAX.

How often do you do this at work? And do you think this is good practice? When should you do it and when shouldn’t you?",t2_jbfeybb1,False,,0,False,How often do you resort back to the language you’re most comfortable with?,[],r/datascience,False,6,tooling,0,,,False,t3_18h5n7e,False,dark,0.93,,public,48,0,{},,,False,[],,False,False,,{},Tools,False,48,,False,False,self,False,,[],{},,True,,1702433278.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my day-to-day, I use R, Python, SQL, PowerBI, Excel, but I’m most familiar with R. Today I was struggling with DAX in creating a measure in PowerBI. I’m still new to it so I couldn’t really find a solution, not even a complicated one, so I resorted back to R, to manipulate my data so that I don’t have to mess with the DAX.&lt;/p&gt;

&lt;p&gt;How often do you do this at work? And do you think this is good practice? When should you do it and when shouldn’t you?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18h5n7e,True,,bernful,,40,True,all_ads,False,[],False,,/r/datascience/comments/18h5n7e/how_often_do_you_resort_back_to_the_language/,all_ads,False,https://www.reddit.com/r/datascience/comments/18h5n7e/how_often_do_you_resort_back_to_the_language/,1209065,1702433278.0,0,,False,,,,,,,,,,448,90
,datascience,"Are there open source LLM projects or products that specialize in inference on tabular data? I am interested in interacting with a chat bot about trends in tabular data. I’m not looking for modeling or prediction, just to ask questions about the data.",t2_bvf1unh0,False,,0,False,Using LLM’s to Understand Tabular Data,[],r/datascience,False,6,discussion,0,,,False,t3_18h12p4,False,dark,0.2,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1702424540.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are there open source LLM projects or products that specialize in inference on tabular data? I am interested in interacting with a chat bot about trends in tabular data. I’m not looking for modeling or prediction, just to ask questions about the data.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18h12p4,True,,traveler-2443,,6,True,all_ads,False,[],False,,/r/datascience/comments/18h12p4/using_llms_to_understand_tabular_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/18h12p4/using_llms_to_understand_tabular_data/,1209065,1702424540.0,0,,False,,,,,,,,,,251,43
,datascience,I have conda which works great for me because of all the features. I have other (non DS) people who need to install basic python libraries and run basic python scripts. Would conda be good for them or is it more than necessary? I know I can download python directly but I've never done that so I don't know if it's more or less confusing than conda.,t2_kcl3tfwe,False,,0,False,What's the simplest way to get Python on a Windows PC?,[],r/datascience,False,6,tooling,0,,,False,t3_18h0fey,False,dark,0.34,,public,0,0,{},,,False,[],,False,False,,{},Tools,False,0,,False,False,self,False,,[],{},,True,,1702423344.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have conda which works great for me because of all the features. I have other (non DS) people who need to install basic python libraries and run basic python scripts. Would conda be good for them or is it more than necessary? I know I can download python directly but I&amp;#39;ve never done that so I don&amp;#39;t know if it&amp;#39;s more or less confusing than conda.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18h0fey,True,,NewEcho2940,,41,True,all_ads,False,[],False,,/r/datascience/comments/18h0fey/whats_the_simplest_way_to_get_python_on_a_windows/,all_ads,False,https://www.reddit.com/r/datascience/comments/18h0fey/whats_the_simplest_way_to_get_python_on_a_windows/,1209065,1702423344.0,0,,False,,,,,,,,,,349,67
,datascience,"Things like presentations, working with stakeholders, etc.",t2_89ar1fajx,False,,0,False,"How long did it take you to get the hang of some of the ""soft skills"" of the job and do you have any advice for getting better at those?",[],r/datascience,False,6,,0,,,False,t3_18gyvf6,False,dark,0.95,,public,79,0,{},,,False,[],,False,False,,{},Challenges,False,79,,False,False,self,False,,[],{},,True,,1702420551.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Things like presentations, working with stakeholders, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,18gyvf6,True,,AnxiousEgg6284,,42,True,all_ads,False,[],False,,/r/datascience/comments/18gyvf6/how_long_did_it_take_you_to_get_the_hang_of_some/,all_ads,False,https://www.reddit.com/r/datascience/comments/18gyvf6/how_long_did_it_take_you_to_get_the_hang_of_some/,1209065,1702420551.0,0,,False,,,,,,,,,,58,7
,datascience,Has anyone ever worked in the mortgage lending industry doing data science? What was the culture/work-life balance like? What were some projects you worked on? Do you recommend it?,t2_a5id8l8c,False,,0,False,DS for Mortgage Lending,[],r/datascience,False,6,fun,0,,,False,t3_18grp3k,False,dark,0.86,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1702403143.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone ever worked in the mortgage lending industry doing data science? What was the culture/work-life balance like? What were some projects you worked on? Do you recommend it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18grp3k,True,,One-Material-9492,,11,True,all_ads,False,[],False,,/r/datascience/comments/18grp3k/ds_for_mortgage_lending/,all_ads,False,https://www.reddit.com/r/datascience/comments/18grp3k/ds_for_mortgage_lending/,1209065,1702403143.0,0,,False,,,,,,,,,,180,29
,datascience,"I've read in google that they prefer linux over windows because it is faster and better for programming

&amp;#x200B;

Is it true you use linux instead of windows? I find it pretty interesting lol",t2_ngyxf,False,,0,False,Is it true data scientists work in Linux?,[],r/datascience,False,6,discussion,0,,,False,t3_18gl9jv,False,dark,0.44,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1702385787.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve read in google that they prefer linux over windows because it is faster and better for programming&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is it true you use linux instead of windows? I find it pretty interesting lol&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18gl9jv,True,,Aston28,,121,True,all_ads,False,[],False,,/r/datascience/comments/18gl9jv/is_it_true_data_scientists_work_in_linux/,all_ads,False,https://www.reddit.com/r/datascience/comments/18gl9jv/is_it_true_data_scientists_work_in_linux/,1209065,1702385787.0,0,,False,,,,,,,,,,196,34
,datascience,"I recently was applying to a job in my specific field of expertise. It is essentially a data science job -- python / pytorch, reccomendation/search algorithms, big data etc. Well written, but well within the distribution of data scientist   


The job title, however, was very specific to the field. E.g., if it was in healthcare it'd be something like 'Customer Healthcare Sr. Scientist.' Accurate to the job.  


It's been up for three days and only has 13 'applications' on Linkedin (really just clicks on the link). Maybe this is a solution to the job application spammers? Don't make your job as easy to find for people who aren't really looking? ",t2_1zkrsyfq,False,,0,False,"Trick for hiring managers to reduce the spam applicants: don't use the job title ""Data Scientist?""",[],r/datascience,False,6,discussion,0,,,False,t3_18g9ot3,False,dark,0.88,,public,184,0,{},,,False,[],,False,False,,{},Discussion,False,184,,False,False,self,False,,[],{},,True,,1702343261.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently was applying to a job in my specific field of expertise. It is essentially a data science job -- python / pytorch, reccomendation/search algorithms, big data etc. Well written, but well within the distribution of data scientist   &lt;/p&gt;

&lt;p&gt;The job title, however, was very specific to the field. E.g., if it was in healthcare it&amp;#39;d be something like &amp;#39;Customer Healthcare Sr. Scientist.&amp;#39; Accurate to the job.  &lt;/p&gt;

&lt;p&gt;It&amp;#39;s been up for three days and only has 13 &amp;#39;applications&amp;#39; on Linkedin (really just clicks on the link). Maybe this is a solution to the job application spammers? Don&amp;#39;t make your job as easy to find for people who aren&amp;#39;t really looking? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18g9ot3,True,,Any-Fig-921,,48,True,all_ads,False,[],False,,/r/datascience/comments/18g9ot3/trick_for_hiring_managers_to_reduce_the_spam/,all_ads,False,https://www.reddit.com/r/datascience/comments/18g9ot3/trick_for_hiring_managers_to_reduce_the_spam/,1209065,1702343261.0,0,,False,,,,,,,,,,652,110
,datascience,"Thanks for all of your support in recent days by giving me feedback on my NLP outline. It builds on work that I have done at AT&amp;T and Toyota. It also builds on a lot of work that I have done on my own outside of corporations. 

The outline is solid, and as my way of giving back to the community, I am it giving away for free. That's right, no annoying email sign-up. No gimmicks. No asking you to buy a timeshare in Florida at the end of the  outline. It's just a link to a zip file which contains the outline and sample code. 

Here is how it works. First, you need to know Python. If you don't know that, then look up how to learn Python on Google. Second, this is an outline, you need to look at each part, go through the links, and really digest the material before moving on. Third, every part of the outline is dense; there is no fluff, and you will will probably need to do multiple passes through the outline.

Also, think of this outline as a gift. It is being provided without warranty, or any guarantee of any kind.  

If you like the outline, hit that share button and share this with someone. Maybe it will help them as well. 

Ok, here is the outline. 

[https://drive.google.com/file/d/1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive\_link](https://drive.google.com/file/d/1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link)

If you have any questions, leave a comment in the section below. If the questions are more specific to what you are doing (and if they are not part of a general conversation), feel free to ask me in Reddit Chat. 

https://preview.redd.it/h0g0fnrqup5c1.png?width=549&amp;format=png&amp;auto=webp&amp;s=246017d349ec09e88d9804c1bb1e61ee8d0fc170

&amp;#x200B;

https://preview.redd.it/r9dczx0vup5c1.png?width=547&amp;format=png&amp;auto=webp&amp;s=2dbc09e7cd586faa8dd41b6d66032349717634c0",t2_cai9i4bo,False,,0,False,"Happy Holidays! Here is the complete 100% free, NLP and LLM Outline",[],r/datascience,False,6,meta,0,124.0,,False,t3_18g1r9f,False,dark,0.96,,public,94,0,{},140.0,,True,[],,False,False,,{},Projects,False,94,,False,False,https://a.thumbs.redditmedia.com/4B7cBVrreSJHLK0NtEfOMxkBIfcJEShGkH1ToDG-Rn0.jpg,False,,[],{},,True,,1702322769.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Thanks for all of your support in recent days by giving me feedback on my NLP outline. It builds on work that I have done at AT&amp;amp;T and Toyota. It also builds on a lot of work that I have done on my own outside of corporations. &lt;/p&gt;

&lt;p&gt;The outline is solid, and as my way of giving back to the community, I am it giving away for free. That&amp;#39;s right, no annoying email sign-up. No gimmicks. No asking you to buy a timeshare in Florida at the end of the  outline. It&amp;#39;s just a link to a zip file which contains the outline and sample code. &lt;/p&gt;

&lt;p&gt;Here is how it works. First, you need to know Python. If you don&amp;#39;t know that, then look up how to learn Python on Google. Second, this is an outline, you need to look at each part, go through the links, and really digest the material before moving on. Third, every part of the outline is dense; there is no fluff, and you will will probably need to do multiple passes through the outline.&lt;/p&gt;

&lt;p&gt;Also, think of this outline as a gift. It is being provided without warranty, or any guarantee of any kind.  &lt;/p&gt;

&lt;p&gt;If you like the outline, hit that share button and share this with someone. Maybe it will help them as well. &lt;/p&gt;

&lt;p&gt;Ok, here is the outline. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://drive.google.com/file/d/1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link""&gt;https://drive.google.com/file/d/1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you have any questions, leave a comment in the section below. If the questions are more specific to what you are doing (and if they are not part of a general conversation), feel free to ask me in Reddit Chat. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/h0g0fnrqup5c1.png?width=549&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=246017d349ec09e88d9804c1bb1e61ee8d0fc170""&gt;https://preview.redd.it/h0g0fnrqup5c1.png?width=549&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=246017d349ec09e88d9804c1bb1e61ee8d0fc170&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/r9dczx0vup5c1.png?width=547&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2dbc09e7cd586faa8dd41b6d66032349717634c0""&gt;https://preview.redd.it/r9dczx0vup5c1.png?width=547&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2dbc09e7cd586faa8dd41b6d66032349717634c0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18g1r9f,True,,whiteowled,,24,True,all_ads,False,[],False,,/r/datascience/comments/18g1r9f/happy_holidays_here_is_the_complete_100_free_nlp/,all_ads,False,https://www.reddit.com/r/datascience/comments/18g1r9f/happy_holidays_here_is_the_complete_100_free_nlp/,1209065,1702322769.0,1,,False,"{'h0g0fnrqup5c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 96, 'x': 108, 'u': 'https://preview.redd.it/h0g0fnrqup5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=32552f4cb2c1b81abd91a210ad5653ed714c6bc1'}, {'y': 192, 'x': 216, 'u': 'https://preview.redd.it/h0g0fnrqup5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b782815c9d43fc191cff0d0a0e18666d31c4419'}, {'y': 284, 'x': 320, 'u': 'https://preview.redd.it/h0g0fnrqup5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd0170926e796699f623fd0d1c300156b76edaa3'}], 's': {'y': 488, 'x': 549, 'u': 'https://preview.redd.it/h0g0fnrqup5c1.png?width=549&amp;format=png&amp;auto=webp&amp;s=246017d349ec09e88d9804c1bb1e61ee8d0fc170'}, 'id': 'h0g0fnrqup5c1'}, 'r9dczx0vup5c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 124, 'x': 108, 'u': 'https://preview.redd.it/r9dczx0vup5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=092dd861033b7e0ceb6e0eccd5994532b068f1b7'}, {'y': 249, 'x': 216, 'u': 'https://preview.redd.it/r9dczx0vup5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe90c844d776d411263f184e67de0adadc043ba0'}, {'y': 370, 'x': 320, 'u': 'https://preview.redd.it/r9dczx0vup5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca5d8e43969a0cf2cff3d30dd49159f5ecacd7f2'}], 's': {'y': 633, 'x': 547, 'u': 'https://preview.redd.it/r9dczx0vup5c1.png?width=547&amp;format=png&amp;auto=webp&amp;s=2dbc09e7cd586faa8dd41b6d66032349717634c0'}, 'id': 'r9dczx0vup5c1'}}",,,,,,,,,1834,271
,datascience,"Hey guys! I work at [Taipy](https://github.com/Avaiga/taipy); we are a Python library designed to create web applications using only Python. Some users had problems displaying charts based on big data, e.g., line charts with 100,000 points. We worked on a feature to reduce the number of displayed points while retaining the shape of the curve as much as possible and wanted to share how we did it. Feel free to take a look [here](https://www.taipy.io/posts/python-charting-taming-big-data-without-crashing):

https://preview.redd.it/nwvr7dt4po5c1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=66ab53fdcd729920ceb26b3d7184cc5253c251e2",t2_4qttbe,False,,0,False,"Plotting 1,000,000 points on a webpage using only Python",[],r/datascience,False,6,tooling,0,120.0,,False,t3_18fx3c6,False,dark,0.9,,public,38,0,{},140.0,,True,[],,False,False,,{},Tools,False,38,,False,False,https://b.thumbs.redditmedia.com/lmbCmlEx-rEpjuCb82tCdbF-MtsKyRPxItXSOl3gsRA.jpg,False,,[],{},,True,,1702308518.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys! I work at &lt;a href=""https://github.com/Avaiga/taipy""&gt;Taipy&lt;/a&gt;; we are a Python library designed to create web applications using only Python. Some users had problems displaying charts based on big data, e.g., line charts with 100,000 points. We worked on a feature to reduce the number of displayed points while retaining the shape of the curve as much as possible and wanted to share how we did it. Feel free to take a look &lt;a href=""https://www.taipy.io/posts/python-charting-taming-big-data-without-crashing""&gt;here&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/nwvr7dt4po5c1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=66ab53fdcd729920ceb26b3d7184cc5253c251e2""&gt;https://preview.redd.it/nwvr7dt4po5c1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=66ab53fdcd729920ceb26b3d7184cc5253c251e2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18fx3c6,True,,Alyx1337,,19,True,all_ads,False,[],False,,/r/datascience/comments/18fx3c6/plotting_1000000_points_on_a_webpage_using_only/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fx3c6/plotting_1000000_points_on_a_webpage_using_only/,1209065,1702308518.0,0,,False,"{'nwvr7dt4po5c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 92, 'x': 108, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4afd797a47195d33a23d659c66dccb5510e0f168'}, {'y': 185, 'x': 216, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6324253381bc2728ac4fda761ba6eb2487d75a23'}, {'y': 275, 'x': 320, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=151b5b8542b6dde93c6171fbe1b709e9a07391b7'}, {'y': 550, 'x': 640, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d355f81095ad690b60ba9d3a0e839a74be04d05'}, {'y': 826, 'x': 960, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=61e16dd54dcb7290ea699fc351101b239f60e43c'}], 's': {'y': 910, 'x': 1057, 'u': 'https://preview.redd.it/nwvr7dt4po5c1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=66ab53fdcd729920ceb26b3d7184cc5253c251e2'}, 'id': 'nwvr7dt4po5c1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?auto=webp&amp;s=c6104cd88b8507fb6c81287302e09008fdba8fc9', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97b40a1d7b5c701670c46129d7df09e72c325bb2', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0bd748ba8f7375bfa4986cc4995b413c98b9cfe7', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45fa4d3473d2194546b1239b395b41a6cd736f4f', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22a3328ccd78d74f4b7d56168d8c3963572f94f9', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6fa6c4e9c3dd8f99814e90ae2dfc34d41fc342e7', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/kD_I7XP6jK_427IG7I8mLv9a5w9S99f2RC_9NuBgQ0Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=08891e9144b49b86535e90008554ce5754b75e14', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'X26BV2P93TgUxZrf-YmwcBrc42n1gXvB6JLd1vbyb84'}], 'enabled': False}",,,,,,,638,74
,datascience," \[Note- Posting this question here as I haven't received responses in the MLOps community\]

Hi all,

I'm a fairly experienced data scientist and I've built and ""deployed"" multiple ML models in my career. I want to dive into the principles of MLOps in a fairly comprehensive and systematic manner. I am not merely interested in tools like MLFlow etc but I want to get my hands really dirty and design a 'simple' tool from scratch that implements key MLOps concepts. It sounds like an ambitious project but I have enough time on my hands (6-8 months, or even 1 year) to work on this and grow my software development skills.

Here is what I know.

1. Python- intermediate level (including iteratables/iterators, generators, decorators, context managers, dictionaries and basic OO programming)
2. Data science and ML - almost all the well known ML algorithms
3. CS knowledge: simple data structures (arrays, linkedlists, graphs, hash tables, trees), basics of how a computer is organized, how networks work, how databases work - nothing more, nothing too complicated.

Here is what I'm currently learning.

1. AWS tools and machine learning in AWS
2. Concurrent programming in Python
3. FastAPI
4. Software design principles- I **SUCK** AT SOFTWARE DEVELOPMENT!!

My purpose of implementing an MLOps tool from scratch are two-fold.

1. To get better at software development
2. To understand how MLOps tools work internally

ML is something I work on a daily basis and software development is a skill that I want to improve. MLOps is needed pretty much everywhere. By building something that I care about, I will be more consistent in my endeavors.

My metric for success is very simple- I should be **better** than what I am right now, 6-9 months in the future.

Apologies, if this idea sounds stupid. I need suggestions, and tips/tricks on how to go about it.

Regards!!",t2_7aj1qm5h,False,,0,False,MLOps- implementation in Python,[],r/datascience,False,6,meta,0,,,False,t3_18fhhs2,False,dark,0.97,,public,27,0,{},,,False,[],,False,False,,{},Projects,False,27,,False,False,self,False,,[],{},,True,,1702253747.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[Note- Posting this question here as I haven&amp;#39;t received responses in the MLOps community]&lt;/p&gt;

&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a fairly experienced data scientist and I&amp;#39;ve built and &amp;quot;deployed&amp;quot; multiple ML models in my career. I want to dive into the principles of MLOps in a fairly comprehensive and systematic manner. I am not merely interested in tools like MLFlow etc but I want to get my hands really dirty and design a &amp;#39;simple&amp;#39; tool from scratch that implements key MLOps concepts. It sounds like an ambitious project but I have enough time on my hands (6-8 months, or even 1 year) to work on this and grow my software development skills.&lt;/p&gt;

&lt;p&gt;Here is what I know.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Python- intermediate level (including iteratables/iterators, generators, decorators, context managers, dictionaries and basic OO programming)&lt;/li&gt;
&lt;li&gt;Data science and ML - almost all the well known ML algorithms&lt;/li&gt;
&lt;li&gt;CS knowledge: simple data structures (arrays, linkedlists, graphs, hash tables, trees), basics of how a computer is organized, how networks work, how databases work - nothing more, nothing too complicated.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is what I&amp;#39;m currently learning.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;AWS tools and machine learning in AWS&lt;/li&gt;
&lt;li&gt;Concurrent programming in Python&lt;/li&gt;
&lt;li&gt;FastAPI&lt;/li&gt;
&lt;li&gt;Software design principles- I &lt;strong&gt;SUCK&lt;/strong&gt; AT SOFTWARE DEVELOPMENT!!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My purpose of implementing an MLOps tool from scratch are two-fold.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;To get better at software development&lt;/li&gt;
&lt;li&gt;To understand how MLOps tools work internally&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ML is something I work on a daily basis and software development is a skill that I want to improve. MLOps is needed pretty much everywhere. By building something that I care about, I will be more consistent in my endeavors.&lt;/p&gt;

&lt;p&gt;My metric for success is very simple- I should be &lt;strong&gt;better&lt;/strong&gt; than what I am right now, 6-9 months in the future.&lt;/p&gt;

&lt;p&gt;Apologies, if this idea sounds stupid. I need suggestions, and tips/tricks on how to go about it.&lt;/p&gt;

&lt;p&gt;Regards!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18fhhs2,True,,madhav1113,,27,True,all_ads,False,[],False,,/r/datascience/comments/18fhhs2/mlops_implementation_in_python/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fhhs2/mlops_implementation_in_python/,1209064,1702253747.0,0,,False,,,,,,,,,,1869,311
,datascience,I work somewhere that has DS working closely with stakeholders and developers to experiment and then deliver DS/ML/AI solutions. I manage a team of DS and Devs and POs/PMs that help with Ops and the business side. I'm responsible for the work and the people.  Is this a thing anywhere else? What would you call it?,t2_5fp93,False,,0,False,Data Science Managers,[],r/datascience,False,6,fun,0,,,False,t3_18fg4rb,False,dark,0.83,,public,12,0,{},,,False,[],,False,False,,{},Career Discussion,False,12,,False,False,self,False,,[],{},,True,,1702249755.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work somewhere that has DS working closely with stakeholders and developers to experiment and then deliver DS/ML/AI solutions. I manage a team of DS and Devs and POs/PMs that help with Ops and the business side. I&amp;#39;m responsible for the work and the people.  Is this a thing anywhere else? What would you call it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18fg4rb,True,,trashed_culture,,22,True,all_ads,False,[],False,,/r/datascience/comments/18fg4rb/data_science_managers/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fg4rb/data_science_managers/,1209064,1702249755.0,0,,False,,,,,,,,,,314,56
,datascience,"I was just curious about what would be some small things that I should have at least basic knowledge of as they would probably help me progress. In my case, as a DS with about 2 yoe, I could say that learning the super basics of git and docker helped me somewhat, especially taking into account that they took only a couple of hours. On the other hand, having a very good math theoretical basis is for sure very important but takes much longer. ",t2_dfmfjyei,False,,0,False,"What are in your opinion the topics with the best cost/benefit (by cost I mean time dedicated) to advance your career as a DS, MLE or even SWE?",[],r/datascience,False,6,fun,0,,,False,t3_18fduey,False,dark,0.9,,public,28,0,{},,,False,[],,False,False,,{},Career Discussion,False,28,,False,False,self,False,,[],{},,True,,1702243581.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was just curious about what would be some small things that I should have at least basic knowledge of as they would probably help me progress. In my case, as a DS with about 2 yoe, I could say that learning the super basics of git and docker helped me somewhat, especially taking into account that they took only a couple of hours. On the other hand, having a very good math theoretical basis is for sure very important but takes much longer. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18fduey,True,,TheManveru,,16,True,all_ads,False,[],False,,/r/datascience/comments/18fduey/what_are_in_your_opinion_the_topics_with_the_best/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fduey/what_are_in_your_opinion_the_topics_with_the_best/,1209064,1702243581.0,0,,False,,,,,,,,,,445,84
,datascience," 

Many folks in the data science and machine learning world often hear the advice to stop doing endless tutorials and instead, ""Build something people actually want to use."" While it sounds great in theory, let's get real for a moment. Real-world systems aren't just about DS/ML; they come with a bunch of other stuff like frontend design, backend development, security, privacy, infrastructure, and deployment. Trying to master all of these by yourself is like chasing a unicorn.

So, is this advice setting us up to be jacks of all trades but masters of none? It's a legit concern, especially for newcomers. While it's awesome to build cool things, maybe the advice needs a little tweaking.",t2_5fbmh3va,False,,0,False,Is the 'Just Build Things' Advice a Good Approach for Newcomers Breaking into Data Science?,[],r/datascience,False,6,meta,0,,,False,t3_18fcuqf,False,dark,0.9,,public,100,0,{},,,False,[],,False,False,,{},Projects,False,100,,False,False,self,False,,[],{},,True,,1702240902.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Many folks in the data science and machine learning world often hear the advice to stop doing endless tutorials and instead, &amp;quot;Build something people actually want to use.&amp;quot; While it sounds great in theory, let&amp;#39;s get real for a moment. Real-world systems aren&amp;#39;t just about DS/ML; they come with a bunch of other stuff like frontend design, backend development, security, privacy, infrastructure, and deployment. Trying to master all of these by yourself is like chasing a unicorn.&lt;/p&gt;

&lt;p&gt;So, is this advice setting us up to be jacks of all trades but masters of none? It&amp;#39;s a legit concern, especially for newcomers. While it&amp;#39;s awesome to build cool things, maybe the advice needs a little tweaking.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18fcuqf,True,,Excellent_Cost170,,69,True,all_ads,False,[],False,,/r/datascience/comments/18fcuqf/is_the_just_build_things_advice_a_good_approach/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fcuqf/is_the_just_build_things_advice_a_good_approach/,1209064,1702240902.0,0,,False,,,,,,,,,,693,115
,datascience,"Basically the title. Interested to know what do industry experts would consider as essential skills/topics in Data Science (along with preferred tech stack used perhaps).

I am asking this as I am building up my portfolio for getting a Data Science internship and wonder when can I consider the breadth of topics I have covered to be enough to start applying for internships.

Currently, I have both theoretical and practical groundwork ready for these topics: Linear Regression, Logistic Regression, SVM, PCA, Näive Bayes, LDA, K-means Clustering, Decision Trees, Deep NN, CNN using seaborn, matplotlib, scikit-learn, keras, tensorflow for the tech stack. Would these be enough to start applying for internship?
Thanks!!",,False,,0,False,"What skills/topics would you consider essential for kickstarting a career in data science, say with an internship?",[],r/datascience,False,6,fun,0,,,False,t3_18fblw6,False,dark,0.77,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,,self,False,,,{},,True,,1702237598.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Basically the title. Interested to know what do industry experts would consider as essential skills/topics in Data Science (along with preferred tech stack used perhaps).&lt;/p&gt;

&lt;p&gt;I am asking this as I am building up my portfolio for getting a Data Science internship and wonder when can I consider the breadth of topics I have covered to be enough to start applying for internships.&lt;/p&gt;

&lt;p&gt;Currently, I have both theoretical and practical groundwork ready for these topics: Linear Regression, Logistic Regression, SVM, PCA, Näive Bayes, LDA, K-means Clustering, Decision Trees, Deep NN, CNN using seaborn, matplotlib, scikit-learn, keras, tensorflow for the tech stack. Would these be enough to start applying for internship?
Thanks!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18fblw6,True,,[deleted],,39,True,all_ads,False,[],,dark,/r/datascience/comments/18fblw6/what_skillstopics_would_you_consider_essential/,all_ads,False,https://www.reddit.com/r/datascience/comments/18fblw6/what_skillstopics_would_you_consider_essential/,1209064,1702237598.0,0,,False,,,,,,,,,,721,111
,datascience,"Speaking specifically on the data side of things, for data analysts, data scientists. How does it compare working private versus public? Lots of people have been telling me that working for a county government or something similar is the dream because it's so much easier you don't have to worry about shareholders anymore, no crunching as fast as you possibly can for month end for quarterly release of statements... Any advice?",t2_dmawn6hx,False,,0,False,Has anyone worked in government? How does it compare to private sector?,[],r/datascience,False,6,discussion,0,,,False,t3_18f349e,False,dark,0.91,#dadada,public,64,0,{},,d898d418-70eb-11ee-81d7-36bf4b44216b,False,[],,False,False,,{},Discussion,False,64,,False,False,self,1702220847.0,,[],{},,True,,1702213219.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Speaking specifically on the data side of things, for data analysts, data scientists. How does it compare working private versus public? Lots of people have been telling me that working for a county government or something similar is the dream because it&amp;#39;s so much easier you don&amp;#39;t have to worry about shareholders anymore, no crunching as fast as you possibly can for month end for quarterly release of statements... Any advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,Junior,[],False,,,,t5_2sptq,False,,,#1a1a1b,18f349e,True,,InevitableTraining69,,62,True,all_ads,False,[],False,dark,/r/datascience/comments/18f349e/has_anyone_worked_in_government_how_does_it/,all_ads,False,https://www.reddit.com/r/datascience/comments/18f349e/has_anyone_worked_in_government_how_does_it/,1209064,1702213219.0,0,,False,,,,,,,,,,429,71
,datascience,"Hi All, i have been given the task to do customer segmentation using clustering. My data is huge, 68M and we use pyspark, i cant convert it to a pandas df. however, i cant find anything solid on DBSCAN in pyspark, can someone pls help me out if they have done it? any resources would be great. 

PS the data is financial ",t2_aohlpzsv,False,,0,False,Clustering on pyspark,[],r/datascience,False,6,meta,0,,,False,t3_18f22lr,False,dark,0.85,,public,31,0,{},,,False,[],,False,False,,{},Projects,False,31,,False,False,self,False,,[],{},,True,,1702209479.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All, i have been given the task to do customer segmentation using clustering. My data is huge, 68M and we use pyspark, i cant convert it to a pandas df. however, i cant find anything solid on DBSCAN in pyspark, can someone pls help me out if they have done it? any resources would be great. &lt;/p&gt;

&lt;p&gt;PS the data is financial &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18f22lr,True,,LieTechnical1662,,27,True,all_ads,False,[],False,,/r/datascience/comments/18f22lr/clustering_on_pyspark/,all_ads,False,https://www.reddit.com/r/datascience/comments/18f22lr/clustering_on_pyspark/,1209064,1702209479.0,0,,False,,,,,,,,,,321,62
,datascience,"I only have about a year's experience in a ""sales-based"" organization. Like an organization where all of our products are sold on a commission basis the process moving through a pipeline of leads, opportunities win/loose type of thing. With my strong data modeling and visualization background, when they ask, ""are the sales managers doing this?"" I got it; when they ask ""on average how many days..."" or ""what percentage..."" no problem. But I am starting to anticipate a common ask ""the theory of everything""

I have been at this organization for only a short time, and I can start to see the formation that they're eventually they're going to start fussing about wanting a single representation of the entire pipeline in the way THEY think about it. With just rudimentary understanding of the domain Im blocked in dreaming up the end product. I just see each stage and how each stage are different type of question models and visualizations, Good claim time? Output: yes/no; Running average time of this step? All steps? This Stage? Output: numerical; Percentage of win/lost? Output Percentage; Reason for loss? Output Categorical/measured by category.

Does anyone have any cool or successful ideas, or tips and tricks I could start to consider so when it eventually the question does gets asked, I am ready with the skill, tools and building blocks prepared?",t2_1tgq8rm3,False,,0,False,Sales Pipeline Managment Tips &amp; Tricks from Experience?,[],r/datascience,False,6,,0,,,False,t3_18eoqnq,False,dark,0.84,,public,9,0,{},,,False,[],,False,False,,{},Challenges,False,9,,False,False,self,False,,[],{},,True,,1702160732.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I only have about a year&amp;#39;s experience in a &amp;quot;sales-based&amp;quot; organization. Like an organization where all of our products are sold on a commission basis the process moving through a pipeline of leads, opportunities win/loose type of thing. With my strong data modeling and visualization background, when they ask, &amp;quot;are the sales managers doing this?&amp;quot; I got it; when they ask &amp;quot;on average how many days...&amp;quot; or &amp;quot;what percentage...&amp;quot; no problem. But I am starting to anticipate a common ask &amp;quot;the theory of everything&amp;quot;&lt;/p&gt;

&lt;p&gt;I have been at this organization for only a short time, and I can start to see the formation that they&amp;#39;re eventually they&amp;#39;re going to start fussing about wanting a single representation of the entire pipeline in the way THEY think about it. With just rudimentary understanding of the domain Im blocked in dreaming up the end product. I just see each stage and how each stage are different type of question models and visualizations, Good claim time? Output: yes/no; Running average time of this step? All steps? This Stage? Output: numerical; Percentage of win/lost? Output Percentage; Reason for loss? Output Categorical/measured by category.&lt;/p&gt;

&lt;p&gt;Does anyone have any cool or successful ideas, or tips and tricks I could start to consider so when it eventually the question does gets asked, I am ready with the skill, tools and building blocks prepared?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,18eoqnq,True,,CleanDataDirtyMind,,2,True,all_ads,False,[],False,,/r/datascience/comments/18eoqnq/sales_pipeline_managment_tips_tricks_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/18eoqnq/sales_pipeline_managment_tips_tricks_from/,1209064,1702160732.0,0,,False,,,,,,,,,,1361,225
,datascience,"I’ve seen a number of “forecasting” data scientist positions online. The descriptions often demand skill sets in statistics relating to time series analysis, forecasting, and productionizing them. 

For any forecasting data scientist here, could you talk about what you do on a day to day basis?",t2_uy28jztl,False,,0,False,"Data scientists in forecasting roles, what’s your day to day?",[],r/datascience,False,6,fun,0,,,False,t3_18ekx9q,False,dark,0.95,,public,119,0,{},,,False,[],,False,False,,{},Career Discussion,False,119,,False,False,self,False,,[],{},,True,,1702149839.0,text,6,,,text,self.datascience,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve seen a number of “forecasting” data scientist positions online. The descriptions often demand skill sets in statistics relating to time series analysis, forecasting, and productionizing them. &lt;/p&gt;

&lt;p&gt;For any forecasting data scientist here, could you talk about what you do on a day to day basis?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ekx9q,True,,Direct-Touch469,,92,True,all_ads,False,[],False,,/r/datascience/comments/18ekx9q/data_scientists_in_forecasting_roles_whats_your/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ekx9q/data_scientists_in_forecasting_roles_whats_your/,1209064,1702149839.0,0,,False,,,,,,,,,,295,46
,datascience,"I am thinking of putting together an outline that represents a good way to go from beginner to expert in NLP. Feel like I have most of it done but there is always room for improvement. 

Without writing a book, I want the guide to take someone who has basic programming skills, and get them to the point where they are utilizing open-source, large language models (""AI"") in production. 

What else should I add to this outline?

&amp;#x200B;

https://preview.redd.it/vyfy743jab5c1.png?width=655&amp;format=png&amp;auto=webp&amp;s=38576b1c4c349587e776061adebc576132914971

https://preview.redd.it/gaaeouimab5c1.png?width=633&amp;format=png&amp;auto=webp&amp;s=d528cde4c444c8ed88d5fcd902830fb0a2629604",t2_cai9i4bo,False,,0,False,What is needed in a comprehensive outline on Natural Language Processing?,[],r/datascience,False,6,,0,140.0,,False,t3_18ejp1i,False,dark,0.81,,public,26,0,{},140.0,,True,[],,False,False,,{},AI,False,26,,False,False,https://b.thumbs.redditmedia.com/tTcw94pvoVIVrXi_F270T3LDmoNXtaAucarTnAnKSgI.jpg,False,,[],{},,True,,1702146413.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am thinking of putting together an outline that represents a good way to go from beginner to expert in NLP. Feel like I have most of it done but there is always room for improvement. &lt;/p&gt;

&lt;p&gt;Without writing a book, I want the guide to take someone who has basic programming skills, and get them to the point where they are utilizing open-source, large language models (&amp;quot;AI&amp;quot;) in production. &lt;/p&gt;

&lt;p&gt;What else should I add to this outline?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vyfy743jab5c1.png?width=655&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38576b1c4c349587e776061adebc576132914971""&gt;https://preview.redd.it/vyfy743jab5c1.png?width=655&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38576b1c4c349587e776061adebc576132914971&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gaaeouimab5c1.png?width=633&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d528cde4c444c8ed88d5fcd902830fb0a2629604""&gt;https://preview.redd.it/gaaeouimab5c1.png?width=633&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d528cde4c444c8ed88d5fcd902830fb0a2629604&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,2f731e52-70eb-11ee-bec5-5a5142e6a4d2,False,False,False,,[],False,,,,t5_2sptq,False,,,#46d160,18ejp1i,True,,whiteowled,,17,True,all_ads,False,[],False,,/r/datascience/comments/18ejp1i/what_is_needed_in_a_comprehensive_outline_on/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ejp1i/what_is_needed_in_a_comprehensive_outline_on/,1209064,1702146413.0,0,,False,"{'vyfy743jab5c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 122, 'x': 108, 'u': 'https://preview.redd.it/vyfy743jab5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb5e64d0762dc449064877322b0ee4ffbcd9d36c'}, {'y': 244, 'x': 216, 'u': 'https://preview.redd.it/vyfy743jab5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a5564cda61be25c7d76efefdeb8f8e41a9947e0c'}, {'y': 362, 'x': 320, 'u': 'https://preview.redd.it/vyfy743jab5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5be7ac97435fb7372525d0f4b22ee0608bd244f1'}, {'y': 725, 'x': 640, 'u': 'https://preview.redd.it/vyfy743jab5c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2db5f163805db58dd5b18a3b4b6ccc8aee58b12f'}], 's': {'y': 742, 'x': 655, 'u': 'https://preview.redd.it/vyfy743jab5c1.png?width=655&amp;format=png&amp;auto=webp&amp;s=38576b1c4c349587e776061adebc576132914971'}, 'id': 'vyfy743jab5c1'}, 'gaaeouimab5c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 94, 'x': 108, 'u': 'https://preview.redd.it/gaaeouimab5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2981bd2468e4d08a0ea1a258600a6160be6eba0f'}, {'y': 189, 'x': 216, 'u': 'https://preview.redd.it/gaaeouimab5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ca453a894ef6941788089d0d9a7b6465288cfa3e'}, {'y': 280, 'x': 320, 'u': 'https://preview.redd.it/gaaeouimab5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e38639add1b9ffe4911eb6bc38fd3f73a4383f95'}], 's': {'y': 554, 'x': 633, 'u': 'https://preview.redd.it/gaaeouimab5c1.png?width=633&amp;format=png&amp;auto=webp&amp;s=d528cde4c444c8ed88d5fcd902830fb0a2629604'}, 'id': 'gaaeouimab5c1'}}",,,,,,,,,699,80
,datascience,"I work as a data analyst doing ad hocs and daily/weekly reports. I use SQL to extract the data but other than that it's all manual in excel, they have no interest in powerBI or R. They won't let me use power query or macros/VBA.

I did a lot of R in my masters and I did courses on statistics, like linear regression and different parametric and non parametric tests and when to use them.

How is data science similar to statistics used for research?",t2_d51zenrcx,False,,0,False,"If you work as a data analyst and have a masters that included statistics, What's missing to bridge the gap to data science?",[],r/datascience,False,6,,0,,,False,t3_18eitjs,False,dark,0.95,,public,115,0,{},,,False,[],,False,False,,{},Statistics,False,115,,False,False,self,False,,[],{},,True,,1702143951.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work as a data analyst doing ad hocs and daily/weekly reports. I use SQL to extract the data but other than that it&amp;#39;s all manual in excel, they have no interest in powerBI or R. They won&amp;#39;t let me use power query or macros/VBA.&lt;/p&gt;

&lt;p&gt;I did a lot of R in my masters and I did courses on statistics, like linear regression and different parametric and non parametric tests and when to use them.&lt;/p&gt;

&lt;p&gt;How is data science similar to statistics used for research?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,18eitjs,True,,InsightSeeker99,,57,True,all_ads,False,[],False,,/r/datascience/comments/18eitjs/if_you_work_as_a_data_analyst_and_have_a_masters/,all_ads,False,https://www.reddit.com/r/datascience/comments/18eitjs/if_you_work_as_a_data_analyst_and_have_a_masters/,1209064,1702143951.0,0,,False,,,,,,,,,,450,85
,datascience,"Hi, the title is my experience in data science in summary, I posted here a while ago about book’s recommendations and you guys mentioned two important books that I am done with now ( hands on ml and statistical learning)
Where should I go next? What are other business concepts and thinking and technical tools I should learn?

I know nothing about cloud services so that might be a good place to start, I solved a good number of problems for my team (operations) with machine learning models, but it was all, you know, local, never deployed in production or anything serious, I did good pipelines on my laptop and dispatch routes with it but not on the system, just guidance and suggestions.

Your thoughts and recommendations are always appreciated.",t2_81zrh19oq,False,,0,False,If only your skillset is statistics (intermediate) and python and SQL and machine learning (SKlearn implementation and traditional statistical learning book) where would you go next?,[],r/datascience,False,6,fun,0,,,False,t3_18ebjro,False,dark,0.91,,public,73,0,{},,,False,[],,False,False,,{},Career Discussion,False,73,,False,False,self,False,,[],{},,True,,1702120812.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, the title is my experience in data science in summary, I posted here a while ago about book’s recommendations and you guys mentioned two important books that I am done with now ( hands on ml and statistical learning)
Where should I go next? What are other business concepts and thinking and technical tools I should learn?&lt;/p&gt;

&lt;p&gt;I know nothing about cloud services so that might be a good place to start, I solved a good number of problems for my team (operations) with machine learning models, but it was all, you know, local, never deployed in production or anything serious, I did good pipelines on my laptop and dispatch routes with it but not on the system, just guidance and suggestions.&lt;/p&gt;

&lt;p&gt;Your thoughts and recommendations are always appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18ebjro,True,,Careful_Engineer_700,,58,True,all_ads,False,[],False,,/r/datascience/comments/18ebjro/if_only_your_skillset_is_statistics_intermediate/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ebjro/if_only_your_skillset_is_statistics_intermediate/,1209064,1702120812.0,0,,False,,,,,,,,,,751,130
,datascience,"Just out of curiosity, how does one verify the legitimacy of a clustering algorithm on an n-dimensional input space? Assuming n &gt; 3",t2_3wr0pzmd,False,,0,False,Clustering on an n-dimensional input space,[],r/datascience,False,6,discussion,0,,,False,t3_18e97qr,False,dark,0.89,,public,14,0,{},,,False,[],,False,False,,{},Discussion,False,14,,False,False,self,False,,[],{},,True,,1702111093.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just out of curiosity, how does one verify the legitimacy of a clustering algorithm on an n-dimensional input space? Assuming n &amp;gt; 3&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18e97qr,True,,sARUcasm,,17,True,all_ads,False,[],False,,/r/datascience/comments/18e97qr/clustering_on_an_ndimensional_input_space/,all_ads,False,https://www.reddit.com/r/datascience/comments/18e97qr/clustering_on_an_ndimensional_input_space/,1209064,1702111093.0,0,,False,,,,,,,,,,134,23
,datascience,"I’m in a situation where I need to create a module/function that can take in a date, and a timeseries and find out when the uplift due to a festival kicks in (n? days before the festival), then measure the uplift in sales until the festival date/when the uplift ends. It should also be able to measure how long there’s a dip in sales post the festival. And also, very importantly if there’s an uplift and/or dip.

My current idea is to first run a linear regression to fit the sales using price and promos and then try to measure the above on the residuals.",t2_15nser,False,,0,False,How would you create an automated module that can find impact of festivals on sales,[],r/datascience,False,6,discussion,0,,,False,t3_18e0qcb,False,dark,0.7,,public,9,0,{},,,False,[],,False,False,,{},Discussion,False,9,,False,False,self,False,,[],{},,True,,1702080901.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m in a situation where I need to create a module/function that can take in a date, and a timeseries and find out when the uplift due to a festival kicks in (n? days before the festival), then measure the uplift in sales until the festival date/when the uplift ends. It should also be able to measure how long there’s a dip in sales post the festival. And also, very importantly if there’s an uplift and/or dip.&lt;/p&gt;

&lt;p&gt;My current idea is to first run a linear regression to fit the sales using price and promos and then try to measure the above on the residuals.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18e0qcb,True,,sarafpiyush98,,23,True,all_ads,False,[],False,,/r/datascience/comments/18e0qcb/how_would_you_create_an_automated_module_that_can/,all_ads,False,https://www.reddit.com/r/datascience/comments/18e0qcb/how_would_you_create_an_automated_module_that_can/,1209064,1702080901.0,0,,False,,,,,,,,,,557,105
,datascience,"Hi everyone, 

I'm a Data Analytics professional with 3 years as a Data Analyst and 1.5 years as an Analytics Consultant for a major Cloud Services company (similar to Snowflake or AWS).

I've been unemployed for 5 months, and looking for 3. A lot of the interviews I got from referrals pulled their consulting roles due to market conditions, so I'm looking in the DA/SDA space.

The search has been... tough, to say the very least. I developed a React website from scratch and embedded professional tableau public dashboards as a portfolio (I literally reskinned one that got me a job offer, so I know it's good), and I re-made my resume which was checked and OK'd by professional recruiters at my previous company and by a Lead Tech Recruiter who's been a recruiter for multiple tech companies successfully.

Despite that, I have maybe a 6-7% hit rate getting screening interviews, while I 100% of the time get screening interviews from referrals. I even dropped my comp expectations by 25% and still the hit rate remains low. I understand it's (A) a down market, and (B) December, so at the very least I'm looking to be 100% prepared for the Jan-Apr hiring window.

I'm not sure where I'm falling short, so I'd like to get a sense for my options of hiring someone to take a look at my process. 

If anyone has any positive experiences or suggestions of where to start searching for this search I would greatly appreciate it.",t2_883ga,False,,0,False,Recommendations for job search - may need professional assistance,[],r/datascience,False,6,fun,0,,,False,t3_18duwle,False,dark,0.53,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1702064791.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m a Data Analytics professional with 3 years as a Data Analyst and 1.5 years as an Analytics Consultant for a major Cloud Services company (similar to Snowflake or AWS).&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been unemployed for 5 months, and looking for 3. A lot of the interviews I got from referrals pulled their consulting roles due to market conditions, so I&amp;#39;m looking in the DA/SDA space.&lt;/p&gt;

&lt;p&gt;The search has been... tough, to say the very least. I developed a React website from scratch and embedded professional tableau public dashboards as a portfolio (I literally reskinned one that got me a job offer, so I know it&amp;#39;s good), and I re-made my resume which was checked and OK&amp;#39;d by professional recruiters at my previous company and by a Lead Tech Recruiter who&amp;#39;s been a recruiter for multiple tech companies successfully.&lt;/p&gt;

&lt;p&gt;Despite that, I have maybe a 6-7% hit rate getting screening interviews, while I 100% of the time get screening interviews from referrals. I even dropped my comp expectations by 25% and still the hit rate remains low. I understand it&amp;#39;s (A) a down market, and (B) December, so at the very least I&amp;#39;m looking to be 100% prepared for the Jan-Apr hiring window.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not sure where I&amp;#39;m falling short, so I&amp;#39;d like to get a sense for my options of hiring someone to take a look at my process. &lt;/p&gt;

&lt;p&gt;If anyone has any positive experiences or suggestions of where to start searching for this search I would greatly appreciate it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18duwle,True,,CarbonHero,,6,True,all_ads,False,[],False,,/r/datascience/comments/18duwle/recommendations_for_job_search_may_need/,all_ads,False,https://www.reddit.com/r/datascience/comments/18duwle/recommendations_for_job_search_may_need/,1209064,1702064791.0,0,,False,,,,,,,,,,1427,251
,datascience,"I feel like I'm fumbling through The first interview every time when I provide an example of my background. I kind of just go from one position to the next to the next describing what I've done at a very high level, but it's not very impactful, and I feel like I just kind of talk about it casually. I've gotten some feedback that I don't include the type of joins I've done in SQL or what scale of data I've done, and it doesn't feel like I'm very effective in explaining myself....


For reference, I'm a data analyst. Can someone explain like a very brief and concise example of how I could relay this information to a hiring manager?",t2_hdeet8zsc,False,,0,False,Can someone provide a good example of a summary of their background during a first interview?,[],r/datascience,False,6,discussion,0,,,False,t3_18dm8t8,False,dark,0.94,,public,27,0,{},,,False,[],,False,False,,{},Discussion,False,27,,False,False,self,False,,[],{},,True,,1702040186.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I feel like I&amp;#39;m fumbling through The first interview every time when I provide an example of my background. I kind of just go from one position to the next to the next describing what I&amp;#39;ve done at a very high level, but it&amp;#39;s not very impactful, and I feel like I just kind of talk about it casually. I&amp;#39;ve gotten some feedback that I don&amp;#39;t include the type of joins I&amp;#39;ve done in SQL or what scale of data I&amp;#39;ve done, and it doesn&amp;#39;t feel like I&amp;#39;m very effective in explaining myself....&lt;/p&gt;

&lt;p&gt;For reference, I&amp;#39;m a data analyst. Can someone explain like a very brief and concise example of how I could relay this information to a hiring manager?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18dm8t8,True,,databro92,,29,True,all_ads,False,[],False,,/r/datascience/comments/18dm8t8/can_someone_provide_a_good_example_of_a_summary/,all_ads,False,https://www.reddit.com/r/datascience/comments/18dm8t8/can_someone_provide_a_good_example_of_a_summary/,1209064,1702040186.0,0,,False,,,,,,,,,,637,120
,datascience,"Essentially title, have searched the sub for discussions on data product roles, but wanted to ask directly.

Additionally, are data products within the wheelhouse of data scientists?",t2_3uoce3bn,False,,0,False,DS subreddit's opinion of data product roles?,[],r/datascience,False,6,discussion,0,,,False,t3_18dm70k,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1702040020.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Essentially title, have searched the sub for discussions on data product roles, but wanted to ask directly.&lt;/p&gt;

&lt;p&gt;Additionally, are data products within the wheelhouse of data scientists?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18dm70k,True,,Tender_Figs,,4,True,all_ads,False,[],False,,/r/datascience/comments/18dm70k/ds_subreddits_opinion_of_data_product_roles/,all_ads,False,https://www.reddit.com/r/datascience/comments/18dm70k/ds_subreddits_opinion_of_data_product_roles/,1209064,1702040020.0,0,,False,,,,,,,,,,182,27
,datascience,"Hello all,

My manager gave me 2 options of projects to work on.

 For background, I am a junior DS at a F500 company with a first 8 months project under my belt, which main’y consisted in classical machine learning for regression, with an optimisation under constraints, and some time series. I took the project from POC to integrating it in a working tool for engineers.

Will be working more on a time series study for 1-2 months, then I have 2 options :

Option A: working on anomaly detection algorithms with a big impact (our team needs to deliver something good in this segment next year). 

Option B: LLMs. Well mostly state of the art and evaluating impact of LLMs on our company’s business, finding a use case accordingly and building a simple POC.

Both seem interesting in their own ways. I’m looking to get meaningful experiences and I am interested in both topics. I know LLMs are hot right now, but anomaly detection is kind of a big thing where I am so I may be able to work with more data and deliver something that’s not yet another POC. 
I want to learn many things, does not know if I should specialize myself yet, but looking to work on things that I like, have real impact, and are great looking on my CV.

Any suggestions ?

Edit :

More info :

Basically part of my team works on a big data platform for the industry I work in, which gets a lot of data but usually raises too much false anomalies with the current algorithms. Important to know : AD is applied on time series.

As it’s one of the main products our team is known for, I think I might get a lot of exposure working on it.

Also, as it is the main product on the team, I am bound to work on AD at some point.

LLM applications might be multiple, like generating a report on the error for an anomaly detection, or other things I could find during a state of the art.

As said by a few comments, I think impact is better than just doing things that will go in the trash. I just wondered if the LLM hype was strong enough so adding it to my CV might be better when I evaluate other options in 1-3 years",t2_u9hbkgyx,False,,0,False,Which project to work on at my job ?,[],r/datascience,False,6,discussion,0,,,False,t3_18d9bm6,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,1702023767.0,,[],{},,True,,1701993171.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;My manager gave me 2 options of projects to work on.&lt;/p&gt;

&lt;p&gt;For background, I am a junior DS at a F500 company with a first 8 months project under my belt, which main’y consisted in classical machine learning for regression, with an optimisation under constraints, and some time series. I took the project from POC to integrating it in a working tool for engineers.&lt;/p&gt;

&lt;p&gt;Will be working more on a time series study for 1-2 months, then I have 2 options :&lt;/p&gt;

&lt;p&gt;Option A: working on anomaly detection algorithms with a big impact (our team needs to deliver something good in this segment next year). &lt;/p&gt;

&lt;p&gt;Option B: LLMs. Well mostly state of the art and evaluating impact of LLMs on our company’s business, finding a use case accordingly and building a simple POC.&lt;/p&gt;

&lt;p&gt;Both seem interesting in their own ways. I’m looking to get meaningful experiences and I am interested in both topics. I know LLMs are hot right now, but anomaly detection is kind of a big thing where I am so I may be able to work with more data and deliver something that’s not yet another POC. 
I want to learn many things, does not know if I should specialize myself yet, but looking to work on things that I like, have real impact, and are great looking on my CV.&lt;/p&gt;

&lt;p&gt;Any suggestions ?&lt;/p&gt;

&lt;p&gt;Edit :&lt;/p&gt;

&lt;p&gt;More info :&lt;/p&gt;

&lt;p&gt;Basically part of my team works on a big data platform for the industry I work in, which gets a lot of data but usually raises too much false anomalies with the current algorithms. Important to know : AD is applied on time series.&lt;/p&gt;

&lt;p&gt;As it’s one of the main products our team is known for, I think I might get a lot of exposure working on it.&lt;/p&gt;

&lt;p&gt;Also, as it is the main product on the team, I am bound to work on AD at some point.&lt;/p&gt;

&lt;p&gt;LLM applications might be multiple, like generating a report on the error for an anomaly detection, or other things I could find during a state of the art.&lt;/p&gt;

&lt;p&gt;As said by a few comments, I think impact is better than just doing things that will go in the trash. I just wondered if the LLM hype was strong enough so adding it to my CV might be better when I evaluate other options in 1-3 years&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18d9bm6,True,,LocPat,,14,True,all_ads,False,[],False,,/r/datascience/comments/18d9bm6/which_project_to_work_on_at_my_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/18d9bm6/which_project_to_work_on_at_my_job/,1209064,1701993171.0,0,,False,,,,,,,,,,2086,398
,datascience,"I'm sure you all know that nothing in statistics is certain, it's all probabilities and degrees of confidence. Well, I'm finding business people simply just don't comprehend that. The amount of times I've had to explain that correlation =/= causation, or why aggregate metrics based on very small sample sizes aren't reliable is insane. Like I get it's not their job to know stats and data science, but at some point these things should be common sense, and I shouldn't have to waste half a meeting explaining it for the 30th time.

And whenever I come back to them with some kind of result, I choose my words carefully, not to over promise, cause guess who's ass is on the line if I'm wrong. If I say ""increased advertising appears to be correlated with increased sales"", they hear ""spend more money on advertising"". They will then spend that money and if it doesn't work, I'm the one who apparently messed up.

I've been working around it by both choosing my words carefully and creating documentation. Kind of like a CYA, if they don't heed my warnings and it blows up in their faces, at least I can point back to them saying I told them. For the former, it's in one ear out the other, are increasingly happening in meetings where there is no official transcript I can point back to. They don't listen to any of my warnings about over-concluding from my results. As to the former, well I was told recently after doing a sales analysis that ""no one gives a fuck"" about my methodology or results. Drop it from the write up. They just want broad conclusions and actions. 

In my mind, my job is to tell them what I found and let them draw their own conclusions. I get that data science and stats aren't their job, but at the same job, sales isn't mine, so why am I making conclusions for sales people about what they should do?

IDK, I figure this is common for this field, so what do you guys do?",t2_abhp8o9x,False,,0,False,How do you deal with people wanting definite answers when statistics isn't deterministic?,[],r/datascience,False,6,discussion,0,,,False,t3_18d4sf5,False,dark,0.94,,public,120,0,{},,,False,[],,False,False,,{},Discussion,False,120,,False,False,self,False,,[],{},,True,,1701981058.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m sure you all know that nothing in statistics is certain, it&amp;#39;s all probabilities and degrees of confidence. Well, I&amp;#39;m finding business people simply just don&amp;#39;t comprehend that. The amount of times I&amp;#39;ve had to explain that correlation =/= causation, or why aggregate metrics based on very small sample sizes aren&amp;#39;t reliable is insane. Like I get it&amp;#39;s not their job to know stats and data science, but at some point these things should be common sense, and I shouldn&amp;#39;t have to waste half a meeting explaining it for the 30th time.&lt;/p&gt;

&lt;p&gt;And whenever I come back to them with some kind of result, I choose my words carefully, not to over promise, cause guess who&amp;#39;s ass is on the line if I&amp;#39;m wrong. If I say &amp;quot;increased advertising appears to be correlated with increased sales&amp;quot;, they hear &amp;quot;spend more money on advertising&amp;quot;. They will then spend that money and if it doesn&amp;#39;t work, I&amp;#39;m the one who apparently messed up.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been working around it by both choosing my words carefully and creating documentation. Kind of like a CYA, if they don&amp;#39;t heed my warnings and it blows up in their faces, at least I can point back to them saying I told them. For the former, it&amp;#39;s in one ear out the other, are increasingly happening in meetings where there is no official transcript I can point back to. They don&amp;#39;t listen to any of my warnings about over-concluding from my results. As to the former, well I was told recently after doing a sales analysis that &amp;quot;no one gives a fuck&amp;quot; about my methodology or results. Drop it from the write up. They just want broad conclusions and actions. &lt;/p&gt;

&lt;p&gt;In my mind, my job is to tell them what I found and let them draw their own conclusions. I get that data science and stats aren&amp;#39;t their job, but at the same job, sales isn&amp;#39;t mine, so why am I making conclusions for sales people about what they should do?&lt;/p&gt;

&lt;p&gt;IDK, I figure this is common for this field, so what do you guys do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18d4sf5,True,,son_of_tv_c,,109,True,all_ads,False,[],False,,/r/datascience/comments/18d4sf5/how_do_you_deal_with_people_wanting_definite/,all_ads,False,https://www.reddit.com/r/datascience/comments/18d4sf5/how_do_you_deal_with_people_wanting_definite/,1209064,1701981058.0,0,,False,,,,,,,,,,1897,348
,datascience,"When I was first hired as a DS, I was working on data analysis, statistics, and experimental design aspects. Whenever I did any ML, it was always just in a Jupyter notebook environment and didn't seem to go anywhere beyond that.

I want to delve deeper into some MLE/CS topics. for a variety of reasons. In the past year I have become more focused on putting ML models and data analysis into production. I want to be self sufficient. I don't like having to beg for help from a software engineer to make changes to the production environment. 

Can you suggest any beginner hands on tutorials on any of these topics:

1) Constructing python modules, including python requirements files, [setup.py](https://setup.py), etc.

2) deploying a module in a docker container

3) Constructing an API with #1 and #2? Not sure if this makes sense.

4) Other topics, such as Airflow, AWS, etc.",t2_f7akb,False,,0,False,Learning Resources for MLE/CS Topics,[],r/datascience,False,6,,0,,,False,t3_18d1lpm,False,dark,0.94,,public,13,0,{},,,False,[],,False,False,,{},Education,False,13,,False,False,self,False,,[],{},,True,,1701972680.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When I was first hired as a DS, I was working on data analysis, statistics, and experimental design aspects. Whenever I did any ML, it was always just in a Jupyter notebook environment and didn&amp;#39;t seem to go anywhere beyond that.&lt;/p&gt;

&lt;p&gt;I want to delve deeper into some MLE/CS topics. for a variety of reasons. In the past year I have become more focused on putting ML models and data analysis into production. I want to be self sufficient. I don&amp;#39;t like having to beg for help from a software engineer to make changes to the production environment. &lt;/p&gt;

&lt;p&gt;Can you suggest any beginner hands on tutorials on any of these topics:&lt;/p&gt;

&lt;p&gt;1) Constructing python modules, including python requirements files, &lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;, etc.&lt;/p&gt;

&lt;p&gt;2) deploying a module in a docker container&lt;/p&gt;

&lt;p&gt;3) Constructing an API with #1 and #2? Not sure if this makes sense.&lt;/p&gt;

&lt;p&gt;4) Other topics, such as Airflow, AWS, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,18d1lpm,True,,Dezireless,,4,True,all_ads,False,[],False,,/r/datascience/comments/18d1lpm/learning_resources_for_mlecs_topics/,all_ads,False,https://www.reddit.com/r/datascience/comments/18d1lpm/learning_resources_for_mlecs_topics/,1209064,1701972680.0,0,,False,,,,,,,,,,880,151
,datascience,"This is regarding the data scientist positions in the industry which are more research focused. Not business facing or product facing ones. I find in the research focused data scientist roles the main criteria is a PhD. However, I’m wondering if there are:

Any MS stats folks working in these types of jobs? 

And if PhDs are the ones hiring, do you exclusively hire PhDs for these roles as oppose to a MS with industry experience?",t2_i69qgpqa,False,,0,False,"For PhD data scientists in research focused roles, do you exclusively hire PhDs?",[],r/datascience,False,6,fun,0,,,False,t3_18cueea,False,dark,0.93,,public,85,0,{},,,False,[],,False,False,,{},Career Discussion,False,85,,False,False,self,False,,[],{},,True,,1701951539.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is regarding the data scientist positions in the industry which are more research focused. Not business facing or product facing ones. I find in the research focused data scientist roles the main criteria is a PhD. However, I’m wondering if there are:&lt;/p&gt;

&lt;p&gt;Any MS stats folks working in these types of jobs? &lt;/p&gt;

&lt;p&gt;And if PhDs are the ones hiring, do you exclusively hire PhDs for these roles as oppose to a MS with industry experience?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18cueea,True,,AdFew4357,,167,True,all_ads,False,[],False,,/r/datascience/comments/18cueea/for_phd_data_scientists_in_research_focused_roles/,all_ads,False,https://www.reddit.com/r/datascience/comments/18cueea/for_phd_data_scientists_in_research_focused_roles/,1209064,1701951539.0,0,,False,,,,,,,,,,432,76
,datascience,"I am working on a project where the client had a bunch of cameras connected to NVR. This is responsible for managing and maintaining the video stream from the camera. 

I need to create a POC with some AI capabilities like object detection on the video streams. 

I have attached a snippet of the home page below. Need help understanding more about how NVR works and how I can consume the video stream from a RTSP stream or any other streaming protocol.  


&amp;#x200B;

https://preview.redd.it/mn0dyil87v4c1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=40fcff2ea297f1d34c3df6c68cddc309b1dcf3fe",t2_aesv5hzu,False,,0,False,Need help figuring out an NVR ( Network video recorder),[],r/datascience,False,6,meta,0,71.0,,False,t3_18cudjt,False,dark,1.0,,public,9,0,{},140.0,,True,[],,False,False,,{},Projects,False,9,,False,False,https://b.thumbs.redditmedia.com/ossoHLt6lRBWycFj1ZeWwla59myv6MEtE59hYzkTa-w.jpg,False,,[],{},,True,,1701951455.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a project where the client had a bunch of cameras connected to NVR. This is responsible for managing and maintaining the video stream from the camera. &lt;/p&gt;

&lt;p&gt;I need to create a POC with some AI capabilities like object detection on the video streams. &lt;/p&gt;

&lt;p&gt;I have attached a snippet of the home page below. Need help understanding more about how NVR works and how I can consume the video stream from a RTSP stream or any other streaming protocol.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/mn0dyil87v4c1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=40fcff2ea297f1d34c3df6c68cddc309b1dcf3fe""&gt;https://preview.redd.it/mn0dyil87v4c1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=40fcff2ea297f1d34c3df6c68cddc309b1dcf3fe&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18cudjt,True,,Queasy_Commission316,,3,True,all_ads,False,[],False,,/r/datascience/comments/18cudjt/need_help_figuring_out_an_nvr_network_video/,all_ads,False,https://www.reddit.com/r/datascience/comments/18cudjt/need_help_figuring_out_an_nvr_network_video/,1209064,1701951455.0,0,,False,"{'mn0dyil87v4c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 55, 'x': 108, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9849da440b84cc6b660f2cf9d5ac2c8387ad2c'}, {'y': 110, 'x': 216, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=600cb03c04e28d6de2fa6eba068ed27f65d7397d'}, {'y': 164, 'x': 320, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dfc8032d08e7d94c949b4b5051191f14c0ef63a4'}, {'y': 328, 'x': 640, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=26384c00b2437f8bf93a8db2ac75ddd29d195144'}, {'y': 492, 'x': 960, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=28c849d1887a55eaeb90c237903af5fc062eec81'}, {'y': 554, 'x': 1080, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e655f870dc0f27b2aa6a59fcefa79f0eb206e0b3'}], 's': {'y': 985, 'x': 1920, 'u': 'https://preview.redd.it/mn0dyil87v4c1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=40fcff2ea297f1d34c3df6c68cddc309b1dcf3fe'}, 'id': 'mn0dyil87v4c1'}}",,,,,,,,,600,84
,datascience,"As per Scikit-learn's documentation, the `LogisticRegression` model is a specialised case of GLM, but for `LinearRegression` model, it is only mentioned under the OLS section. Is it a GLM model too? If not, the models described in the sub-section ""Usage"" of section ""Generalized Linear Models"" are GLM?",t2_3wr0pzmd,False,,0,False,Scikit-learn GLM models,[],r/datascience,False,6,projects,0,,,False,t3_18cq7g4,False,dark,0.86,,public,15,0,{},,,False,[],,False,False,,{},ML,False,15,,False,False,self,False,,[],{},,True,,1701933512.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As per Scikit-learn&amp;#39;s documentation, the &lt;code&gt;LogisticRegression&lt;/code&gt; model is a specialised case of GLM, but for &lt;code&gt;LinearRegression&lt;/code&gt; model, it is only mentioned under the OLS section. Is it a GLM model too? If not, the models described in the sub-section &amp;quot;Usage&amp;quot; of section &amp;quot;Generalized Linear Models&amp;quot; are GLM?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18cq7g4,True,,sARUcasm,,20,True,all_ads,False,[],False,,/r/datascience/comments/18cq7g4/scikitlearn_glm_models/,all_ads,False,https://www.reddit.com/r/datascience/comments/18cq7g4/scikitlearn_glm_models/,1209064,1701933512.0,0,,False,,,,,,,,,,302,47
,datascience,"A while back I had a low/mid level DS interview question that asked how I would approach training demand models for a nationwide grocery retailer that accounted for their vast range of products and localities. What are some approaches that different teams would potentially take to tackle that much segmentation without simply training so many models? While the level of segmentation addressed would range greatly across companies and teams,  are there any high level approaches that can ignore the abstraction needed to find out which customer markets and products could potentially remain grouped together? And what would the validation process look like for so many models outside of ensuring a certain level of overfitting is not crossed by some raw measure? I know a proper answer would involve a lot more domain knowledge and address specific business goals and metrics in mind but would appreciate to keep it abstract as possible. Thanks!",t2_ejcvs,False,,0,False,Interview question discussion,[],r/datascience,False,6,discussion,0,,,False,t3_18cirqg,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1701908909.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A while back I had a low/mid level DS interview question that asked how I would approach training demand models for a nationwide grocery retailer that accounted for their vast range of products and localities. What are some approaches that different teams would potentially take to tackle that much segmentation without simply training so many models? While the level of segmentation addressed would range greatly across companies and teams,  are there any high level approaches that can ignore the abstraction needed to find out which customer markets and products could potentially remain grouped together? And what would the validation process look like for so many models outside of ensuring a certain level of overfitting is not crossed by some raw measure? I know a proper answer would involve a lot more domain knowledge and address specific business goals and metrics in mind but would appreciate to keep it abstract as possible. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18cirqg,True,,shdets,,10,True,all_ads,False,[],False,,/r/datascience/comments/18cirqg/interview_question_discussion/,all_ads,False,https://www.reddit.com/r/datascience/comments/18cirqg/interview_question_discussion/,1209064,1701908909.0,0,,False,,,,True,,,,,,945,152
,datascience,"I’ve recently completed a soccer prediction model using a custom neural net architecture, which exceeds the best model previously published in the literature. I am still working on the paper, but it will by no means be the long, mathematical bash I’m used to seeing in a top journal like ICML or NeurIPS. 

Does anyone know of a good applied ML journal I could submit to? 

I will also consider just publishing on Arxiv, but it would be nice to get some peer reviewed papers on my resume.",t2_13co83,False,,0,False,Best Journals for Publishing Applied ML work?,[],r/datascience,False,6,projects,0,,,False,t3_18cirpw,False,dark,0.85,,public,17,0,{},,,False,[],,False,False,,{},ML,False,17,,False,False,self,False,,[],{},,True,,1701908907.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve recently completed a soccer prediction model using a custom neural net architecture, which exceeds the best model previously published in the literature. I am still working on the paper, but it will by no means be the long, mathematical bash I’m used to seeing in a top journal like ICML or NeurIPS. &lt;/p&gt;

&lt;p&gt;Does anyone know of a good applied ML journal I could submit to? &lt;/p&gt;

&lt;p&gt;I will also consider just publishing on Arxiv, but it would be nice to get some peer reviewed papers on my resume.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18cirpw,True,,fastbutlame,,12,True,all_ads,False,[],False,,/r/datascience/comments/18cirpw/best_journals_for_publishing_applied_ml_work/,all_ads,False,https://www.reddit.com/r/datascience/comments/18cirpw/best_journals_for_publishing_applied_ml_work/,1209064,1701908907.0,0,,False,,,,,,,,,,488,88
,datascience,"Came across this helpful tutorial on comparing datasets: [How to Compare 2 Datasets with Pandas Profiling](https://medium.com/towards-artificial-intelligence/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e). It breaks down the process nicely.

Figured it might be useful for others dealing with data comparisons!",t2_54ka7fmt,False,,0,False,Comparing the distribution of 2 different datasets,[],r/datascience,False,6,tooling,0,,,False,t3_18c9kdp,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Tools,False,0,,False,False,self,False,,[],{},,True,,1701884805.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Came across this helpful tutorial on comparing datasets: &lt;a href=""https://medium.com/towards-artificial-intelligence/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e""&gt;How to Compare 2 Datasets with Pandas Profiling&lt;/a&gt;. It breaks down the process nicely.&lt;/p&gt;

&lt;p&gt;Figured it might be useful for others dealing with data comparisons!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18c9kdp,True,,Dry_Cattle9399,,2,True,all_ads,False,[],False,,/r/datascience/comments/18c9kdp/comparing_the_distribution_of_2_different_datasets/,all_ads,False,https://www.reddit.com/r/datascience/comments/18c9kdp/comparing_the_distribution_of_2_different_datasets/,1209064,1701884805.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?auto=webp&amp;s=87e4d82f83cc682e8f34321a7bec771eb19f55ca', 'width': 1200, 'height': 473}, 'resolutions': [{'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc2486ba98d5728684c93e258a7a7edd0393cb0a', 'width': 108, 'height': 42}, {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=072eb9882d1febecfd43045bfc38811ab32647fd', 'width': 216, 'height': 85}, {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2151637bb3273917a02ab4cbc39744b6bf6a67a2', 'width': 320, 'height': 126}, {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=58f11d2209abad88eacf948e0bcd5cc9fc48dbfe', 'width': 640, 'height': 252}, {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=30839b76090fc26f3b24543f57e680dfae389500', 'width': 960, 'height': 378}, {'url': 'https://external-preview.redd.it/WjbBw7-CzRZCMax1nEktQucu9Ck-k1n_35a_heOR4jk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d77cfeac016422ae539812a885b386b573df3c9a', 'width': 1080, 'height': 425}], 'variants': {}, 'id': 'JrLKuHY8n9q9dJwUeJZ0iEs8EcXe9wP2Zu5EFogFMIs'}], 'enabled': False}",,,,,,,324,33
,datascience,"Hello everyone,

I have currently a full sponsorship to pursue my PhD in machine learning but also I just got into a technical management position in Data science and analytics. 

For who have been in a similar position of switching to academia after working in the industry for awhile, what did make you do that ? And what did make you say no for the opposite side ?",t2_khjzitgu,False,,0,False,Fully sponsored PhD or technical managerial path,[],r/datascience,False,6,fun,0,,,False,t3_18c9i6l,False,dark,0.82,,public,21,0,{},,,False,[],,False,False,,{},Career Discussion,False,21,,False,False,self,False,,[],{},,True,,1701884649.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I have currently a full sponsorship to pursue my PhD in machine learning but also I just got into a technical management position in Data science and analytics. &lt;/p&gt;

&lt;p&gt;For who have been in a similar position of switching to academia after working in the industry for awhile, what did make you do that ? And what did make you say no for the opposite side ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18c9i6l,True,,Tryingtosurvaive,,40,True,all_ads,False,[],False,,/r/datascience/comments/18c9i6l/fully_sponsored_phd_or_technical_managerial_path/,all_ads,False,https://www.reddit.com/r/datascience/comments/18c9i6l/fully_sponsored_phd_or_technical_managerial_path/,1209064,1701884649.0,0,,False,,,,,,,,,,367,68
,datascience,"Last Friday I was laid off on a group call with 5 other people. I worked for a small company and they basically ran out of money and are shutting down our entire half of the business besides 2-3 people (almost 30 people were laid off I believe).

An hour after the call, my boss called me (he’s been there for 25 years and is staying) saying that he has no one else who can handle large data sets and he didn’t know what he would do if they received customer leads and needed data help. I was the only person doing analytics on the entire team. He said they are now going to offer me a contracting position to help as needed. 

What can I expect from the contracting offer? Any advice on whether to accept it or not, or a threshold at which I should accept/deny?

Also, I have two previous bosses from this company and both were able to set up interviews for me at their current companies. I had an initial screen at the first one yesterday and it seemed horrendous - I would really prefer not to work there but I know I can’t be picky. The guy was demeaning (“why did you choose to go for your master’s in analytics?” - as if he didn’t even understand what analytics is), but said if he decides to take a certain project, I would be a good fit. I’m more hopeful for the second company as it seems like a less toxic environment and I have specific experience in that industry, but I don’t have an interview scheduled there yet.

I feel lost, displaced, upset, and have not heard back from a single application I’ve put out (not surprising, I know the market is insane). Any advice is greatly appreciated.",t2_a5id8l8c,False,,0,False,"Laid off, being offered a contracting position, need advice",[],r/datascience,False,6,fun,0,,,False,t3_18c5bjn,False,dark,0.94,,public,51,0,{},,,False,[],,False,False,,{},Career Discussion,False,51,,False,False,self,False,,[],{},,True,,1701873459.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Last Friday I was laid off on a group call with 5 other people. I worked for a small company and they basically ran out of money and are shutting down our entire half of the business besides 2-3 people (almost 30 people were laid off I believe).&lt;/p&gt;

&lt;p&gt;An hour after the call, my boss called me (he’s been there for 25 years and is staying) saying that he has no one else who can handle large data sets and he didn’t know what he would do if they received customer leads and needed data help. I was the only person doing analytics on the entire team. He said they are now going to offer me a contracting position to help as needed. &lt;/p&gt;

&lt;p&gt;What can I expect from the contracting offer? Any advice on whether to accept it or not, or a threshold at which I should accept/deny?&lt;/p&gt;

&lt;p&gt;Also, I have two previous bosses from this company and both were able to set up interviews for me at their current companies. I had an initial screen at the first one yesterday and it seemed horrendous - I would really prefer not to work there but I know I can’t be picky. The guy was demeaning (“why did you choose to go for your master’s in analytics?” - as if he didn’t even understand what analytics is), but said if he decides to take a certain project, I would be a good fit. I’m more hopeful for the second company as it seems like a less toxic environment and I have specific experience in that industry, but I don’t have an interview scheduled there yet.&lt;/p&gt;

&lt;p&gt;I feel lost, displaced, upset, and have not heard back from a single application I’ve put out (not surprising, I know the market is insane). Any advice is greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18c5bjn,True,,One-Material-9492,,29,True,all_ads,False,[],False,,/r/datascience/comments/18c5bjn/laid_off_being_offered_a_contracting_position/,all_ads,False,https://www.reddit.com/r/datascience/comments/18c5bjn/laid_off_being_offered_a_contracting_position/,1209064,1701873459.0,0,,False,,,,,,,,,,1604,304
,datascience,"I created a prediction model but would like to identify which variables for one line of the data make it sway to the prediction. 

For example, say I had a model that identifies between shiitake and oyster mushrooms. After getting the predictions from the model, is there a way to identify which variables from each line are mostly making it sway to each side? Or gave it away to make its prediction? Was it the odor, or cap shape or both out of maybe 10 variables? Is there a method anyone uses to identify this? 

I was thinking to maybe look at the highest variances between the types within each variable to identify thresholds if that makes sense. But would like to know if there is an easier way.",t2_5akq1mi3,False,,0,False,What methods do you use to identify the variables in a model?,[],r/datascience,False,6,network,0,,,False,t3_18c253b,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Analysis,False,0,,False,False,self,False,,[],{},,True,,1701862806.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I created a prediction model but would like to identify which variables for one line of the data make it sway to the prediction. &lt;/p&gt;

&lt;p&gt;For example, say I had a model that identifies between shiitake and oyster mushrooms. After getting the predictions from the model, is there a way to identify which variables from each line are mostly making it sway to each side? Or gave it away to make its prediction? Was it the odor, or cap shape or both out of maybe 10 variables? Is there a method anyone uses to identify this? &lt;/p&gt;

&lt;p&gt;I was thinking to maybe look at the highest variances between the types within each variable to identify thresholds if that makes sense. But would like to know if there is an easier way.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18c253b,True,,Dapper-Economy,,12,True,all_ads,False,[],False,,/r/datascience/comments/18c253b/what_methods_do_you_use_to_identify_the_variables/,all_ads,False,https://www.reddit.com/r/datascience/comments/18c253b/what_methods_do_you_use_to_identify_the_variables/,1209064,1701862806.0,0,,False,,,,,,,,,,702,129
,datascience,"Every data scientist I’ve talked to has told me that I have all the makings of a data scientist - the tech foundations + communication skills. A BS in mathematics from a top school (including advanced statistics and coding courses like C++), ~10 years of teaching experience, aced every boot camp project, and now have ~3 years of experience as a Data Analyst. 

A former recruiter now in HR at a tech company was supposed to give me advice after a resume review, and said that she has no advice because I’m a great candidate. 

However, the only job I could get recently is an hourly job - Excel pivot tables, and using a BI reporting tool. No real data work. I introduced my current team to SQL and Python and code to automate a couple of things, but not learning anything from my team. I am the lowest paid team member at $30 an hour, lower than my teaching salary.

I know I’m starting late and competing against people who started earlier, have more experience, have a higher degree… all in a bad market. 

I know people who started 2 years before I switched - some without a STEM background, most who did boot camps, and are now Senior DS or DA managers.

It feels like expectations that I have to meet  keep moving just out of reach - every data scientist job wants someone with # YOE, even entry level or junior positions - if they exist, if they are open to non-students.

I’m not sure what to do at this point, go back to graduate school at my age? I am tired and broke - is it worth the gamble? Or is it further sunk cost? Or just be grateful I have a job?",t2_jzdhrzu2,False,,0,False,What do I do next?,[],r/datascience,False,6,fun,0,,,False,t3_18c0x1w,False,dark,0.92,,public,49,0,{},,,False,[],,False,False,,{},Career Discussion,False,49,,False,False,self,False,,[],{},,True,,1701857640.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Every data scientist I’ve talked to has told me that I have all the makings of a data scientist - the tech foundations + communication skills. A BS in mathematics from a top school (including advanced statistics and coding courses like C++), ~10 years of teaching experience, aced every boot camp project, and now have ~3 years of experience as a Data Analyst. &lt;/p&gt;

&lt;p&gt;A former recruiter now in HR at a tech company was supposed to give me advice after a resume review, and said that she has no advice because I’m a great candidate. &lt;/p&gt;

&lt;p&gt;However, the only job I could get recently is an hourly job - Excel pivot tables, and using a BI reporting tool. No real data work. I introduced my current team to SQL and Python and code to automate a couple of things, but not learning anything from my team. I am the lowest paid team member at $30 an hour, lower than my teaching salary.&lt;/p&gt;

&lt;p&gt;I know I’m starting late and competing against people who started earlier, have more experience, have a higher degree… all in a bad market. &lt;/p&gt;

&lt;p&gt;I know people who started 2 years before I switched - some without a STEM background, most who did boot camps, and are now Senior DS or DA managers.&lt;/p&gt;

&lt;p&gt;It feels like expectations that I have to meet  keep moving just out of reach - every data scientist job wants someone with # YOE, even entry level or junior positions - if they exist, if they are open to non-students.&lt;/p&gt;

&lt;p&gt;I’m not sure what to do at this point, go back to graduate school at my age? I am tired and broke - is it worth the gamble? Or is it further sunk cost? Or just be grateful I have a job?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18c0x1w,True,,blurry_forest,,48,True,all_ads,False,[],False,,/r/datascience/comments/18c0x1w/what_do_i_do_next/,all_ads,False,https://www.reddit.com/r/datascience/comments/18c0x1w/what_do_i_do_next/,1209064,1701857640.0,0,,False,,,,,,,,,,1567,297
,datascience,"Hey everyone, I am a young former teacher with a bachelors and a masters from two pretty prestigious west coast universities in sociology/political science/ethnic studies and education. I thought I would commit my life to teaching and education administration, but I was pushed out by the pay. I literally couldn't afford to teach.

I am now pursuing my second passion which is data science. I honestly regret not double majoring in undergrad in sociology and data science so I could have had two bachelors but I can't go back now. I am pursing an associates in DS right now, and I should finish in a year. I would get a masters but I just can't afford it after the two degrees I have already, although I'm not entirely opposed to taking out more loans for the right program.

I am learning python and statistics, with plans on taking C++, SQL databases, linear algebra, calculus, math for AI, finance, data structures, and possibly some electives. These are all courses for my degree, although I don't think they would be the ones I would chose for myself. I plan on teaching myself Tableau on my own since I don't believe my community college offers those classes.

Just wondering what my best approach would be, and how my experience teaching and doing admin/student affairs work would translate to the field of data science. I would like to start working ASAP while still self-learning (I absolutely love learning new things), with the possibility of getting back into education to possibly teach DS when I build a strong financial base for myself. I am interested in data analysis particularly for policy and finance (I taught advance economics for HS), but am open to literally anything.",t2_cv4gsz7b,False,,0,False,"Education background to data science, what is the most efficient route?",[],r/datascience,False,6,fun,0,,,False,t3_18bvgws,False,dark,0.59,,public,4,0,{},,,False,[],,False,False,,{},Career Discussion,False,4,,False,False,self,False,,[],{},,True,,1701835757.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, I am a young former teacher with a bachelors and a masters from two pretty prestigious west coast universities in sociology/political science/ethnic studies and education. I thought I would commit my life to teaching and education administration, but I was pushed out by the pay. I literally couldn&amp;#39;t afford to teach.&lt;/p&gt;

&lt;p&gt;I am now pursuing my second passion which is data science. I honestly regret not double majoring in undergrad in sociology and data science so I could have had two bachelors but I can&amp;#39;t go back now. I am pursing an associates in DS right now, and I should finish in a year. I would get a masters but I just can&amp;#39;t afford it after the two degrees I have already, although I&amp;#39;m not entirely opposed to taking out more loans for the right program.&lt;/p&gt;

&lt;p&gt;I am learning python and statistics, with plans on taking C++, SQL databases, linear algebra, calculus, math for AI, finance, data structures, and possibly some electives. These are all courses for my degree, although I don&amp;#39;t think they would be the ones I would chose for myself. I plan on teaching myself Tableau on my own since I don&amp;#39;t believe my community college offers those classes.&lt;/p&gt;

&lt;p&gt;Just wondering what my best approach would be, and how my experience teaching and doing admin/student affairs work would translate to the field of data science. I would like to start working ASAP while still self-learning (I absolutely love learning new things), with the possibility of getting back into education to possibly teach DS when I build a strong financial base for myself. I am interested in data analysis particularly for policy and finance (I taught advance economics for HS), but am open to literally anything.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18bvgws,True,,mrmulatto7,,28,True,all_ads,False,[],False,,/r/datascience/comments/18bvgws/education_background_to_data_science_what_is_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bvgws/education_background_to_data_science_what_is_the/,1209064,1701835757.0,0,,False,,,,,,,,,,1693,290
,datascience,I'm using xgboost for modeling units sold of products on pricing + other factors. There is a phenomenon that once the reduction in price crosses a threshold the units sold increase by 200-300 percent. Unfortunately xgboost is not able to capture this sudden increase and severely underpredicts. Any ideas?,t2_3puw409o,False,,0,False,Price Elasticity - xgb predictions,[],r/datascience,False,6,network,0,,,False,t3_18bunqm,False,dark,0.97,,public,27,0,{},,,False,[],,False,False,,{},Analysis,False,27,,False,False,self,False,,[],{},,True,,1701833191.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using xgboost for modeling units sold of products on pricing + other factors. There is a phenomenon that once the reduction in price crosses a threshold the units sold increase by 200-300 percent. Unfortunately xgboost is not able to capture this sudden increase and severely underpredicts. Any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18bunqm,True,,hoolahan100,,27,True,all_ads,False,[],False,,/r/datascience/comments/18bunqm/price_elasticity_xgb_predictions/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bunqm/price_elasticity_xgb_predictions/,1209064,1701833191.0,0,,False,,,,,,,,,,305,49
,datascience,"Has anyone played with it yet? Thoughts on the approach?

https://github.com/state-spaces/mamba",t2_k7ifh2t8,False,,0,False,Is this the GRU of Transformers?,[],r/datascience,False,6,projects,0,,,False,t3_18bse7q,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},ML,False,1,,False,False,self,False,,[],{},,True,,1701826309.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone played with it yet? Thoughts on the approach?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/state-spaces/mamba""&gt;https://github.com/state-spaces/mamba&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18bse7q,True,,Moist_Stuff4509,,0,True,all_ads,False,[],False,,/r/datascience/comments/18bse7q/is_this_the_gru_of_transformers/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bse7q/is_this_the_gru_of_transformers/,1209064,1701826309.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?auto=webp&amp;s=15ab353ad8dd957821d6a99c6ee8ec6c10c22d17', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d5c091d11edffdd383f97697a66da774a9bfc69', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=091c71a1fa8fa9becfd57f46356e9972bea2f92f', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=557cf0fad4c24fdeb9500319ffb895b55f93821e', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=702ed57f299840f04491c5d34af682583cf0fa8e', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=84643be0f19013395a9ac3413121d704fc8278ee', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/dsL_TAXbytXSxSRQLRhISlovdLazrmWrRTGgfbKdunA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77c0f1207e6f2e527555dadc0bd3a742e8f796a1', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'VN0njodhRPafee593wvUqcD3dxT7rXm7cKTlVYofMA8'}], 'enabled': False}",,,,,,,95,11
,datascience,"I have a couple of fun, personal projects (primarily college football ML models) that I would like to host on a website for users to play with. I would need a service that can host a small DB and some architecture that allows me to run Python code. I've looked into something like AWS Lightsail but don't know if that's the best route. Do any of you have experience with something like this? My main objective is to keep costs low.

Thanks!",t2_52uw3bfj,False,,0,False,Hosting service for personal projects,[],r/datascience,False,6,meta,0,,,False,t3_18bogzk,False,dark,0.93,,public,13,0,{},,,False,[],,False,False,,{},Projects,False,13,,False,False,self,False,,[],{},,True,,1701815640.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a couple of fun, personal projects (primarily college football ML models) that I would like to host on a website for users to play with. I would need a service that can host a small DB and some architecture that allows me to run Python code. I&amp;#39;ve looked into something like AWS Lightsail but don&amp;#39;t know if that&amp;#39;s the best route. Do any of you have experience with something like this? My main objective is to keep costs low.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18bogzk,True,,WetOrangutan,,9,True,all_ads,False,[],False,,/r/datascience/comments/18bogzk/hosting_service_for_personal_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bogzk/hosting_service_for_personal_projects/,1209064,1701815640.0,0,,False,,,,,,,,,,440,82
,datascience,"When you interview a candidate, is it blatantly obvious that the interviewee is desperate to get out of their bad job and into your company? I’m racking my brain why I keep getting turned down. Maybe it’s arrogance? Maybe forgetting details? Maybe it’s too obvious that I’m trying to find a better role? 

My confidence keeps getting bruised. The job market is so tough. Answer questions perfectly, still get turned down. I just don’t get it. Are yall farming for reasons to send the job to India? Are you just getting inundated with top tier candidates?",t2_9l80yrty,False,,0,False,"Hiring managers, is it obvious?",[],r/datascience,False,6,fun,0,,,False,t3_18blxjo,False,dark,0.91,,public,116,0,{},,,False,[],,False,False,,{},Career Discussion,False,116,,False,False,self,False,,[],{},,True,,1701809304.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When you interview a candidate, is it blatantly obvious that the interviewee is desperate to get out of their bad job and into your company? I’m racking my brain why I keep getting turned down. Maybe it’s arrogance? Maybe forgetting details? Maybe it’s too obvious that I’m trying to find a better role? &lt;/p&gt;

&lt;p&gt;My confidence keeps getting bruised. The job market is so tough. Answer questions perfectly, still get turned down. I just don’t get it. Are yall farming for reasons to send the job to India? Are you just getting inundated with top tier candidates?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18blxjo,True,,cruelbankai,,77,True,all_ads,False,[],False,,/r/datascience/comments/18blxjo/hiring_managers_is_it_obvious/,all_ads,False,https://www.reddit.com/r/datascience/comments/18blxjo/hiring_managers_is_it_obvious/,1209064,1701809304.0,0,,False,,,,,,,,,,554,96
,datascience,"Context - I built a V1 of a model and I have an experiment running that takes the results of the model and distributes coupons to users based on the model output. Control is users who don’t receive a coupon. I’m trying to measure how much retention is improved by the coupon. 

I built a v2 of the model and I’m not sure about how I should implement it. Do I run it side by side with my v1 to see which one performs better? Or do I wait for my v1 experiment to finish running and then replace it with the v2 and run it for the same period of time? 

The experiment design for situation 1 is tough for me from a CRM perspective. The experiment design in situation 2 is tough for me from a seasonality perspective and it’ll introduce extra work as I’ll have to make adjustments to my analysis.",t2_jrhff4f29,False,,0,False,For experienced DS - How did you go about the process of experimenting a new model?,[],r/datascience,False,6,network,0,,,False,t3_18bijm7,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Analysis,False,4,,False,False,self,False,,[],{},,True,,1701800645.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Context - I built a V1 of a model and I have an experiment running that takes the results of the model and distributes coupons to users based on the model output. Control is users who don’t receive a coupon. I’m trying to measure how much retention is improved by the coupon. &lt;/p&gt;

&lt;p&gt;I built a v2 of the model and I’m not sure about how I should implement it. Do I run it side by side with my v1 to see which one performs better? Or do I wait for my v1 experiment to finish running and then replace it with the v2 and run it for the same period of time? &lt;/p&gt;

&lt;p&gt;The experiment design for situation 1 is tough for me from a CRM perspective. The experiment design in situation 2 is tough for me from a seasonality perspective and it’ll introduce extra work as I’ll have to make adjustments to my analysis.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18bijm7,True,,Terrible-Hamster-342,,11,True,all_ads,False,[],False,,/r/datascience/comments/18bijm7/for_experienced_ds_how_did_you_go_about_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bijm7/for_experienced_ds_how_did_you_go_about_the/,1209064,1701800645.0,0,,False,,,,,,,,,,791,154
,datascience,"Hey, I’m working as a Data Scientist for almost a year and I’m trying to figure out where I can find job offers except inside country I live. Is it hard to find remote jobs like that eg in US or anywhere inside Europe (currently living in Poland)? What are your experiences with that topic?",t2_babvbok2,False,,0,False,What job boards are you recommending for finding remote job in another country?,[],r/datascience,False,6,fun,0,,,False,t3_18bi8oh,False,dark,0.67,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,False,,[],{},,True,,1701799870.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, I’m working as a Data Scientist for almost a year and I’m trying to figure out where I can find job offers except inside country I live. Is it hard to find remote jobs like that eg in US or anywhere inside Europe (currently living in Poland)? What are your experiences with that topic?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18bi8oh,True,,jesteartyste,,10,True,all_ads,False,[],False,,/r/datascience/comments/18bi8oh/what_job_boards_are_you_recommending_for_finding/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bi8oh/what_job_boards_are_you_recommending_for_finding/,1209064,1701799870.0,0,,False,,,,,,,,,,290,55
,datascience," Is there still room for research on techniques and models that are commonly used in the industry? I currently work as a Data Scientist and am considering pursuing a Master's or Ph.D. in machine learning. However, it appears that most recent developments focus primarily on neural networks, especially Large Language Models (LLMs). Despite extensively searching through arXiv articles, I've had little success in finding research on areas like feature engineering, probability models, and tree-based algorithms. If anyone knows professors specializing in these more traditional machine learning aspects, please let me know. ",t2_nr338hpnv,False,,0,False,How alive is traditional machine learning in academia?,[],r/datascience,False,6,projects,0,,,False,t3_18bhvfd,False,dark,0.92,,public,33,0,{},,,False,[],,False,False,,{},ML,False,33,,False,False,self,False,,[],{},,True,,1701798949.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there still room for research on techniques and models that are commonly used in the industry? I currently work as a Data Scientist and am considering pursuing a Master&amp;#39;s or Ph.D. in machine learning. However, it appears that most recent developments focus primarily on neural networks, especially Large Language Models (LLMs). Despite extensively searching through arXiv articles, I&amp;#39;ve had little success in finding research on areas like feature engineering, probability models, and tree-based algorithms. If anyone knows professors specializing in these more traditional machine learning aspects, please let me know. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,18bhvfd,True,,BrDataScientist,,24,True,all_ads,False,[],False,,/r/datascience/comments/18bhvfd/how_alive_is_traditional_machine_learning_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bhvfd/how_alive_is_traditional_machine_learning_in/,1209064,1701798949.0,1,,False,,,,,,,,,,624,91
,datascience,"This community has been tremendously helpful for me when I was first breaking into data science and MLE, and I'm looking to give back through free online education.

Unfortunately, a lot of AI/ML resources online, especially those for generative AI, are way too math heavy and focus more on tedious proofs rather than what you actually need to know for side projects or to work as an MLE. That's why I created [GPT and Chill](https://www.youtube.com/@GPTandChill/videos), a one stop shop for learning different ML concepts from scratch.

The structure of most of my videos is first 10 minutes explaining on a whiteboard, last 10 minutes live coding in Python. There's only one video left in my first to be released in my first playlist/series, [Coding a GPT from scratch](https://www.youtube.com/playlist?list=PLf2BgkdQjMYsyPx7HPO4M6aqTfPl2iEPx)

The next playlist/series will either be explaining how to code a self-driving car, or an image generator like DALL-E! I will also be releasing a companion platform where you can run your code against test cases for sample exercises/questions.

If anyone has any suggestions for future videos, feel free to leave a comment or DM me!",t2_o8bqxbsy3,False,,0,False,"Explaining how generative AI works in code, from scratch, without excessive math",[],r/datascience,False,6,,0,,,False,t3_18bgpy2,False,dark,0.89,,public,100,0,{},,,False,[],,False,False,,{},Education,False,100,,False,False,self,False,,[],{},,True,,1701795917.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This community has been tremendously helpful for me when I was first breaking into data science and MLE, and I&amp;#39;m looking to give back through free online education.&lt;/p&gt;

&lt;p&gt;Unfortunately, a lot of AI/ML resources online, especially those for generative AI, are way too math heavy and focus more on tedious proofs rather than what you actually need to know for side projects or to work as an MLE. That&amp;#39;s why I created &lt;a href=""https://www.youtube.com/@GPTandChill/videos""&gt;GPT and Chill&lt;/a&gt;, a one stop shop for learning different ML concepts from scratch.&lt;/p&gt;

&lt;p&gt;The structure of most of my videos is first 10 minutes explaining on a whiteboard, last 10 minutes live coding in Python. There&amp;#39;s only one video left in my first to be released in my first playlist/series, &lt;a href=""https://www.youtube.com/playlist?list=PLf2BgkdQjMYsyPx7HPO4M6aqTfPl2iEPx""&gt;Coding a GPT from scratch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The next playlist/series will either be explaining how to code a self-driving car, or an image generator like DALL-E! I will also be releasing a companion platform where you can run your code against test cases for sample exercises/questions.&lt;/p&gt;

&lt;p&gt;If anyone has any suggestions for future videos, feel free to leave a comment or DM me!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,18bgpy2,True,,GPTandChill,,9,True,all_ads,False,[],False,,/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/,1209064,1701795917.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?auto=webp&amp;s=63e09f3058721ac5a9287eae3674d6bd0b506926', 'width': 900, 'height': 900}, 'resolutions': [{'url': 'https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ce253083bde24aaff6d930d70869d7ebf6d2892', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55ef50f690051b621b3a56caaaa9551a741837ef', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fcb8590f8ffbdde81a5cc8e9ce23555b71565b3e', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9afaf5577c46ce889e689b362b2449007e061acc', 'width': 640, 'height': 640}], 'variants': {}, 'id': 'RqKWZpSnc0py3dnE4oXk9Xiq2NE8I4zvB1IYU2h9gbE'}], 'enabled': False}",,,,,,,1178,184
,datascience,"I wanna do some self learning along with my college, I see lots of these courses that are specific to Microsoft or Google. can I benefit from it? if so in which situations?",t2_4rvlor2p,False,,0,False,Should I enroll in Google Cloud/Microsoft Azure courses?,[],r/datascience,False,6,discussion,0,,,False,t3_18bf2ej,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1701791688.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wanna do some self learning along with my college, I see lots of these courses that are specific to Microsoft or Google. can I benefit from it? if so in which situations?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18bf2ej,True,,1kmile,,6,True,all_ads,False,[],False,,/r/datascience/comments/18bf2ej/should_i_enroll_in_google_cloudmicrosoft_azure/,all_ads,False,https://www.reddit.com/r/datascience/comments/18bf2ej/should_i_enroll_in_google_cloudmicrosoft_azure/,1209064,1701791688.0,0,,False,,,,,,,,,,172,33
,datascience,"Hi,

I am new to the field and curious as to what your day to day looks like. 

Are you hybrid or remote? Do you have meetings or make presentations?",t2_b3hvfhlp,False,,0,False,Data Scientist day to day,[],r/datascience,False,6,fun,0,,,False,t3_18baxdp,False,dark,0.86,,public,40,0,{},,,False,[],,False,False,,{},Career Discussion,False,40,,False,False,self,False,,[],{},,True,,1701779344.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am new to the field and curious as to what your day to day looks like. &lt;/p&gt;

&lt;p&gt;Are you hybrid or remote? Do you have meetings or make presentations?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18baxdp,True,,Exotic_Avocado6164,,51,True,all_ads,False,[],False,,/r/datascience/comments/18baxdp/data_scientist_day_to_day/,all_ads,False,https://www.reddit.com/r/datascience/comments/18baxdp/data_scientist_day_to_day/,1209064,1701779344.0,0,,False,,,,,,,,,,149,30
,datascience,"Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more ""production-ready"", then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol",t2_oxk1j,False,,0,False,Write OOP from the beginning or refactor?,[],r/datascience,False,6,,0,,,False,t3_18b5s7f,False,dark,0.79,,public,11,0,{},,,False,[],,False,False,,{},Coding,False,11,,False,False,self,False,,[],{},,True,,1701757640.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more &amp;quot;production-ready&amp;quot;, then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,18b5s7f,True,,PinstripePride97,,10,True,all_ads,False,[],False,,/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/,all_ads,False,https://www.reddit.com/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/,1209064,1701757640.0,0,,False,,,,,,,,,,622,113
,datascience,"I’m turning 40 next year and it’s got me wondering about the future and how I’ll be able to make a living when I’m older.

We’ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don’t really want to climb the corporate ladder, I’d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. 

I’ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. 

Just wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?",t2_nya9l4wu,False,,0,False,Do you see this doing this work past 50 years of age and into retirement?,[],r/datascience,False,6,fun,0,,,False,t3_18b1ery,False,dark,0.93,,public,69,0,{},,,False,[],,False,False,,{},Career Discussion,False,69,,False,False,self,False,,[],{},,True,,1701743270.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m turning 40 next year and it’s got me wondering about the future and how I’ll be able to make a living when I’m older.&lt;/p&gt;

&lt;p&gt;We’ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don’t really want to climb the corporate ladder, I’d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. &lt;/p&gt;

&lt;p&gt;I’ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. &lt;/p&gt;

&lt;p&gt;Just wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18b1ery,True,,TheUserAboveFarted,,41,True,all_ads,False,[],False,,/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/,1209064,1701743270.0,0,,False,,,,,,,,,,746,138
,datascience,"Hi,

I'm newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don't have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?

I'm in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I've constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population 'cell', e.g. permutation of geography (postcode in this case), sex, and age bucket:

cell | year | age_bucket | sex | postcode | population
:--|--:|--:|:--|:--|--:
1036 | 2021 | 25-30 | Male | 2000 |  4,390

My intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we'll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.

user | year | height | weight | age_bucket | sex | postcode
:---|--:|--:|--:|--:|:--|:--
a89bf96e | 2021| 180 | 80 | 25-30 | Male | 2000

From the **user** and **cell** tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).

However I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:


    # get the total population
    total_population = data['population'].sum()
    
    # get the weighted estimate
    weighted_bmi_estimate = (data['survey_weight'] * data['bmi']).sum() / total_population
    
    # work out the design effect by comparing simple (SRS) and complex variance measures
    
    mean_bmi = data['bmi'].mean()
    simple_variance = ((data['bmi'] - mean_bmi)**2).sum() / (total_population - 1)
    
    data['weighted_deviance'] = data['survey_weight'] * (data['bmi'] - weighted_bmi_estimate)**2
    complex_variance = data['weighted_deviance'].sum() / total_population
    
    deff = complex_variance / simple_variance
    
    # use the deff to get the rse for the bmi estimate
    rse = (deff * simple_variance)**0.5
    
    # NOTE: when doing an obesity _rate_ instead of BMI we'd use a different calc for the simple_variance


Tbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it'd be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.

Further thoughts:

- I will need to interpolate population counts for non-census years or otherwise just take the closest
- Though I haven't yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it
- I'll need to handle summation across cells when weighting by only a subset of the cell dimensions 
- To handle distortion from small counts, weight trimming seemed like the simplest solution but I'm unsure if any adjustments are necessary when determining RSEs
- I'm not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using `approxQuantile` to set the weight caps, broadcasting my means and total_populations)

Thank you!",t2_i0a3z0l,False,,0,False,Please sense-check my approach for applying survey weights and RSEs in spark,[],r/datascience,False,6,,0,,,False,t3_18b113j,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Statistics,False,1,,False,False,self,1701744760.0,,[],{},,True,,1701742148.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don&amp;#39;t have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I&amp;#39;ve constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population &amp;#39;cell&amp;#39;, e.g. permutation of geography (postcode in this case), sex, and age bucket:&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;cell&lt;/th&gt;
&lt;th align=""right""&gt;year&lt;/th&gt;
&lt;th align=""right""&gt;age_bucket&lt;/th&gt;
&lt;th align=""left""&gt;sex&lt;/th&gt;
&lt;th align=""left""&gt;postcode&lt;/th&gt;
&lt;th align=""right""&gt;population&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;1036&lt;/td&gt;
&lt;td align=""right""&gt;2021&lt;/td&gt;
&lt;td align=""right""&gt;25-30&lt;/td&gt;
&lt;td align=""left""&gt;Male&lt;/td&gt;
&lt;td align=""left""&gt;2000&lt;/td&gt;
&lt;td align=""right""&gt;4,390&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;My intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we&amp;#39;ll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;user&lt;/th&gt;
&lt;th align=""right""&gt;year&lt;/th&gt;
&lt;th align=""right""&gt;height&lt;/th&gt;
&lt;th align=""right""&gt;weight&lt;/th&gt;
&lt;th align=""right""&gt;age_bucket&lt;/th&gt;
&lt;th align=""left""&gt;sex&lt;/th&gt;
&lt;th align=""left""&gt;postcode&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;a89bf96e&lt;/td&gt;
&lt;td align=""right""&gt;2021&lt;/td&gt;
&lt;td align=""right""&gt;180&lt;/td&gt;
&lt;td align=""right""&gt;80&lt;/td&gt;
&lt;td align=""right""&gt;25-30&lt;/td&gt;
&lt;td align=""left""&gt;Male&lt;/td&gt;
&lt;td align=""left""&gt;2000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;From the &lt;strong&gt;user&lt;/strong&gt; and &lt;strong&gt;cell&lt;/strong&gt; tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).&lt;/p&gt;

&lt;p&gt;However I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# get the total population
total_population = data[&amp;#39;population&amp;#39;].sum()

# get the weighted estimate
weighted_bmi_estimate = (data[&amp;#39;survey_weight&amp;#39;] * data[&amp;#39;bmi&amp;#39;]).sum() / total_population

# work out the design effect by comparing simple (SRS) and complex variance measures

mean_bmi = data[&amp;#39;bmi&amp;#39;].mean()
simple_variance = ((data[&amp;#39;bmi&amp;#39;] - mean_bmi)**2).sum() / (total_population - 1)

data[&amp;#39;weighted_deviance&amp;#39;] = data[&amp;#39;survey_weight&amp;#39;] * (data[&amp;#39;bmi&amp;#39;] - weighted_bmi_estimate)**2
complex_variance = data[&amp;#39;weighted_deviance&amp;#39;].sum() / total_population

deff = complex_variance / simple_variance

# use the deff to get the rse for the bmi estimate
rse = (deff * simple_variance)**0.5

# NOTE: when doing an obesity _rate_ instead of BMI we&amp;#39;d use a different calc for the simple_variance
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it&amp;#39;d be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.&lt;/p&gt;

&lt;p&gt;Further thoughts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I will need to interpolate population counts for non-census years or otherwise just take the closest&lt;/li&gt;
&lt;li&gt;Though I haven&amp;#39;t yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it&lt;/li&gt;
&lt;li&gt;I&amp;#39;ll need to handle summation across cells when weighting by only a subset of the cell dimensions &lt;/li&gt;
&lt;li&gt;To handle distortion from small counts, weight trimming seemed like the simplest solution but I&amp;#39;m unsure if any adjustments are necessary when determining RSEs&lt;/li&gt;
&lt;li&gt;I&amp;#39;m not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using &lt;code&gt;approxQuantile&lt;/code&gt; to set the weight caps, broadcasting my means and total_populations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,18b113j,True,,sansampersamp,,0,True,all_ads,False,[],False,,/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/,all_ads,False,https://www.reddit.com/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/,1209064,1701742148.0,0,,False,,,,,,,,,,4101,646
,datascience,"Hey,  


Has anyone tried this model for hierarchical time series forecasting from gluonts? [https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical\_model\_tutorial.html](https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html). The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?",t2_k7ifh2t8,False,,0,False,Hierarchical Time Series Forecasting using GluonTS DeepVarHierarchical,[],r/datascience,False,6,discussion,0,,,False,t3_18ay60f,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1701733960.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey,  &lt;/p&gt;

&lt;p&gt;Has anyone tried this model for hierarchical time series forecasting from gluonts? &lt;a href=""https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html""&gt;https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html&lt;/a&gt;. The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18ay60f,True,,Moist_Stuff4509,,1,True,all_ads,False,[],False,,/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/,1209064,1701733960.0,0,,False,,,,,,,,,,523,57
,datascience,"I'm currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I'm assuming I will have to make one myself. I'm fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I'm being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.

Are there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?",t2_1mt6zlx5,False,,0,False,How to make a good dataset,[],r/datascience,False,6,network,0,,,False,t3_18ausi6,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Analysis,False,2,,False,False,self,False,,[],{},,True,,1701725168.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I&amp;#39;m assuming I will have to make one myself. I&amp;#39;m fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I&amp;#39;m being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.&lt;/p&gt;

&lt;p&gt;Are there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18ausi6,True,,ixw123,,8,True,all_ads,False,[],False,,/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/,1209064,1701725168.0,0,,False,,,,,,,,,,821,150
,datascience,"
I’m a stats major and keep hearing the importance of computer science for any stats major who wants to get a “good” job (anything beyond data analysis, though I’d be completely happy with a DA job initially). 

My stats major covers programming in R, python, C, and some classes involving sql, tableau, git, etc, so I have decent exposure in that regard. 

What I’m worried about not having exposure to is data structures and algorithms (I guess aside from electives in text mining and in machine learning). Is it really that important for me to take these classes? I’d have to take a handful of pre reqs (discrete math, programming, differential) and I really don’t see myself wanting a job in that kind of data engineering/software developer role.",t2_5412hsg,False,,0,False,Value in taking classes on data structures/algorithms in stats undergrad?,[],r/datascience,False,6,discussion,0,,,False,t3_18atvvx,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1701722808.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m a stats major and keep hearing the importance of computer science for any stats major who wants to get a “good” job (anything beyond data analysis, though I’d be completely happy with a DA job initially). &lt;/p&gt;

&lt;p&gt;My stats major covers programming in R, python, C, and some classes involving sql, tableau, git, etc, so I have decent exposure in that regard. &lt;/p&gt;

&lt;p&gt;What I’m worried about not having exposure to is data structures and algorithms (I guess aside from electives in text mining and in machine learning). Is it really that important for me to take these classes? I’d have to take a handful of pre reqs (discrete math, programming, differential) and I really don’t see myself wanting a job in that kind of data engineering/software developer role.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18atvvx,True,,Voldemort57,,14,True,all_ads,False,[],False,,/r/datascience/comments/18atvvx/value_in_taking_classes_on_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/18atvvx/value_in_taking_classes_on_data/,1209064,1701722808.0,0,,False,,,,,,,,,,750,128
,datascience," I've been on the lookout for some cool code challenges to step up my Python game and explore the data science tools a bit more. Came across these two:

1. [Advent of Code](https://adventofcode.com/)
2. [Zilliz Advent of Code](https://zilliz.com/advent-of-code)

Anyone else thinking of jumping into these challenges? ",t2_54ka7fmt,False,,0,False,Programming challenges,[],r/datascience,False,6,,0,,,False,t3_18aqknk,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Challenges,False,4,,False,False,self,False,,[],{},,True,,1701714413.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been on the lookout for some cool code challenges to step up my Python game and explore the data science tools a bit more. Came across these two:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=""https://adventofcode.com/""&gt;Advent of Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://zilliz.com/advent-of-code""&gt;Zilliz Advent of Code&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Anyone else thinking of jumping into these challenges? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,18aqknk,True,,Dry_Cattle9399,,4,True,all_ads,False,[],False,,/r/datascience/comments/18aqknk/programming_challenges/,all_ads,False,https://www.reddit.com/r/datascience/comments/18aqknk/programming_challenges/,1209064,1701714413.0,0,,False,,,,,,,,,,318,46
,datascience,Been stuck with package dependency failures with R3.6.1 and can't seem to get out of it.,t2_9axqyq8u,False,,0,False,What's the best way to manage packages for different versions of R?,[],r/datascience,False,6,,0,,,False,t3_18aqhu2,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Coding,False,6,,False,False,self,False,,[],{},,True,,1701714212.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Been stuck with package dependency failures with R3.6.1 and can&amp;#39;t seem to get out of it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,18aqhu2,True,,Difficult-Big-3890,,16,True,all_ads,False,[],False,,/r/datascience/comments/18aqhu2/whats_the_best_way_to_manage_packages_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/18aqhu2/whats_the_best_way_to_manage_packages_for/,1209064,1701714212.0,0,,False,,,,,,,,,,88,16
,datascience,"I'm looking for some good GitHub example repos of a machine learning model deployed in a flask server API. Preferably something deployed in a customer-facing production environment, and preferably **not** a simple toy server example.

My team has been deploying some of our models, mostly following documentation and tutorials. But I'd love some ""in the wild"" examples to see what other people do differently.

Any recommendations?",t2_jqnnc,False,,0,False,Good example of model deployed in flask server API?,[],r/datascience,False,6,tooling,0,,,False,t3_18aq8w1,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},Tools,False,8,,False,False,self,False,,[],{},,True,,1701713564.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for some good GitHub example repos of a machine learning model deployed in a flask server API. Preferably something deployed in a customer-facing production environment, and preferably &lt;strong&gt;not&lt;/strong&gt; a simple toy server example.&lt;/p&gt;

&lt;p&gt;My team has been deploying some of our models, mostly following documentation and tutorials. But I&amp;#39;d love some &amp;quot;in the wild&amp;quot; examples to see what other people do differently.&lt;/p&gt;

&lt;p&gt;Any recommendations?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,18aq8w1,True,,MindlessTime,,9,True,all_ads,False,[],False,,/r/datascience/comments/18aq8w1/good_example_of_model_deployed_in_flask_server_api/,all_ads,False,https://www.reddit.com/r/datascience/comments/18aq8w1/good_example_of_model_deployed_in_flask_server_api/,1209064,1701713564.0,0,,False,,,,,,,,,,431,66
,datascience,"For a model training on a loss function consisting of weighted losses:

&amp;#x200B;

https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;format=png&amp;auto=webp&amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379

I want to know what can be said about a model that converges based on this ℒ loss in terms of the losses ℒ\_i, or perhaps the models that converge on the ℒ\_i losses seperately.For instance, if I have some guarantees / properties for models m\_i that converge to losses ℒ\_i, if some of those guarantees properties transition over to the model m that converges on ℒ.

Would greatly appreciate links to theoretical papers that talk on this issue, or even keywords to help me in my search for such papers.

Thank you very much in advance for any help / guidance!",t2_3ogexpy8,False,,0,False,loss weighting - theoretical guarantees?,[],r/datascience,False,6,,0,70.0,,False,t3_18ap2g5,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},AI,False,1,,False,False,https://b.thumbs.redditmedia.com/swc1M3q3qPyP2yL5WAhcG8NuaAPgbM_fB8ZW1OA46kA.jpg,False,,[],{},,True,,1701710489.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For a model training on a loss function consisting of weighted losses:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379""&gt;https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I want to know what can be said about a model that converges based on this ℒ loss in terms of the losses ℒ_i, or perhaps the models that converge on the ℒ_i losses seperately.For instance, if I have some guarantees / properties for models m_i that converge to losses ℒ_i, if some of those guarantees properties transition over to the model m that converges on ℒ.&lt;/p&gt;

&lt;p&gt;Would greatly appreciate links to theoretical papers that talk on this issue, or even keywords to help me in my search for such papers.&lt;/p&gt;

&lt;p&gt;Thank you very much in advance for any help / guidance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,2f731e52-70eb-11ee-bec5-5a5142e6a4d2,False,False,False,,[],False,,,,t5_2sptq,False,,,#46d160,18ap2g5,True,,progmayo,,1,True,all_ads,False,[],False,,/r/datascience/comments/18ap2g5/loss_weighting_theoretical_guarantees/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ap2g5/loss_weighting_theoretical_guarantees/,1209064,1701710489.0,0,,False,"{'0z9fppvyab4c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 54, 'x': 108, 'u': 'https://preview.redd.it/0z9fppvyab4c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9661b85b99c23c7c6347e936fb61cb9c2828066b'}], 's': {'y': 77, 'x': 153, 'u': 'https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;format=png&amp;auto=webp&amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379'}, 'id': '0z9fppvyab4c1'}}",,,,,,,,,775,116
,datascience,"I am currently enrolled in a top MS Statistics program (with Data Science specialization), and I’m taking primarily CS classes: ML, deep learning, NLP, CV, RL, generative models, big data algorithms, parallel programming etc. On top of this I will be taking ‘pure stats’ courses in stochastics, inference, and applied stats.

I recently learned that I can switch to the MS in Computer Science with the AI specialization and take exactly the same classes, but with OS, programming languages, and logic instead of the aforementioned pure stats classes.

I studied CS (~13 core courses) and biology in undergrad, and graduated with a Bioinformatics degree (so I don’t have BSCS on my resume, but I do have extensive knowledge in CS). I have written a number of software packages in Python and C++, and have a couple years of industry and research experience in DS and MLE roles.

**My question is: For career prospects, is it better for me to stick with my MS in Statistics or switch to the MS in Computer Science?**

**Edit: Unfortunately, I just learned that switching programs follows a different process with the MS CS and that it would be infeasible for me to scrap all the things I need together by the deadline. Appreciate all the insights from everyone.**",t2_13co83,False,,0,False,MS Statistics vs. MS CS,[],r/datascience,False,6,fun,0,,,False,t3_18aoqmk,False,dark,0.88,,public,27,0,{},,,False,[],,False,False,,{},Career Discussion,False,27,,False,False,self,1701804714.0,,[],{},,True,,1701709595.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently enrolled in a top MS Statistics program (with Data Science specialization), and I’m taking primarily CS classes: ML, deep learning, NLP, CV, RL, generative models, big data algorithms, parallel programming etc. On top of this I will be taking ‘pure stats’ courses in stochastics, inference, and applied stats.&lt;/p&gt;

&lt;p&gt;I recently learned that I can switch to the MS in Computer Science with the AI specialization and take exactly the same classes, but with OS, programming languages, and logic instead of the aforementioned pure stats classes.&lt;/p&gt;

&lt;p&gt;I studied CS (~13 core courses) and biology in undergrad, and graduated with a Bioinformatics degree (so I don’t have BSCS on my resume, but I do have extensive knowledge in CS). I have written a number of software packages in Python and C++, and have a couple years of industry and research experience in DS and MLE roles.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My question is: For career prospects, is it better for me to stick with my MS in Statistics or switch to the MS in Computer Science?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit: Unfortunately, I just learned that switching programs follows a different process with the MS CS and that it would be infeasible for me to scrap all the things I need together by the deadline. Appreciate all the insights from everyone.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18aoqmk,True,,fastbutlame,,37,True,all_ads,False,[],False,,/r/datascience/comments/18aoqmk/ms_statistics_vs_ms_cs/,all_ads,False,https://www.reddit.com/r/datascience/comments/18aoqmk/ms_statistics_vs_ms_cs/,1209064,1701709595.0,0,,False,,,,,,,,,,1260,214
,datascience,"Everyone in this sub seems to absolutely hate take-home assignments. I used to find it stupid as well until I was involved in a hiring process a few months back.

We were hiring for a junior to mid level DS position, it only took a couple of days to gather half a thousand applications. (It’s absolutely insane, maybe due to the job being remote) Even after filtering out those with quantitative degrees or relevant experience, we still had to deal with slightly over 100 candidates. Interview all of them is definitely out of the question here.

The process we had was to get them do a coding test. Easy to medium leetcode questions with some SQL questions. Of the 2/3 that passed, we send them an assignment with one week deadline. Once submitted, they get a zoom interview to present their work. Here’s the thing, **take-home assignments work.** It very effectively cut down the number of applicants to around 10. 

I understand it’s not fun doing these assignments, but given the job market, what’s a good alternative that helps you filter among 100s of qualified candidates on paper, and also help you understand how they do their work and communicate? DS resumes these days all look the same. Everyone claims to know everything with no proof of proficiency. Recruiting is very time consuming and costly, and the cost of hiring a fraud DS costs even more.

Some argue that assignments will deter the best candidates from continuing the application. The reality is that, unless it’s meta or google, employers are not obsessed with finding the best person out of hundreds of candidates. They just want to find someone who is **good enough** to perform certain tasks without adding burden to the team. 

So for those really hates take-home assignments, if you’re in the position of hiring, how will you evaluate your applicants?",t2_2kh4l8ej,False,,0,False,What realistically is a good alternative take-home assignments?,[],r/datascience,False,6,fun,0,,,False,t3_18aif1a,False,dark,0.81,,public,60,0,{},,,False,[],,False,False,,{},Career Discussion,False,60,,False,False,self,False,,[],{},,True,,1701689960.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Everyone in this sub seems to absolutely hate take-home assignments. I used to find it stupid as well until I was involved in a hiring process a few months back.&lt;/p&gt;

&lt;p&gt;We were hiring for a junior to mid level DS position, it only took a couple of days to gather half a thousand applications. (It’s absolutely insane, maybe due to the job being remote) Even after filtering out those with quantitative degrees or relevant experience, we still had to deal with slightly over 100 candidates. Interview all of them is definitely out of the question here.&lt;/p&gt;

&lt;p&gt;The process we had was to get them do a coding test. Easy to medium leetcode questions with some SQL questions. Of the 2/3 that passed, we send them an assignment with one week deadline. Once submitted, they get a zoom interview to present their work. Here’s the thing, &lt;strong&gt;take-home assignments work.&lt;/strong&gt; It very effectively cut down the number of applicants to around 10. &lt;/p&gt;

&lt;p&gt;I understand it’s not fun doing these assignments, but given the job market, what’s a good alternative that helps you filter among 100s of qualified candidates on paper, and also help you understand how they do their work and communicate? DS resumes these days all look the same. Everyone claims to know everything with no proof of proficiency. Recruiting is very time consuming and costly, and the cost of hiring a fraud DS costs even more.&lt;/p&gt;

&lt;p&gt;Some argue that assignments will deter the best candidates from continuing the application. The reality is that, unless it’s meta or google, employers are not obsessed with finding the best person out of hundreds of candidates. They just want to find someone who is &lt;strong&gt;good enough&lt;/strong&gt; to perform certain tasks without adding burden to the team. &lt;/p&gt;

&lt;p&gt;So for those really hates take-home assignments, if you’re in the position of hiring, how will you evaluate your applicants?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,18aif1a,True,,supper_ham,,127,True,all_ads,False,[],False,,/r/datascience/comments/18aif1a/what_realistically_is_a_good_alternative_takehome/,all_ads,False,https://www.reddit.com/r/datascience/comments/18aif1a/what_realistically_is_a_good_alternative_takehome/,1209064,1701689960.0,0,,False,,,,,,,,,,1830,312
,datascience,"What’s your sniff test or initial analysis to see if there is any potential for ML in a dataset?

Edit: Maybe I should have added more context.  Assume there is a business problem in mind and there is a target variable that the company would like predicted in the data set and a data analyst is pulling the data you request and then handing it off to you. ",t2_495cn7pm,False,,0,False,"Handed a dataset, what’s your sniff test?",[],r/datascience,False,6,network,0,,,False,t3_18ahxus,False,dark,0.82,,public,30,0,{},,,False,[],,False,False,,{},Analysis,False,30,,False,False,self,1701704259.0,,[],{},,True,,1701687964.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What’s your sniff test or initial analysis to see if there is any potential for ML in a dataset?&lt;/p&gt;

&lt;p&gt;Edit: Maybe I should have added more context.  Assume there is a business problem in mind and there is a target variable that the company would like predicted in the data set and a data analyst is pulling the data you request and then handing it off to you. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,18ahxus,True,,Throwawayforgainz99,,24,True,all_ads,False,[],False,,/r/datascience/comments/18ahxus/handed_a_dataset_whats_your_sniff_test/,all_ads,False,https://www.reddit.com/r/datascience/comments/18ahxus/handed_a_dataset_whats_your_sniff_test/,1209064,1701687964.0,0,,False,,,,,,,,,,356,68
,datascience,"I'm an AI/ML architect at Snowflake and an adjunct professor so I figured I'd share some 101 knowledge since someone made a post about materials yesterday.  This [repo](https://github.com/cromano8/Snowflake_ML_Intro) contains a zero -&gt; ML model video/materials in under 8 minutes from setting up your free trial -&gt; loading data -&gt; feature engineering -&gt; model training.  Students/educators get 120 days everyone else 30.  I'll add another lesson to the repo on more advanced topics like near real-time/batch inferencing, and model registry but this demo is a very easy-to-follow guide for people new to Snowflake/ML.  If you have any questions feel free to comment and I'll try to answer them.  The class I teach is around Streamlit and I'll be posting some materials on that as well, and will be using all open source stuff for those lessons.  Hope you all enjoy it cause teaching has always been a passion of mine, even started my career as a high school AP stats/SAS programming teacher.",t2_1ddx9ayn,False,,0,False,Educational intro to Snowflake for Data Science,[],r/datascience,False,6,,0,,,False,t3_18a501i,False,dark,1.0,,public,110,0,{},,,False,[],,False,False,,{},Education,False,110,,False,False,self,False,,[],{},,True,,1701641847.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m an AI/ML architect at Snowflake and an adjunct professor so I figured I&amp;#39;d share some 101 knowledge since someone made a post about materials yesterday.  This &lt;a href=""https://github.com/cromano8/Snowflake_ML_Intro""&gt;repo&lt;/a&gt; contains a zero -&amp;gt; ML model video/materials in under 8 minutes from setting up your free trial -&amp;gt; loading data -&amp;gt; feature engineering -&amp;gt; model training.  Students/educators get 120 days everyone else 30.  I&amp;#39;ll add another lesson to the repo on more advanced topics like near real-time/batch inferencing, and model registry but this demo is a very easy-to-follow guide for people new to Snowflake/ML.  If you have any questions feel free to comment and I&amp;#39;ll try to answer them.  The class I teach is around Streamlit and I&amp;#39;ll be posting some materials on that as well, and will be using all open source stuff for those lessons.  Hope you all enjoy it cause teaching has always been a passion of mine, even started my career as a high school AP stats/SAS programming teacher.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,18a501i,True,,crom5805,,17,True,all_ads,False,[],False,,/r/datascience/comments/18a501i/educational_intro_to_snowflake_for_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/18a501i/educational_intro_to_snowflake_for_data_science/,1209064,1701641847.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?auto=webp&amp;s=50236785a3988517e801565dcbfa3a1d8d9abc46', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d26c82c87ab44a4850f354532e5a96eab3b14d21', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55e4cd8f1633b27153b288fd8447f659846e2bcd', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2734bc29c0dd3b8fdbf807de327b3c8e8d0ddbd', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dec9ee71d9e042ca4ce328a15491f5427e51f1d3', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=96d7ec02ea7b30b09a9bd298147744172e5dff8c', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/QfabnA2rHH-_pgyONwvAkIo57FXOAIvqKJZRgH_qe5M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=990e996c238440dbb8677935c056dfb7f4c9b7e1', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'N7Cnp7sfhcnlygdN54ErakxrUusVRt4hHGYUywSY2gI'}], 'enabled': False}",,,,,,,1002,161
,datascience,"Reason why Data Scientists get laid off so much and have a harder time to find a new job than other tech job profiles (such as SDE) in this market is that Data Science is considered a support team that can enhance the company, but not a product without which a company crumbles. 

This isn't the case with Software Engineering because for most tech companies, the software is the product, not a secondary team that can be laid off for fun",t2_5w8qs8zr,False,,0,False,"Any company/industry where data is the product, not a support team",[],r/datascience,False,6,fun,0,,,False,t3_189ycfa,False,dark,0.88,,public,79,0,{},,,False,[],,False,False,,{},Career Discussion,False,79,,False,False,self,1701632527.0,,[],{},,True,,1701624439.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Reason why Data Scientists get laid off so much and have a harder time to find a new job than other tech job profiles (such as SDE) in this market is that Data Science is considered a support team that can enhance the company, but not a product without which a company crumbles. &lt;/p&gt;

&lt;p&gt;This isn&amp;#39;t the case with Software Engineering because for most tech companies, the software is the product, not a secondary team that can be laid off for fun&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,189ycfa,True,,Snoo_72181,,132,True,all_ads,False,[],False,,/r/datascience/comments/189ycfa/any_companyindustry_where_data_is_the_product_not/,all_ads,False,https://www.reddit.com/r/datascience/comments/189ycfa/any_companyindustry_where_data_is_the_product_not/,1209064,1701624439.0,0,,False,,,,,,,,,,438,81
,datascience,"I have seen many people in this thread/channel discuss the importance of stem degrees to get into the field. I currently have a bachelor's degree in Sociology with foci on data science and data analytics.

I have the opportunity to get a reduced tuition degree, and I'm thinking of getting a data science degree. 

First question - is it worth going back to school to get another degree if i want to enter into data science at some point and not just data analytics?

Second question - If I go back, should I get a second bachelor's in Data Science or add to my current bachelor's and get a Master's? Would there be a difference in what I'm learning per degree? Would one look better/sound better? Does it matter which one I get?

Third question - should I consider something outside of data science as a degree?

Thank you so much!!!!",t2_r2x7vr4v,False,,0,False,is a degree worth it?,[],r/datascience,False,6,discussion,0,,,False,t3_189u6lt,False,dark,0.77,,public,26,0,{},,,False,[],,False,False,,{},Discussion,False,26,,False,False,self,False,,[],{},,True,,1701612350.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have seen many people in this thread/channel discuss the importance of stem degrees to get into the field. I currently have a bachelor&amp;#39;s degree in Sociology with foci on data science and data analytics.&lt;/p&gt;

&lt;p&gt;I have the opportunity to get a reduced tuition degree, and I&amp;#39;m thinking of getting a data science degree. &lt;/p&gt;

&lt;p&gt;First question - is it worth going back to school to get another degree if i want to enter into data science at some point and not just data analytics?&lt;/p&gt;

&lt;p&gt;Second question - If I go back, should I get a second bachelor&amp;#39;s in Data Science or add to my current bachelor&amp;#39;s and get a Master&amp;#39;s? Would there be a difference in what I&amp;#39;m learning per degree? Would one look better/sound better? Does it matter which one I get?&lt;/p&gt;

&lt;p&gt;Third question - should I consider something outside of data science as a degree?&lt;/p&gt;

&lt;p&gt;Thank you so much!!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,189u6lt,True,,iAskTooMuch_cd,,121,True,all_ads,False,[],False,,/r/datascience/comments/189u6lt/is_a_degree_worth_it/,all_ads,False,https://www.reddit.com/r/datascience/comments/189u6lt/is_a_degree_worth_it/,1209064,1701612350.0,0,,False,,,,,,,,,,835,151
,datascience,"Hello.

I'm trying to find a library or code that implements mixture Sequential Probability Ratio Test  in python or tell me how you do your sequential a/b tests?",t2_eappb,False,,0,False,mSPRT library in python,[],r/datascience,False,6,tooling,0,,,False,t3_189fnkw,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Tools,False,7,,False,False,self,False,,[],{},,True,,1701558512.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to find a library or code that implements mixture Sequential Probability Ratio Test  in python or tell me how you do your sequential a/b tests?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,189fnkw,True,,LibiSC,,3,True,all_ads,False,[],False,,/r/datascience/comments/189fnkw/msprt_library_in_python/,all_ads,False,https://www.reddit.com/r/datascience/comments/189fnkw/msprt_library_in_python/,1209064,1701558512.0,0,,False,,,,,,,,,,162,28
,datascience,Honestly I kind of hate it. Everything has to be optimized because of cost and if you make one mistake you can really fuck up. It’s so popular right now it’s hard to avoid.,t2_kcl3tfwe,False,,0,False,What do you think about cloud infrastructure?,[],r/datascience,False,6,fun,0,,,False,t3_188ila7,False,dark,0.8,,public,30,0,{},,,False,[],,False,False,,{},Career Discussion,False,30,,False,False,self,False,,[],{},,True,,1701454698.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Honestly I kind of hate it. Everything has to be optimized because of cost and if you make one mistake you can really fuck up. It’s so popular right now it’s hard to avoid.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,188ila7,True,,NewEcho2940,,29,True,all_ads,False,[],False,,/r/datascience/comments/188ila7/what_do_you_think_about_cloud_infrastructure/,all_ads,False,https://www.reddit.com/r/datascience/comments/188ila7/what_do_you_think_about_cloud_infrastructure/,1209064,1701454698.0,0,,False,,,,,,,,,,172,34
,datascience,"I have a technical interview Monday with a large company, which I'm both excited for and extremely nervous. With that being said, I think I'll be able to handle questions about data storytelling, sql, and basic stats. The one question that I think I'll probably have trouble with is a question regarding your process as an analyst with a vague, unknown purpose (their wording). I drafted the following. Anything I'm missing?

ex. define the problem by asking questions: who is the target audience? what type of data? what is the problem that needs addressing? Is the data clean? Are there outliers? EDA to get acclimated to the dataset.

What I think they are really asking, while being vague, is how I approach a data problem. What should I add to the few questions above?

&amp;#x200B;

Thinking something like this might help as a guide?

https://preview.redd.it/a3scdt114q3c1.png?width=1015&amp;format=png&amp;auto=webp&amp;s=d353e7e218adc88b0e853215075b5c0be049a9f4",t2_3pnizflv,False,,0,False,Technical Interview: How do you handle intentionally vague data prompts?,[],r/datascience,False,6,fun,0,78.0,,False,t3_188hl9r,False,dark,0.86,,public,5,0,{},140.0,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,https://b.thumbs.redditmedia.com/59ewhARGLwvc3cj6djzPMPkxqfkiwByHydtTdxlGG_g.jpg,1701453922.0,,[],{},,True,,1701452136.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a technical interview Monday with a large company, which I&amp;#39;m both excited for and extremely nervous. With that being said, I think I&amp;#39;ll be able to handle questions about data storytelling, sql, and basic stats. The one question that I think I&amp;#39;ll probably have trouble with is a question regarding your process as an analyst with a vague, unknown purpose (their wording). I drafted the following. Anything I&amp;#39;m missing?&lt;/p&gt;

&lt;p&gt;ex. define the problem by asking questions: who is the target audience? what type of data? what is the problem that needs addressing? Is the data clean? Are there outliers? EDA to get acclimated to the dataset.&lt;/p&gt;

&lt;p&gt;What I think they are really asking, while being vague, is how I approach a data problem. What should I add to the few questions above?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thinking something like this might help as a guide?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/a3scdt114q3c1.png?width=1015&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d353e7e218adc88b0e853215075b5c0be049a9f4""&gt;https://preview.redd.it/a3scdt114q3c1.png?width=1015&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d353e7e218adc88b0e853215075b5c0be049a9f4&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,188hl9r,True,,Tyron_Slothrop,,7,True,all_ads,False,[],False,,/r/datascience/comments/188hl9r/technical_interview_how_do_you_handle/,all_ads,False,https://www.reddit.com/r/datascience/comments/188hl9r/technical_interview_how_do_you_handle/,1209064,1701452136.0,0,,False,"{'a3scdt114q3c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3fb2742475fe7dc0c19461699e3003850c4080fb'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=81ec675144b507683f4c88750e90abd7a525f95e'}, {'y': 179, 'x': 320, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf0398f98e30b157492952bdc4bc57b9e8e722d7'}, {'y': 359, 'x': 640, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f57318d16cba1ef55628db608454de84102ca863'}, {'y': 539, 'x': 960, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e92c065f13622cf9fa4e0f0bb43fd7b382746d4e'}], 's': {'y': 570, 'x': 1015, 'u': 'https://preview.redd.it/a3scdt114q3c1.png?width=1015&amp;format=png&amp;auto=webp&amp;s=d353e7e218adc88b0e853215075b5c0be049a9f4'}, 'id': 'a3scdt114q3c1'}}",,,,,,,,,970,145
,datascience,"Because of a re-org, I have the chance to move from my team that has a horrible work-life balance, 20+ hours of meetings, but really great projects with high visibility. I can say my projects are actually quite important to the corporation and EC view it. But dealing with my team and having to stay in a city I don’t care for isn’t it. 

The other team I’m re-orging to is much smaller, I actually like the team members compared to my team, have 4 hours max of meetings, but they’re not able to get projects into production, which is why they’e seen churn. 

In my area, I’m always putting projects into production. The area they’re in is more regulated than mine. I don’t feel valued by my manager and honestly, have a lot of resentment towards him. I’ve had to play politics to get the projects I wanted, and then he barely gave me support. I’ve been told no on so many things, and the resentment has just built up. He also wouldn’t allow me a particular tool and has been supporting a newer teammate who’s been annoying me since he gave a project I wanted to this newer person, yet expected me to train him/answer all of their questions even when it was detracting from my work. And I would get the blame for my other work. 

He and the other team’s director have been arguing over me to their manager. They did a formal interview process which I passed. I get so angry during the day that I have to take myself away from work and get work done. 

I want to switch and have told him that I prefer the opportunity, but he wants to continue to have these meetings. Even if I were to switch, I’d have to support both teams until my current team is OK (they have a ton of projects that only I’m doing/have the ability to). 

The new team technically doesn’t need me until February full time, so until then, I’m the child in a Divorce. I’m so resentful towards my manager that I’ve been communicating in writing over speaking since I don’t think I’d be able to not let my resentment show. 

How would you handle this situation? It’s like limbo with my team resenting me if I leave, and also more work if I do switch roles.

The only thing he does say is that the other team doesn’t get models into production, which is true and is a worry of mine. But I can’t continue to work in such a toxic environment and blamed for everything, then praised to business partners/EC. Publically it looks like he’s very supportive to me, but I know how little support I have and how I’ve had to play politics to get anything. Just so much resentment.

Edit: this is all internal",t2_6lukipdd,False,,0,False,How to tell manager I’m leaving after he keeps trying to get me to stay?,[],r/datascience,False,6,fun,0,,,False,t3_188grh6,False,dark,0.77,,public,21,0,{},,,False,[],,False,False,,{},Career Discussion,False,21,,False,False,self,1701584446.0,,[],{},,True,,1701450053.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Because of a re-org, I have the chance to move from my team that has a horrible work-life balance, 20+ hours of meetings, but really great projects with high visibility. I can say my projects are actually quite important to the corporation and EC view it. But dealing with my team and having to stay in a city I don’t care for isn’t it. &lt;/p&gt;

&lt;p&gt;The other team I’m re-orging to is much smaller, I actually like the team members compared to my team, have 4 hours max of meetings, but they’re not able to get projects into production, which is why they’e seen churn. &lt;/p&gt;

&lt;p&gt;In my area, I’m always putting projects into production. The area they’re in is more regulated than mine. I don’t feel valued by my manager and honestly, have a lot of resentment towards him. I’ve had to play politics to get the projects I wanted, and then he barely gave me support. I’ve been told no on so many things, and the resentment has just built up. He also wouldn’t allow me a particular tool and has been supporting a newer teammate who’s been annoying me since he gave a project I wanted to this newer person, yet expected me to train him/answer all of their questions even when it was detracting from my work. And I would get the blame for my other work. &lt;/p&gt;

&lt;p&gt;He and the other team’s director have been arguing over me to their manager. They did a formal interview process which I passed. I get so angry during the day that I have to take myself away from work and get work done. &lt;/p&gt;

&lt;p&gt;I want to switch and have told him that I prefer the opportunity, but he wants to continue to have these meetings. Even if I were to switch, I’d have to support both teams until my current team is OK (they have a ton of projects that only I’m doing/have the ability to). &lt;/p&gt;

&lt;p&gt;The new team technically doesn’t need me until February full time, so until then, I’m the child in a Divorce. I’m so resentful towards my manager that I’ve been communicating in writing over speaking since I don’t think I’d be able to not let my resentment show. &lt;/p&gt;

&lt;p&gt;How would you handle this situation? It’s like limbo with my team resenting me if I leave, and also more work if I do switch roles.&lt;/p&gt;

&lt;p&gt;The only thing he does say is that the other team doesn’t get models into production, which is true and is a worry of mine. But I can’t continue to work in such a toxic environment and blamed for everything, then praised to business partners/EC. Publically it looks like he’s very supportive to me, but I know how little support I have and how I’ve had to play politics to get anything. Just so much resentment.&lt;/p&gt;

&lt;p&gt;Edit: this is all internal&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,188grh6,True,,Much-Focus-1408,,23,True,all_ads,False,[],False,,/r/datascience/comments/188grh6/how_to_tell_manager_im_leaving_after_he_keeps/,all_ads,False,https://www.reddit.com/r/datascience/comments/188grh6/how_to_tell_manager_im_leaving_after_he_keeps/,1209064,1701450053.0,0,,False,,,,,,,,,,2562,479
,datascience,"I worked in Tech where it was fast paced and best tech. Learned a ton but burn out was a problem.

I’ve worked in Telecom where pace was slow and tech was terrible. Low stress but very boring.

Are there any industries in the middle? Decent tech with some growth but not overwhelming.",t2_kcl3tfwe,False,,0,False,What are good middle of the road industries?,[],r/datascience,False,6,fun,0,,,False,t3_188epke,False,dark,0.98,,public,130,0,{},,,False,[],,False,False,,{},Career Discussion,False,130,,False,False,self,False,,[],{},,True,,1701444755.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I worked in Tech where it was fast paced and best tech. Learned a ton but burn out was a problem.&lt;/p&gt;

&lt;p&gt;I’ve worked in Telecom where pace was slow and tech was terrible. Low stress but very boring.&lt;/p&gt;

&lt;p&gt;Are there any industries in the middle? Decent tech with some growth but not overwhelming.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,188epke,True,,NewEcho2940,,95,True,all_ads,False,[],False,,/r/datascience/comments/188epke/what_are_good_middle_of_the_road_industries/,all_ads,False,https://www.reddit.com/r/datascience/comments/188epke/what_are_good_middle_of_the_road_industries/,1209064,1701444755.0,0,,False,,,,,,,,,,284,53
,datascience,"Sorry if I'm asking that in a really odd or unintuitive way. Say I have data from a year ago and use the first months worth and extract the first 2 principal components for visual inspection on density-based clustering. I can use that same fit on the PCA instance to transform the data for the second month and third month and so on. But how can I determine if that change of basis is still appropriate (along the directions of highest variance) for future data? Are there tests for checking this (outside of monitoring for model drift)?

I'm using PCA to provide some level of inspection for density-based clustering. I'm using the clustering labels to train classifiers, so I'm thinking that a change of basis by refitting the PCA instance will trash the classifiers disciminative ability without necessarily voiding the clustering results (specifically a change in k).

Is this possible? I'm wanting to treat changes symptomatically rather than tearing everything down and rebuilding. If it requires that, its not a problem (and part of the pipeline) but it shouldn't be the only reaction to a change in model performance.",t2_131bi6,False,,0,False,How long should one continue to transform from a single PCA fit?,[],r/datascience,False,6,projects,0,,,False,t3_1884j6m,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},ML,False,8,,False,False,self,False,,[],{},,True,,1701410111.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sorry if I&amp;#39;m asking that in a really odd or unintuitive way. Say I have data from a year ago and use the first months worth and extract the first 2 principal components for visual inspection on density-based clustering. I can use that same fit on the PCA instance to transform the data for the second month and third month and so on. But how can I determine if that change of basis is still appropriate (along the directions of highest variance) for future data? Are there tests for checking this (outside of monitoring for model drift)?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using PCA to provide some level of inspection for density-based clustering. I&amp;#39;m using the clustering labels to train classifiers, so I&amp;#39;m thinking that a change of basis by refitting the PCA instance will trash the classifiers disciminative ability without necessarily voiding the clustering results (specifically a change in k).&lt;/p&gt;

&lt;p&gt;Is this possible? I&amp;#39;m wanting to treat changes symptomatically rather than tearing everything down and rebuilding. If it requires that, its not a problem (and part of the pipeline) but it shouldn&amp;#39;t be the only reaction to a change in model performance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,1884j6m,True,,WadeEffingWilson,,9,True,all_ads,False,[],False,,/r/datascience/comments/1884j6m/how_long_should_one_continue_to_transform_from_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/1884j6m/how_long_should_one_continue_to_transform_from_a/,1209064,1701410111.0,0,,False,,,,,,,,,,1125,189
,datascience,"Hi everyone!

I'm creating a job board for sport analytics and software/data jobs in sports in general. Could be for teams, for betting companies, for consultancy or something more broad. It's just me and my will to create the board I would love to have when I was looking for a new role.

It's new , it's simple and it might be terrible if you look for fancy things, but I'm trying to make it useful.

It totally free and without sign ups , so happy to see you around, if you have any feedback is obviously welcome and I hope you find something useful if that's your target market!

[www.sportsjobs.online](https://www.sportsjobs.online)

&amp;#x200B;

The plan is to add more things, news, etc if people uses it. Thanks!",t2_24mvheq,False,,0,False,Job board for sport analytics and software in sports in general,[],r/datascience,False,6,meta,0,,,False,t3_18812qe,False,dark,0.89,,public,21,0,{},,,False,[],,False,False,,{},Projects,False,21,,False,False,self,False,,[],{},,True,,1701399244.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m creating a job board for sport analytics and software/data jobs in sports in general. Could be for teams, for betting companies, for consultancy or something more broad. It&amp;#39;s just me and my will to create the board I would love to have when I was looking for a new role.&lt;/p&gt;

&lt;p&gt;It&amp;#39;s new , it&amp;#39;s simple and it might be terrible if you look for fancy things, but I&amp;#39;m trying to make it useful.&lt;/p&gt;

&lt;p&gt;It totally free and without sign ups , so happy to see you around, if you have any feedback is obviously welcome and I hope you find something useful if that&amp;#39;s your target market!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.sportsjobs.online""&gt;www.sportsjobs.online&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The plan is to add more things, news, etc if people uses it. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18812qe,True,,fark13,,13,True,all_ads,False,[],False,,/r/datascience/comments/18812qe/job_board_for_sport_analytics_and_software_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/18812qe/job_board_for_sport_analytics_and_software_in/,1209064,1701399244.0,0,,False,,,,,,,,,,722,126
,datascience,"Im at the point in my career where there are a few directions I could go as a DS and struggling to find good advice from someone that has traveled this path. What are the best ways to find a career mentor outside of your current company? 

Networking events seem promising but are so often just thinly veiled sales pitches for xyz co's saas product  

Thoughts?",t2_7nuksarw,False,,0,False,Best ways to find a career mentor?,[],r/datascience,False,6,fun,0,,,False,t3_187upvl,False,dark,0.92,,public,9,0,{},,,False,[],,False,False,,{},Career Discussion,False,9,,False,False,self,False,,[],{},,True,,1701382194.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im at the point in my career where there are a few directions I could go as a DS and struggling to find good advice from someone that has traveled this path. What are the best ways to find a career mentor outside of your current company? &lt;/p&gt;

&lt;p&gt;Networking events seem promising but are so often just thinly veiled sales pitches for xyz co&amp;#39;s saas product  &lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,187upvl,True,,Agitated_Hedgehog_,,11,True,all_ads,False,[],False,,/r/datascience/comments/187upvl/best_ways_to_find_a_career_mentor/,all_ads,False,https://www.reddit.com/r/datascience/comments/187upvl/best_ways_to_find_a_career_mentor/,1209064,1701382194.0,0,,False,,,,,,,,,,361,66
,datascience,"How does your team use version control?

I’ve worked in 2 companies that did it vastly different:

On one team, everyone model we had have its own repository. I found this made code-sharing and collaboration minimal but was super flexible. I had no worries about pushing to main (I actually always worked out of it lol), never stepped on people’s toes, and could format it however I wanted.

On my most recent team, we use 1 single repo. Every push to main has a PR, we all share code since we’re familiar with each other’s work, and it helps us all the learn from one another. I really like this approach but I can be a burden waiting on PRs to be reviewed and you’re ultimately a bit slower since you spend time doing code reviews.

From a software engineering perspective, two is definitely better. From the perspective of a manager, I could see them preferring the first due to velocity (there could be a counter point here that sharing code and finding bugs before they’re deployed speeds things up too)

What are your thoughts? How does your team do version control?",t2_91itiala,False,,0,False,Monolith or Many Repos?,[],r/datascience,False,6,discussion,0,,,False,t3_187suqo,False,dark,0.94,,public,15,0,{},,,False,[],,False,False,,{},Discussion,False,15,,False,False,self,False,,[],{},,True,,1701377656.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How does your team use version control?&lt;/p&gt;

&lt;p&gt;I’ve worked in 2 companies that did it vastly different:&lt;/p&gt;

&lt;p&gt;On one team, everyone model we had have its own repository. I found this made code-sharing and collaboration minimal but was super flexible. I had no worries about pushing to main (I actually always worked out of it lol), never stepped on people’s toes, and could format it however I wanted.&lt;/p&gt;

&lt;p&gt;On my most recent team, we use 1 single repo. Every push to main has a PR, we all share code since we’re familiar with each other’s work, and it helps us all the learn from one another. I really like this approach but I can be a burden waiting on PRs to be reviewed and you’re ultimately a bit slower since you spend time doing code reviews.&lt;/p&gt;

&lt;p&gt;From a software engineering perspective, two is definitely better. From the perspective of a manager, I could see them preferring the first due to velocity (there could be a counter point here that sharing code and finding bugs before they’re deployed speeds things up too)&lt;/p&gt;

&lt;p&gt;What are your thoughts? How does your team do version control?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,187suqo,True,,MGeeeeeezy,,57,True,all_ads,False,[],False,,/r/datascience/comments/187suqo/monolith_or_many_repos/,all_ads,False,https://www.reddit.com/r/datascience/comments/187suqo/monolith_or_many_repos/,1209064,1701377656.0,0,,False,,,,,,,,,,1072,192
,datascience,"Anybody else taking on a temporary job in this terrible DS/DA/ML job climate? I just got an offer to work as a sales rep at Kohl's for $15.50/hr (basically minimum wage where I live in Southern California). If so what are you doing at what's the pay?

This has been a humbling experience for me. I went from a \~$90k/yr comfortable and stable software engineering job, to spending $41k on a Masters in Statistics, burning through all of my savings, all so that I could try to find something I'm more passionate about (which I wouldn't say I'm any more passionate about DS positions than my previous work), and ending up with 0 offers and a handful of interviews in the 6 months since graduating.",t2_tho4v,False,,0,False,Holdover Positions,[],r/datascience,False,6,fun,0,,,False,t3_187pe2d,False,dark,0.93,,public,12,0,{},,,False,[],,False,False,,{},Career Discussion,False,12,,False,False,self,False,,[],{},,True,,1701368857.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anybody else taking on a temporary job in this terrible DS/DA/ML job climate? I just got an offer to work as a sales rep at Kohl&amp;#39;s for $15.50/hr (basically minimum wage where I live in Southern California). If so what are you doing at what&amp;#39;s the pay?&lt;/p&gt;

&lt;p&gt;This has been a humbling experience for me. I went from a ~$90k/yr comfortable and stable software engineering job, to spending $41k on a Masters in Statistics, burning through all of my savings, all so that I could try to find something I&amp;#39;m more passionate about (which I wouldn&amp;#39;t say I&amp;#39;m any more passionate about DS positions than my previous work), and ending up with 0 offers and a handful of interviews in the 6 months since graduating.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,187pe2d,True,,PraiseChrist420,,19,True,all_ads,False,[],False,,/r/datascience/comments/187pe2d/holdover_positions/,all_ads,False,https://www.reddit.com/r/datascience/comments/187pe2d/holdover_positions/,1209064,1701368857.0,0,,False,,,,,,,,,,695,125
,datascience,"
Does anyone here know of or has worked in this area? How applicable is research in optimal experimental design in the industry? I saw Facebook had a lot of work being done in this area, and in general with experimentation being a huge part of data science I’d assume that optimal experimental design research could be something that would have utility in the industry as well?",t2_uy28jztl,False,,0,False,Optimal experimental design as a research area,[],r/datascience,False,6,discussion,0,,,False,t3_187m5en,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1701360612.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone here know of or has worked in this area? How applicable is research in optimal experimental design in the industry? I saw Facebook had a lot of work being done in this area, and in general with experimentation being a huge part of data science I’d assume that optimal experimental design research could be something that would have utility in the industry as well?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,187m5en,True,,Direct-Touch469,,10,True,all_ads,False,[],False,,/r/datascience/comments/187m5en/optimal_experimental_design_as_a_research_area/,all_ads,False,https://www.reddit.com/r/datascience/comments/187m5en/optimal_experimental_design_as_a_research_area/,1209064,1701360612.0,0,,False,,,,,,,,,,377,66
,datascience,Im interested in cases where the better solution was a more 'traditional' model than Gradient Booster in a tabular data project at your job or personal proyect.,t2_oxk1j,False,,0,False,Cases when a 'simpler' model was a better solution than Gradient Boosters in your job or project?,[],r/datascience,False,6,projects,0,,,False,t3_187lnnd,False,dark,0.96,,public,76,0,{},,,False,[],,False,False,,{},ML,False,76,,False,False,self,False,,[],{},,True,,1701359365.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im interested in cases where the better solution was a more &amp;#39;traditional&amp;#39; model than Gradient Booster in a tabular data project at your job or personal proyect.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,187lnnd,True,,PinstripePride97,,52,True,all_ads,False,[],False,,/r/datascience/comments/187lnnd/cases_when_a_simpler_model_was_a_better_solution/,all_ads,False,https://www.reddit.com/r/datascience/comments/187lnnd/cases_when_a_simpler_model_was_a_better_solution/,1209064,1701359365.0,0,,False,,,,,,,,,,160,27
,datascience,"My daughter’s career day is tomorrow. She’s 3 years old. How would you explain data science to a class full of preschoolers who can barely count to 10 and have the attention spans of an amnesiac goldfish hopped up on caffeine?

Edit: I talked about how I solve problems and puzzles using math and numbers at work. We talked about a super simple example of collaborative filtering - how if kids liked Mickey Mouse and their friend liked Mickey Mouse and Paw Patrol, then they might like Paw Patrol as well. Then we made histograms out of fruit snacks and used them to identify which colors had the most and least in a single pack. Then I encouraged them to start applying for internships now.",t2_1vnymz5j,False,,0,False,Data Science Career Day,[],r/datascience,False,6,,0,,,False,t3_187kug2,False,dark,0.94,,public,111,0,{},,,False,[],,False,False,,{},Challenges,False,111,,False,False,self,1701447986.0,,[],{},,True,,1701357233.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My daughter’s career day is tomorrow. She’s 3 years old. How would you explain data science to a class full of preschoolers who can barely count to 10 and have the attention spans of an amnesiac goldfish hopped up on caffeine?&lt;/p&gt;

&lt;p&gt;Edit: I talked about how I solve problems and puzzles using math and numbers at work. We talked about a super simple example of collaborative filtering - how if kids liked Mickey Mouse and their friend liked Mickey Mouse and Paw Patrol, then they might like Paw Patrol as well. Then we made histograms out of fruit snacks and used them to identify which colors had the most and least in a single pack. Then I encouraged them to start applying for internships now.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,187kug2,True,,save_the_panda_bears,,70,True,all_ads,False,[],False,,/r/datascience/comments/187kug2/data_science_career_day/,all_ads,False,https://www.reddit.com/r/datascience/comments/187kug2/data_science_career_day/,1209064,1701357233.0,0,,False,,,,,,,,,,691,125
,datascience,I've found that the timeline for getting data science to production is much longer than I would have previously expected... are any of you running into the same problem? What have you found works to get to the finish line for a project faster? ,t2_anwr3x7ou,False,,0,False,What is preventing you from iterating more effectively on your DS projects at work?,[],r/datascience,False,6,discussion,0,,,False,t3_187krkq,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,False,self,False,,[],{},,True,,1701357024.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve found that the timeline for getting data science to production is much longer than I would have previously expected... are any of you running into the same problem? What have you found works to get to the finish line for a project faster? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,187krkq,True,,zero-true,,23,True,all_ads,False,[],False,,/r/datascience/comments/187krkq/what_is_preventing_you_from_iterating_more/,all_ads,False,https://www.reddit.com/r/datascience/comments/187krkq/what_is_preventing_you_from_iterating_more/,1209064,1701357024.0,0,,False,,,,,,,,,,244,44
,datascience,"I have made a few small changes to a report I developed from my tech job pipeline. I also added some new queries for jobs such as MLOps engineer and AI engineer. 

Background: I built a transformer based pipeline that predicts several attributes from job postings. The scope spans automated data collection, cleaning, database, annotation, training/evaluation to visualization, scheduling, and monitoring.

This report is barely scratching the insights surface from the 230k+ dataset I have gathered over just a few months in 2023. But this could be a North Star or w/e they call it. 

Let me know if you have any questions! I’m also looking for volunteers. Message me if you’re a student/recent grad or experienced pro and would like to work with me on this. I usually do incremental work on the weekends.",t2_6xp1skf7,False,,0,False,US Data Science Skill Report 11/22-11/29,[],r/datascience,False,6,network,0,79.0,,False,t3_187fnbf,False,dark,0.95,,public,299,0,{},140.0,,False,[],,True,False,,{},Analysis,False,299,,False,True,https://b.thumbs.redditmedia.com/9WjLqVEulbOIOLaUVLadOS1-xzLRiNaT3O9yfSnpF1I.jpg,False,,[],{},,False,,1701340752.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have made a few small changes to a report I developed from my tech job pipeline. I also added some new queries for jobs such as MLOps engineer and AI engineer. &lt;/p&gt;

&lt;p&gt;Background: I built a transformer based pipeline that predicts several attributes from job postings. The scope spans automated data collection, cleaning, database, annotation, training/evaluation to visualization, scheduling, and monitoring.&lt;/p&gt;

&lt;p&gt;This report is barely scratching the insights surface from the 230k+ dataset I have gathered over just a few months in 2023. But this could be a North Star or w/e they call it. &lt;/p&gt;

&lt;p&gt;Let me know if you have any questions! I’m also looking for volunteers. Message me if you’re a student/recent grad or experienced pro and would like to work with me on this. I usually do incremental work on the weekends.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,187fnbf,True,,Kbig22,,50,True,all_ads,False,[],False,,/r/datascience/comments/187fnbf/us_data_science_skill_report_11221129/,all_ads,False,https://i.redd.it/de6158vjrg3c1.jpg,1209064,1701340752.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?auto=webp&amp;s=66f5915d35808119df520296dc39f77b72a4db8d', 'width': 2652, 'height': 1501}, 'resolutions': [{'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9800f794af93e7ddda53325f3f1c663537dcc184', 'width': 108, 'height': 61}, {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=09a91aef5b8c7fcf0383b555dbe13014102e6ec5', 'width': 216, 'height': 122}, {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36041be6286cb0c4b78b3d649754aba23d81d320', 'width': 320, 'height': 181}, {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f81d54750c76ec21f56bd69187e33dfdf9254aa7', 'width': 640, 'height': 362}, {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e8a593e176ab6e05fbee96388de510f33a9c56', 'width': 960, 'height': 543}, {'url': 'https://preview.redd.it/de6158vjrg3c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f7e369551f6ac5704ec9d0c833f8ecf420c810a', 'width': 1080, 'height': 611}], 'variants': {}, 'id': 'M-h4X5JqZSzPSms6YazjGSCcl-fBg_2jylKSrBvXz2k'}], 'enabled': True}",,https://i.redd.it/de6158vjrg3c1.jpg,,,,,806,135
,datascience,"Im a Product Data scientist and recently got a contract to develop a Bandits algorithm. It's basically a recommender system that uses ideas from reinforcement learning to iteratively improve itself.

Is there a demand for reinforcement learning in product DS? If so, what are some use cases besides recommender systems?",t2_vmnhefbj,False,,0,False,Are you using Reinforcement Learning at work? If so how?,[],r/datascience,False,6,fun,0,,,False,t3_187ey68,False,dark,0.92,,public,11,0,{},,,False,[],,False,False,,{},Career Discussion,False,11,,False,False,self,False,,[],{},,True,,1701337837.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im a Product Data scientist and recently got a contract to develop a Bandits algorithm. It&amp;#39;s basically a recommender system that uses ideas from reinforcement learning to iteratively improve itself.&lt;/p&gt;

&lt;p&gt;Is there a demand for reinforcement learning in product DS? If so, what are some use cases besides recommender systems?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,187ey68,True,,tootieloolie,,26,True,all_ads,False,[],False,,/r/datascience/comments/187ey68/are_you_using_reinforcement_learning_at_work_if/,all_ads,False,https://www.reddit.com/r/datascience/comments/187ey68/are_you_using_reinforcement_learning_at_work_if/,1209064,1701337837.0,0,,False,,,,,,,,,,319,50
,datascience,"I have currently been working at a R&amp;D center (North of Spain) in DS/ML applied to cybersecurity and security analytics for over a year now. Most of the problems that we deal at my team are related to unsupervised anomaly detection in multiple settings (industrial networks, it networks, system logs, iot networks, etc.) for detection of cyberattacks (using traditional and deep learning models). The problem I am facing is that due to the unsupervised nature of these problems and that the data we deal with is not very similar to any known labeled dataset, it turns out to be almost imposible to validate our developments properly (to know if what we are doing is correct) properly. This has led me to feel quite impotent and to develop some kind of impostor syndrome/feeling that I am not learning a lot nor developing meaningful skills. I have tried to tackle this focusing on the parts of the pipeline where I can learn (MLOps, data quality, ML monitoring, explainability) but I feel that things are a bit odd. Has anyone felt that way or been in a similar situation?  If so, what have you done to solve this and keep learning?

Thank you in advance!",t2_nn7b1,False,,0,False,Feeling a but stuck in my current DS applied to cybersecurity R&amp;D job,[],r/datascience,False,6,fun,0,,,False,t3_187dpg1,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1701332659.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have currently been working at a R&amp;amp;D center (North of Spain) in DS/ML applied to cybersecurity and security analytics for over a year now. Most of the problems that we deal at my team are related to unsupervised anomaly detection in multiple settings (industrial networks, it networks, system logs, iot networks, etc.) for detection of cyberattacks (using traditional and deep learning models). The problem I am facing is that due to the unsupervised nature of these problems and that the data we deal with is not very similar to any known labeled dataset, it turns out to be almost imposible to validate our developments properly (to know if what we are doing is correct) properly. This has led me to feel quite impotent and to develop some kind of impostor syndrome/feeling that I am not learning a lot nor developing meaningful skills. I have tried to tackle this focusing on the parts of the pipeline where I can learn (MLOps, data quality, ML monitoring, explainability) but I feel that things are a bit odd. Has anyone felt that way or been in a similar situation?  If so, what have you done to solve this and keep learning?&lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,187dpg1,True,,camipi_07,,3,True,all_ads,False,[],False,,/r/datascience/comments/187dpg1/feeling_a_but_stuck_in_my_current_ds_applied_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/187dpg1/feeling_a_but_stuck_in_my_current_ds_applied_to/,1209064,1701332659.0,0,,False,,,,,,,,,,1159,202
,datascience,I'm just sense checking what tasks I might find difficult if I do get a DS role.,t2_amfdjuba,False,,0,False,What tasks do you find difficult in your data science role?,[],r/datascience,False,6,discussion,0,,,False,t3_187diad,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1701331867.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m just sense checking what tasks I might find difficult if I do get a DS role.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,187diad,True,,limedove,,12,True,all_ads,False,[],False,,/r/datascience/comments/187diad/what_tasks_do_you_find_difficult_in_your_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/187diad/what_tasks_do_you_find_difficult_in_your_data/,1209064,1701331867.0,0,,False,,,,,,,,,,80,17
,datascience,"I work for a govt entity at 30% lower than my market rate in a LCOL area. Usually we feel happy if we get 10 applications total and a couple of decent ones. But recently opened one for a DS position with entry level requirements. In a couple of weeks we got ""flooded"" with applicants with MS and PhD from tier 1 universities including Carnegie Mellon, Northwestern, University of Chicago, John Hopkins. I have been looking for a new role and this was a good reminder for me as well that the market is shit and if you are looking for a new role, there couldn't be any worse time lately. So, if you are on the same boat, just hang tight. Not getting an offer has a lot to do with factors beyond your control.",t2_9axqyq8u,False,,0,False,A gentle reminder that the market is a shitshow now if you are looking for a job. Just hang in there.,[],r/datascience,False,6,fun,0,,,False,t3_1877ryl,False,dark,0.98,,public,600,0,{},,,False,[],,False,False,,{},Career Discussion,False,600,,False,False,self,False,,[],{},,True,,1701312527.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work for a govt entity at 30% lower than my market rate in a LCOL area. Usually we feel happy if we get 10 applications total and a couple of decent ones. But recently opened one for a DS position with entry level requirements. In a couple of weeks we got &amp;quot;flooded&amp;quot; with applicants with MS and PhD from tier 1 universities including Carnegie Mellon, Northwestern, University of Chicago, John Hopkins. I have been looking for a new role and this was a good reminder for me as well that the market is shit and if you are looking for a new role, there couldn&amp;#39;t be any worse time lately. So, if you are on the same boat, just hang tight. Not getting an offer has a lot to do with factors beyond your control.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,1877ryl,True,,Difficult-Big-3890,,185,True,all_ads,False,[],False,,/r/datascience/comments/1877ryl/a_gentle_reminder_that_the_market_is_a_shitshow/,all_ads,False,https://www.reddit.com/r/datascience/comments/1877ryl/a_gentle_reminder_that_the_market_is_a_shitshow/,1209064,1701312527.0,0,,False,,,,,,,,,,706,136
,datascience,"Hi, I have been working in data science for some time and mostly using conda to manage my dev packages.  However, as the number of packages grows, I constantly have issue keeping my packages ""backward compatible"" since conda tends to upgrade old packages when they are not compatible with new packages to be installed.  And it tends to be a headache to sort out what the problem is when old code fails to run, and trying to ""revert"" to previous env to fix it takes forever.  

I recently came across docker, and am thinking if the ""layer-structure"" of docker would be easier to maintain in the long run, and easier to ""revert"" if things break?  Not familiar with docker, so wonder if anyone has any experience regarding this?

Thanks!",t2_lodqn3wz,False,,0,False,maintaining docker vs conda-environment,[],r/datascience,False,6,discussion,0,,,False,t3_1876oho,False,dark,0.93,,public,13,0,{},,,False,[],,False,False,,{},Discussion,False,13,,False,False,self,False,,[],{},,True,,1701309505.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have been working in data science for some time and mostly using conda to manage my dev packages.  However, as the number of packages grows, I constantly have issue keeping my packages &amp;quot;backward compatible&amp;quot; since conda tends to upgrade old packages when they are not compatible with new packages to be installed.  And it tends to be a headache to sort out what the problem is when old code fails to run, and trying to &amp;quot;revert&amp;quot; to previous env to fix it takes forever.  &lt;/p&gt;

&lt;p&gt;I recently came across docker, and am thinking if the &amp;quot;layer-structure&amp;quot; of docker would be easier to maintain in the long run, and easier to &amp;quot;revert&amp;quot; if things break?  Not familiar with docker, so wonder if anyone has any experience regarding this?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,1876oho,True,,Illustrious-Pay-7516,,12,True,all_ads,False,[],False,,/r/datascience/comments/1876oho/maintaining_docker_vs_condaenvironment/,all_ads,False,https://www.reddit.com/r/datascience/comments/1876oho/maintaining_docker_vs_condaenvironment/,1209064,1701309505.0,0,,False,,,,,,,,,,734,129
,datascience,"What was, from your point of view, the most important thing you did in order to be offered your current job? Was it about a project you developed? A question you answered super well? A tool you showed proficiency in?

My story

How it started: I was approached by a now teammate because he had seen me posting about statistics on LinkedIn.

How it went on: I had to do a 2-hour data science test which they said was company-default.

How it worked out: I believe it was the computed ROI of a solution in the previous position + a good, friend-making slides-led introduction of myself in the last interview that sealed the deal.",t2_nr338hpnv,False,,0,False,How did you get your current job?,[],r/datascience,False,6,fun,0,,,False,t3_1870jv7,False,dark,0.94,,public,40,0,{},,,False,[],,False,False,,{},Career Discussion,False,40,,False,False,self,False,,[],{},,True,,1701293198.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What was, from your point of view, the most important thing you did in order to be offered your current job? Was it about a project you developed? A question you answered super well? A tool you showed proficiency in?&lt;/p&gt;

&lt;p&gt;My story&lt;/p&gt;

&lt;p&gt;How it started: I was approached by a now teammate because he had seen me posting about statistics on LinkedIn.&lt;/p&gt;

&lt;p&gt;How it went on: I had to do a 2-hour data science test which they said was company-default.&lt;/p&gt;

&lt;p&gt;How it worked out: I believe it was the computed ROI of a solution in the previous position + a good, friend-making slides-led introduction of myself in the last interview that sealed the deal.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,1870jv7,True,,BrDataScientist,,51,True,all_ads,False,[],False,,/r/datascience/comments/1870jv7/how_did_you_get_your_current_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/1870jv7/how_did_you_get_your_current_job/,1209064,1701293198.0,0,,False,,,,,,,,,,627,114
,datascience,"hey guys, so I am doing ETL for our databases in netsuite/salesforce/many other disparate db through DBT into Snowflake for data warehouse.

NS/SF themselves doesn't seem to have any convention/logical way of how they order columns. When you do select \* from \[table\] from these db, how the data is presented doesn't seem to be organized in any particular way.

but as i am transforming these data into the data warehouse, do you guys re-order these columns?

I am torn by ordering them in

1. alphabetical order, or
2. ordering them in terms of context i.e. (primary key, data type 1like qty, data type 2 like product info..., foreign keys, data\_trackings)

is there a standard way or best practice of doing this or completely by preference?",t2_cooe1,False,,0,False,Column ordering standard/practice for ETL?,[],r/datascience,False,6,,0,,,False,t3_186xv5m,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Coding,False,7,,False,False,self,False,,[],{},,True,,1701286208.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hey guys, so I am doing ETL for our databases in netsuite/salesforce/many other disparate db through DBT into Snowflake for data warehouse.&lt;/p&gt;

&lt;p&gt;NS/SF themselves doesn&amp;#39;t seem to have any convention/logical way of how they order columns. When you do select * from [table] from these db, how the data is presented doesn&amp;#39;t seem to be organized in any particular way.&lt;/p&gt;

&lt;p&gt;but as i am transforming these data into the data warehouse, do you guys re-order these columns?&lt;/p&gt;

&lt;p&gt;I am torn by ordering them in&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;alphabetical order, or&lt;/li&gt;
&lt;li&gt;ordering them in terms of context i.e. (primary key, data type 1like qty, data type 2 like product info..., foreign keys, data_trackings)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;is there a standard way or best practice of doing this or completely by preference?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,186xv5m,True,,tyw214,,2,True,all_ads,False,[],False,,/r/datascience/comments/186xv5m/column_ordering_standardpractice_for_etl/,all_ads,False,https://www.reddit.com/r/datascience/comments/186xv5m/column_ordering_standardpractice_for_etl/,1209064,1701286208.0,0,,False,,,,,,,,,,745,126
,datascience,"I've came across this even in Eventbrite: [https://www.eventbrite.com/e/land-your-dream-job-with-a-data-science-portfolio-tickets-767692658407](https://www.eventbrite.com/e/land-your-dream-job-with-a-data-science-portfolio-tickets-767692658407?aff=ebdssbdestsearch)

I'm not sure how to feel about Data Science portfolios tbh. I've found that in the past they were super relevant to put yourself apart from others, but not so much anymore as everyone have more a less the same type of materials available.   
Do you still value portfolios? What traits do you look after in a Portfolio?",t2_54ka7fmt,False,,0,False,How important is to have a Data Science portfolio nowadays,[],r/datascience,False,6,fun,0,,,False,t3_186w5ak,False,dark,0.86,,public,53,0,{},,,False,[],,False,False,,{},Career Discussion,False,53,,False,False,self,False,,[],{},,True,,1701281884.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve came across this even in Eventbrite: &lt;a href=""https://www.eventbrite.com/e/land-your-dream-job-with-a-data-science-portfolio-tickets-767692658407?aff=ebdssbdestsearch""&gt;https://www.eventbrite.com/e/land-your-dream-job-with-a-data-science-portfolio-tickets-767692658407&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not sure how to feel about Data Science portfolios tbh. I&amp;#39;ve found that in the past they were super relevant to put yourself apart from others, but not so much anymore as everyone have more a less the same type of materials available.&lt;br/&gt;
Do you still value portfolios? What traits do you look after in a Portfolio?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,186w5ak,True,,Dry_Cattle9399,,48,True,all_ads,False,[],False,,/r/datascience/comments/186w5ak/how_important_is_to_have_a_data_science_portfolio/,all_ads,False,https://www.reddit.com/r/datascience/comments/186w5ak/how_important_is_to_have_a_data_science_portfolio/,1209064,1701281884.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?auto=webp&amp;s=c3aa0f662d49deffea0374789d88ef07382824b4', 'width': 1000, 'height': 500}, 'resolutions': [{'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1db5c5c35f0b473d8b8fd7a97e10f32de3478e1', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=99bc4274fa41d359f926eae9523257959a522186', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9885b206cb9009e1759b8985fd00bdc55971b77a', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af1926b565c7eb2447ae8691c843a186186e211d', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/8DUJmIoGn-qHByO5475jE6uWtobC_tyqstxiiQ-Rh4Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e762ceacd2d8c4ea7a9efe67563cc8b4e4371806', 'width': 960, 'height': 480}], 'variants': {}, 'id': 'cDKBpiSi7e6q8oEqwJQN29qjZCfX2fUjPdCkdf0dMOA'}], 'enabled': False}",,,,,,,585,66
,datascience,"I feel the most common way to do it is to take work from a Jupyter notebook, save some spreadsheets and plots, and then spend a bunch of time to put them in a PPT.

Does anyone have another workflow? What have you found makes your data science presentations successful? ",t2_anwr3x7ou,False,,0,False,[D] What is your favorite way to show your work at your job?,[],r/datascience,False,6,discussion,0,,,False,t3_186qp7v,False,dark,1.0,,public,47,0,{},,,False,[],,False,False,,{},Discussion,False,47,,False,False,self,False,,[],{},,True,,1701268212.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I feel the most common way to do it is to take work from a Jupyter notebook, save some spreadsheets and plots, and then spend a bunch of time to put them in a PPT.&lt;/p&gt;

&lt;p&gt;Does anyone have another workflow? What have you found makes your data science presentations successful? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,186qp7v,True,,zero-true,,40,True,all_ads,False,[],False,,/r/datascience/comments/186qp7v/d_what_is_your_favorite_way_to_show_your_work_at/,all_ads,False,https://www.reddit.com/r/datascience/comments/186qp7v/d_what_is_your_favorite_way_to_show_your_work_at/,1209064,1701268212.0,0,,False,,,,,,,,,,270,50
,datascience,"I have a binary classification problem. Imbalanced dataset of 30/70. 

In this example, I know that the actual percentage of the target variable is closer 45% in the training data, the 15% is just labeled incorrectly/missed. 

So 15% of the training data is false negatives.

Would unsupervised ML be an acceptable approach here given that the 15% is pretty similar to the original 30%?

Would regular supervised learning not work here or am I completely overthinking this?",t2_495cn7pm,False,,0,False,Is this the correct usage of unsupervised ML?,[],r/datascience,False,6,projects,0,,,False,t3_186la5y,False,dark,0.74,,public,9,0,{},,,False,[],,False,False,,{},ML,False,9,,False,False,self,False,,[],{},,True,,1701249095.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a binary classification problem. Imbalanced dataset of 30/70. &lt;/p&gt;

&lt;p&gt;In this example, I know that the actual percentage of the target variable is closer 45% in the training data, the 15% is just labeled incorrectly/missed. &lt;/p&gt;

&lt;p&gt;So 15% of the training data is false negatives.&lt;/p&gt;

&lt;p&gt;Would unsupervised ML be an acceptable approach here given that the 15% is pretty similar to the original 30%?&lt;/p&gt;

&lt;p&gt;Would regular supervised learning not work here or am I completely overthinking this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,186la5y,True,,Throwawayforgainz99,,30,True,all_ads,False,[],False,,/r/datascience/comments/186la5y/is_this_the_correct_usage_of_unsupervised_ml/,all_ads,False,https://www.reddit.com/r/datascience/comments/186la5y/is_this_the_correct_usage_of_unsupervised_ml/,1209064,1701249095.0,0,,False,,,,,,,,,,473,77
,datascience,"Hey so I recently got a new grad job offer as a data scientist with TC about 125k in Dallas, Texas. But I have never really done data science before in my life and I'm a little worried about going in there and just complete flopping. My statistics teacher made the class wayyyy too easy so I'm really going in with only a little knowledge. I barely know what a standard deviation is.

I have worked on projects as an intern software developer where I built a tool which helps people who do data analysis but I don't actually know how to do any of it myself. I think the hiring manager was more impressed with what I can do in software development, but the job description was tons of what looks like traditional DS stuff.

Just wondering if anybody had any ideas on what I should be focusing on to improve upon my weak points? I have a BS in CS.

Skills: python, using LLMs, full stack swe, a bit of pandas, beautifulsoup, databases, sql

Lacking: actual data science skills

Side note: how are the opportunities for remote work in DS as compared to software development?",t2_pt7x3,False,,0,False,125k offer as a data scientist but I have no idea what a data scientist does,[],r/datascience,False,6,fun,0,,,False,t3_186id1x,False,dark,0.89,,public,589,0,{},,,False,[],,False,False,,{},Career Discussion,False,589,,False,False,self,1701318935.0,,[],{},,True,,1701237165.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey so I recently got a new grad job offer as a data scientist with TC about 125k in Dallas, Texas. But I have never really done data science before in my life and I&amp;#39;m a little worried about going in there and just complete flopping. My statistics teacher made the class wayyyy too easy so I&amp;#39;m really going in with only a little knowledge. I barely know what a standard deviation is.&lt;/p&gt;

&lt;p&gt;I have worked on projects as an intern software developer where I built a tool which helps people who do data analysis but I don&amp;#39;t actually know how to do any of it myself. I think the hiring manager was more impressed with what I can do in software development, but the job description was tons of what looks like traditional DS stuff.&lt;/p&gt;

&lt;p&gt;Just wondering if anybody had any ideas on what I should be focusing on to improve upon my weak points? I have a BS in CS.&lt;/p&gt;

&lt;p&gt;Skills: python, using LLMs, full stack swe, a bit of pandas, beautifulsoup, databases, sql&lt;/p&gt;

&lt;p&gt;Lacking: actual data science skills&lt;/p&gt;

&lt;p&gt;Side note: how are the opportunities for remote work in DS as compared to software development?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,186id1x,True,,Yung-Split,,268,True,all_ads,False,[],False,,/r/datascience/comments/186id1x/125k_offer_as_a_data_scientist_but_i_have_no_idea/,all_ads,False,https://www.reddit.com/r/datascience/comments/186id1x/125k_offer_as_a_data_scientist_but_i_have_no_idea/,1209064,1701237165.0,0,,False,,,,,,,,,,1071,197
,datascience,I guess sex just drives a lot of things…,t2_y9a4a,False,,0,False,The cover of my linear regression textbook would seem to indicate that sex is the primary driver of salary.,[],r/datascience,False,6,discussion,0,140.0,,False,t3_1868lzn,False,dark,0.87,,public,213,0,{},140.0,,False,[],,True,False,,{},Discussion,False,213,,False,False,https://b.thumbs.redditmedia.com/xY67aT_BeS4myOPknNx-Xb5nCX5oyMncdBogFYBnYWs.jpg,False,,[],{},,False,,1701209981.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I guess sex just drives a lot of things…&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,1868lzn,True,,WartimeHotTot,,61,True,all_ads,False,[],False,,/r/datascience/comments/1868lzn/the_cover_of_my_linear_regression_textbook_would/,all_ads,False,https://i.redd.it/f2y15d6py53c1.jpg,1209064,1701209981.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?auto=webp&amp;s=f9d84e26e1aeda914329fefcd117d7bbfce34f29', 'width': 3024, 'height': 4032}, 'resolutions': [{'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f16e1f8e1d5c6604a39e5c6703c324a3cd6a0db7', 'width': 108, 'height': 144}, {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a514e62e236c6bb084acac916742eb0e621fc55a', 'width': 216, 'height': 288}, {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b33013c4eec5f939c74e183490c33e03db7dc41b', 'width': 320, 'height': 426}, {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=259e8b85bfcfc1e9c8f92bd128139c9963cef371', 'width': 640, 'height': 853}, {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b666ab4efc2f022b54885e60e75e85de116f6c64', 'width': 960, 'height': 1280}, {'url': 'https://preview.redd.it/f2y15d6py53c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28b00aa2195cc5dae8733ed3f1d687b4a3d2acba', 'width': 1080, 'height': 1440}], 'variants': {}, 'id': 'wCOziiXNYUc4zLReujU89Cs6H64imHl3b9SOiqTMAAA'}], 'enabled': True}",,https://i.redd.it/f2y15d6py53c1.jpg,,,,,40,9
,datascience,"There are too many case studies on teams and leadership that don't relate to analytics or data science. What are the companies which have really innovated or advanced how to do data (science, engineering, analytics, etc) in teams. I'm thinking about Hillary Parker's work at Stitch Fix for example. What are some examples from modern business history? Know of any specific examples about LLM data? How about smaller companies than the usual Silicon Valley names? I'm thinking about writing a blog or book on the subject but still in the exploratory phase.",t2_dtic2,False,,0,False,What are the best data teams in business history?,[],r/datascience,False,6,,0,,,False,t3_1863f7q,False,dark,0.9,,public,97,0,{},,,False,[],,False,False,,{},Education,False,97,,False,False,self,False,,[],{},,True,,1701197335.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There are too many case studies on teams and leadership that don&amp;#39;t relate to analytics or data science. What are the companies which have really innovated or advanced how to do data (science, engineering, analytics, etc) in teams. I&amp;#39;m thinking about Hillary Parker&amp;#39;s work at Stitch Fix for example. What are some examples from modern business history? Know of any specific examples about LLM data? How about smaller companies than the usual Silicon Valley names? I&amp;#39;m thinking about writing a blog or book on the subject but still in the exploratory phase.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,1863f7q,True,,eastofwestla,,85,True,all_ads,False,[],False,,/r/datascience/comments/1863f7q/what_are_the_best_data_teams_in_business_history/,all_ads,False,https://www.reddit.com/r/datascience/comments/1863f7q/what_are_the_best_data_teams_in_business_history/,1209064,1701197335.0,0,,False,,,,,,,,,,555,92
,datascience,"I ran into an intersting case today, which I would like to discuss. I have changed some details to keep the companies involved anonymous.

The shopping portal GoGreen🍏 allows customers to view the carbon footprint of each item they shop, enabling them to make informed decisions that could minimize their environmental impact. While shopping, the customer sees a bar chart that shows both the stacked CO2 emisions from all the items they have selected so far, and a second bar that that shows the stacked CO2 emisions for alternative items with a smaller footprint.

[An illustration of the described bar chart](https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;format=png&amp;auto=webp&amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9)

Unfortunatelt, not all sub-vendors are able to provide an CO2 estimate for all their items. When this happens, GoGreen🍏 instead relys on an official rapport that have calculated the average carbon footprint for a huge amount of items. This will be an average value based on similar products.

The problem is this: Vendors who are spending their ressources on providing good CO2 estiamates naturally wants to be rewarded for this effort. However, it is not clear how this should be done in a fair way. I see several solutions, but neither are good:

1. If we fill the nan-values based on the averages from the rapport, the averages will sometimes comes out better. This would create an incentive to not rapport the carbon footprint if the vendors suspects they will come out worse than the average
2. If we exclude the nan-values, this will essentailly be the same as saying the footprint is zero, which would insentivice the previous behaviour even more
3. If we penalise the vendors who don't report a CO2 estimate with a ""bad data quality tax"", this will be seen unfair by the user's who don't rapport such estimates (who in many cases have legitimate reasons why they are not able to). And we simply do not have enough data to create a fair penalty.

This whole thing would not be a problem if all vendors either did or did not offer CO2 estimates. However, it becomes a huge fairness-issue when there is a mix. We want to reward good data quality, but is has to be done fairly. We also need to present this in a way that enables customers to make well-informed decisions.

Anyone with relevant tips or experiences? 🤓",t2_2boatuxv,False,,0,False,How to reward good data quality in decision making?,[],r/datascience,False,6,discussion,0,134.0,,False,t3_185su4m,False,dark,0.83,,public,19,0,{},140.0,,False,[],,False,False,,{},Discussion,False,19,,False,False,https://b.thumbs.redditmedia.com/Am6pP6EHxv93XV6vCaENJAVGFjzC-xt-8cB2jGJEK-Q.jpg,False,,[],{},,True,,1701166672.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I ran into an intersting case today, which I would like to discuss. I have changed some details to keep the companies involved anonymous.&lt;/p&gt;

&lt;p&gt;The shopping portal GoGreen🍏 allows customers to view the carbon footprint of each item they shop, enabling them to make informed decisions that could minimize their environmental impact. While shopping, the customer sees a bar chart that shows both the stacked CO2 emisions from all the items they have selected so far, and a second bar that that shows the stacked CO2 emisions for alternative items with a smaller footprint.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9""&gt;An illustration of the described bar chart&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Unfortunatelt, not all sub-vendors are able to provide an CO2 estimate for all their items. When this happens, GoGreen🍏 instead relys on an official rapport that have calculated the average carbon footprint for a huge amount of items. This will be an average value based on similar products.&lt;/p&gt;

&lt;p&gt;The problem is this: Vendors who are spending their ressources on providing good CO2 estiamates naturally wants to be rewarded for this effort. However, it is not clear how this should be done in a fair way. I see several solutions, but neither are good:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If we fill the nan-values based on the averages from the rapport, the averages will sometimes comes out better. This would create an incentive to not rapport the carbon footprint if the vendors suspects they will come out worse than the average&lt;/li&gt;
&lt;li&gt;If we exclude the nan-values, this will essentailly be the same as saying the footprint is zero, which would insentivice the previous behaviour even more&lt;/li&gt;
&lt;li&gt;If we penalise the vendors who don&amp;#39;t report a CO2 estimate with a &amp;quot;bad data quality tax&amp;quot;, this will be seen unfair by the user&amp;#39;s who don&amp;#39;t rapport such estimates (who in many cases have legitimate reasons why they are not able to). And we simply do not have enough data to create a fair penalty.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This whole thing would not be a problem if all vendors either did or did not offer CO2 estimates. However, it becomes a huge fairness-issue when there is a mix. We want to reward good data quality, but is has to be done fairly. We also need to present this in a way that enables customers to make well-informed decisions.&lt;/p&gt;

&lt;p&gt;Anyone with relevant tips or experiences? 🤓&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,185su4m,True,,PostponeIdiocracy,,42,True,all_ads,False,[],False,,/r/datascience/comments/185su4m/how_to_reward_good_data_quality_in_decision_making/,all_ads,False,https://www.reddit.com/r/datascience/comments/185su4m/how_to_reward_good_data_quality_in_decision_making/,1209064,1701166672.0,0,,False,"{'fzl2lt2ud23c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 103, 'x': 108, 'u': 'https://preview.redd.it/fzl2lt2ud23c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddab52c1c22e111c6f08137feaceebc1492301c'}, {'y': 207, 'x': 216, 'u': 'https://preview.redd.it/fzl2lt2ud23c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7512f8d09eb05df991b979e804e8b1cf6a0757c2'}, {'y': 307, 'x': 320, 'u': 'https://preview.redd.it/fzl2lt2ud23c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=977eac0ed475303e85da1cc874f4bda4661bd64a'}], 's': {'y': 384, 'x': 400, 'u': 'https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;format=png&amp;auto=webp&amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9'}, 'id': 'fzl2lt2ud23c1'}}",,,,,,,,,2362,387
,datascience,"I'm curious if anyone has dared putting a solution that uses an LLM (e.g. ChatGPT) to parse unstructured text into e.g. JSON?

I've only tested this with ChatGPT and it works surprisingly well. But I'm still not convinced I could trust it to go through large scales of text in production.",t2_2boatuxv,False,,0,False,Experiences using ChatGPT to structure unstructured data?,[],r/datascience,False,6,discussion,0,,,False,t3_185sq4v,False,dark,0.67,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1701166220.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m curious if anyone has dared putting a solution that uses an LLM (e.g. ChatGPT) to parse unstructured text into e.g. JSON?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve only tested this with ChatGPT and it works surprisingly well. But I&amp;#39;m still not convinced I could trust it to go through large scales of text in production.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,185sq4v,True,,PostponeIdiocracy,,12,True,all_ads,False,[],False,,/r/datascience/comments/185sq4v/experiences_using_chatgpt_to_structure/,all_ads,False,https://www.reddit.com/r/datascience/comments/185sq4v/experiences_using_chatgpt_to_structure/,1209064,1701166220.0,0,,False,,,,,,,,,,288,51
,datascience,What are some useful relationships/graphs you guys use with independent variables and the target variable when doing the initial EDA? Assuming most of your variables are categorical.,t2_495cn7pm,False,,0,False,EDA With Binary Classification,[],r/datascience,False,6,projects,0,,,False,t3_185sk3d,False,dark,0.89,,public,14,0,{},,,False,[],,False,False,,{},ML,False,14,,False,False,self,False,,[],{},,True,,1701165553.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What are some useful relationships/graphs you guys use with independent variables and the target variable when doing the initial EDA? Assuming most of your variables are categorical.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,185sk3d,True,,Throwawayforgainz99,,16,True,all_ads,False,[],False,,/r/datascience/comments/185sk3d/eda_with_binary_classification/,all_ads,False,https://www.reddit.com/r/datascience/comments/185sk3d/eda_with_binary_classification/,1209064,1701165553.0,0,,False,,,,,,,,,,182,27
,datascience,"Do you ever embed sanity checks in your reporting?

How thorough are you, what kind do you use, etc?

Do you make it part of the reporting query, or do you trust a separate query with the task?",t2_a1m88yyw,False,,0,False,Losing my sanity (checks),[],r/datascience,False,6,discussion,0,,,False,t3_185r2od,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1701159215.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you ever embed sanity checks in your reporting?&lt;/p&gt;

&lt;p&gt;How thorough are you, what kind do you use, etc?&lt;/p&gt;

&lt;p&gt;Do you make it part of the reporting query, or do you trust a separate query with the task?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,185r2od,True,,Status-Efficiency851,,4,True,all_ads,False,[],False,,/r/datascience/comments/185r2od/losing_my_sanity_checks/,all_ads,False,https://www.reddit.com/r/datascience/comments/185r2od/losing_my_sanity_checks/,1209064,1701159215.0,0,,False,,,,,,,,,,193,38
,datascience,"Hello!

All my data wrangling is currently done. I have 4 (2 in each pair) sets of data each with 500 ""baskets"" of groceries . The data contains all the item descriptions, together with the target variable of interest, the subdepartment the item is in. (think carrots--&gt;produce). Each data pair contains the first bought and then second bought basket in different files. I am trying to predict, given a bought basket of groceries, what is the mostly likely sub department a customer would buy from on their next visit.

I am still just a Computer Science student so I lack the experience here to pick a good predictive model for my situation. I was thinking of doing a Hollistic Linear Regression, or a simple KNN, but I thought about asking here first to see if anyone had any recommendations for me. Unfortunately I cannot use any models that involve hypothesis testing.

I apologize if I missed a rule before posting this. Thanks in advance!",t2_1713jl,False,,0,False,Recommendations for a Prediction Model,[],r/datascience,False,6,meta,0,,,False,t3_185qkmm,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1701157143.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;All my data wrangling is currently done. I have 4 (2 in each pair) sets of data each with 500 &amp;quot;baskets&amp;quot; of groceries . The data contains all the item descriptions, together with the target variable of interest, the subdepartment the item is in. (think carrots--&amp;gt;produce). Each data pair contains the first bought and then second bought basket in different files. I am trying to predict, given a bought basket of groceries, what is the mostly likely sub department a customer would buy from on their next visit.&lt;/p&gt;

&lt;p&gt;I am still just a Computer Science student so I lack the experience here to pick a good predictive model for my situation. I was thinking of doing a Hollistic Linear Regression, or a simple KNN, but I thought about asking here first to see if anyone had any recommendations for me. Unfortunately I cannot use any models that involve hypothesis testing.&lt;/p&gt;

&lt;p&gt;I apologize if I missed a rule before posting this. Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,185qkmm,True,,Akavire,,4,True,all_ads,False,[],False,,/r/datascience/comments/185qkmm/recommendations_for_a_prediction_model/,all_ads,False,https://www.reddit.com/r/datascience/comments/185qkmm/recommendations_for_a_prediction_model/,1209064,1701157143.0,0,,False,,,,,,,,,,947,164
,datascience,"How would you identify them? How do you think they get in? 

Do you think they enjoy an unfair advantage of calling the shots, higher salary, etc. in your org?

EDIT: [Same question. Different Sub. Interesting responses. Does region influence how data science is perceived as a profession?
](https://www.reddit.com/r/developersIndia/s/xfCukCZg0O)",t2_al1087x2,False,,0,False,Do you think there are too many frauds masquerading as data scientists?,[],r/datascience,False,6,discussion,0,,,False,t3_185kril,False,dark,0.35,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,1701152428.0,,[],{},,True,,1701137268.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How would you identify them? How do you think they get in? &lt;/p&gt;

&lt;p&gt;Do you think they enjoy an unfair advantage of calling the shots, higher salary, etc. in your org?&lt;/p&gt;

&lt;p&gt;EDIT: &lt;a href=""https://www.reddit.com/r/developersIndia/s/xfCukCZg0O""&gt;Same question. Different Sub. Interesting responses. Does region influence how data science is perceived as a profession?
&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,185kril,True,,OverratedDataScience,,39,True,all_ads,False,[],False,,/r/datascience/comments/185kril/do_you_think_there_are_too_many_frauds/,all_ads,False,https://www.reddit.com/r/datascience/comments/185kril/do_you_think_there_are_too_many_frauds/,1209064,1701137268.0,0,,False,,,,,,,,,,346,49
,datascience,Sharing this interesting blogpost: [https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261](https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261),t2_54ka7fmt,False,,0,False,Get started with exploratory data analysis,[],r/datascience,False,6,tooling,0,,,False,t3_185jd31,False,dark,0.76,,public,9,0,{},,,False,[],,False,False,,{},Tools,False,9,,False,False,self,False,,[],{},,True,,1701133294.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sharing this interesting blogpost: &lt;a href=""https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261""&gt;https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,185jd31,True,,Dry_Cattle9399,,2,True,all_ads,False,[],False,,/r/datascience/comments/185jd31/get_started_with_exploratory_data_analysis/,all_ads,False,https://www.reddit.com/r/datascience/comments/185jd31/get_started_with_exploratory_data_analysis/,1209064,1701133294.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?auto=webp&amp;s=288a87a604d4eca8bca5a3324528b5725ea683ca', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e18d80e187e0dcc73cace254310d8375afd9ab2', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07cdabf745d28b06d27b2b8149b73e472ab43d4a', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5418b1b92157e5374e998e775a136e3da513c399', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db39befb9a66b32968df449bc6681265853aa843', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e62285c4b8e0feff48457c4447597899470c896', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02ad4c4d32b126427298206f6ccba48fd45b2ebe', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'a1JplVCh5uF_FCo04tibM83p1AmIBdf0mruuMa1R8Ys'}], 'enabled': False}",,,,,,,179,5
,datascience,"At some point, certainly by the time you approach the big four-oh, you will come to a fork in your career path. Which branch will you/ did you choose, and why? Stay technical, even though your job opportunities and earnings growth could flatline as you pass the big five- oh.  Transition to a management role. That would be more lucrative and impactful, if you can master the bureaucratic BS and knife in the back politics. Or would you rather leave corporate life behind and become an independent consultant.",t2_lkjsx0aw0,False,,0,False,"Stay technical, go management, or consult?",[],r/datascience,False,6,fun,0,,,False,t3_185fya9,False,dark,0.94,,public,77,0,{},,,False,[],,False,False,,{},Career Discussion,False,77,,False,False,self,False,,[],{},,True,,1701124514.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At some point, certainly by the time you approach the big four-oh, you will come to a fork in your career path. Which branch will you/ did you choose, and why? Stay technical, even though your job opportunities and earnings growth could flatline as you pass the big five- oh.  Transition to a management role. That would be more lucrative and impactful, if you can master the bureaucratic BS and knife in the back politics. Or would you rather leave corporate life behind and become an independent consultant.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,185fya9,True,,AdParticular6193,,74,True,all_ads,False,[],False,,/r/datascience/comments/185fya9/stay_technical_go_management_or_consult/,all_ads,False,https://www.reddit.com/r/datascience/comments/185fya9/stay_technical_go_management_or_consult/,1209064,1701124514.0,0,,False,,,,,,,,,,509,88
,datascience,"Does anyone else feel like their management blocks them from actually implementing ""data science""? Whether for lack of understanding or fear of trying something that may not work?

Let me elaborate. I have worked as a DS at several companies small companies. What I have found in my experience is that there is always a hurdle to actually implementing data science by building models, testing hypothesis, etc. Sometimes it's data, sometimes badly defined business processes, but the most frustrating for me is when I get the feeling that my manager just isn't creative enough to see how DS could be used to solve the problem. Instead, handwaving and feeding you blanket statements like ""that's too hard"" or ""too complex"".

If I were a more motivated employee I would probably build out a POC on my own time to prove my point, but I have a family and better things to do than put in extra effort at work for stuff that will probably sit on a shelf.",t2_h09oj56,False,,0,False,Venting about management,[],r/datascience,False,6,fun,0,,,False,t3_185ele0,False,dark,0.75,,public,12,0,{},,,False,[],,False,False,,{},Career Discussion,False,12,,False,False,self,False,,[],{},,True,,1701121259.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone else feel like their management blocks them from actually implementing &amp;quot;data science&amp;quot;? Whether for lack of understanding or fear of trying something that may not work?&lt;/p&gt;

&lt;p&gt;Let me elaborate. I have worked as a DS at several companies small companies. What I have found in my experience is that there is always a hurdle to actually implementing data science by building models, testing hypothesis, etc. Sometimes it&amp;#39;s data, sometimes badly defined business processes, but the most frustrating for me is when I get the feeling that my manager just isn&amp;#39;t creative enough to see how DS could be used to solve the problem. Instead, handwaving and feeding you blanket statements like &amp;quot;that&amp;#39;s too hard&amp;quot; or &amp;quot;too complex&amp;quot;.&lt;/p&gt;

&lt;p&gt;If I were a more motivated employee I would probably build out a POC on my own time to prove my point, but I have a family and better things to do than put in extra effort at work for stuff that will probably sit on a shelf.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,185ele0,True,,clashofphish,,24,True,all_ads,False,[],False,,/r/datascience/comments/185ele0/venting_about_management/,all_ads,False,https://www.reddit.com/r/datascience/comments/185ele0/venting_about_management/,1209064,1701121259.0,0,,False,,,,,,,,,,947,167
,datascience,My train recall and precision are 0.68 each but my test recall is 0.24 and test precision is 0.75. What am I doing wrong and what can I do to fix this?,t2_jrhff4f29,False,,0,False,Why does my PR curve look like this?,[],r/datascience,False,6,projects,0,111.0,,False,t3_1857bao,False,dark,0.9,,public,113,0,{},140.0,,False,[],,True,False,,{},ML,False,113,,False,False,https://b.thumbs.redditmedia.com/i6BczB22NKygC_FpE_4KkHRNjSlKYUfSPZTDE7m_D8o.jpg,False,,[],{},,False,,1701103515.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My train recall and precision are 0.68 each but my test recall is 0.24 and test precision is 0.75. What am I doing wrong and what can I do to fix this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,1857bao,True,,Terrible-Hamster-342,,36,True,all_ads,False,[],False,,/r/datascience/comments/1857bao/why_does_my_pr_curve_look_like_this/,all_ads,False,https://i.redd.it/ky50y4l46x2c1.jpeg,1209064,1701103515.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/ky50y4l46x2c1.jpeg?auto=webp&amp;s=249e4b66ca08fc566d1139931b77a6c8f0584c3c', 'width': 710, 'height': 565}, 'resolutions': [{'url': 'https://preview.redd.it/ky50y4l46x2c1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92b0047f6ef7b01b4d1ced32a83df402f2d8b773', 'width': 108, 'height': 85}, {'url': 'https://preview.redd.it/ky50y4l46x2c1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3de804fb754e3d56eaa27f34e52e9f1c183c4b2f', 'width': 216, 'height': 171}, {'url': 'https://preview.redd.it/ky50y4l46x2c1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ebf5ca2e2a34b414af7645c0993c69c6be20fa9', 'width': 320, 'height': 254}, {'url': 'https://preview.redd.it/ky50y4l46x2c1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3437a50d228cef3a7dc4a089667c19cc5d33909c', 'width': 640, 'height': 509}], 'variants': {}, 'id': 'O7tlZEB8KWK94hktT3GtUcL2X1bT6zxRWAzrngAylgI'}], 'enabled': True}",,https://i.redd.it/ky50y4l46x2c1.jpeg,,,,,151,32
,datascience,"I am looking for books that can discuss how things go in the hardware side while loading, training and deployment. Otherwise any interesting book is welcome !",t2_7wkh6o3g,False,,0,False,Books for mid-senior eng,[],r/datascience,False,6,,0,,,False,t3_184pyhz,False,dark,1.0,,public,14,0,{},,,False,[],,False,False,,{},Education,False,14,,False,False,self,False,,[],{},,True,,1701045739.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking for books that can discuss how things go in the hardware side while loading, training and deployment. Otherwise any interesting book is welcome !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,184pyhz,True,,weluuu,,8,True,all_ads,False,[],False,,/r/datascience/comments/184pyhz/books_for_midsenior_eng/,all_ads,False,https://www.reddit.com/r/datascience/comments/184pyhz/books_for_midsenior_eng/,1209064,1701045739.0,0,,False,,,,,,,,,,158,27
,datascience,"I know there are a lot of experience data professionals in this subreddit and I am curious about what has and hasn't changed in data science, both as a practice and a career, of their careers.   Does anyone care to share their experiences?",t2_rx9i21bh,False,,0,False,What has changed the most about data science the last 5-10 years? What hasn't changed at all?,[],r/datascience,False,6,fun,0,,,False,t3_184ovxy,False,dark,0.96,,public,132,0,{},,,False,[],,False,False,,{},Career Discussion,False,132,,False,False,self,False,,[],{},,True,,1701042830.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know there are a lot of experience data professionals in this subreddit and I am curious about what has and hasn&amp;#39;t changed in data science, both as a practice and a career, of their careers.   Does anyone care to share their experiences?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,184ovxy,True,,brybrydataguy,,63,True,all_ads,False,[],False,,/r/datascience/comments/184ovxy/what_has_changed_the_most_about_data_science_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/184ovxy/what_has_changed_the_most_about_data_science_the/,1209064,1701042830.0,0,,False,,,,,,,,,,239,43
,datascience,May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I’m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.,t2_i69qgpqa,False,,0,False,"If you had to list a “tier list” of software that data scientists should be competent with prior to their first job, what would it be?",[],r/datascience,False,6,discussion,0,,,False,t3_184ezlq,False,dark,0.95,,public,244,0,{},,,False,[],,False,False,,{},Discussion,False,244,,False,False,self,False,,[],{},,True,,1701017549.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I’m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,184ezlq,True,,AdFew4357,,140,True,all_ads,False,[],False,,/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/,all_ads,False,https://www.reddit.com/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/,1209064,1701017549.0,0,,False,,,,,,,,,,399,74
,datascience,"I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.

The way the model is set up is the following:

Firstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven't come back in a while rather than those that are buying stuff regularly. However, I haven't given this issue much thought, yet, because I focusing on other aspects.

Secondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn't really improve the model and hence, I decided to not include it for now.

Thirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn't really think of much on how to deal with that issue and would like to hear how you would approach this.

Lastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. 

So, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?

Many thanks in advance and I am curious to hear what you guys think about this project.",t2_8xlmglbe,False,,0,False,Retail based recommendation system - Setup and how to deal with severe class imbalance?,[],r/datascience,False,6,meta,0,,,False,t3_18488s8,False,dark,0.82,,public,14,0,{},,,False,[],,False,False,,{},Projects,False,14,,False,False,self,False,,[],{},,True,,1700996066.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.&lt;/p&gt;

&lt;p&gt;The way the model is set up is the following:&lt;/p&gt;

&lt;p&gt;Firstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven&amp;#39;t come back in a while rather than those that are buying stuff regularly. However, I haven&amp;#39;t given this issue much thought, yet, because I focusing on other aspects.&lt;/p&gt;

&lt;p&gt;Secondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn&amp;#39;t really improve the model and hence, I decided to not include it for now.&lt;/p&gt;

&lt;p&gt;Thirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn&amp;#39;t really think of much on how to deal with that issue and would like to hear how you would approach this.&lt;/p&gt;

&lt;p&gt;Lastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. &lt;/p&gt;

&lt;p&gt;So, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?&lt;/p&gt;

&lt;p&gt;Many thanks in advance and I am curious to hear what you guys think about this project.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,18488s8,True,,vossiplayz,,15,True,all_ads,False,[],False,,/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/,all_ads,False,https://www.reddit.com/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/,1209064,1700996066.0,0,,False,,,,,,,,,,3100,523
,datascience,"I have been asked by my boss to submit a budget for learning. 

I am looking for course ideas that actually add value. 

I am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :

1) telling better stories (how I feedback analyse to the business )
2) insight in operational parts of the business especially product managers and product marketing managers
3) strategic insights (why is what I present important to the business ) 

I feel these are linked but curious on this communities experience. 

I am looking at doing an MBA but will only do that in a few years.",t2_2sbgb66v,False,,0,False,Learning opportunities,[],r/datascience,False,6,fun,0,,,False,t3_1847uj1,False,dark,0.91,,public,9,0,{},,,False,[],,False,False,,{},Career Discussion,False,9,,False,False,self,False,,[],{},,True,,1700994395.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been asked by my boss to submit a budget for learning. &lt;/p&gt;

&lt;p&gt;I am looking for course ideas that actually add value. &lt;/p&gt;

&lt;p&gt;I am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :&lt;/p&gt;

&lt;p&gt;1) telling better stories (how I feedback analyse to the business )
2) insight in operational parts of the business especially product managers and product marketing managers
3) strategic insights (why is what I present important to the business ) &lt;/p&gt;

&lt;p&gt;I feel these are linked but curious on this communities experience. &lt;/p&gt;

&lt;p&gt;I am looking at doing an MBA but will only do that in a few years.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,1847uj1,True,,oryx_za,,23,True,all_ads,False,[],False,,/r/datascience/comments/1847uj1/learning_opportunities/,all_ads,False,https://www.reddit.com/r/datascience/comments/1847uj1/learning_opportunities/,1209064,1700994395.0,0,,False,,,,,,,,,,687,127
,datascience,"I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven’t use it before, is it viable?",t2_t4026fbr,False,,0,False,NLP for dirty data,[],r/datascience,False,6,,0,,,False,t3_1843m38,False,dark,0.9,,public,21,0,{},,,False,[],,False,False,,{},AI,False,21,,False,False,self,False,,[],{},,True,,1700976808.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven’t use it before, is it viable?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,2f731e52-70eb-11ee-bec5-5a5142e6a4d2,False,False,False,,[],False,,,,t5_2sptq,False,,,#46d160,1843m38,True,,chris_813,,23,True,all_ads,False,[],False,,/r/datascience/comments/1843m38/nlp_for_dirty_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/1843m38/nlp_for_dirty_data/,1209064,1700976808.0,0,,False,,,,,,,,,,227,43
,datascience,"Hi! 

Curious as to what industry has the best (work-life balance)/(compensation) ratio. 

1. Work hours/week
2. Compensation
3. Job security",t2_b3hvfhlp,False,,0,False,Working in which industry has a better work-life balance/pay ratio: Finance or Big Tech?,[],r/datascience,False,6,fun,0,,,False,t3_183vc1k,False,dark,0.9,,public,51,0,{},,,False,[],,False,False,,{},Career Discussion,False,51,,False,False,self,1700955599.0,,[],{},,True,,1700951243.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! &lt;/p&gt;

&lt;p&gt;Curious as to what industry has the best (work-life balance)/(compensation) ratio. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Work hours/week&lt;/li&gt;
&lt;li&gt;Compensation&lt;/li&gt;
&lt;li&gt;Job security&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,183vc1k,True,,Exotic_Avocado6164,,47,True,all_ads,False,[],False,,/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/,all_ads,False,https://www.reddit.com/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/,1209064,1700951243.0,0,,False,,,,,,,,,,141,20
,datascience,"So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.

But the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I'm sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn't really build the thing yourself.

Looking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!

**EDIT** ***I wanted to share something a very knowledgeable poster provided about what specific aspects of an LLM (or other advance ML) should be public and what should remain a companies IP.  It's very comprehensive and well thought through:***

&gt;I think the entire set of training data (technically I mean the entire dataset and not in the sense of training, validation, test, or any other subset used for calibration) should be made available, even what is created in-house. I think it's very important that everyone at least have the same access to the data. My reasoning for that is because it is extremely important to ensure that dataset is not biased, which would take a lot of people with a lot of different perspectives to figure out. It also removes the major barrier to entry so hopefully people would focus on innovation, instead of obtaining data. That's it though. Everything else is the spawn of creativity and compute resources and opening them would serve no purpose beyond allowing replication of the product.  
&gt;  
&gt;The parameter weights are the product of the compute time, so once that expense gets high enough, IMO, it really seems like theft to force them to give it away. It would remove the incentive for anyone else to spend more time making a better product. The structure of the models, the order the functions are called, even the way the training data is applied can all make a big difference in performance. So I see that as a creative work requiring a lot of effort which also shouldn't be given away. If the models are only using techniques developed in academia, then anyone can learn those regardless of whether or not any specific company makes their models public (spoiler: they aren't).  
&gt;  
&gt;I would also be supportive of making it a requirement to provide no-cost API access for watchdogs or organizations to ensure an unbiased final model. Like an audit of the final product.

&amp;#x200B;",t2_9bow4eln,False,,0,False,Change my mind: AI is inherently public domain knowledge and should not be commercialized,[],r/datascience,False,6,discussion,0,,,False,t3_183uo20,False,dark,0.71,,public,124,0,{},,,False,[],,False,False,,{},Discussion,False,124,,False,False,self,1701055943.0,,[],{},,True,,1700949444.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.&lt;/p&gt;

&lt;p&gt;But the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I&amp;#39;m sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn&amp;#39;t really build the thing yourself.&lt;/p&gt;

&lt;p&gt;Looking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;I wanted to share something a very knowledgeable poster provided about what specific aspects of an LLM (or other advance ML) should be public and what should remain a companies IP.  It&amp;#39;s very comprehensive and well thought through:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I think the entire set of training data (technically I mean the entire dataset and not in the sense of training, validation, test, or any other subset used for calibration) should be made available, even what is created in-house. I think it&amp;#39;s very important that everyone at least have the same access to the data. My reasoning for that is because it is extremely important to ensure that dataset is not biased, which would take a lot of people with a lot of different perspectives to figure out. It also removes the major barrier to entry so hopefully people would focus on innovation, instead of obtaining data. That&amp;#39;s it though. Everything else is the spawn of creativity and compute resources and opening them would serve no purpose beyond allowing replication of the product.  &lt;/p&gt;

&lt;p&gt;The parameter weights are the product of the compute time, so once that expense gets high enough, IMO, it really seems like theft to force them to give it away. It would remove the incentive for anyone else to spend more time making a better product. The structure of the models, the order the functions are called, even the way the training data is applied can all make a big difference in performance. So I see that as a creative work requiring a lot of effort which also shouldn&amp;#39;t be given away. If the models are only using techniques developed in academia, then anyone can learn those regardless of whether or not any specific company makes their models public (spoiler: they aren&amp;#39;t).  &lt;/p&gt;

&lt;p&gt;I would also be supportive of making it a requirement to provide no-cost API access for watchdogs or organizations to ensure an unbiased final model. Like an audit of the final product.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,183uo20,True,,Unhappy_Technician68,,101,True,all_ads,False,[],False,,/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/,all_ads,False,https://www.reddit.com/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/,1209064,1700949444.0,0,,False,,,,True,,,,,,3485,600
,datascience,"I ran across this reel in Instagram of a one of those ""finance gurus"" that said something like:

&gt; If you invest $1,500 per month with this bond scheme, after 20 years, you end up with $1,000,000.

which I thought ""meh, it's not that much"", just the principal or capital is $360K ($1,500 for 240 months).

But then I thought, it doesn't seem like A HUGE return, but what is it?

**What is the monthly return in that case?**

(Assuming you reinvest all the proceedings and consistently add $1,500 on top every month).

Can you solve it? It's not that hard, and it's not that ""Data Science"" (although I did end up using some Python and Fortran to solve it), but it's a fun brain teaser. I can post the solution later if you want.

EDIT: I’m getting downvoted into oblivion. I thought you guys would enjoy a fun challenge 🥲.

EDIT: there’s a perfectly reasonable way to come up with the correct answer using math and without brute force.",t2_782al,False,,0,False,"Silly problem I ran into today in an Instagram reel, can you solve it?",[],r/datascience,False,6,,0,,,False,t3_183qz8o,False,dark,0.23,,public,0,0,{},,,False,[],,False,False,,{},Challenges,False,0,,False,False,self,1700950177.0,,[],{},,True,,1700939333.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I ran across this reel in Instagram of a one of those &amp;quot;finance gurus&amp;quot; that said something like:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you invest $1,500 per month with this bond scheme, after 20 years, you end up with $1,000,000.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;which I thought &amp;quot;meh, it&amp;#39;s not that much&amp;quot;, just the principal or capital is $360K ($1,500 for 240 months).&lt;/p&gt;

&lt;p&gt;But then I thought, it doesn&amp;#39;t seem like A HUGE return, but what is it?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the monthly return in that case?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(Assuming you reinvest all the proceedings and consistently add $1,500 on top every month).&lt;/p&gt;

&lt;p&gt;Can you solve it? It&amp;#39;s not that hard, and it&amp;#39;s not that &amp;quot;Data Science&amp;quot; (although I did end up using some Python and Fortran to solve it), but it&amp;#39;s a fun brain teaser. I can post the solution later if you want.&lt;/p&gt;

&lt;p&gt;EDIT: I’m getting downvoted into oblivion. I thought you guys would enjoy a fun challenge 🥲.&lt;/p&gt;

&lt;p&gt;EDIT: there’s a perfectly reasonable way to come up with the correct answer using math and without brute force.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,183qz8o,True,,santiagobasulto,,62,True,all_ads,False,[],False,,/r/datascience/comments/183qz8o/silly_problem_i_ran_into_today_in_an_instagram/,all_ads,False,https://www.reddit.com/r/datascience/comments/183qz8o/silly_problem_i_ran_into_today_in_an_instagram/,1209064,1700939333.0,0,,False,,,,,,,,,,937,170
,datascience,"REMOTE Data Scientist Requirements/Responsibilities 

*MUST be a USC or Green Card Holder. NO C2C* 

- Exploring new analytical technologies and evaluate their technical and commercial viability. 

- Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools. 

- Working across various data mediums: text, audio, imagery, sensory, and structured data. 

- Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients. 

- Testing and rejecting hypotheses around data processing and ML model building. 

- Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task. 

- Building ML pipelines that ingest, clean data, and make predictions. 

- Focusing on AI and ML techniques that are broadly applicable across all industries. 

- Staying abreast of new AI research from leading labs by reading papers and experimenting with code. 

- Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients. 

- Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.). 

- Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique. 

- Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow). 

- Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application. 

- Building ML models and systems, interpreting their output, and communicating the results. 

- Moving models from development to production; conducting lab research and publishing work. 

- Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:

- Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix. 

- Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.). 

- Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow. 

- Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy. 

- Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots &amp; Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS. 

- Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio). 

- Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS. 

- Minimum Degree Required: Bachelor Degree. 

- Additional Educational Requirements: Bachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college. 

- Degree Preferred: Master Degree. 

- Preferred Fields of Study: Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research. 

- Additional Educational Preferences: PhD highly preferred.

&amp;nbsp;

I found this on Linkedin, I don't understand how something like this is even remotely okay",t2_fb4ll,False,,0,False,Worst JD of the year,[],r/datascience,False,6,fun,0,,,False,t3_183p9u1,False,dark,0.91,,public,102,0,{},,,False,[],,False,False,,{},Career Discussion,False,102,,False,False,self,False,,[],{},,True,,1700934703.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;REMOTE Data Scientist Requirements/Responsibilities &lt;/p&gt;

&lt;p&gt;&lt;em&gt;MUST be a USC or Green Card Holder. NO C2C&lt;/em&gt; &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Exploring new analytical technologies and evaluate their technical and commercial viability. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Working across various data mediums: text, audio, imagery, sensory, and structured data. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Testing and rejecting hypotheses around data processing and ML model building. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Building ML pipelines that ingest, clean data, and make predictions. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Focusing on AI and ML techniques that are broadly applicable across all industries. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Staying abreast of new AI research from leading labs by reading papers and experimenting with code. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.). &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow). &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Building ML models and systems, interpreting their output, and communicating the results. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Moving models from development to production; conducting lab research and publishing work. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.). &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots &amp;amp; Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio). &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum Degree Required: Bachelor Degree. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Additional Educational Requirements: Bachelor&amp;#39;s degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Degree Preferred: Master Degree. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preferred Fields of Study: Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Additional Educational Preferences: PhD highly preferred.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;I found this on Linkedin, I don&amp;#39;t understand how something like this is even remotely okay&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,183p9u1,True,,PLxFTW,,75,True,all_ads,False,[],False,,/r/datascience/comments/183p9u1/worst_jd_of_the_year/,all_ads,False,https://www.reddit.com/r/datascience/comments/183p9u1/worst_jd_of_the_year/,1209064,1700934703.0,0,,False,,,,,,,,,,4171,551
,datascience,"I am working closely with people with background in Sales. My bosses are pretty cool, nice and very smart people. I have been working with tech people for a long time. Compared to that working with business folks is a different experience. For eg in my prev roles people were not into writing verbose and well worded e-mails. I sometimes feel I am behind when it comes to writing good e-mails and overall communication. I may have even forgotten to add please before a verb sometimes when writing an email to boss. Although they haven't mentioned this to me. Overall I feel these people are so far ahead. As a Data Scientist how do you work on your communication skills?",t2_b63krvaxs,False,,0,False,Improving communication skills as a DS,[],r/datascience,False,6,discussion,0,,,False,t3_183kc1j,False,dark,0.95,,public,23,0,{},,,False,[],,False,False,,{},Discussion,False,23,,False,False,self,False,,[],{},,True,,1700920780.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working closely with people with background in Sales. My bosses are pretty cool, nice and very smart people. I have been working with tech people for a long time. Compared to that working with business folks is a different experience. For eg in my prev roles people were not into writing verbose and well worded e-mails. I sometimes feel I am behind when it comes to writing good e-mails and overall communication. I may have even forgotten to add please before a verb sometimes when writing an email to boss. Although they haven&amp;#39;t mentioned this to me. Overall I feel these people are so far ahead. As a Data Scientist how do you work on your communication skills?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,183kc1j,True,,ExcuseNo6720,,31,True,all_ads,False,[],False,,/r/datascience/comments/183kc1j/improving_communication_skills_as_a_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/183kc1j/improving_communication_skills_as_a_ds/,1209064,1700920780.0,0,,False,,,,,,,,,,670,120
,datascience,"Hi all!
I am looking for advice about the best practices to make one of my little project happening.

Background:
&gt; I created a python script and would like to bring that to life by integrating this ""solution"" in a whole ""backend + website frontend"".
&gt; I have no problems paying for a domain name, a sql on azure/aws etc
&gt; this python script is creating an index using emails (textai sementic search) and the idea would be that when i paste an email in the frontend, click a button, i got as result the matchs displayed

Progress so far:
I was advised to use django.
I was advised to change from textai to huggingface transformers 

But i am looking for some feedback from this community. How would you do that? All in one server? Cloud?

Any help welcome!",t2_aket2ob8,False,,0,False,Best practice and tips to make a project happening,[],r/datascience,False,6,meta,0,,,False,t3_183hll2,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1700910865.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all!
I am looking for advice about the best practices to make one of my little project happening.&lt;/p&gt;

&lt;p&gt;Background:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I created a python script and would like to bring that to life by integrating this &amp;quot;solution&amp;quot; in a whole &amp;quot;backend + website frontend&amp;quot;.
I have no problems paying for a domain name, a sql on azure/aws etc
this python script is creating an index using emails (textai sementic search) and the idea would be that when i paste an email in the frontend, click a button, i got as result the matchs displayed&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Progress so far:
I was advised to use django.
I was advised to change from textai to huggingface transformers &lt;/p&gt;

&lt;p&gt;But i am looking for some feedback from this community. How would you do that? All in one server? Cloud?&lt;/p&gt;

&lt;p&gt;Any help welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,183hll2,True,,486321581,,5,True,all_ads,False,[],False,,/r/datascience/comments/183hll2/best_practice_and_tips_to_make_a_project_happening/,all_ads,False,https://www.reddit.com/r/datascience/comments/183hll2/best_practice_and_tips_to_make_a_project_happening/,1209064,1700910865.0,0,,False,,,,,,,,,,765,139
,datascience,"Apart from missing data, outliers, insufficient data, low computing/human resources, etc., what are some peculiar challenges you have faced in projects?",t2_a3lten1,False,,0,False,Peculiar challenges in DS projects?,[],r/datascience,False,6,,0,,,False,t3_183ccbj,False,dark,0.93,,public,12,0,{},,,False,[],,False,False,,{},Challenges,False,12,,False,False,self,False,,[],{},,True,,1700889519.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Apart from missing data, outliers, insufficient data, low computing/human resources, etc., what are some peculiar challenges you have faced in projects?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,183ccbj,True,,roy1979,,28,True,all_ads,False,[],False,,/r/datascience/comments/183ccbj/peculiar_challenges_in_ds_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/183ccbj/peculiar_challenges_in_ds_projects/,1209064,1700889519.0,0,,False,,,,,,,,,,152,21
,datascience,"Hello fellow data lovers👋 

I'm wondering if I could get some advice from the community, especially from the data scientists who've successfully immigrated there from another country without a Euro passport/European family members etc.

Ever since my first trip there a few years back, I've been dying to experience more of the European culture/lifestyle again so I figure I'd really give it a go to move across the pond for a few years while I'm still young without too much responsibilities (coming from NA). But as you've probably heard a million times, the job market is tough and I haven't been getting any call backs from the dozens of applications I've sent out. And I've also only been working professionally as a data analyst for one year so I'm sure that doesn't help when I'm being weighed against plenty of other qualified candidate. Regardless, I want to keep trying because eventually I might catch a job interview or two to give myself a chance to achieve this goal.

What I'm really hoping you folks could help me out with is a strategy for applying to jobs or networking? Basically, does the community have any thoughts on a strategy that would give me the biggest chance to succeed in terms of moving to Europe for a few years? Also before anyone suggests, asking my boss to let me work fully remote is not really an option due to legislations surrounding the data we work with. That said, here are a couple strategies I've been trying so far but I'd be really open to other ideas from the community I haven't given much thought to:

1) Applying for data roles of all kinds to Euro-native companies?

2) Applying for fully remote data roles in North America and living abroad?

3) Applying for roles within multinational companies with offices in countries I'm interested in most to live in (such as France**, Switzerland**, Italy, Greece, the Nordics, Czechia, or Hungary)?


Any help from the community would be greatly appreciated 🙂",t2_5ccccb5h,False,,0,False,What's the best way to work as a data professional in Europe?,[],r/datascience,False,6,fun,0,,,False,t3_183c5ax,False,dark,0.95,,public,18,0,{},,,False,[],,False,False,,{},Career Discussion,False,18,,False,False,self,1700934168.0,,[],{},,True,,1700888817.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello fellow data lovers👋 &lt;/p&gt;

&lt;p&gt;I&amp;#39;m wondering if I could get some advice from the community, especially from the data scientists who&amp;#39;ve successfully immigrated there from another country without a Euro passport/European family members etc.&lt;/p&gt;

&lt;p&gt;Ever since my first trip there a few years back, I&amp;#39;ve been dying to experience more of the European culture/lifestyle again so I figure I&amp;#39;d really give it a go to move across the pond for a few years while I&amp;#39;m still young without too much responsibilities (coming from NA). But as you&amp;#39;ve probably heard a million times, the job market is tough and I haven&amp;#39;t been getting any call backs from the dozens of applications I&amp;#39;ve sent out. And I&amp;#39;ve also only been working professionally as a data analyst for one year so I&amp;#39;m sure that doesn&amp;#39;t help when I&amp;#39;m being weighed against plenty of other qualified candidate. Regardless, I want to keep trying because eventually I might catch a job interview or two to give myself a chance to achieve this goal.&lt;/p&gt;

&lt;p&gt;What I&amp;#39;m really hoping you folks could help me out with is a strategy for applying to jobs or networking? Basically, does the community have any thoughts on a strategy that would give me the biggest chance to succeed in terms of moving to Europe for a few years? Also before anyone suggests, asking my boss to let me work fully remote is not really an option due to legislations surrounding the data we work with. That said, here are a couple strategies I&amp;#39;ve been trying so far but I&amp;#39;d be really open to other ideas from the community I haven&amp;#39;t given much thought to:&lt;/p&gt;

&lt;p&gt;1) Applying for data roles of all kinds to Euro-native companies?&lt;/p&gt;

&lt;p&gt;2) Applying for fully remote data roles in North America and living abroad?&lt;/p&gt;

&lt;p&gt;3) Applying for roles within multinational companies with offices in countries I&amp;#39;m interested in most to live in (such as France&lt;strong&gt;, Switzerland&lt;/strong&gt;, Italy, Greece, the Nordics, Czechia, or Hungary)?&lt;/p&gt;

&lt;p&gt;Any help from the community would be greatly appreciated 🙂&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,183c5ax,True,,vanisle_kahuna,,16,True,all_ads,False,[],False,,/r/datascience/comments/183c5ax/whats_the_best_way_to_work_as_a_data_professional/,all_ads,False,https://www.reddit.com/r/datascience/comments/183c5ax/whats_the_best_way_to_work_as_a_data_professional/,1209064,1700888817.0,0,,False,,,,,,,,,,1953,336
,datascience,"Hello again!

&amp;#x200B;

Since I got a fair amount of traction on my last post and it seemed like a lot of people found the app useful, I thought everyone might be interested that I listened to all of your feedback and have implemented some cool new features! In no particular order:

* There are now [location filters on the jobs page](https://jobcrawler.matthewrkaye.com/jobs)
* I've added a ton of [company metadata to the companies pages](https://jobcrawler.matthewrkaye.com/companies/Oura) to help you learn about any given company more quickly. I also added similar companies to easily get from page to page.
* There's now a [roadmap](https://jobcrawler.matthewrkaye.com/roadmap) and a [changelog](https://jobcrawler.matthewrkaye.com/changelog) to help keep track of new features and see what's coming up soon
* Misc UI/UX improvements

&amp;#x200B;

[Here's the original post](https://www.reddit.com/r/datascience/comments/17s5fyq/i_built_an_app_to_make_my_job_search_a_little/)

[Here's the blog post about the app](https://matthewrkaye.com/posts/2023-11-10-jobcrawler/jobcrawler.html)

[And here's the app itself](https://jobcrawler.matthewrkaye.com/)

&amp;#x200B;

As per last time, happy to hear any feedback!",t2_15v03egd,False,,0,False,"UPDATE: I built an app to make my job search a little more sane, and I thought others might like it too! No ads, no recruiter spam, etc.",[],r/datascience,False,6,tooling,0,,,False,t3_183562x,False,dark,0.96,,public,199,0,{},,,False,[],,False,False,,{},Tools,False,199,,False,False,self,False,,[],{},,True,,1700867987.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello again!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Since I got a fair amount of traction on my last post and it seemed like a lot of people found the app useful, I thought everyone might be interested that I listened to all of your feedback and have implemented some cool new features! In no particular order:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are now &lt;a href=""https://jobcrawler.matthewrkaye.com/jobs""&gt;location filters on the jobs page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I&amp;#39;ve added a ton of &lt;a href=""https://jobcrawler.matthewrkaye.com/companies/Oura""&gt;company metadata to the companies pages&lt;/a&gt; to help you learn about any given company more quickly. I also added similar companies to easily get from page to page.&lt;/li&gt;
&lt;li&gt;There&amp;#39;s now a &lt;a href=""https://jobcrawler.matthewrkaye.com/roadmap""&gt;roadmap&lt;/a&gt; and a &lt;a href=""https://jobcrawler.matthewrkaye.com/changelog""&gt;changelog&lt;/a&gt; to help keep track of new features and see what&amp;#39;s coming up soon&lt;/li&gt;
&lt;li&gt;Misc UI/UX improvements&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/r/datascience/comments/17s5fyq/i_built_an_app_to_make_my_job_search_a_little/""&gt;Here&amp;#39;s the original post&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://matthewrkaye.com/posts/2023-11-10-jobcrawler/jobcrawler.html""&gt;Here&amp;#39;s the blog post about the app&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://jobcrawler.matthewrkaye.com/""&gt;And here&amp;#39;s the app itself&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;As per last time, happy to hear any feedback!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,183562x,True,,eipi-10,,14,True,all_ads,False,[],False,,/r/datascience/comments/183562x/update_i_built_an_app_to_make_my_job_search_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/183562x/update_i_built_an_app_to_make_my_job_search_a/,1209064,1700867987.0,0,,False,,,,,,,,,,1224,148
,datascience,"What communities do people recommend for sharing personal projects?

These communities would be useful for inspiration, collaboration, and constructive feedback. I envision something less anonymous than this forum, where it is easy to stay connected with people and keep up with their work. And while meetups are great in connected cities, I welcome online forums that you can access anywhere.

Thanks for the suggestions.",t2_s27ul7aa,False,,0,False,Best communities for data science project feedback,[],r/datascience,False,6,meta,0,,,False,t3_1831842,False,dark,0.87,,public,11,0,{},,,False,[],,False,False,,{},Projects,False,11,,False,False,self,False,,[],{},,True,,1700857606.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What communities do people recommend for sharing personal projects?&lt;/p&gt;

&lt;p&gt;These communities would be useful for inspiration, collaboration, and constructive feedback. I envision something less anonymous than this forum, where it is easy to stay connected with people and keep up with their work. And while meetups are great in connected cities, I welcome online forums that you can access anywhere.&lt;/p&gt;

&lt;p&gt;Thanks for the suggestions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,1831842,True,,chiqui-bee,,8,True,all_ads,False,[],False,,/r/datascience/comments/1831842/best_communities_for_data_science_project_feedback/,all_ads,False,https://www.reddit.com/r/datascience/comments/1831842/best_communities_for_data_science_project_feedback/,1209064,1700857606.0,0,,False,,,,,,,,,,422,64
,datascience,"Hi all,

I'm a college junior who'll be starting a 6 month data science co-op with a large national retail company, and I'm wondering if anyone here has any insight on what DS looks like at a company like this. I won't name the company for sake of privacy, but I'm concerned that the job will be a lot of dashboard building, etc and not a ton of modelling, and I'm worried I'll end up spending 6 months as an excel monkey. The job description mentioned modelling and explicitly had Python and whatnot as a requirement, but i was wondering if anyone in retail DS had any advice or experiences to share as I prepare to get started.

(As a note, I do not at *all* view myself as above dashboard building, excel, etc. it's just not what I'm hoping to get out of the co-op, I'm looking to build my skills in modelling, ML, etc., so I promise I'm not trying to come off as pretentious or above that kind of work. I'm also very aware I wont be building giant sophisticated neural nets or anything crazy cutting edge like that).

Thank you!",t2_2islhao1,False,,0,False,Incoming DS Co-op with many questions,[],r/datascience,False,6,fun,0,,,False,t3_182zp6o,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,False,,[],{},,True,,1700853474.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a college junior who&amp;#39;ll be starting a 6 month data science co-op with a large national retail company, and I&amp;#39;m wondering if anyone here has any insight on what DS looks like at a company like this. I won&amp;#39;t name the company for sake of privacy, but I&amp;#39;m concerned that the job will be a lot of dashboard building, etc and not a ton of modelling, and I&amp;#39;m worried I&amp;#39;ll end up spending 6 months as an excel monkey. The job description mentioned modelling and explicitly had Python and whatnot as a requirement, but i was wondering if anyone in retail DS had any advice or experiences to share as I prepare to get started.&lt;/p&gt;

&lt;p&gt;(As a note, I do not at &lt;em&gt;all&lt;/em&gt; view myself as above dashboard building, excel, etc. it&amp;#39;s just not what I&amp;#39;m hoping to get out of the co-op, I&amp;#39;m looking to build my skills in modelling, ML, etc., so I promise I&amp;#39;m not trying to come off as pretentious or above that kind of work. I&amp;#39;m also very aware I wont be building giant sophisticated neural nets or anything crazy cutting edge like that).&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,182zp6o,True,,Dyljam2345,,2,True,all_ads,False,[],False,,/r/datascience/comments/182zp6o/incoming_ds_coop_with_many_questions/,all_ads,False,https://www.reddit.com/r/datascience/comments/182zp6o/incoming_ds_coop_with_many_questions/,1209064,1700853474.0,0,,False,,,,,,,,,,1032,194
,datascience,"Hey friends,

I'm working on  a pet-project and I've started to run into a data availability problem (as per usual). I'm currently scraping company job boards for title, location, description etc., but wondered if anyone has intel on a good API that might have a broader base than just the Fortune-50. I'd rather not build a bespoke scraper if I don't have to. LinkedIn and Indeed seem to only have API tools to post new jobs, but not to submit queries. Glassdoor appears to let you automate (?). 

&amp;#x200B;

I'm ok paying a little bit if there's something high-quality and reliable. 

Thanks!",t2_43c8jfck,False,,0,False,Current Job Opening APIs?,[],r/datascience,False,6,meta,0,,,False,t3_182viiv,False,dark,0.89,,public,13,0,{},,,False,[],,False,False,,{},Projects,False,13,,False,False,self,False,,[],{},,True,,1700842226.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey friends,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on  a pet-project and I&amp;#39;ve started to run into a data availability problem (as per usual). I&amp;#39;m currently scraping company job boards for title, location, description etc., but wondered if anyone has intel on a good API that might have a broader base than just the Fortune-50. I&amp;#39;d rather not build a bespoke scraper if I don&amp;#39;t have to. LinkedIn and Indeed seem to only have API tools to post new jobs, but not to submit queries. Glassdoor appears to let you automate (?). &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m ok paying a little bit if there&amp;#39;s something high-quality and reliable. &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,182viiv,True,,Biologistathome,,9,True,all_ads,False,[],False,,/r/datascience/comments/182viiv/current_job_opening_apis/,all_ads,False,https://www.reddit.com/r/datascience/comments/182viiv/current_job_opening_apis/,1209064,1700842226.0,0,,False,,,,,,,,,,597,102
,datascience,"I am a US/EU citizen currently working in Budapest. I have a MS in Stats from the US and currently work in Eastern Europe. I am looking to relocate to Switzerland (Zurich/Basel) with my gf and am curious what is the job market like for data related jobs. Right now I work for a non-Swiss big pharma as a data analyst but do more data engineering and data science. 

Anyone have any input on what data related jobs are most abundent in Swiss cities and what skills are in demand? Also, do you need to know German?",t2_ynk7h,False,,0,False,Job Market in Switzerland,[],r/datascience,False,6,fun,0,,,False,t3_182u94o,False,dark,0.83,,public,19,0,{},,,False,[],,False,False,,{},Career Discussion,False,19,,False,False,self,False,,[],{},,True,,1700838773.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a US/EU citizen currently working in Budapest. I have a MS in Stats from the US and currently work in Eastern Europe. I am looking to relocate to Switzerland (Zurich/Basel) with my gf and am curious what is the job market like for data related jobs. Right now I work for a non-Swiss big pharma as a data analyst but do more data engineering and data science. &lt;/p&gt;

&lt;p&gt;Anyone have any input on what data related jobs are most abundent in Swiss cities and what skills are in demand? Also, do you need to know German?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,182u94o,True,,LeaguePrototype,,15,True,all_ads,False,[],False,,/r/datascience/comments/182u94o/job_market_in_switzerland/,all_ads,False,https://www.reddit.com/r/datascience/comments/182u94o/job_market_in_switzerland/,1209064,1700838773.0,0,,False,,,,,,,,,,512,97
,datascience,"I graduated with an MS in Data Science and am pursuing an MS in Statistics.

I believe there are a lot of people here who have jobs and companies that were from domains not related to their previous work experience. For example, get an internship in a Finance or Pharma Firm even when you have no clue or experience in that domain, but honed skills that would make you a great data scientist.

&amp;#x200B;

How did you present yourself as a desirable or valuable addition in your application or interview for an unrelated job?",t2_fa3o8svh,False,,0,False,Get jobs in Data Science in domains not related to your work experience.,[],r/datascience,False,6,fun,0,,,False,t3_181x3p3,False,dark,0.87,,public,22,0,{},,,False,[],,False,False,,{},Career Discussion,False,22,,False,False,self,False,,[],{},,True,,1700730134.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I graduated with an MS in Data Science and am pursuing an MS in Statistics.&lt;/p&gt;

&lt;p&gt;I believe there are a lot of people here who have jobs and companies that were from domains not related to their previous work experience. For example, get an internship in a Finance or Pharma Firm even when you have no clue or experience in that domain, but honed skills that would make you a great data scientist.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;How did you present yourself as a desirable or valuable addition in your application or interview for an unrelated job?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181x3p3,True,,Informal-Fly5759,,10,True,all_ads,False,[],False,,/r/datascience/comments/181x3p3/get_jobs_in_data_science_in_domains_not_related/,all_ads,False,https://www.reddit.com/r/datascience/comments/181x3p3/get_jobs_in_data_science_in_domains_not_related/,1209064,1700730134.0,0,,False,,,,,,,,,,527,94
,datascience,"
I’m a data scientist with a bit of a weird background. I have PhD in my domain field and transitioned into data science after graduating by self-teaching missing ds skills (mostly coding and ML). My current ds job is in my domain and I spend most of my time coding for ML projects. 

I’ve noticed that when I try to read up on data science interviews, I’m disproportionately very weak in everything related to probability. It’s just something that I wasn’t really exposed to in grad school or my current position. For example, I struggle with most of the “easy” problems in the probability chapter of Ace the Data Science Interview. Where can I get started with learning to answer these types of interview questions? Is there a book or course that covers probability considering what’d be expected from a data scientist? Would really appreciate any recommendations, thanks!",t2_vj9xwd07,False,,0,False,Resources for improving at probability problems in interviews?,[],r/datascience,False,6,discussion,0,,,False,t3_181v5dq,False,dark,0.95,,public,34,0,{},,,False,[],,False,False,,{},Discussion,False,34,,False,False,self,False,,[],{},,True,,1700722080.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m a data scientist with a bit of a weird background. I have PhD in my domain field and transitioned into data science after graduating by self-teaching missing ds skills (mostly coding and ML). My current ds job is in my domain and I spend most of my time coding for ML projects. &lt;/p&gt;

&lt;p&gt;I’ve noticed that when I try to read up on data science interviews, I’m disproportionately very weak in everything related to probability. It’s just something that I wasn’t really exposed to in grad school or my current position. For example, I struggle with most of the “easy” problems in the probability chapter of Ace the Data Science Interview. Where can I get started with learning to answer these types of interview questions? Is there a book or course that covers probability considering what’d be expected from a data scientist? Would really appreciate any recommendations, thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,181v5dq,True,,NDVGuy,,22,True,all_ads,False,[],False,,/r/datascience/comments/181v5dq/resources_for_improving_at_probability_problems/,all_ads,False,https://www.reddit.com/r/datascience/comments/181v5dq/resources_for_improving_at_probability_problems/,1209064,1700722080.0,0,,False,,,,,,,,,,874,148
,datascience,"Hello! I have very little experience with conferences, especially in the U.S., and I'm attending DS Salon in SF next week. I recently moved to the US from Scandinavia and I'm looking for a DS job here. I have five years of experience from before, and I have a visa already.

Do you have any tips for how to get the most out of the conference? Should I do research on who's going there and where they work before going so I can approach the companies that seem the most likely to be interested in me when I'm there? And like, how do I approach people - should my goal be just to talk to people and then connect with them later for job opportunities, or should I just be direct in that I'm looking for a job and ask if they're hiring? As I said, I'm from Scandinavia where people are generally much less direct than here, so I'm really unsure what the best way to go about it is.

Thank you!",t2_n0dbqwr,False,,0,False,job searching at conference,[],r/datascience,False,6,fun,0,,,False,t3_181tja0,False,dark,0.76,,public,6,0,{},,,False,[],,False,False,,{},Career Discussion,False,6,,False,False,self,False,,[],{},,True,,1700716105.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I have very little experience with conferences, especially in the U.S., and I&amp;#39;m attending DS Salon in SF next week. I recently moved to the US from Scandinavia and I&amp;#39;m looking for a DS job here. I have five years of experience from before, and I have a visa already.&lt;/p&gt;

&lt;p&gt;Do you have any tips for how to get the most out of the conference? Should I do research on who&amp;#39;s going there and where they work before going so I can approach the companies that seem the most likely to be interested in me when I&amp;#39;m there? And like, how do I approach people - should my goal be just to talk to people and then connect with them later for job opportunities, or should I just be direct in that I&amp;#39;m looking for a job and ask if they&amp;#39;re hiring? As I said, I&amp;#39;m from Scandinavia where people are generally much less direct than here, so I&amp;#39;m really unsure what the best way to go about it is.&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181tja0,True,,EvilGarlicFarts,,5,True,all_ads,False,[],False,,/r/datascience/comments/181tja0/job_searching_at_conference/,all_ads,False,https://www.reddit.com/r/datascience/comments/181tja0/job_searching_at_conference/,1209064,1700716105.0,0,,False,,,,,,,,,,889,173
,datascience,"Currently adding to my list of hot skills that I should learn now based on my recent job search and looking for notes / additional tools :

- tableu
- snowflake
- go 
- kubernetes 
- azure

I know these are old but I haven't learned them yet and looking to boost my resume.

Edit:
- pyspark
- prompt engineering 
- power BI
- genAI / LLMs",t2_7zv2xwb2,False,,0,False,Hot skills for 2023?,[],r/datascience,False,6,fun,0,,,False,t3_181t3eh,False,dark,0.88,,public,91,0,{},,,False,[],,False,False,,{},Career Discussion,False,91,,False,False,self,1700752890.0,,[],{},,True,,1700714529.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently adding to my list of hot skills that I should learn now based on my recent job search and looking for notes / additional tools :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tableu&lt;/li&gt;
&lt;li&gt;snowflake&lt;/li&gt;
&lt;li&gt;go &lt;/li&gt;
&lt;li&gt;kubernetes &lt;/li&gt;
&lt;li&gt;azure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I know these are old but I haven&amp;#39;t learned them yet and looking to boost my resume.&lt;/p&gt;

&lt;p&gt;Edit:
- pyspark
- prompt engineering 
- power BI
- genAI / LLMs&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181t3eh,True,,queen_quarantine,,84,True,all_ads,False,[],False,,/r/datascience/comments/181t3eh/hot_skills_for_2023/,all_ads,False,https://www.reddit.com/r/datascience/comments/181t3eh/hot_skills_for_2023/,1209064,1700714529.0,0,,False,,,,,,,,,,338,67
,datascience,"My background, in case it's relevant: I have a masters and PhD in data science, and I've been in my first data science role for about a year and a half.


I am a data scientist in a business intelligence department. When I joined, I inherited an extremely poor churn model - like ~10% precision, ~5% recall, ~91% accurate (due to imbalance). This thing was in production for over a year because my manager didn't realize that accuracy is a poor metric to use for imbalanced data.


I've spent the last year and a half redoing this model myself to a place where it is a lot better. But, my manager wants me to present the old model to executives. Now, if this were simply a comparison of the old one and the new one or an examination into why the old one didn't work so well, that would be fine. That's not what he wants. He wants me to present the model as if its predictions are perfect in order to show executives areas that we need to improve on in order to prevent churn.


This... makes no sense. E.g., let's say the old model classified old customers as most at-risk, but it's newer customers who actually churn more. Basing business decisions on the model's poor predictions is a really bad idea. 


To be clear, I don't have a problem making these slides. I have pushed back on the idea behind it, but I've never refused to do it. What I'm concerned about is that it's my name that's going on this and it's going to be presented as my sole effort, albeit from within the department, even though it's a model I had no hand in building whatsoever. My boss also has a tendency to throw people under the bus, and I feel like I'm being sacrificed.


I see a few options:


1. I can carefully word things so that I do not invite any conclusions drawn from my presentation whatsoever and also gently shut down any possible business decisions that might be made from this presentation.


2. I present it the way my boss wants but stay honest when anyone asks about the actual churn results and how much they differ from the model.


So basically, my questions are:


* Do I need to shut up and do as I'm told and act like a cog in the business machine? 


* Is this really normal business practice that I need to get used to? 


* Am I being dramatic?


* Or do I right to have a problem with this request? 


I am coming from academia where every little decision in the modeling process has to be justified and everything gets examined by multiple people, so maybe this is me just struggling to adapt to corporate life.",t2_rswxz,False,,0,False,Non-technical boss wants me to present results of a extremely ill-performing model to executives,[],r/datascience,False,6,fun,0,,,False,t3_181okvd,False,dark,0.95,,public,240,0,{},,,False,[],,False,False,,{},Career Discussion,False,240,,False,False,self,False,,[],{},,True,,1700700042.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My background, in case it&amp;#39;s relevant: I have a masters and PhD in data science, and I&amp;#39;ve been in my first data science role for about a year and a half.&lt;/p&gt;

&lt;p&gt;I am a data scientist in a business intelligence department. When I joined, I inherited an extremely poor churn model - like ~10% precision, ~5% recall, ~91% accurate (due to imbalance). This thing was in production for over a year because my manager didn&amp;#39;t realize that accuracy is a poor metric to use for imbalanced data.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve spent the last year and a half redoing this model myself to a place where it is a lot better. But, my manager wants me to present the old model to executives. Now, if this were simply a comparison of the old one and the new one or an examination into why the old one didn&amp;#39;t work so well, that would be fine. That&amp;#39;s not what he wants. He wants me to present the model as if its predictions are perfect in order to show executives areas that we need to improve on in order to prevent churn.&lt;/p&gt;

&lt;p&gt;This... makes no sense. E.g., let&amp;#39;s say the old model classified old customers as most at-risk, but it&amp;#39;s newer customers who actually churn more. Basing business decisions on the model&amp;#39;s poor predictions is a really bad idea. &lt;/p&gt;

&lt;p&gt;To be clear, I don&amp;#39;t have a problem making these slides. I have pushed back on the idea behind it, but I&amp;#39;ve never refused to do it. What I&amp;#39;m concerned about is that it&amp;#39;s my name that&amp;#39;s going on this and it&amp;#39;s going to be presented as my sole effort, albeit from within the department, even though it&amp;#39;s a model I had no hand in building whatsoever. My boss also has a tendency to throw people under the bus, and I feel like I&amp;#39;m being sacrificed.&lt;/p&gt;

&lt;p&gt;I see a few options:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;I can carefully word things so that I do not invite any conclusions drawn from my presentation whatsoever and also gently shut down any possible business decisions that might be made from this presentation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I present it the way my boss wants but stay honest when anyone asks about the actual churn results and how much they differ from the model.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So basically, my questions are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Do I need to shut up and do as I&amp;#39;m told and act like a cog in the business machine? &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is this really normal business practice that I need to get used to? &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Am I being dramatic?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Or do I right to have a problem with this request? &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am coming from academia where every little decision in the modeling process has to be justified and everything gets examined by multiple people, so maybe this is me just struggling to adapt to corporate life.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181okvd,True,,goatsnboots,,88,True,all_ads,False,[],False,,/r/datascience/comments/181okvd/nontechnical_boss_wants_me_to_present_results_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/181okvd/nontechnical_boss_wants_me_to_present_results_of/,1209064,1700700042.0,0,,False,,,,,,,,,,2520,470
,datascience,"I have a stats/analytics background but I keep getting pulled into meetings about things like data centers, DNS, IP subnets and I have no idea what anyone is talking about.",t2_kcl3tfwe,False,,0,False,How do I learn CS stuff?,[],r/datascience,False,6,fun,0,,,False,t3_181ndj0,False,dark,0.88,,public,37,0,{},,,False,[],,False,False,,{},Career Discussion,False,37,,False,False,self,False,,[],{},,True,,1700696595.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a stats/analytics background but I keep getting pulled into meetings about things like data centers, DNS, IP subnets and I have no idea what anyone is talking about.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181ndj0,True,,NewEcho2940,,43,True,all_ads,False,[],False,,/r/datascience/comments/181ndj0/how_do_i_learn_cs_stuff/,all_ads,False,https://www.reddit.com/r/datascience/comments/181ndj0/how_do_i_learn_cs_stuff/,1209064,1700696595.0,0,,False,,,,,,,,,,172,30
,datascience,"Also if you have any other tips/advice, please feel free to share them.

Edit: I believe there is some ambiguity in my title. What I meant was, for junior NLP engineers who already know concepts like stemming, lemmatization, etc (the basics of NLP) and stuff like transformers, vector databases (which have become essential for juniors too), what concepts should we learn to become senior NLP engineers?",t2_cs54hyd66,False,,0,False,"Senior NLP engineers, what concepts would you recommend juniors learn?",[],r/datascience,False,6,discussion,0,,,False,t3_181epyp,False,dark,0.97,,public,137,0,{},,,False,[],,False,False,,{},Discussion,False,137,,False,False,self,1700710124.0,,[],{},,True,,1700674374.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Also if you have any other tips/advice, please feel free to share them.&lt;/p&gt;

&lt;p&gt;Edit: I believe there is some ambiguity in my title. What I meant was, for junior NLP engineers who already know concepts like stemming, lemmatization, etc (the basics of NLP) and stuff like transformers, vector databases (which have become essential for juniors too), what concepts should we learn to become senior NLP engineers?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,181epyp,True,,Mission-Language8789,,35,True,all_ads,False,[],False,,/r/datascience/comments/181epyp/senior_nlp_engineers_what_concepts_would_you/,all_ads,False,https://www.reddit.com/r/datascience/comments/181epyp/senior_nlp_engineers_what_concepts_would_you/,1209064,1700674374.0,0,,False,,,,,,,,,,403,66
,datascience,"I applied for position titled database technician. When I did my research, I only find results for database administrators? Is it a fake title?",t2_903k40ag,False,,0,False,What is a database technician?,[],r/datascience,False,6,fun,0,,,False,t3_181e96g,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1700673203.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I applied for position titled database technician. When I did my research, I only find results for database administrators? Is it a fake title?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181e96g,True,,Impossible-Cry-495,,8,True,all_ads,False,[],False,,/r/datascience/comments/181e96g/what_is_a_database_technician/,all_ads,False,https://www.reddit.com/r/datascience/comments/181e96g/what_is_a_database_technician/,1209064,1700673203.0,0,,False,,,,,,,,,,143,24
,datascience,I got into a great but expensive school and desperately need ideas. Thanks!,t2_b3hvfhlp,False,,0,False,"How did you pay for Grad school? (loans, scholarship, employer reimbursement, etc)",[],r/datascience,False,6,fun,0,,,False,t3_181c7tq,False,dark,0.75,,public,11,0,{},,,False,[],,False,False,,{},Career Discussion,False,11,,False,False,self,False,,[],{},,True,,1700668193.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I got into a great but expensive school and desperately need ideas. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181c7tq,True,,Exotic_Avocado6164,,38,True,all_ads,False,[],False,,/r/datascience/comments/181c7tq/how_did_you_pay_for_grad_school_loans_scholarship/,all_ads,False,https://www.reddit.com/r/datascience/comments/181c7tq/how_did_you_pay_for_grad_school_loans_scholarship/,1209064,1700668193.0,0,,False,,,,,,,,,,75,13
,datascience,"What is the current state of the data jobs market in Norway:

Is it friendly for expats - can someone get a job only with English or Norwegian language knowledge is mandatory? 

Any other nuances?",t2_60jo8coj,False,,0,False,Job market in Norway,[],r/datascience,False,6,fun,0,,,False,t3_181c563,False,dark,0.83,,public,22,0,{},,,False,[],,False,False,,{},Career Discussion,False,22,,False,False,self,False,,[],{},,True,,1700668004.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What is the current state of the data jobs market in Norway:&lt;/p&gt;

&lt;p&gt;Is it friendly for expats - can someone get a job only with English or Norwegian language knowledge is mandatory? &lt;/p&gt;

&lt;p&gt;Any other nuances?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,181c563,True,,petburiraja,,29,True,all_ads,False,[],False,,/r/datascience/comments/181c563/job_market_in_norway/,all_ads,False,https://www.reddit.com/r/datascience/comments/181c563/job_market_in_norway/,1209064,1700668004.0,0,,False,,,,,,,,,,196,35
,datascience,"Hello everyone,

I'm exploring building a model of customer accounts over time to predict a very infrequent event. \~0.5% of my population would be classified as a positive at any given time. I had been using aggregated features for different attributes over various intervals of time in an attempt to capture some time dynamic. For example, total purchases and total payments might be attributes of interest, so I take the sum of both over the last 1,5,7 days and end up with a 2 dimensional feature matrix containing 6 covariates and I'd feed that into a gradient boosted trees algorithm. I am wondering if it would be worthwhile to explore modeling this problem with a 3 dimensional feature matrix that I could use to train a more advanced type of neural network. Would transformers be a viable path forward here? Or would a simple LSTM or GRU be a better choice? Any good literature on this topic? CNNs are interesting to me as well. I know traditionally they are more suited toward things like image classification, but I wonder if they might also work to help capture more nuanced temporal structure in my data?

My apologies if anything I'm asking just makes no sense at all. Still learning!

&amp;#x200B;

&amp;#x200B;",t2_gj1m6,False,,0,False,2d obs vectors with various aggregations vs. 3d obs vector of multiple time series,[],r/datascience,False,6,projects,0,,,False,t3_1812io4,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},ML,False,1,,False,False,self,1702950773.0,,[],{},,True,,1700633679.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m exploring building a model of customer accounts over time to predict a very infrequent event. ~0.5% of my population would be classified as a positive at any given time. I had been using aggregated features for different attributes over various intervals of time in an attempt to capture some time dynamic. For example, total purchases and total payments might be attributes of interest, so I take the sum of both over the last 1,5,7 days and end up with a 2 dimensional feature matrix containing 6 covariates and I&amp;#39;d feed that into a gradient boosted trees algorithm. I am wondering if it would be worthwhile to explore modeling this problem with a 3 dimensional feature matrix that I could use to train a more advanced type of neural network. Would transformers be a viable path forward here? Or would a simple LSTM or GRU be a better choice? Any good literature on this topic? CNNs are interesting to me as well. I know traditionally they are more suited toward things like image classification, but I wonder if they might also work to help capture more nuanced temporal structure in my data?&lt;/p&gt;

&lt;p&gt;My apologies if anything I&amp;#39;m asking just makes no sense at all. Still learning!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,1812io4,True,,JimBeanery,,1,True,all_ads,False,[],False,,/r/datascience/comments/1812io4/2d_obs_vectors_with_various_aggregations_vs_3d/,all_ads,False,https://www.reddit.com/r/datascience/comments/1812io4/2d_obs_vectors_with_various_aggregations_vs_3d/,1209064,1700633679.0,0,,False,,,,,,,,,,1226,210
,datascience,"A Data Scientist position opened up at a smallish startup (50 people) that I am very interested in (Startup A). I have previously interviewed with the startup in the past, but pulled out when I received a better offer (salary/position) from another startup (Startup B). I ended up being laid off from Startup B (the company had a lot of growing pains); however, a few months later I was contacted by Startup A's CEO and the hiring manager I previously spoke with. They mentioned they were interested in hiring me again, but the conversation was really them trying to glean information about Startup B. I was pretty vague since I signed an NDA in exchange for good severance, but shared what I felt was allowed (I also accepted an offer elsewhere by that point so didn't really feal incentivized to be to straightforward).  I didn't follow-up with them (had accepted an offer, was getting married, etc.) but remained cordial with the HM.

That was about a year ago, the HM has left the company for an academic position and the only contact I have left is the CEO. My question is - should I reach back out to the CEO or to the HM who I was initially in contact with (he also seems to still be involved with the company in someway but isn't an employee). 

Short-version: Would it be over-stepping to reach out to a CEO who I previously interacted with when applying for a job at a 50 person startup?",t2_tjfy4w2o,False,,0,False,Networking: Who should I contact when I apply?,[],r/datascience,False,6,fun,0,,,False,t3_180yd5o,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1700619525.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A Data Scientist position opened up at a smallish startup (50 people) that I am very interested in (Startup A). I have previously interviewed with the startup in the past, but pulled out when I received a better offer (salary/position) from another startup (Startup B). I ended up being laid off from Startup B (the company had a lot of growing pains); however, a few months later I was contacted by Startup A&amp;#39;s CEO and the hiring manager I previously spoke with. They mentioned they were interested in hiring me again, but the conversation was really them trying to glean information about Startup B. I was pretty vague since I signed an NDA in exchange for good severance, but shared what I felt was allowed (I also accepted an offer elsewhere by that point so didn&amp;#39;t really feal incentivized to be to straightforward).  I didn&amp;#39;t follow-up with them (had accepted an offer, was getting married, etc.) but remained cordial with the HM.&lt;/p&gt;

&lt;p&gt;That was about a year ago, the HM has left the company for an academic position and the only contact I have left is the CEO. My question is - should I reach back out to the CEO or to the HM who I was initially in contact with (he also seems to still be involved with the company in someway but isn&amp;#39;t an employee). &lt;/p&gt;

&lt;p&gt;Short-version: Would it be over-stepping to reach out to a CEO who I previously interacted with when applying for a job at a 50 person startup?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,180yd5o,True,,Illustrious-Mind9435,,10,True,all_ads,False,[],False,,/r/datascience/comments/180yd5o/networking_who_should_i_contact_when_i_apply/,all_ads,False,https://www.reddit.com/r/datascience/comments/180yd5o/networking_who_should_i_contact_when_i_apply/,1209064,1700619525.0,0,,False,,,,,,,,,,1397,253
,datascience,"I've noticed that I'm contacted by US recruiters when I set my LinkedIn location to Europe, regardless of the location's language, but not if I set it to my home country (Brazil).

Given that hiring people from South America is cheaper, why is it not usually looked up?",t2_nr338hpnv,False,,0,False,"Why do US recruiters usually give preference to European workforce rather than to people from similar time zones, like South Americans?",[],r/datascience,False,6,discussion,0,,,False,t3_180rfws,False,dark,0.84,,public,104,0,{},,,False,[],,False,False,,{},Discussion,False,104,,False,False,self,False,,[],{},,True,,1700600693.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve noticed that I&amp;#39;m contacted by US recruiters when I set my LinkedIn location to Europe, regardless of the location&amp;#39;s language, but not if I set it to my home country (Brazil).&lt;/p&gt;

&lt;p&gt;Given that hiring people from South America is cheaper, why is it not usually looked up?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,180rfws,True,,BrDataScientist,,65,True,all_ads,False,[],False,,/r/datascience/comments/180rfws/why_do_us_recruiters_usually_give_preference_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/180rfws/why_do_us_recruiters_usually_give_preference_to/,1209064,1700600693.0,0,,False,,,,,,,,,,269,48
,datascience,"I just graduated with a masters in data science from a uk university. To say it was difficult would be an understatement, and it’s not just the program itself that made it so, but two external factors which (I’ll list below) made studying a challenge. 



1. WORK: If you have a hard job already, DON’T combine it with a data science masters. You could literally breakdown completely due to stress. My school recommend working only 10 hours per week and I ignored the advice because I needed the money. I worked 20 hours per week doing menial jobs. At some point I thought I would actually drop dead due to stress. Keep in mind that 20 hours is still part time work. I strongly recommend working a maximum  10 hours per week or not working at all if you’re prone to stress.   My classmates who worked full time during their masters had very poor grades (some even dropped out). 



2. Family and peer support:  I always thought of myself as a lone journeyman who took on the world without needing to speak to anyone. Uhh…. Yeah that went out the window completely when things got heated during the program. Not seeing family in the flesh  affected my mental health. I noticed that people who took the program with their families  were a lot happier than those of us who didn’t have any family around. Speaking to family, friends and classmates going through the same program really helped A LOT though. You really can’t go through this program as a loner. Life would hit you on the face like a brick for every single day of your existence if you attempt to do so. 

That’s my 2 cents. AA

EDIT: 
Course Selection: Just remembered this but uhh course selection is REALLY IMPORTANT. I had done enough online courses on data science before my masters, to know that neural networks and deep learning is something you study ON YOUR OWN, and  NOT as part of an official course. If you’re new to data science, pick the easiest courses for your masters. I saw enough people completely fail their courses (and subsequently the entire masters) because they wanted courses that sound trendy. Seriously that’s the only reason they chose them. Please research “Natural Language Engineering” and “Combinatorial Optimisation” before choosing it as a course alright. 😂😂",t2_c8s8psg,False,,0,False,Word of advice on taking on a Data Science masters (from someone who just completed one),[],r/datascience,False,6,discussion,0,,,False,t3_180kgb9,False,dark,0.89,,public,104,0,{},,,False,[],,False,False,,{},Discussion,False,104,,False,False,self,1700586251.0,,[],{},,True,,1700582779.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just graduated with a masters in data science from a uk university. To say it was difficult would be an understatement, and it’s not just the program itself that made it so, but two external factors which (I’ll list below) made studying a challenge. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;WORK: If you have a hard job already, DON’T combine it with a data science masters. You could literally breakdown completely due to stress. My school recommend working only 10 hours per week and I ignored the advice because I needed the money. I worked 20 hours per week doing menial jobs. At some point I thought I would actually drop dead due to stress. Keep in mind that 20 hours is still part time work. I strongly recommend working a maximum  10 hours per week or not working at all if you’re prone to stress.   My classmates who worked full time during their masters had very poor grades (some even dropped out). &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Family and peer support:  I always thought of myself as a lone journeyman who took on the world without needing to speak to anyone. Uhh…. Yeah that went out the window completely when things got heated during the program. Not seeing family in the flesh  affected my mental health. I noticed that people who took the program with their families  were a lot happier than those of us who didn’t have any family around. Speaking to family, friends and classmates going through the same program really helped A LOT though. You really can’t go through this program as a loner. Life would hit you on the face like a brick for every single day of your existence if you attempt to do so. &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That’s my 2 cents. AA&lt;/p&gt;

&lt;p&gt;EDIT: 
Course Selection: Just remembered this but uhh course selection is REALLY IMPORTANT. I had done enough online courses on data science before my masters, to know that neural networks and deep learning is something you study ON YOUR OWN, and  NOT as part of an official course. If you’re new to data science, pick the easiest courses for your masters. I saw enough people completely fail their courses (and subsequently the entire masters) because they wanted courses that sound trendy. Seriously that’s the only reason they chose them. Please research “Natural Language Engineering” and “Combinatorial Optimisation” before choosing it as a course alright. 😂😂&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,180kgb9,True,,abdulj07,,70,True,all_ads,False,[],False,,/r/datascience/comments/180kgb9/word_of_advice_on_taking_on_a_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/180kgb9/word_of_advice_on_taking_on_a_data_science/,1209064,1700582779.0,0,,False,,,,,,,,,,2253,393
,datascience,"I've been tasked with finding out if we can do a GenAI based chatbot.

My general understanding:  
\- Take an input (which can be voice to text transcription for a customer service call center agent)  
\- Send that input, via API call, to a vendor (like Open AI or other ones, given the recent stuff maybe we look hard at other vendors)  
\- The API will respond with relevant information

Now this presumes that there is an LLM on the other end of that API call that knows the context of the conversation. If you want to have this work for your call center agents, for example, to help them figure out where to go next with troubleshooting, that LLM would need to be trained on your specific knowledge base (and not a generic ChatGPT3 type open response). That's my understanding at least. So two main questions:  
1) Is my understanding of this general process correct (that it goes via API call to a vendor and you get a response)?  
2) What is the process like for setting up access to a vendor to get that kind of trained LLM? Is there a list of decent vendors out there? I presume we need A LOT of text to train this LLM on and I'm hoping a vendor can help us walk through that process.",t2_7jjayp3,False,,0,False,Question for those who have worked with GenAI,[],r/datascience,False,6,meta,0,,,False,t3_180k7qx,False,dark,0.82,,public,17,0,{},,,False,[],,False,False,,{},Projects,False,17,,False,False,self,False,,[],{},,True,,1700582182.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been tasked with finding out if we can do a GenAI based chatbot.&lt;/p&gt;

&lt;p&gt;My general understanding:&lt;br/&gt;
- Take an input (which can be voice to text transcription for a customer service call center agent)&lt;br/&gt;
- Send that input, via API call, to a vendor (like Open AI or other ones, given the recent stuff maybe we look hard at other vendors)&lt;br/&gt;
- The API will respond with relevant information&lt;/p&gt;

&lt;p&gt;Now this presumes that there is an LLM on the other end of that API call that knows the context of the conversation. If you want to have this work for your call center agents, for example, to help them figure out where to go next with troubleshooting, that LLM would need to be trained on your specific knowledge base (and not a generic ChatGPT3 type open response). That&amp;#39;s my understanding at least. So two main questions:&lt;br/&gt;
1) Is my understanding of this general process correct (that it goes via API call to a vendor and you get a response)?&lt;br/&gt;
2) What is the process like for setting up access to a vendor to get that kind of trained LLM? Is there a list of decent vendors out there? I presume we need A LOT of text to train this LLM on and I&amp;#39;m hoping a vendor can help us walk through that process.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,180k7qx,True,,quantpsychguy,,26,True,all_ads,False,[],False,,/r/datascience/comments/180k7qx/question_for_those_who_have_worked_with_genai/,all_ads,False,https://www.reddit.com/r/datascience/comments/180k7qx/question_for_those_who_have_worked_with_genai/,1209064,1700582182.0,0,,False,,,,,,,,,,1192,224
,datascience,"Looking at jobs, and I see some (right now one at Harris Poll) that offer ""unlimited PTO."" I've seen this in the news once or twice, but I've never experienced it. Looking at Harris Poll reviews on glassdoor I see a mix of comments, including ""unlimited vacation is nice"" and ""long hours, nights, weekends..."" 

So how does that work? ""Unlimited PTO"" sounds too good to be true so I assume it is too good to be true. What happens in reality working for a company offering ""unlimited paid time off""?

*Edit*: Thanks everyone for your experiences and thoughts. This gives me some good things to consider.",t2_36gej,False,,0,False,"""Unlimited PTO"" vs work-life balance... how does that work?",[],r/datascience,False,6,fun,0,,,False,t3_180gg97,False,dark,0.93,,public,94,0,{},,,False,[],,False,False,,{},Career Discussion,False,94,,False,False,self,1700600764.0,,[],{},,True,,1700571652.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Looking at jobs, and I see some (right now one at Harris Poll) that offer &amp;quot;unlimited PTO.&amp;quot; I&amp;#39;ve seen this in the news once or twice, but I&amp;#39;ve never experienced it. Looking at Harris Poll reviews on glassdoor I see a mix of comments, including &amp;quot;unlimited vacation is nice&amp;quot; and &amp;quot;long hours, nights, weekends...&amp;quot; &lt;/p&gt;

&lt;p&gt;So how does that work? &amp;quot;Unlimited PTO&amp;quot; sounds too good to be true so I assume it is too good to be true. What happens in reality working for a company offering &amp;quot;unlimited paid time off&amp;quot;?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt;: Thanks everyone for your experiences and thoughts. This gives me some good things to consider.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,180gg97,True,,bobbyfiend,,117,True,all_ads,False,[],False,,/r/datascience/comments/180gg97/unlimited_pto_vs_worklife_balance_how_does_that/,all_ads,False,https://www.reddit.com/r/datascience/comments/180gg97/unlimited_pto_vs_worklife_balance_how_does_that/,1209064,1700571652.0,0,,False,,,,,,,,,,602,106
,datascience," Hello everyone,

I'm about to start a new position as a Data Scientist at an audit company. Coming from a technical background, my primary responsibilities will include building models to detect specific types of fraud, developing an OCR model, implementing an LLM model, and creating data analytics dashboards. I've been actively involved in model development for the past two years, so I feel quite comfortable with these tasks.

However, I haven't had much experience with dashboarding. While I frequently use data analytics in my workflow, it's usually as an exploratory data analysis (EDA) step before moving on to feature engineering. I typically use pyplot for my graphs, and I'm aware that pyplot has Dash, which could be a solution for dashboards.

Do you recommend Dash for creating dashboards? Additionally, do you have any books or resources you would recommend for someone working in Data Science/Analytics within the context of audit?",t2_5gzyxvce,False,,0,False,Data Sciences and Audit,[],r/datascience,False,6,discussion,0,,,False,t3_180eocx,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1700565419.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m about to start a new position as a Data Scientist at an audit company. Coming from a technical background, my primary responsibilities will include building models to detect specific types of fraud, developing an OCR model, implementing an LLM model, and creating data analytics dashboards. I&amp;#39;ve been actively involved in model development for the past two years, so I feel quite comfortable with these tasks.&lt;/p&gt;

&lt;p&gt;However, I haven&amp;#39;t had much experience with dashboarding. While I frequently use data analytics in my workflow, it&amp;#39;s usually as an exploratory data analysis (EDA) step before moving on to feature engineering. I typically use pyplot for my graphs, and I&amp;#39;m aware that pyplot has Dash, which could be a solution for dashboards.&lt;/p&gt;

&lt;p&gt;Do you recommend Dash for creating dashboards? Additionally, do you have any books or resources you would recommend for someone working in Data Science/Analytics within the context of audit?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,180eocx,True,,dekozr,,8,True,all_ads,False,[],False,,/r/datascience/comments/180eocx/data_sciences_and_audit/,all_ads,False,https://www.reddit.com/r/datascience/comments/180eocx/data_sciences_and_audit/,1209064,1700565419.0,0,,False,,,,,,,,,,949,150
,datascience,"Just saw this article:

[https://arstechnica.com/health/2023/11/ai-with-90-error-rate-forces-elderly-out-of-rehab-nursing-homes-suit-claims/?comments=1&amp;comments-page=1](https://arstechnica.com/health/2023/11/ai-with-90-error-rate-forces-elderly-out-of-rehab-nursing-homes-suit-claims/?comments=1&amp;comments-page=1)

A fair criticism or too harsh on the data scientists?",t2_6cjiszgb,False,,0,False,"ars technica article ""UnitedHealth uses AI model with 90% error rate to deny care, lawsuit alleges""",[],r/datascience,False,6,discussion,0,,,False,t3_18082r5,False,dark,0.94,,public,97,0,{},,,False,[],,False,False,,{},Discussion,False,97,,False,False,self,False,,[],{},,True,,1700539350.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just saw this article:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://arstechnica.com/health/2023/11/ai-with-90-error-rate-forces-elderly-out-of-rehab-nursing-homes-suit-claims/?comments=1&amp;amp;comments-page=1""&gt;https://arstechnica.com/health/2023/11/ai-with-90-error-rate-forces-elderly-out-of-rehab-nursing-homes-suit-claims/?comments=1&amp;amp;comments-page=1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A fair criticism or too harsh on the data scientists?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,18082r5,True,,RobertWF_47,,23,True,all_ads,False,[],False,,/r/datascience/comments/18082r5/ars_technica_article_unitedhealth_uses_ai_model/,all_ads,False,https://www.reddit.com/r/datascience/comments/18082r5/ars_technica_article_unitedhealth_uses_ai_model/,1209064,1700539350.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BM_ivgunGmttMjq_Oii0wIP12a_BxeCSzHQHCbM-PNE.jpg?auto=webp&amp;s=01ed192d14c0579cbc1bed760a0d65ee5fc0f5f3', 'width': 760, 'height': 380}, 'resolutions': [{'url': 'https://external-preview.redd.it/BM_ivgunGmttMjq_Oii0wIP12a_BxeCSzHQHCbM-PNE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=70c96ae83d35c1f16eeae4545e940fce75ffd09f', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/BM_ivgunGmttMjq_Oii0wIP12a_BxeCSzHQHCbM-PNE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4534c1d12010fc9b70bd2fb06b65bddab0d21a85', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/BM_ivgunGmttMjq_Oii0wIP12a_BxeCSzHQHCbM-PNE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4800746a92d102ce43e3b513c39d9d14722d1e8b', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/BM_ivgunGmttMjq_Oii0wIP12a_BxeCSzHQHCbM-PNE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd8ee9f399957b670d387c7598ba1be10fa16a24', 'width': 640, 'height': 320}], 'variants': {}, 'id': 'xE-3y46n3NUaxzMoGd14wQYy_WHNcSS2R9gc-ZYDjLs'}], 'enabled': False}",,,,,,,375,15
,datascience,"Hi all,

I'm coming into a more standard data science role which will primarily use python and SQL. In your experience, what are your go to applications for SQL (oracleSQL) and how do you get that data into python?

This may seem like a silly question to ask as a DA/DS professional already, but professionally I have been working in a lesser used application known as alteryx desktop designer. It's a tools based approach to DA that allows you to use the SQL tool to write queries and read that data straight into the workflow you are working on. From there I would do my data preprocessing in alteryx and export it out into a CSV for python where I do my modeling. I am already proficient in stats/DS and my SQL is up to snuff, I just don’t know what other people use  and their pipeline from SQL to python since our entire org basically only uses Alteryx.

Thanks!

&amp;#x200B;",t2_7ca522z4,False,,0,False,Pulling Data from SQL into Python,[],r/datascience,False,6,tooling,0,,,False,t3_1806uac,False,dark,0.94,,public,31,0,{},,,False,[],,False,False,,{},Tools,False,31,,False,False,self,False,,[],{},,True,,1700535526.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m coming into a more standard data science role which will primarily use python and SQL. In your experience, what are your go to applications for SQL (oracleSQL) and how do you get that data into python?&lt;/p&gt;

&lt;p&gt;This may seem like a silly question to ask as a DA/DS professional already, but professionally I have been working in a lesser used application known as alteryx desktop designer. It&amp;#39;s a tools based approach to DA that allows you to use the SQL tool to write queries and read that data straight into the workflow you are working on. From there I would do my data preprocessing in alteryx and export it out into a CSV for python where I do my modeling. I am already proficient in stats/DS and my SQL is up to snuff, I just don’t know what other people use  and their pipeline from SQL to python since our entire org basically only uses Alteryx.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,1806uac,True,,throwaway69xx420,,37,True,all_ads,False,[],False,,/r/datascience/comments/1806uac/pulling_data_from_sql_into_python/,all_ads,False,https://www.reddit.com/r/datascience/comments/1806uac/pulling_data_from_sql_into_python/,1209064,1700535526.0,0,,False,,,,,,,,,,881,161
,datascience,"I was laid off from my company earlier this year after 1.8 years of successful work experience at this company. I was recognized three times over that period, given merit increases in bonuses, shares of stock as rewards. Constantly praised and recognized several times, and never disciplined in any way or even told that my performance was an issue. I was laid off and they admitted that it was not for performance reasons, I was a great employee, they would love to see me work for them again...

So I start reapplying, I'm very dedicated to working for this company, and the interviews that I get are much more challenging than they were when I started with the company. Previously, they asked me about my background, skills, experience, and had me interview with other people on the team. This time around, I had to do case studies that were extremely challenging. One of them I had 3 hours to go through an absurdly complex Excel assignment that involved three separate spreadsheets of data and building a data lookup tool using Excel. Like, creating a tableau report, just using data validation and dropdowns and stuff and conditional formatting I guess? Sounds stupid and I've never done something so crazy so yep I failed hard. Also had another interview based around SQL, which I know like the back of my hand. Aced the interview, and almost got an offer, but disqualified last round.

Then I had another interview for BI engineer position, and they were “disappointed” with me for not speaking to what SQL I’d used. The manager was honestly a douche, I could tell just from his demeanor, and how he acted. Dude seemed like he was barely invested in the interview. It was supposed to be a meet and greet, NOT an interview, that’s verbatim what I was told. Then I get told I should’ve explained size of my SQL queries, how many rows, types of joins. Like uh, it’s a meet and greet to learn more about the role, and YOU did not ask ME any of that either?

It’s just so infuriating.... 3 years ago, we had 1-3 interviews for low to mid level jobs. Now its 3-8 interviews minimum plus 2+ case studies, for ANY JOB. Like, imagine working for a company and being praised for years, now because of ""economic conditions"" hundreds get laid off, and treated like children in interviews to rejoin the firm. This is just sad. ",t2_dmawn6hx,False,,0,False,Interviewing is terrible now. They don't treat you with any respect anymore,[],r/datascience,False,6,discussion,0,,,False,t3_1802ydm,False,dark,0.92,#dadada,public,458,0,{},,d898d418-70eb-11ee-81d7-36bf4b44216b,False,[],,False,False,,{},Discussion,False,458,,False,False,self,False,,[],{},,True,,1700524167.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was laid off from my company earlier this year after 1.8 years of successful work experience at this company. I was recognized three times over that period, given merit increases in bonuses, shares of stock as rewards. Constantly praised and recognized several times, and never disciplined in any way or even told that my performance was an issue. I was laid off and they admitted that it was not for performance reasons, I was a great employee, they would love to see me work for them again...&lt;/p&gt;

&lt;p&gt;So I start reapplying, I&amp;#39;m very dedicated to working for this company, and the interviews that I get are much more challenging than they were when I started with the company. Previously, they asked me about my background, skills, experience, and had me interview with other people on the team. This time around, I had to do case studies that were extremely challenging. One of them I had 3 hours to go through an absurdly complex Excel assignment that involved three separate spreadsheets of data and building a data lookup tool using Excel. Like, creating a tableau report, just using data validation and dropdowns and stuff and conditional formatting I guess? Sounds stupid and I&amp;#39;ve never done something so crazy so yep I failed hard. Also had another interview based around SQL, which I know like the back of my hand. Aced the interview, and almost got an offer, but disqualified last round.&lt;/p&gt;

&lt;p&gt;Then I had another interview for BI engineer position, and they were “disappointed” with me for not speaking to what SQL I’d used. The manager was honestly a douche, I could tell just from his demeanor, and how he acted. Dude seemed like he was barely invested in the interview. It was supposed to be a meet and greet, NOT an interview, that’s verbatim what I was told. Then I get told I should’ve explained size of my SQL queries, how many rows, types of joins. Like uh, it’s a meet and greet to learn more about the role, and YOU did not ask ME any of that either?&lt;/p&gt;

&lt;p&gt;It’s just so infuriating.... 3 years ago, we had 1-3 interviews for low to mid level jobs. Now its 3-8 interviews minimum plus 2+ case studies, for ANY JOB. Like, imagine working for a company and being praised for years, now because of &amp;quot;economic conditions&amp;quot; hundreds get laid off, and treated like children in interviews to rejoin the firm. This is just sad. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,Junior,[],False,,,,t5_2sptq,False,,,#1a1a1b,1802ydm,True,,InevitableTraining69,,132,True,all_ads,False,[],False,dark,/r/datascience/comments/1802ydm/interviewing_is_terrible_now_they_dont_treat_you/,all_ads,False,https://www.reddit.com/r/datascience/comments/1802ydm/interviewing_is_terrible_now_they_dont_treat_you/,1209064,1700524167.0,0,,False,,,,,,,,,,2322,413
,datascience,"Hi all, I’ve been working at a consulting firm for about 6 months now and have another 6 months of internships under my belt at the same place.

I’ve posted here and elsewhere before about just how much I do not enjoy working here for various reasons, so I will not delve into the reasons why, but the gist of the matter is that I do eventually want to switch jobs.

I work as a data scientist, but I see so many individuals here and on linkedin posting about how they work with ML algorithms and python data-central frameworks in their day to day. I do none of that.

Since at a consulting firm, the work you do changes on a case to case basis, over the last year or so, I’ve architectured, created, and maintained end to end full stack software, with my primary tech stack being VueJs, NextJs, Python and C#. 

I’m worried that this experience has essentially ruled out the possibility of landing a DS job for me in the future (the last time I did ML related projects was in grad school) but also the fact that since I have to switch between stacks quite often, this makes me less than an ideal candidate for a full stack/front end software job too. This feeling is corroborated by the fact that I have been getting next to no interview calls over the last 6 months or so as I have been actively applying.

To the people in higher positions at tech firms or otherwise, is my fear legitimate or am I overthinking? In terms of the next steps, what kind of job profile must I target? 

Thanks :)",t2_i9fgk8dg,False,,0,False,I’m worried the experience I’m accruing at my current job is not useful for when I want to switch,[],r/datascience,False,6,fun,0,,,False,t3_17ztuqh,False,dark,0.89,,public,18,0,{},,,False,[],,False,False,,{},Career Discussion,False,18,,False,False,self,False,,[],{},,True,,1700501391.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I’ve been working at a consulting firm for about 6 months now and have another 6 months of internships under my belt at the same place.&lt;/p&gt;

&lt;p&gt;I’ve posted here and elsewhere before about just how much I do not enjoy working here for various reasons, so I will not delve into the reasons why, but the gist of the matter is that I do eventually want to switch jobs.&lt;/p&gt;

&lt;p&gt;I work as a data scientist, but I see so many individuals here and on linkedin posting about how they work with ML algorithms and python data-central frameworks in their day to day. I do none of that.&lt;/p&gt;

&lt;p&gt;Since at a consulting firm, the work you do changes on a case to case basis, over the last year or so, I’ve architectured, created, and maintained end to end full stack software, with my primary tech stack being VueJs, NextJs, Python and C#. &lt;/p&gt;

&lt;p&gt;I’m worried that this experience has essentially ruled out the possibility of landing a DS job for me in the future (the last time I did ML related projects was in grad school) but also the fact that since I have to switch between stacks quite often, this makes me less than an ideal candidate for a full stack/front end software job too. This feeling is corroborated by the fact that I have been getting next to no interview calls over the last 6 months or so as I have been actively applying.&lt;/p&gt;

&lt;p&gt;To the people in higher positions at tech firms or otherwise, is my fear legitimate or am I overthinking? In terms of the next steps, what kind of job profile must I target? &lt;/p&gt;

&lt;p&gt;Thanks :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ztuqh,True,,Objective-Test5021,,23,True,all_ads,False,[],False,,/r/datascience/comments/17ztuqh/im_worried_the_experience_im_accruing_at_my/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ztuqh/im_worried_the_experience_im_accruing_at_my/,1209064,1700501391.0,0,,False,,,,,,,,,,1494,281
,datascience,"I am preparing a dataset for a classification task at work, as you can see, I have 13 features with multicollinearity, also, I could not infer any good decisions about what to do given the correlation matrix.

What do you think I should do here? I have a total of 60 features, I cleaned the data and checked for duplicates and outliers, standardized the data and everything, now it’s a matter of feature selection I think?

Could really use some advice",t2_81zrh19oq,False,,0,False,What do you do with highly correlated features? When the VIF is high in particular?,[],r/datascience,False,6,projects,0,105.0,,False,t3_17zshma,False,dark,0.85,,public,68,0,{},140.0,,False,[],,False,False,,{},ML,False,68,,False,False,https://b.thumbs.redditmedia.com/fMSrbwxLQdoQcsgEYBkKkRTAw9YQI_0bNFa6UDLUVAQ.jpg,False,,[],{},,False,,1700497938.0,text,6,,,text,reddit.com,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am preparing a dataset for a classification task at work, as you can see, I have 13 features with multicollinearity, also, I could not infer any good decisions about what to do given the correlation matrix.&lt;/p&gt;

&lt;p&gt;What do you think I should do here? I have a total of 60 features, I cleaned the data and checked for duplicates and outliers, standardized the data and everything, now it’s a matter of feature selection I think?&lt;/p&gt;

&lt;p&gt;Could really use some advice&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17zshma,True,,Careful_Engineer_700,,83,True,all_ads,False,[],False,,/r/datascience/comments/17zshma/what_do_you_do_with_highly_correlated_features/,all_ads,False,https://www.reddit.com/gallery/17zshma,1209064,1700497938.0,1,,False,"{'kt0ltakb5j1c1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47080517183ca73b541c2b609dadccf165440351'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11581f562b1d7a8cac50cbfa4e82558eb50817f0'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebe66919cd9d14fd1063fcd98c1da3cdb666fd96'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39ae1fe67b56682c83fd9ab4412e4cc89ac05b67'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c074041adcdc38d565150ff34a43dd47e4099402'}, {'y': 810, 'x': 1080, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16ef3129300857178f1a142dcb687db9b5b33127'}], 's': {'y': 3024, 'x': 4032, 'u': 'https://preview.redd.it/kt0ltakb5j1c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=dd9e6c0cf857c3d22923d3b4a44fa6e0e489643f'}, 'id': 'kt0ltakb5j1c1'}, 't23kbbkb5j1c1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fbca2c481944086302d66cd46b9eb8d099bad29'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ae6b5f17c66340887a3f946fab66f49511a74d3'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aaa534a7245c19474b92aa6a79659d535d0a2abc'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a87619d73b828209997ad6dc4c781347f8a6c0a4'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3937a7e577c6c96091f523bdfbb9d0b5b27e7dc'}, {'y': 810, 'x': 1080, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9a065ba6a41df460155ffdded999de3242981733'}], 's': {'y': 3024, 'x': 4032, 'u': 'https://preview.redd.it/t23kbbkb5j1c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=eadb0911ecc3d29d05481473fbcb463bda025e43'}, 'id': 't23kbbkb5j1c1'}}",,,,https://www.reddit.com/gallery/17zshma,,,True,"{'items': [{'media_id': 'kt0ltakb5j1c1', 'id': 362969982}, {'media_id': 't23kbbkb5j1c1', 'id': 362969983}]}",452,81
,datascience,"
Not the typical post here, but I’ve been thinking about getting a stats based tattoo. Some ideas I’ve had are:

Normal equations in matrix form, or OLS solutions in matrix form

Lasso penalty function

Acceptance ratio in MCMC algorithms

Any other ideas?",t2_uy28jztl,False,,0,False,Statistics tattoo ideas?,[],r/datascience,False,6,discussion,0,,,False,t3_17zseh3,False,dark,0.71,,public,45,0,{},,,False,[],,False,False,,{},Discussion,False,45,,False,False,self,False,,[],{},,True,,1700497714.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not the typical post here, but I’ve been thinking about getting a stats based tattoo. Some ideas I’ve had are:&lt;/p&gt;

&lt;p&gt;Normal equations in matrix form, or OLS solutions in matrix form&lt;/p&gt;

&lt;p&gt;Lasso penalty function&lt;/p&gt;

&lt;p&gt;Acceptance ratio in MCMC algorithms&lt;/p&gt;

&lt;p&gt;Any other ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17zseh3,True,,Direct-Touch469,,86,True,all_ads,False,[],False,,/r/datascience/comments/17zseh3/statistics_tattoo_ideas/,all_ads,False,https://www.reddit.com/r/datascience/comments/17zseh3/statistics_tattoo_ideas/,1209064,1700497714.0,0,,False,,,,,,,,,,256,42
,datascience,One major downside of DS is you have to work directly with executives. I never met one that wasn’t a self serving short sighted idiot. They do more to sabotage projects than literally anything else.,t2_kcl3tfwe,False,,0,False,Anyone ever work somewhere with good executives?,[],r/datascience,False,6,fun,0,,,False,t3_17zqxnx,False,dark,0.86,,public,85,0,{},,,False,[],,False,False,,{},Career Discussion,False,85,,False,False,self,False,,[],{},,True,,1700493850.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;One major downside of DS is you have to work directly with executives. I never met one that wasn’t a self serving short sighted idiot. They do more to sabotage projects than literally anything else.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17zqxnx,True,,NewEcho2940,,82,True,all_ads,False,[],False,,/r/datascience/comments/17zqxnx/anyone_ever_work_somewhere_with_good_executives/,all_ads,False,https://www.reddit.com/r/datascience/comments/17zqxnx/anyone_ever_work_somewhere_with_good_executives/,1209064,1700493850.0,0,,False,,,,,,,,,,198,35
,datascience,"Use case: I have an xgboost model that predicts customer purchase decisions (Y/N) based on 50+ features. The product team is interested in learning about the effect of some specific features (5 in total) on specific users. Running an experiment isn't possible. So, thinking, methodology-wise, would it be a good idea to run some simulations and report out of T cases S would result in a positive outcome? Also, if it's a sound approach, can you please point me to any resources?",t2_9axqyq8u,False,,0,False,Is there a methodologically sound way to derive causal insights from a predictive model (e.g. xgboost) using simulation?,[],r/datascience,False,6,meta,0,,,False,t3_17zquxa,False,dark,1.0,,public,13,0,{},,,False,[],,False,False,,{},Projects,False,13,,False,False,self,False,,[],{},,True,,1700493638.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Use case: I have an xgboost model that predicts customer purchase decisions (Y/N) based on 50+ features. The product team is interested in learning about the effect of some specific features (5 in total) on specific users. Running an experiment isn&amp;#39;t possible. So, thinking, methodology-wise, would it be a good idea to run some simulations and report out of T cases S would result in a positive outcome? Also, if it&amp;#39;s a sound approach, can you please point me to any resources?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17zquxa,True,,Difficult-Big-3890,,24,True,all_ads,False,[],False,,/r/datascience/comments/17zquxa/is_there_a_methodologically_sound_way_to_derive/,all_ads,False,https://www.reddit.com/r/datascience/comments/17zquxa/is_there_a_methodologically_sound_way_to_derive/,1209064,1700493638.0,0,,False,,,,,,,,,,478,82
,datascience,"Like a lot of people who studied data science, i spend a lot more of my career looking at analytics, reporting and visualisation these days - lets face it, thats where the bulk of the value and jobs are in most industries.

I spend my first few years working in teams that used R (mostly) or Python. And SQL, obviously. Basically understanding and investigating stuff was done in SQL, visualisation, dashboards, packs were done in R (shout out to ggplot2).

I now work in consulting, where i get to see a lot of industry analytics teams and a lot of the analytics teams i work with these days are ""no code"" teams.

These teams use click and drag tools for ETL, analytics, visualisation and reporting (qlikview, dataiku, power bi, sas EG, alteryx, informatica). There are entire analytics and even engineering functionalities within some companies where noone can code.

Now these tools are expensive as hell - but they are time efficient, reduce a lot of IT risk around data access, and limit the amount of fuckery a single rogue idiot can wreak.

My question is, as these tools become more entrenched in major organisations is there any role for analysts that can code?

To be honest, im biased - i love coding, so i want to believe there is a future for it. But also dont want to bury my head in the sand either, if coding is going the way of the typewriter.",t2_s5fhuj6d,False,,0,False,The future of coding in data analytics,[],r/datascience,False,6,discussion,0,,,False,t3_17zgu1a,False,dark,0.91,,public,154,0,{},,,False,[],,False,False,,{},Discussion,False,154,,False,False,self,False,,[],{},,True,,1700456471.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Like a lot of people who studied data science, i spend a lot more of my career looking at analytics, reporting and visualisation these days - lets face it, thats where the bulk of the value and jobs are in most industries.&lt;/p&gt;

&lt;p&gt;I spend my first few years working in teams that used R (mostly) or Python. And SQL, obviously. Basically understanding and investigating stuff was done in SQL, visualisation, dashboards, packs were done in R (shout out to ggplot2).&lt;/p&gt;

&lt;p&gt;I now work in consulting, where i get to see a lot of industry analytics teams and a lot of the analytics teams i work with these days are &amp;quot;no code&amp;quot; teams.&lt;/p&gt;

&lt;p&gt;These teams use click and drag tools for ETL, analytics, visualisation and reporting (qlikview, dataiku, power bi, sas EG, alteryx, informatica). There are entire analytics and even engineering functionalities within some companies where noone can code.&lt;/p&gt;

&lt;p&gt;Now these tools are expensive as hell - but they are time efficient, reduce a lot of IT risk around data access, and limit the amount of fuckery a single rogue idiot can wreak.&lt;/p&gt;

&lt;p&gt;My question is, as these tools become more entrenched in major organisations is there any role for analysts that can code?&lt;/p&gt;

&lt;p&gt;To be honest, im biased - i love coding, so i want to believe there is a future for it. But also dont want to bury my head in the sand either, if coding is going the way of the typewriter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17zgu1a,True,,catfood_and_glue,,54,True,all_ads,False,[],False,,/r/datascience/comments/17zgu1a/the_future_of_coding_in_data_analytics/,all_ads,False,https://www.reddit.com/r/datascience/comments/17zgu1a/the_future_of_coding_in_data_analytics/,1209064,1700456471.0,0,,False,,,,,,,,,,1360,244
,datascience,"It's already established that LLMs are more than a fad and here to stay. Soon there will be very stable APIs for using LLMs like we use sklearn, Tensirflow, Pytorch, Keras etc. We'll know the fundamentals but will rely totally on the already optimized implemented APIs. But, I see a lot of skepticism around LLM specially from DS circles not much from MLE circles though. Any thoughts?",t2_9axqyq8u,False,,0,False,"Data Scientists already in the industry more than a couple of years, are you actively learning LLM frameworks? If so, how? If no, why?",[],r/datascience,False,6,discussion,0,,,False,t3_17z8kkh,False,dark,0.88,,public,119,0,{},,,False,[],,False,False,,{},Discussion,False,119,,False,False,self,False,,[],{},,True,,1700432065.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It&amp;#39;s already established that LLMs are more than a fad and here to stay. Soon there will be very stable APIs for using LLMs like we use sklearn, Tensirflow, Pytorch, Keras etc. We&amp;#39;ll know the fundamentals but will rely totally on the already optimized implemented APIs. But, I see a lot of skepticism around LLM specially from DS circles not much from MLE circles though. Any thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17z8kkh,True,,Difficult-Big-3890,,96,True,all_ads,False,[],False,,/r/datascience/comments/17z8kkh/data_scientists_already_in_the_industry_more_than/,all_ads,False,https://www.reddit.com/r/datascience/comments/17z8kkh/data_scientists_already_in_the_industry_more_than/,1209064,1700432065.0,0,,False,,,,,,,,,,385,67
,datascience,"I would like to know what are the day to day tasks of a new, or 2-3 years experienced data scientist in large organisations, like in the MNCs.

Apart from daily meetings, I want to know on the technical side of your work: time required in various stages, the tools you use, the data sources, what the clients ask about, etc.

I want to compare it with my current situation and prepare the resume likewise",t2_3ndr0y7l,False,,0,False,"Junior or mid level data scientists/ ML engineers in large companies or MNCs, what are your day to day tasks?",[],r/datascience,False,6,fun,0,,,False,t3_17z6ms5,False,dark,0.88,,public,23,0,{},,,False,[],,False,False,,{},Career Discussion,False,23,,False,False,self,False,,[],{},,True,,1700427129.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I would like to know what are the day to day tasks of a new, or 2-3 years experienced data scientist in large organisations, like in the MNCs.&lt;/p&gt;

&lt;p&gt;Apart from daily meetings, I want to know on the technical side of your work: time required in various stages, the tools you use, the data sources, what the clients ask about, etc.&lt;/p&gt;

&lt;p&gt;I want to compare it with my current situation and prepare the resume likewise&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17z6ms5,True,,swb_rise,,17,True,all_ads,False,[],False,,/r/datascience/comments/17z6ms5/junior_or_mid_level_data_scientists_ml_engineers/,all_ads,False,https://www.reddit.com/r/datascience/comments/17z6ms5/junior_or_mid_level_data_scientists_ml_engineers/,1209064,1700427129.0,0,,False,,,,,,,,,,404,75
,datascience,"Hello 

What are the primary differences between A/B testing and hypothesis testing? 

I have preformed many of hypothesis tests in my academic experience and even taught them as an intro stats TA multiple times. However I have never done an A/B test. I am now applying to data science skills and know this is a valuable skill to put on a resume. Should I just say I know how to conduct one due to similarities to hypothesis testing or are there intricacies and differences I am unaware of?",t2_44oxrfns,False,,0,False,AB tests vs hypothesis tests,[],r/datascience,False,6,network,0,,,False,t3_17z682i,False,dark,0.62,,public,3,0,{},,,False,[],,False,False,,{},Analysis,False,3,,False,False,self,False,,[],{},,True,,1700426024.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello &lt;/p&gt;

&lt;p&gt;What are the primary differences between A/B testing and hypothesis testing? &lt;/p&gt;

&lt;p&gt;I have preformed many of hypothesis tests in my academic experience and even taught them as an intro stats TA multiple times. However I have never done an A/B test. I am now applying to data science skills and know this is a valuable skill to put on a resume. Should I just say I know how to conduct one due to similarities to hypothesis testing or are there intricacies and differences I am unaware of?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17z682i,True,,medylan,,10,True,all_ads,False,[],False,,/r/datascience/comments/17z682i/ab_tests_vs_hypothesis_tests/,all_ads,False,https://www.reddit.com/r/datascience/comments/17z682i/ab_tests_vs_hypothesis_tests/,1209064,1700426024.0,0,,False,,,,,,,,,,490,88
,datascience,"I did a few Kaggle competitions in college and really enjoyed the experience. It’s been awhile, but I’m thinking about getting back into it merely for the experience of working on interesting problems and keeping my skills sharp. 

Is Kaggle still a popular and engaging space for this community?",t2_nm4npbzv,False,,0,False,Do Kaggle competitions still interest you?,[],r/datascience,False,6,,0,,,False,t3_17z4wg8,False,dark,0.92,,public,61,0,{},,,False,[],,False,False,,{},Challenges,False,61,,False,False,self,False,,[],{},,True,,1700422424.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I did a few Kaggle competitions in college and really enjoyed the experience. It’s been awhile, but I’m thinking about getting back into it merely for the experience of working on interesting problems and keeping my skills sharp. &lt;/p&gt;

&lt;p&gt;Is Kaggle still a popular and engaging space for this community?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,17z4wg8,True,,jacobwlyman,,49,True,all_ads,False,[],False,,/r/datascience/comments/17z4wg8/do_kaggle_competitions_still_interest_you/,all_ads,False,https://www.reddit.com/r/datascience/comments/17z4wg8/do_kaggle_competitions_still_interest_you/,1209064,1700422424.0,0,,False,,,,,,,,,,296,49
,datascience,I'm a bit worried about the change in some of the norms and ways of conducting work between academia and industry so just hopping to start preparing for that,t2_89ar1fajx,False,,0,False,"If you moved from academia to q data science industry, what was the biggest adjustment for you?",[],r/datascience,False,6,fun,0,,,False,t3_17z0rh4,False,dark,0.94,,public,59,0,{},,,False,[],,False,False,,{},Career Discussion,False,59,,False,False,self,False,,[],{},,True,,1700411060.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a bit worried about the change in some of the norms and ways of conducting work between academia and industry so just hopping to start preparing for that&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17z0rh4,True,,AnxiousEgg6284,,43,True,all_ads,False,[],False,,/r/datascience/comments/17z0rh4/if_you_moved_from_academia_to_q_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17z0rh4/if_you_moved_from_academia_to_q_data_science/,1209064,1700411060.0,0,,False,,,,,,,,,,157,29
,datascience,"I am building a model (which would be my second practical one) so I have little experience with avoiding overfitting ( a colleague in my company told me the model would overfit if I used 25 features on a 140,000 rows dataset).

So, what should I do here if he is in the right?

Thanks.",t2_81zrh19oq,False,,0,False,Is there a rule of thumb for the amount of rows you should have for each fearure you have in the dataset?,[],r/datascience,False,6,projects,0,,,False,t3_17yw88u,False,dark,0.93,,public,23,0,{},,,False,[],,False,False,,{},ML,False,23,,False,False,self,False,,[],{},,True,,1700397170.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am building a model (which would be my second practical one) so I have little experience with avoiding overfitting ( a colleague in my company told me the model would overfit if I used 25 features on a 140,000 rows dataset).&lt;/p&gt;

&lt;p&gt;So, what should I do here if he is in the right?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17yw88u,True,,Careful_Engineer_700,,32,True,all_ads,False,[],False,,/r/datascience/comments/17yw88u/is_there_a_rule_of_thumb_for_the_amount_of_rows/,all_ads,False,https://www.reddit.com/r/datascience/comments/17yw88u/is_there_a_rule_of_thumb_for_the_amount_of_rows/,1209064,1700397170.0,0,,False,,,,,,,,,,285,55
,datascience,"I understand it conceptually but I'm trying to figure out how to implement it.

I have data that I have clustered and so I have labels. Training a classifier on this is trivial but I would like for it to appropriately handle potentially new classes. The pipeline will have massive amounts of data and there's no way to approximate when or how often new classes will appear. Another complication is subclasses but I'll cross that bridge when (and if) it comes up. Right now, I just need to figure out the open-world classification issue.

I figure something like an OC-SVM where I take all currently known classes and consolidate them into a single class to train the SVM on. That way, it can make the distinction between previously seen data and new data. Data that has been seen previously can be sent to the next classifier (one trained on the cluster labels) and all others can be sent to a buffer/queue/bucket for further consideration (eg, recluster to include the new class/es).

What other approaches are there to dealing with open classification in a practical sense?",t2_131bi6,False,,0,False,How is open-world classification implemented?,[],r/datascience,False,6,projects,0,,,False,t3_17ykajp,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},ML,False,1,,False,False,self,False,,[],{},,True,,1700353241.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I understand it conceptually but I&amp;#39;m trying to figure out how to implement it.&lt;/p&gt;

&lt;p&gt;I have data that I have clustered and so I have labels. Training a classifier on this is trivial but I would like for it to appropriately handle potentially new classes. The pipeline will have massive amounts of data and there&amp;#39;s no way to approximate when or how often new classes will appear. Another complication is subclasses but I&amp;#39;ll cross that bridge when (and if) it comes up. Right now, I just need to figure out the open-world classification issue.&lt;/p&gt;

&lt;p&gt;I figure something like an OC-SVM where I take all currently known classes and consolidate them into a single class to train the SVM on. That way, it can make the distinction between previously seen data and new data. Data that has been seen previously can be sent to the next classifier (one trained on the cluster labels) and all others can be sent to a buffer/queue/bucket for further consideration (eg, recluster to include the new class/es).&lt;/p&gt;

&lt;p&gt;What other approaches are there to dealing with open classification in a practical sense?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17ykajp,True,,WadeEffingWilson,,0,True,all_ads,False,[],False,,/r/datascience/comments/17ykajp/how_is_openworld_classification_implemented/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ykajp/how_is_openworld_classification_implemented/,1209064,1700353241.0,1,,False,,,,,,,,,,1075,185
,datascience,"Hi guys, I'm currently looking on a platform for my hobby projects for training models end etc. Do you have any suggestion?",t2_dk1rx8sn,False,,0,False,"Which platform do you use for your hobby projects? (Colab pro, sagemaker, azure etc.)",[],r/datascience,False,6,discussion,0,,,False,t3_17ycg39,False,dark,0.84,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,False,self,False,,[],{},,True,,1700331518.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I&amp;#39;m currently looking on a platform for my hobby projects for training models end etc. Do you have any suggestion?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ycg39,True,,CarGold87,,35,True,all_ads,False,[],False,,/r/datascience/comments/17ycg39/which_platform_do_you_use_for_your_hobby_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ycg39/which_platform_do_you_use_for_your_hobby_projects/,1209064,1700331518.0,0,,False,,,,,,,,,,123,22
,datascience,"I like to be a generalist over specialist. Is this a bad habit? Should I change it or rather embrace it and plan my career around it?

Some background. I work as a data scientist. Being part of a smaller org I have to wear different hats e.g. data engineer, data analyst, mle, dev ops etc. I recently stated looking for job and have had couple of interviews with DS teams in large corporations. Talking to them it's pretty obvious the DSs are handed down their data and do the modeling and then hand it over to MLE/SWEs. 

This doesn't sound interesting at all to me. I like the variations in my work. But seeing specialization is the norm, I'm kind of confused about whether I should change my liking and be more specialized or rather embrace it and look for opportunities that match this habit.

Edit 1: corrected typos. 
Edit 2: figured I never mentioned that I primarily work as a DS. So mentioned that. ",t2_9axqyq8u,False,,0,False,Generalist vs Specialist,[],r/datascience,False,6,fun,0,,,False,t3_17ybzjf,False,dark,0.85,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,False,self,1700331282.0,,[],{},,True,,1700330259.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I like to be a generalist over specialist. Is this a bad habit? Should I change it or rather embrace it and plan my career around it?&lt;/p&gt;

&lt;p&gt;Some background. I work as a data scientist. Being part of a smaller org I have to wear different hats e.g. data engineer, data analyst, mle, dev ops etc. I recently stated looking for job and have had couple of interviews with DS teams in large corporations. Talking to them it&amp;#39;s pretty obvious the DSs are handed down their data and do the modeling and then hand it over to MLE/SWEs. &lt;/p&gt;

&lt;p&gt;This doesn&amp;#39;t sound interesting at all to me. I like the variations in my work. But seeing specialization is the norm, I&amp;#39;m kind of confused about whether I should change my liking and be more specialized or rather embrace it and look for opportunities that match this habit.&lt;/p&gt;

&lt;p&gt;Edit 1: corrected typos. 
Edit 2: figured I never mentioned that I primarily work as a DS. So mentioned that. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ybzjf,True,,Difficult-Big-3890,,32,True,all_ads,False,[],False,,/r/datascience/comments/17ybzjf/generalist_vs_specialist/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ybzjf/generalist_vs_specialist/,1209064,1700330259.0,0,,False,,,,,,,,,,908,166
,datascience,"Un-expectedly got pulled into a Google Meets call on Friday afternoon and let go.

Thought I was crushing it, literally had shipped some updates to our products last week.

Any advice on job-hunting? Have lots of experience with LLMs, trying to stay in the GenAI space.

Thanks!

Update: Over the weekend a friend of mine at Microsoft pulled a few strings, think I'm joining them. Thanks for the help. ",t2_6zm7tswg,False,,0,False,Blindsided At Work &amp; Fired - Any Advice?,[],r/datascience,False,6,fun,0,,,False,t3_17yb2yw,False,dark,0.91,,public,261,0,{},,,True,[],,False,False,,{},Career Discussion,False,261,,False,False,self,1700485768.0,,[],{},,True,,1700327730.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Un-expectedly got pulled into a Google Meets call on Friday afternoon and let go.&lt;/p&gt;

&lt;p&gt;Thought I was crushing it, literally had shipped some updates to our products last week.&lt;/p&gt;

&lt;p&gt;Any advice on job-hunting? Have lots of experience with LLMs, trying to stay in the GenAI space.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;Update: Over the weekend a friend of mine at Microsoft pulled a few strings, think I&amp;#39;m joining them. Thanks for the help. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,Author | Ace the Data Science Interview,[],False,,,,t5_2sptq,False,,,#0079d3,17yb2yw,True,,NickSinghTechCareers,,39,True,all_ads,False,[],False,dark,/r/datascience/comments/17yb2yw/blindsided_at_work_fired_any_advice/,all_ads,False,https://www.reddit.com/r/datascience/comments/17yb2yw/blindsided_at_work_fired_any_advice/,1209064,1700327730.0,0,,False,,,,,,,,,,402,69
,datascience,"We all know that in general notebooks are the standard for many data science teams and that they can lead to bad practise (notebooks that can’t be run top to bottom, functions that change definition etc.).


Are there any resources for what best design practice looks like for notebook lead DS for the sake of clear and repeatable analysis/modeling. 


For example:

1. Should non-package functions be defined in notebooks or imported from a separate .py.

2. Handling data imports (all at the top or only for each separate piece of analysis)

3. When to separate notebooks (eg for a model training task would you have data pulling, cleaning, validation, hyper parameter tuning, final training, out-of-sample checks all in one notebook or a folder that contains X ordered notebooks to do those tasks.)



The obvious answer is “do what your team does”, but in case you are in charge of practise or there is no design doc for the team are there good defaults.

(The other obvious is move to just .py files, but let’s ignore that option as a lot of people prefer notebooks).",t2_tmvny,False,,0,False,DS Professionalism: Notebook best practices,[],r/datascience,False,6,discussion,0,,,False,t3_17y72e7,False,dark,0.91,,public,59,0,{},,,False,[],,False,False,,{},Discussion,False,59,,False,False,self,False,,[],{},,True,,1700316035.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We all know that in general notebooks are the standard for many data science teams and that they can lead to bad practise (notebooks that can’t be run top to bottom, functions that change definition etc.).&lt;/p&gt;

&lt;p&gt;Are there any resources for what best design practice looks like for notebook lead DS for the sake of clear and repeatable analysis/modeling. &lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Should non-package functions be defined in notebooks or imported from a separate .py.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Handling data imports (all at the top or only for each separate piece of analysis)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When to separate notebooks (eg for a model training task would you have data pulling, cleaning, validation, hyper parameter tuning, final training, out-of-sample checks all in one notebook or a folder that contains X ordered notebooks to do those tasks.)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The obvious answer is “do what your team does”, but in case you are in charge of practise or there is no design doc for the team are there good defaults.&lt;/p&gt;

&lt;p&gt;(The other obvious is move to just .py files, but let’s ignore that option as a lot of people prefer notebooks).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17y72e7,True,,Pl4yByNumbers,,71,True,all_ads,False,[],False,,/r/datascience/comments/17y72e7/ds_professionalism_notebook_best_practices/,all_ads,False,https://www.reddit.com/r/datascience/comments/17y72e7/ds_professionalism_notebook_best_practices/,1209064,1700316035.0,0,,False,,,,,,,,,,1072,184
,datascience,The way I understand this is that statistical significance isn't an indicator of predictive strength. It just tells us the coefficient is non zero with a level of confidence but predictive power from tree models tell us there's a strong association between the feature and target.,t2_9axqyq8u,False,,0,False,"Is this the right explanation for ""why a strong predictor found out from a Tree ensemble models may not be statistically significant in Regression model"" question?",[],r/datascience,False,6,,0,,,False,t3_17y08f1,False,dark,0.75,,public,6,0,{},,,False,[],,False,False,,{},Statistics,False,6,,False,False,self,False,,[],{},,True,,1700288546.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The way I understand this is that statistical significance isn&amp;#39;t an indicator of predictive strength. It just tells us the coefficient is non zero with a level of confidence but predictive power from tree models tell us there&amp;#39;s a strong association between the feature and target.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,17y08f1,True,,Difficult-Big-3890,,5,True,all_ads,False,[],False,,/r/datascience/comments/17y08f1/is_this_the_right_explanation_for_why_a_strong/,all_ads,False,https://www.reddit.com/r/datascience/comments/17y08f1/is_this_the_right_explanation_for_why_a_strong/,1209064,1700288546.0,0,,False,,,,,,,,,,280,46
,datascience,"Started a new role lately in data analytics and within 2 weeks already immersed in a 1500 line SQL query with dozens of crazy calculations transformations references tables that look almost identical with no documentation no notes nothing. It's so stressful and I already want to quit. I feel like I'm just days away from giving up and failing. 



Anyone been here? How do I build my confidence?",t2_dmawn6hx,False,,0,False,I honestly feel like I'm in way too deep,[],r/datascience,False,6,discussion,0,,,False,t3_17xub38,False,dark,0.91,#dadada,public,127,0,{},,d898d418-70eb-11ee-81d7-36bf4b44216b,False,[],,False,False,,{},Discussion,False,127,,False,False,self,False,,[],{},,True,,1700269104.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Started a new role lately in data analytics and within 2 weeks already immersed in a 1500 line SQL query with dozens of crazy calculations transformations references tables that look almost identical with no documentation no notes nothing. It&amp;#39;s so stressful and I already want to quit. I feel like I&amp;#39;m just days away from giving up and failing. &lt;/p&gt;

&lt;p&gt;Anyone been here? How do I build my confidence?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,Junior,[],False,,,,t5_2sptq,False,,,#1a1a1b,17xub38,True,,InevitableTraining69,,116,True,all_ads,False,[],False,dark,/r/datascience/comments/17xub38/i_honestly_feel_like_im_in_way_too_deep/,all_ads,False,https://www.reddit.com/r/datascience/comments/17xub38/i_honestly_feel_like_im_in_way_too_deep/,1209064,1700269104.0,0,,False,,,,,,,,,,396,68
,datascience,Considering you don't know much about the data and need to do it quickly.,t2_9axqyq8u,False,,0,False,"What's your favorite statistical technique to explore missing values (find trends, decide how to impute etc)?",[],r/datascience,False,6,discussion,0,,,False,t3_17xqbbw,False,dark,0.93,,public,36,0,{},,,False,[],,False,False,,{},Discussion,False,36,,False,False,self,False,,[],{},,True,,1700258399.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Considering you don&amp;#39;t know much about the data and need to do it quickly.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17xqbbw,True,,Difficult-Big-3890,,33,True,all_ads,False,[],False,,/r/datascience/comments/17xqbbw/whats_your_favorite_statistical_technique_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17xqbbw/whats_your_favorite_statistical_technique_to/,1209064,1700258399.0,0,,False,,,,,,,,,,73,14
,datascience,"I’ve been trying to get into data science for a few months (i have a bs in sociology and have done analytics for my course). From online courses and reading comments in this sub, I was under the impression that key skills of a data scientist is to solve business problems with data, communicate with business stakeholders, plot graphs or charts on tableau or excel, perform analysis on data, and develop ML models on jupyter notebooks. I thought it was perfect for me because it sounded like a business role that look at numbers.

But when I look at the data scientist job descriptions out there, more than half are asking for software engineering skills. I’m familiar with the statistics but I know nothing about docker, github, spark or deploying models to production. Isn’t that the role of a software engineer? There are already so much in data science to learn, is it a reasonable expectation from the employer to ask for software engineering skills too? Is this a common thing?

Sorry if I seem like rambling but I feel pretty overwhelmed right now. There seem to be so few opportunities out there that are just purely data science skills.",t2_l6lp7fm00,False,,0,False,How much software engineering skills does it take to do a DS job?,[],r/datascience,False,6,fun,0,,,False,t3_17xobtu,False,dark,0.88,,public,97,0,{},,,False,[],,False,False,,{},Career Discussion,False,97,,False,False,self,False,,[],{},,True,,1700253117.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been trying to get into data science for a few months (i have a bs in sociology and have done analytics for my course). From online courses and reading comments in this sub, I was under the impression that key skills of a data scientist is to solve business problems with data, communicate with business stakeholders, plot graphs or charts on tableau or excel, perform analysis on data, and develop ML models on jupyter notebooks. I thought it was perfect for me because it sounded like a business role that look at numbers.&lt;/p&gt;

&lt;p&gt;But when I look at the data scientist job descriptions out there, more than half are asking for software engineering skills. I’m familiar with the statistics but I know nothing about docker, github, spark or deploying models to production. Isn’t that the role of a software engineer? There are already so much in data science to learn, is it a reasonable expectation from the employer to ask for software engineering skills too? Is this a common thing?&lt;/p&gt;

&lt;p&gt;Sorry if I seem like rambling but I feel pretty overwhelmed right now. There seem to be so few opportunities out there that are just purely data science skills.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17xobtu,True,,i_can_be_angier,,71,True,all_ads,False,[],False,,/r/datascience/comments/17xobtu/how_much_software_engineering_skills_does_it_take/,all_ads,False,https://www.reddit.com/r/datascience/comments/17xobtu/how_much_software_engineering_skills_does_it_take/,1209064,1700253117.0,0,,False,,,,,,,,,,1145,200
,datascience,Pros/cons? What are the best features? What do you wish was different? My org is considering it and I just wanted to get some opinions.,t2_kxbit68r,False,,0,False,Anyone here use databricks for ds and ml?,[],r/datascience,False,6,tooling,0,,,False,t3_17xfl5o,False,dark,0.88,,public,12,0,{},,,False,[],,False,False,,{},Tools,False,12,,False,False,self,False,,[],{},,True,,1700229343.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Pros/cons? What are the best features? What do you wish was different? My org is considering it and I just wanted to get some opinions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17xfl5o,True,,data-influencer,,14,True,all_ads,False,[],False,,/r/datascience/comments/17xfl5o/anyone_here_use_databricks_for_ds_and_ml/,all_ads,False,https://www.reddit.com/r/datascience/comments/17xfl5o/anyone_here_use_databricks_for_ds_and_ml/,1209064,1700229343.0,0,,False,,,,,,,,,,135,25
,datascience,"At work, I find myself doing more of what I've been doing - building custom models with BERT, etc. I would like to get some experience with GPT-4 and other generative LLMs, but management always has the software engineers working on those, because.. well, it's just an API. Meanwhile, all the Data Scientist job ads call for LLM experience. Anyone else in the same boat?",t2_6amo8yyb,False,,0,False,Any other data scientists struggle to get assigned to LLM projects?,[],r/datascience,False,6,fun,0,,,False,t3_17x898h,False,dark,0.79,,public,75,0,{},,,False,[],,False,False,,{},Career Discussion,False,75,,False,False,self,False,,[],{},,True,,1700200072.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At work, I find myself doing more of what I&amp;#39;ve been doing - building custom models with BERT, etc. I would like to get some experience with GPT-4 and other generative LLMs, but management always has the software engineers working on those, because.. well, it&amp;#39;s just an API. Meanwhile, all the Data Scientist job ads call for LLM experience. Anyone else in the same boat?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17x898h,True,,mindmech,,64,True,all_ads,False,[],False,,/r/datascience/comments/17x898h/any_other_data_scientists_struggle_to_get/,all_ads,False,https://www.reddit.com/r/datascience/comments/17x898h/any_other_data_scientists_struggle_to_get/,1209064,1700200072.0,0,,False,,,,,,,,,,370,65
,datascience,Other than books I didn't find much applications of these regressions in my DS experience. So wondering how others experience.,t2_9axqyq8u,False,,0,False,"Do you use Poisson, Gamma Regressions?",[],r/datascience,False,6,discussion,0,,,False,t3_17x72la,False,dark,0.96,,public,53,0,{},,,False,[],,False,False,,{},Discussion,False,53,,False,False,self,False,,[],{},,True,,1700195749.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Other than books I didn&amp;#39;t find much applications of these regressions in my DS experience. So wondering how others experience.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17x72la,True,,Difficult-Big-3890,,41,True,all_ads,False,[],False,,/r/datascience/comments/17x72la/do_you_use_poisson_gamma_regressions/,all_ads,False,https://www.reddit.com/r/datascience/comments/17x72la/do_you_use_poisson_gamma_regressions/,1209064,1700195749.0,0,,False,,,,,,,,,,126,20
,datascience,"I’m currently a DS at a media/martech agency, and spend a lot of time doing more data engineering work than focused on just building models, but have been putting my thoughts together about starting a small food retail business.   
   
I’ve had experience as a cook and miss that world, although a big reason I dream of the career change is getting to leverage the skills of data science (predictive modeling, live cost/revenue visualization, automated insights) in a business “from the ground up”.     
   
Just curious if anyone else has gone the small business path and built their own data infra/modeling systems.",t2_2jxngpnh,False,,0,False,Anyone left corporate to go the entrepreneur route and used DS in their new venture,[],r/datascience,False,6,fun,0,,,False,t3_17wyjhh,False,dark,0.91,,public,27,0,{},,,False,[],,False,False,,{},Career Discussion,False,27,,False,False,self,False,,[],{},,True,,1700171532.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m currently a DS at a media/martech agency, and spend a lot of time doing more data engineering work than focused on just building models, but have been putting my thoughts together about starting a small food retail business.   &lt;/p&gt;

&lt;p&gt;I’ve had experience as a cook and miss that world, although a big reason I dream of the career change is getting to leverage the skills of data science (predictive modeling, live cost/revenue visualization, automated insights) in a business “from the ground up”.     &lt;/p&gt;

&lt;p&gt;Just curious if anyone else has gone the small business path and built their own data infra/modeling systems.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17wyjhh,True,,king-toot,,24,True,all_ads,False,[],False,,/r/datascience/comments/17wyjhh/anyone_left_corporate_to_go_the_entrepreneur/,all_ads,False,https://www.reddit.com/r/datascience/comments/17wyjhh/anyone_left_corporate_to_go_the_entrepreneur/,1209064,1700171532.0,0,,False,,,,,,,,,,617,100
,datascience,"Hi all! I’ve got a dataset that contains 3 years worth of sales data at a daily level, the dataset is about 10m rows. A description of the columns are 

Distribution hub that the order was sent from
Uk postal district that was ordered from
Loyalty card - Y/N
Spend
Number of items
Date

I’ve already aggregated the data to a monthly level.

I want to build a choropleth dashboard that will allow me to see the number of orders/revenue from each uk postal district. I want to be able to slice it on the date, whether they have a loyalty card or not and by the distribution hub.

I’ve tried using ArcGis map on powerBI but the map has issues with load times and with heat map colors when slicers are applied.

Has any one done something similar or have any suggestions on tools to use?

Thanks!",t2_12awm9,False,,0,False,Choropleth Dashboarding Tools?,[],r/datascience,False,6,tooling,0,,,False,t3_17wve6v,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Tools,False,4,,False,False,self,False,,[],{},,True,,1700163381.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all! I’ve got a dataset that contains 3 years worth of sales data at a daily level, the dataset is about 10m rows. A description of the columns are &lt;/p&gt;

&lt;p&gt;Distribution hub that the order was sent from
Uk postal district that was ordered from
Loyalty card - Y/N
Spend
Number of items
Date&lt;/p&gt;

&lt;p&gt;I’ve already aggregated the data to a monthly level.&lt;/p&gt;

&lt;p&gt;I want to build a choropleth dashboard that will allow me to see the number of orders/revenue from each uk postal district. I want to be able to slice it on the date, whether they have a loyalty card or not and by the distribution hub.&lt;/p&gt;

&lt;p&gt;I’ve tried using ArcGis map on powerBI but the map has issues with load times and with heat map colors when slicers are applied.&lt;/p&gt;

&lt;p&gt;Has any one done something similar or have any suggestions on tools to use?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17wve6v,True,,HiddenBladez99,,2,True,all_ads,False,[],False,,/r/datascience/comments/17wve6v/choropleth_dashboarding_tools/,all_ads,False,https://www.reddit.com/r/datascience/comments/17wve6v/choropleth_dashboarding_tools/,1209064,1700163381.0,0,,False,,,,,,,,,,792,148
,datascience,"Hi all

Looking for standards/ideas for two issues.

1. Our team is involved in data science research projects (usually 6-18 months long). The orientation is more applied, and mostly not trying to publish it. How do you document your ongoing and finished research projects?  

2. Relatedly, how do you keep track of all the projects in the team, and their progress (e.g., JIRA)?",t2_5hjxl4ya,False,,0,False,"Best practice for research documentation, and research tracking?",[],r/datascience,False,6,tooling,0,,,False,t3_17wrrkq,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Tools,False,5,,False,False,self,False,,[],{},,True,,1700153842.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all&lt;/p&gt;

&lt;p&gt;Looking for standards/ideas for two issues.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Our team is involved in data science research projects (usually 6-18 months long). The orientation is more applied, and mostly not trying to publish it. How do you document your ongoing and finished research projects?  &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Relatedly, how do you keep track of all the projects in the team, and their progress (e.g., JIRA)?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17wrrkq,True,,PlainPiano9,,5,True,all_ads,False,[],False,,/r/datascience/comments/17wrrkq/best_practice_for_research_documentation_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17wrrkq/best_practice_for_research_documentation_and/,1209064,1700153842.0,0,,False,,,,,,,,,,378,63
,datascience,"As title. The company is creating a product for PII detection, and they only have other data scientists working within the company, each one on its own project.

I was assigned this project with only one requirements doc, and I need to develop the whole thing from there. Nothing is quite clear, is all about desires, I really am lost on that, never worked on a company with no structure as this.

There is no project manager, no Agile methodology, no sprints. They don't even use Jira. How would you proceed?  


Thanks a lot",t2_67oqkl0p,False,,0,False,"Just started a Data Scientist position on a company that has no structure, need advices",[],r/datascience,False,6,fun,0,,,False,t3_17wr0f2,False,dark,0.87,,public,39,0,{},,,False,[],,False,False,,{},Career Discussion,False,39,,False,False,self,False,,[],{},,True,,1700151973.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As title. The company is creating a product for PII detection, and they only have other data scientists working within the company, each one on its own project.&lt;/p&gt;

&lt;p&gt;I was assigned this project with only one requirements doc, and I need to develop the whole thing from there. Nothing is quite clear, is all about desires, I really am lost on that, never worked on a company with no structure as this.&lt;/p&gt;

&lt;p&gt;There is no project manager, no Agile methodology, no sprints. They don&amp;#39;t even use Jira. How would you proceed?  &lt;/p&gt;

&lt;p&gt;Thanks a lot&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17wr0f2,True,,dick_veganas,,23,True,all_ads,False,[],False,,/r/datascience/comments/17wr0f2/just_started_a_data_scientist_position_on_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/17wr0f2/just_started_a_data_scientist_position_on_a/,1209064,1700151973.0,0,,False,,,,,,,,,,526,94
,datascience,"For a variety of work and non-work reasons I think I'm very burnt out, and really need to make a drastic change. However, I still need to earn money to pay for family and the house. I thought maybe I could look at a 3 or 4 day per week role, doing something else on the freed up days, earning less but not catastrophically less. However, I can find basically zero data science roles advertised in my country (Australia). Do part time data science roles exist and how do you go about finding one? ",t2_69ulbyxe,False,,0,False,What kinds of part time Data Science roles are there? How do you find them?,[],r/datascience,False,6,fun,0,,,False,t3_17weph6,False,dark,0.9,,public,23,0,{},,,False,[],,False,False,,{},Career Discussion,False,23,,False,False,self,False,,[],{},,True,,1700111153.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For a variety of work and non-work reasons I think I&amp;#39;m very burnt out, and really need to make a drastic change. However, I still need to earn money to pay for family and the house. I thought maybe I could look at a 3 or 4 day per week role, doing something else on the freed up days, earning less but not catastrophically less. However, I can find basically zero data science roles advertised in my country (Australia). Do part time data science roles exist and how do you go about finding one? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17weph6,True,,AntiqueFigure6,,16,True,all_ads,False,[],False,,/r/datascience/comments/17weph6/what_kinds_of_part_time_data_science_roles_are/,all_ads,False,https://www.reddit.com/r/datascience/comments/17weph6/what_kinds_of_part_time_data_science_roles_are/,1209064,1700111153.0,0,,False,,,,,,,,,,496,94
,datascience,"Hi! 

Are John Hopkins/Berkeley worth the price tag of 60k-70k for the MS in Data Science? 

I have a BS in Economics and need to acquire the technical skills.",t2_b3hvfhlp,False,,0,False,"Are prestigious outrageously expensive MS in DS worth it over a cheaper less known school? (Berkeley, JHU, Carnegie M are all 60-70k USD) vs Eastern Uni 9k",[],r/datascience,False,6,fun,0,,,False,t3_17w56aq,False,dark,0.92,,public,113,0,{},,,False,[],,False,False,,{},Career Discussion,False,113,,False,False,self,False,,[],{},,True,,1700085787.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! &lt;/p&gt;

&lt;p&gt;Are John Hopkins/Berkeley worth the price tag of 60k-70k for the MS in Data Science? &lt;/p&gt;

&lt;p&gt;I have a BS in Economics and need to acquire the technical skills.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17w56aq,True,,Exotic_Avocado6164,,182,True,all_ads,False,[],False,,/r/datascience/comments/17w56aq/are_prestigious_outrageously_expensive_ms_in_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/17w56aq/are_prestigious_outrageously_expensive_ms_in_ds/,1209064,1700085787.0,0,,False,,,,,,,,,,159,29
,datascience,"Hello all,

Preface:

* Bachelors double major in Data Analytics &amp; Finance, minor in I.T (2019 grad)
* Master of Science in Data Science (Machine Learning) (2023 grad)
* 3 Years of relevant experience doing data migrations (lots of SQL, Excel, VBA, Azure/AWS, Shell scripting)

I know I have a lot of the credentials to get into the industry - but I'm still having a hard time landing a role. Whether that role is analytics, BI, DS, DE or anything in that vein. I'm not necessarily discouraged since I love what I do currently - I just miss the exploration aspect of the analytics/ds world. 

Are projects still relevant to someone like me given my background? I have a small portfolio with 3 projects on it, but I don't know what else I can do to stand out and get one of those roles. 

Is it possible that my home country (Canada) doesn't have enough opportunities? Is my resume not strong enough to even get an entry-level role based on everything I've already laid out? ",t2_1x7s010,False,,0,False,"How to ""Break-In"" to the Industry When I Already Have Solid Academic/Work Experience?",[],r/datascience,False,6,fun,0,,,False,t3_17w4u6r,False,dark,0.84,,public,19,0,{},,,False,[],,False,False,,{},Career Discussion,False,19,,False,False,self,False,,[],{},,True,,1700085009.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;Preface:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bachelors double major in Data Analytics &amp;amp; Finance, minor in I.T (2019 grad)&lt;/li&gt;
&lt;li&gt;Master of Science in Data Science (Machine Learning) (2023 grad)&lt;/li&gt;
&lt;li&gt;3 Years of relevant experience doing data migrations (lots of SQL, Excel, VBA, Azure/AWS, Shell scripting)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I know I have a lot of the credentials to get into the industry - but I&amp;#39;m still having a hard time landing a role. Whether that role is analytics, BI, DS, DE or anything in that vein. I&amp;#39;m not necessarily discouraged since I love what I do currently - I just miss the exploration aspect of the analytics/ds world. &lt;/p&gt;

&lt;p&gt;Are projects still relevant to someone like me given my background? I have a small portfolio with 3 projects on it, but I don&amp;#39;t know what else I can do to stand out and get one of those roles. &lt;/p&gt;

&lt;p&gt;Is it possible that my home country (Canada) doesn&amp;#39;t have enough opportunities? Is my resume not strong enough to even get an entry-level role based on everything I&amp;#39;ve already laid out? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17w4u6r,True,,HercHuntsdirty,,10,True,all_ads,False,[],False,,/r/datascience/comments/17w4u6r/how_to_breakin_to_the_industry_when_i_already/,all_ads,False,https://www.reddit.com/r/datascience/comments/17w4u6r/how_to_breakin_to_the_industry_when_i_already/,1209064,1700085009.0,0,,False,,,,,,,,,,978,175
,datascience,"Your team makes a model and dashboard after stakeholders essentially begged for it. You warn them that alone these products will not solve the business problem at hand and that regular communication and discussions about what exactly the company is trying to accomplish will be necessary. Then they don't use it, and months later claim the work wasn't valuable. 

This is all too common, so I'm wondering who of you have overcome this and helped establish a healthier system /practice of decision support.",t2_apemm,False,,0,False,Have you had success changing stakeholder usage of tools and data insights?,[],r/datascience,False,6,discussion,0,,,False,t3_17w0xea,False,dark,0.91,,public,9,0,{},,,False,[],,False,False,,{},Discussion,False,9,,False,False,self,1700075250.0,,[],{},,True,,1700074930.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Your team makes a model and dashboard after stakeholders essentially begged for it. You warn them that alone these products will not solve the business problem at hand and that regular communication and discussions about what exactly the company is trying to accomplish will be necessary. Then they don&amp;#39;t use it, and months later claim the work wasn&amp;#39;t valuable. &lt;/p&gt;

&lt;p&gt;This is all too common, so I&amp;#39;m wondering who of you have overcome this and helped establish a healthier system /practice of decision support.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17w0xea,True,,WhosaWhatsa,,15,True,all_ads,False,[],False,,/r/datascience/comments/17w0xea/have_you_had_success_changing_stakeholder_usage/,all_ads,False,https://www.reddit.com/r/datascience/comments/17w0xea/have_you_had_success_changing_stakeholder_usage/,1209064,1700074930.0,0,,False,,,,,,,,,,505,83
,datascience,"This community contains great advice for marketable personal projects:

https://www.reddit.com/r/datascience/comments/gf9hrs/what_makes_a_good_personal_project_from_the/

Many may be wondering, where do you find the time?

Let's hear your secrets for chipping away at personal projects alongside school, work, and other grown-up responsibilities. For example: How do you scope and plan the work? What time frames do you follow? How do you decide when it's ""good enough?"" And-- really-- where *do* you find the time?",t2_s27ul7aa,False,,0,False,Process for personal projects,[],r/datascience,False,6,meta,0,,,False,t3_17w0gtw,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Projects,False,7,,False,False,self,False,,[],{},,True,,1700073750.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This community contains great advice for marketable personal projects:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/r/datascience/comments/gf9hrs/what_makes_a_good_personal_project_from_the/""&gt;https://www.reddit.com/r/datascience/comments/gf9hrs/what_makes_a_good_personal_project_from_the/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Many may be wondering, where do you find the time?&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s hear your secrets for chipping away at personal projects alongside school, work, and other grown-up responsibilities. For example: How do you scope and plan the work? What time frames do you follow? How do you decide when it&amp;#39;s &amp;quot;good enough?&amp;quot; And-- really-- where &lt;em&gt;do&lt;/em&gt; you find the time?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17w0gtw,True,,chiqui-bee,,6,True,all_ads,False,[],False,,/r/datascience/comments/17w0gtw/process_for_personal_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/17w0gtw/process_for_personal_projects/,1209064,1700073750.0,0,,False,,,,,,,,,,515,69
,datascience,"Hi. I'm migrating SAS code to Databricks, and one thing that I need to reproduce is summary statistics, especially frequency distributions. For example ""proc freq"" and univariate functions in SAS.

I calculated the frequency distribution manually, but it would be helpful if there was a function to give you that and more. I'm searching but not seeing much.

Is there a particular Pyspark library I should be looking at? Thanks.",t2_2o0q5m4h,False,,0,False,Does Pyspark have more detailed summary statistics beyond .describe and .summary?,[],r/datascience,False,6,,0,,,False,t3_17vuevm,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Statistics,False,7,,False,False,self,False,,[],{},,True,,1700057333.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I&amp;#39;m migrating SAS code to Databricks, and one thing that I need to reproduce is summary statistics, especially frequency distributions. For example &amp;quot;proc freq&amp;quot; and univariate functions in SAS.&lt;/p&gt;

&lt;p&gt;I calculated the frequency distribution manually, but it would be helpful if there was a function to give you that and more. I&amp;#39;m searching but not seeing much.&lt;/p&gt;

&lt;p&gt;Is there a particular Pyspark library I should be looking at? Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,17vuevm,True,,rotterdamn8,,3,True,all_ads,False,[],False,,/r/datascience/comments/17vuevm/does_pyspark_have_more_detailed_summary/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vuevm/does_pyspark_have_more_detailed_summary/,1209064,1700057333.0,0,,False,,,,,,,,,,428,70
,datascience,"I built a tool to make it faster/easier to write python scripts that will clean up Excel files. It's mostly targeted towards people who are less technical, or people like me who can never remember the best practice keyword arguments for pd.read\_csv() lol. 

I called it [Computron](https://app.squack.io/?utm_content=datascience&amp;utm_medium=social&amp;utm_source=reddit&amp;utm_campaign=v0p3_uifix).  

You may have seen me post about this a few weeks back, but we've added a ton of new updates based on feedback we got from many of you!

Here's how it works: 

* Upload any messy csv, xlsx, xls, or xlsm file
* Type out commands for how you want to clean it up
* Computron builds and executes Python code to follow the command using GPT-4
* Once you're done, the code can compiled into a stand-alone automation and reused for other files
* API support for the hosted automations is coming soon 

I didn't explicitly say this last time, but I really don't want this to be another bullshit AI tool. I want you guys to [try it](https://app.squack.io/?utm_content=datascience&amp;utm_medium=social&amp;utm_source=reddit&amp;utm_campaign=v0p3_uifix) and be brutally honest about how to make it better.   

As a token of my appreciation for helping, anybody who makes an account at this early stage will have access to all of the paid features forever. I'm also happy to answer any questions, or give anybody a more in depth tutorial.",t2_898csv1,False,,0,False,"""Data Roomba"" to get clean-up tasks done faster",[],r/datascience,False,6,tooling,0,,,False,t3_17vucmd,False,dark,0.91,,public,82,0,{},,,False,[],,False,False,,{},Tools,False,82,,False,True,self,False,,[],{},,True,,1700057144.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I built a tool to make it faster/easier to write python scripts that will clean up Excel files. It&amp;#39;s mostly targeted towards people who are less technical, or people like me who can never remember the best practice keyword arguments for pd.read_csv() lol. &lt;/p&gt;

&lt;p&gt;I called it &lt;a href=""https://app.squack.io/?utm_content=datascience&amp;amp;utm_medium=social&amp;amp;utm_source=reddit&amp;amp;utm_campaign=v0p3_uifix""&gt;Computron&lt;/a&gt;.  &lt;/p&gt;

&lt;p&gt;You may have seen me post about this a few weeks back, but we&amp;#39;ve added a ton of new updates based on feedback we got from many of you!&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s how it works: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Upload any messy csv, xlsx, xls, or xlsm file&lt;/li&gt;
&lt;li&gt;Type out commands for how you want to clean it up&lt;/li&gt;
&lt;li&gt;Computron builds and executes Python code to follow the command using GPT-4&lt;/li&gt;
&lt;li&gt;Once you&amp;#39;re done, the code can compiled into a stand-alone automation and reused for other files&lt;/li&gt;
&lt;li&gt;API support for the hosted automations is coming soon &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I didn&amp;#39;t explicitly say this last time, but I really don&amp;#39;t want this to be another bullshit AI tool. I want you guys to &lt;a href=""https://app.squack.io/?utm_content=datascience&amp;amp;utm_medium=social&amp;amp;utm_source=reddit&amp;amp;utm_campaign=v0p3_uifix""&gt;try it&lt;/a&gt; and be brutally honest about how to make it better.   &lt;/p&gt;

&lt;p&gt;As a token of my appreciation for helping, anybody who makes an account at this early stage will have access to all of the paid features forever. I&amp;#39;m also happy to answer any questions, or give anybody a more in depth tutorial.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17vucmd,True,,evilredpanda,,20,True,all_ads,False,[],False,,/r/datascience/comments/17vucmd/data_roomba_to_get_cleanup_tasks_done_faster/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vucmd/data_roomba_to_get_cleanup_tasks_done_faster/,1209064,1700057144.0,0,,False,,,,,,,,,,1433,220
,datascience,"Most data scientist or analyst positions consist of say 70% pulling and prepping data and 30% statistical analysis &amp; modelling. A typical company's analytics department may contain a bunch of data scientists with the same 70/30 job responsibilities.

These are two very different jobs that have gotten mashed together. The data part is very detail oriented &amp; requires in-depth knowledge of the kind of data collected by the company. The modelling part is more creative &amp; academic. 

Wouldn't it be more efficient to have one team focused on the SQL stuff and another team focused on the modelling in R or Python or whatever? ",t2_6cjiszgb,False,,0,False,"Should the ""data"" part and ""scientist"" part be two separate jobs?",[],r/datascience,False,6,discussion,0,,,False,t3_17vtefx,False,dark,0.76,,public,61,0,{},,,False,[],,False,False,,{},Discussion,False,61,,False,False,self,False,,[],{},,True,,1700054134.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Most data scientist or analyst positions consist of say 70% pulling and prepping data and 30% statistical analysis &amp;amp; modelling. A typical company&amp;#39;s analytics department may contain a bunch of data scientists with the same 70/30 job responsibilities.&lt;/p&gt;

&lt;p&gt;These are two very different jobs that have gotten mashed together. The data part is very detail oriented &amp;amp; requires in-depth knowledge of the kind of data collected by the company. The modelling part is more creative &amp;amp; academic. &lt;/p&gt;

&lt;p&gt;Wouldn&amp;#39;t it be more efficient to have one team focused on the SQL stuff and another team focused on the modelling in R or Python or whatever? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17vtefx,True,,RobertWF_47,,66,True,all_ads,False,[],False,,/r/datascience/comments/17vtefx/should_the_data_part_and_scientist_part_be_two/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vtefx/should_the_data_part_and_scientist_part_be_two/,1209064,1700054134.0,0,,False,,,,,,,,,,637,104
,datascience,"*Disclaimer: just for fun, feel free to roast me*

Imagine a world where automatic gradient calculation packages didn’t exist, but ML had still advanced at an exponential (but obviously slower) rate. 

ML / DS would have a much higher barrier of entry on the math / theory side, and the field would not be reduced to the glorified SW engineering that it is now. 

Most DS / ML roles would focus on the coolest parts of this job - building models, innovating, solving hard problems - and think how much we’d be paid. 

Anyway like I said this is just for fun, I fully understand autograd is an amazing advancement, but sometimes from a fully selfish pov, I wonder what if…",t2_k61pnmdw,False,,0,False,I wish Autograd didn’t exist,[],r/datascience,False,6,discussion,0,,,False,t3_17vqily,False,dark,0.3,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1700042880.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;em&gt;Disclaimer: just for fun, feel free to roast me&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Imagine a world where automatic gradient calculation packages didn’t exist, but ML had still advanced at an exponential (but obviously slower) rate. &lt;/p&gt;

&lt;p&gt;ML / DS would have a much higher barrier of entry on the math / theory side, and the field would not be reduced to the glorified SW engineering that it is now. &lt;/p&gt;

&lt;p&gt;Most DS / ML roles would focus on the coolest parts of this job - building models, innovating, solving hard problems - and think how much we’d be paid. &lt;/p&gt;

&lt;p&gt;Anyway like I said this is just for fun, I fully understand autograd is an amazing advancement, but sometimes from a fully selfish pov, I wonder what if…&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17vqily,True,,Professional-Pace158,,57,False,all_ads,False,[],False,,/r/datascience/comments/17vqily/i_wish_autograd_didnt_exist/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vqily/i_wish_autograd_didnt_exist/,1209064,1700042880.0,0,,False,,,,,,,,,,671,121
,datascience,"I worked with time series DS, MLE and coding, but in a different domain.  Starting in a completely new application and environment.

I  previously worked mostly with tech-savvy stakeholders. Now my stakeholders will be from financial and economics. How different will it be, any advises on positioning myself, adjusting comm?

Also, open to suggestions on the best books, blogs and courses as a crash-course into my role in portfolio management business. Though, I don't want to overwhelm myself, but more to entertain and know the basics.",t2_f3y80e7s,False,,0,False,I am an experienced DS \ MLE without any financial background. Joining a pension and asset management fund. What will I do? What are the specifics of work environment? How to best prepare myself?,[],r/datascience,False,6,fun,0,,,False,t3_17vomp4,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},Career Discussion,False,7,,False,False,self,False,,[],{},,True,,1700034391.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I worked with time series DS, MLE and coding, but in a different domain.  Starting in a completely new application and environment.&lt;/p&gt;

&lt;p&gt;I  previously worked mostly with tech-savvy stakeholders. Now my stakeholders will be from financial and economics. How different will it be, any advises on positioning myself, adjusting comm?&lt;/p&gt;

&lt;p&gt;Also, open to suggestions on the best books, blogs and courses as a crash-course into my role in portfolio management business. Though, I don&amp;#39;t want to overwhelm myself, but more to entertain and know the basics.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17vomp4,True,,docoja1739,,9,True,all_ads,False,[],False,,/r/datascience/comments/17vomp4/i_am_an_experienced_ds_mle_without_any_financial/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vomp4/i_am_an_experienced_ds_mle_without_any_financial/,1209064,1700034391.0,0,,False,,,,,,,,,,539,86
,datascience,"Hi guys, I have an interesting problem and would like to ask you guys for your opinion.

Context: Our business team has a manual process where they put each documents into either redacted or not redacted (1 or 0).
We (another team) are running an independent assessment to figure out whether any of those not redacted (0) should have been redacted (1) instead. (Basically trying to catch the human errors) 

Another way to think about it, it is like we are trying to optimize for the false negatives. However, without this ground truth to train on, how will you go about building a ML solution to tackle this?

Hope I’m clear enough. Happy to add more details.",t2_pnx7y1h,False,,0,False,“Optimising” on False Negative?!,[],r/datascience,False,6,projects,0,,,False,t3_17vmprh,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},ML,False,5,,False,False,self,False,,[],{},,True,,1700026540.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I have an interesting problem and would like to ask you guys for your opinion.&lt;/p&gt;

&lt;p&gt;Context: Our business team has a manual process where they put each documents into either redacted or not redacted (1 or 0).
We (another team) are running an independent assessment to figure out whether any of those not redacted (0) should have been redacted (1) instead. (Basically trying to catch the human errors) &lt;/p&gt;

&lt;p&gt;Another way to think about it, it is like we are trying to optimize for the false negatives. However, without this ground truth to train on, how will you go about building a ML solution to tackle this?&lt;/p&gt;

&lt;p&gt;Hope I’m clear enough. Happy to add more details.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17vmprh,True,,appleciderv,,17,True,all_ads,False,[],False,,/r/datascience/comments/17vmprh/optimising_on_false_negative/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vmprh/optimising_on_false_negative/,1209064,1700026540.0,0,,False,,,,True,,,,,,660,117
,datascience,"Hi, I recently switched from browser to vs code for using jupyter notebook and the IDE-like features (e.g. auto-complete, debugging, etc) provided by VS code is really so much better than a browser. But one thing bothers me is that **whenever I wake my laptop from sleep mode**, it often has issue re-connecting to existing jupyter notebook server (in my case localhost:8888). When using browser, I simply refresh the page and it works. But VS code does not seem to be able to ""reconnect"" to the server. I also tried close/reopen my ipynb notebook, but still no luck. I could just restart the server, but I would lose all my saved results so it is usually not the best option.

So I am just wondering if you guys see similar issue and if you have any idea how to fix it?

Thank you!",t2_lodqn3wz,False,,0,False,cannot reconnect to existing jupyter notebook server when waking my laptop,[],r/datascience,False,6,discussion,0,,,False,t3_17vkv5v,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1700019941.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I recently switched from browser to vs code for using jupyter notebook and the IDE-like features (e.g. auto-complete, debugging, etc) provided by VS code is really so much better than a browser. But one thing bothers me is that &lt;strong&gt;whenever I wake my laptop from sleep mode&lt;/strong&gt;, it often has issue re-connecting to existing jupyter notebook server (in my case localhost:8888). When using browser, I simply refresh the page and it works. But VS code does not seem to be able to &amp;quot;reconnect&amp;quot; to the server. I also tried close/reopen my ipynb notebook, but still no luck. I could just restart the server, but I would lose all my saved results so it is usually not the best option.&lt;/p&gt;

&lt;p&gt;So I am just wondering if you guys see similar issue and if you have any idea how to fix it?&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17vkv5v,True,,Illustrious-Pay-7516,,3,True,all_ads,False,[],False,,/r/datascience/comments/17vkv5v/cannot_reconnect_to_existing_jupyter_notebook/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vkv5v/cannot_reconnect_to_existing_jupyter_notebook/,1209064,1700019941.0,0,,False,,,,,,,,,,782,143
,datascience,"Anyone work in Atmospheric Sciences? How possible is it to get somewhat accurate weather forecasts 30 days out. Just curious, seems like the data is there but you never see weather platforms being able to forecast accurate weather outcomes more than 7 days in advance (I’m sure it’s much more complicated than it seems).

EDIT: This is why I love Reddit. So many people that can bring light to something I’ve always been curious about no matter the niche. ",t2_524iawau,False,,0,False,Long-term Weather Forecasting?,[],r/datascience,False,6,projects,0,,,False,t3_17vins3,False,dark,0.63,,public,6,0,{},,,False,[],,False,False,,{},ML,False,6,,False,False,self,1700108036.0,,[],{},,True,,1700013291.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone work in Atmospheric Sciences? How possible is it to get somewhat accurate weather forecasts 30 days out. Just curious, seems like the data is there but you never see weather platforms being able to forecast accurate weather outcomes more than 7 days in advance (I’m sure it’s much more complicated than it seems).&lt;/p&gt;

&lt;p&gt;EDIT: This is why I love Reddit. So many people that can bring light to something I’ve always been curious about no matter the niche. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17vins3,True,,bassabyss,,28,True,all_ads,False,[],False,,/r/datascience/comments/17vins3/longterm_weather_forecasting/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vins3/longterm_weather_forecasting/,1209064,1700013291.0,0,,False,,,,,,,,,,456,79
,datascience,"Hi! Wondering what companies have good reputation when it comes to work/life balance.

I heard Tesla, Amazon, and Apple are a no-no. Appreciate any insight. You’ll be helping all of us!",t2_b3hvfhlp,False,,0,False,Companies with good work-life balance reputation? All is welcome: Tech/Finance/Medical,[],r/datascience,False,6,fun,0,,,False,t3_17vh1p9,False,dark,0.84,,public,27,0,{},,,False,[],,False,False,,{},Career Discussion,False,27,,False,False,self,False,,[],{},,True,,1700008597.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! Wondering what companies have good reputation when it comes to work/life balance.&lt;/p&gt;

&lt;p&gt;I heard Tesla, Amazon, and Apple are a no-no. Appreciate any insight. You’ll be helping all of us!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17vh1p9,True,,Exotic_Avocado6164,,26,True,all_ads,False,[],False,,/r/datascience/comments/17vh1p9/companies_with_good_worklife_balance_reputation/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vh1p9/companies_with_good_worklife_balance_reputation/,1209064,1700008597.0,0,,False,,,,,,,,,,185,31
,datascience,"Was thinking about a problem sales has been having at work, say we have a list of prospects all based in different geographic locations (zip codes, states etc.) and each prospect belongs to a market size (lower or upper).

Sales wants to equally distribute a mix of lower and upper across 3 sales AE's. The constraint is that each Sales AE's territory has to be touching at a state/zip level and the distribution has to be relatively even. 

I've solved this problem heuristically when we remove the geographic element but I'd like to understand what an approach would look like from an optimization perspective. 

To date, I've just been ""eye-balling"" territory maps and seeing how they line-up and then fiddling with it until it ""looks right, but I'd appreciate something more scientific.",t2_bw543,False,,0,False,Help needed with what I think is an optimization problem,[],r/datascience,False,6,network,0,,,False,t3_17vfji4,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Analysis,False,6,,False,False,self,False,,[],{},,True,,1700004466.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Was thinking about a problem sales has been having at work, say we have a list of prospects all based in different geographic locations (zip codes, states etc.) and each prospect belongs to a market size (lower or upper).&lt;/p&gt;

&lt;p&gt;Sales wants to equally distribute a mix of lower and upper across 3 sales AE&amp;#39;s. The constraint is that each Sales AE&amp;#39;s territory has to be touching at a state/zip level and the distribution has to be relatively even. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve solved this problem heuristically when we remove the geographic element but I&amp;#39;d like to understand what an approach would look like from an optimization perspective. &lt;/p&gt;

&lt;p&gt;To date, I&amp;#39;ve just been &amp;quot;eye-balling&amp;quot; territory maps and seeing how they line-up and then fiddling with it until it &amp;quot;looks right, but I&amp;#39;d appreciate something more scientific.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17vfji4,True,,Dysfu,,6,True,all_ads,False,[],False,,/r/datascience/comments/17vfji4/help_needed_with_what_i_think_is_an_optimization/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vfji4/help_needed_with_what_i_think_is_an_optimization/,1209064,1700004466.0,0,,False,,,,,,,,,,790,132
,datascience,"Hey everyone!

My work has given us the clear to have some amount of tuition reimbursed for continuing education. I currently have an MS in Statistics, but it's largely focused on traditional statistics with a bit of ML. I think it makes sense to pursue an MS in ML to further my understanding, but since I'm employed full-time, in-person classes are not an option. Does the community have an opinions on which programs may be more or less worth looking into for a respectable credential and a strong learning experience?

&amp;#x200B;",t2_tcne0,False,,0,False,Online MS in Machine Learning?,[],r/datascience,False,6,,0,,,False,t3_17vaypt,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},Education,False,4,,False,False,self,False,,[],{},,True,,1699992411.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;

&lt;p&gt;My work has given us the clear to have some amount of tuition reimbursed for continuing education. I currently have an MS in Statistics, but it&amp;#39;s largely focused on traditional statistics with a bit of ML. I think it makes sense to pursue an MS in ML to further my understanding, but since I&amp;#39;m employed full-time, in-person classes are not an option. Does the community have an opinions on which programs may be more or less worth looking into for a respectable credential and a strong learning experience?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17vaypt,True,,Karsticles,,15,True,all_ads,False,[],False,,/r/datascience/comments/17vaypt/online_ms_in_machine_learning/,all_ads,False,https://www.reddit.com/r/datascience/comments/17vaypt/online_ms_in_machine_learning/,1209064,1699992411.0,0,,False,,,,,,,,,,535,91
,datascience,"So, I've been in DS/ML for almost 2 years. For the last 1 year, I'm working in a project where I barely receive any feedback. My code quality and standards have remained the same as it was when I started. It has remained straightforward, no use of advanced Python functionalities, no consideration to performance optimization, no utilization of newer libraries, etc. Sometimes I can't understand how to check the pattern and quality of the data.

When I view experienced folks' works on Kaggle or GitHub, it seriously gives me anxiety and I start getting inferiority complex. Like, their codes, visualizations, practices are so good. They use awesome libraries I've never heard of. They get so good performance and scores. My work is nothing compared to them, it's laughable.

Ok, so how can I drastically improve my code skill, performance? I have been following experts' patterns, their data checking practices, for a long time. But I find it difficult implementing them on my own. I just can't understand where improvement is needed, and if needed, how do I do that!

Please help!",t2_3ndr0y7l,False,,0,False,How do I drastically improve my DS+ML coding skill? Following the pros gives me inferiority complex!,[],r/datascience,False,6,,0,,,False,t3_17v7pn7,False,dark,0.92,,public,99,0,{},,,False,[],,False,False,,{},Coding,False,99,,False,False,self,False,,[],{},,True,,1699983900.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So, I&amp;#39;ve been in DS/ML for almost 2 years. For the last 1 year, I&amp;#39;m working in a project where I barely receive any feedback. My code quality and standards have remained the same as it was when I started. It has remained straightforward, no use of advanced Python functionalities, no consideration to performance optimization, no utilization of newer libraries, etc. Sometimes I can&amp;#39;t understand how to check the pattern and quality of the data.&lt;/p&gt;

&lt;p&gt;When I view experienced folks&amp;#39; works on Kaggle or GitHub, it seriously gives me anxiety and I start getting inferiority complex. Like, their codes, visualizations, practices are so good. They use awesome libraries I&amp;#39;ve never heard of. They get so good performance and scores. My work is nothing compared to them, it&amp;#39;s laughable.&lt;/p&gt;

&lt;p&gt;Ok, so how can I drastically improve my code skill, performance? I have been following experts&amp;#39; patterns, their data checking practices, for a long time. But I find it difficult implementing them on my own. I just can&amp;#39;t understand where improvement is needed, and if needed, how do I do that!&lt;/p&gt;

&lt;p&gt;Please help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,17v7pn7,True,,swb_rise,,26,True,all_ads,False,[],False,,/r/datascience/comments/17v7pn7/how_do_i_drastically_improve_my_dsml_coding_skill/,all_ads,False,https://www.reddit.com/r/datascience/comments/17v7pn7/how_do_i_drastically_improve_my_dsml_coding_skill/,1209064,1699983900.0,1,,False,,,,,,,,,,1083,181
,datascience,"I’m currently debating between pursuing either a Masters in Data Science (MS-DS) or a Masters in Applied &amp; Computational Math (MS-AM). For the MS-DS, my choices right now are either Rutgers NB or Georgia Tech’s online program (OMSA). I know most data science programs tend to be “cash cows” or too watered down but I did extensive research into their curriculums and they’re both pretty rigorous. And they’re both ranked well. 

On the other hand, for the MS-AP, I’m looking into John Hopkins’ Engineering for Professionals program’s online masters. This program is very rigorous, offers flexibility to tailor your degree to however you want via their numerous course offerings, and doesn’t compromise depth of knowledge. I like this because I can take classes that excite me and might be relevant but aren’t offered in a typical data science degree. Plus, it’ll build a very strong mathematical foundation. It’s also ranked well. But its very expensive. 

Rutgers would be in-person and the other two are online and part-time so that I can start working and gaining experience. Though with just a bachelor’s, it’s virtually impossible to get a job in a relevant field right now. So being in-person at Rutgers would help me network better and perhaps do paid research on campus.",t2_3yx8ekgr,False,,0,False,Masters in Data Science vs Applied &amp; Computational Math?,[],r/datascience,False,6,,0,,,False,t3_17v6qht,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Education,False,3,,False,False,self,False,,[],{},,True,,1699981354.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m currently debating between pursuing either a Masters in Data Science (MS-DS) or a Masters in Applied &amp;amp; Computational Math (MS-AM). For the MS-DS, my choices right now are either Rutgers NB or Georgia Tech’s online program (OMSA). I know most data science programs tend to be “cash cows” or too watered down but I did extensive research into their curriculums and they’re both pretty rigorous. And they’re both ranked well. &lt;/p&gt;

&lt;p&gt;On the other hand, for the MS-AP, I’m looking into John Hopkins’ Engineering for Professionals program’s online masters. This program is very rigorous, offers flexibility to tailor your degree to however you want via their numerous course offerings, and doesn’t compromise depth of knowledge. I like this because I can take classes that excite me and might be relevant but aren’t offered in a typical data science degree. Plus, it’ll build a very strong mathematical foundation. It’s also ranked well. But its very expensive. &lt;/p&gt;

&lt;p&gt;Rutgers would be in-person and the other two are online and part-time so that I can start working and gaining experience. Though with just a bachelor’s, it’s virtually impossible to get a job in a relevant field right now. So being in-person at Rutgers would help me network better and perhaps do paid research on campus.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17v6qht,True,,mowa0199,,8,True,all_ads,False,[],False,,/r/datascience/comments/17v6qht/masters_in_data_science_vs_applied_computational/,all_ads,False,https://www.reddit.com/r/datascience/comments/17v6qht/masters_in_data_science_vs_applied_computational/,1209064,1699981354.0,0,,False,,,,,,,,,,1282,211
,datascience,Please help shed light on actual salary expectations per city/state 🙏🏻,t2_b3hvfhlp,False,,0,False,What was your salary progression in DS? (Base/Bonus) + Location,[],r/datascience,False,6,fun,0,,,False,t3_17v1jv7,False,dark,0.92,,public,108,0,{},,,False,[],,False,False,,{},Career Discussion,False,108,,False,False,self,False,,[],{},,True,,1699966274.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Please help shed light on actual salary expectations per city/state 🙏🏻&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17v1jv7,True,,Exotic_Avocado6164,,222,True,all_ads,False,[],False,,/r/datascience/comments/17v1jv7/what_was_your_salary_progression_in_ds_basebonus/,all_ads,False,https://www.reddit.com/r/datascience/comments/17v1jv7/what_was_your_salary_progression_in_ds_basebonus/,1209064,1699966274.0,0,,False,,,,,,,,,,70,11
,datascience,"I’m a decently paid “Senior Data Scientist” for a startup, who, in the two years in this role:
1.  hasn’t done a single “proper” data science experiment (p-values, etc etc) to inform business decisions
2. Hasn’t pushed a single model to production, hell I haven’t even trained one.

Instead, I’m doing dashboards, data engineering, hacking scripts to improve analytics because the devs are too busy, responding to customer requests which are generally “can we have this in a csv” type stuff.

It’s getting to a point where I think I should either change my job title or change my job because I’m not sure I’m getting good experience, although despite the stupidly long hours I do enjoy it and am respected with autonomy.",t2_6ae1kvay,False,,0,False,Anyone else a DS that doesn’t actually do DS?,[],r/datascience,False,6,discussion,0,,,False,t3_17uytmb,False,dark,0.98,,public,328,0,{},,,False,[],,False,False,,{},Discussion,False,328,,False,False,self,False,,[],{},,True,,1699954994.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m a decently paid “Senior Data Scientist” for a startup, who, in the two years in this role:
1.  hasn’t done a single “proper” data science experiment (p-values, etc etc) to inform business decisions
2. Hasn’t pushed a single model to production, hell I haven’t even trained one.&lt;/p&gt;

&lt;p&gt;Instead, I’m doing dashboards, data engineering, hacking scripts to improve analytics because the devs are too busy, responding to customer requests which are generally “can we have this in a csv” type stuff.&lt;/p&gt;

&lt;p&gt;It’s getting to a point where I think I should either change my job title or change my job because I’m not sure I’m getting good experience, although despite the stupidly long hours I do enjoy it and am respected with autonomy.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17uytmb,True,,Disastrous_Classic96,,105,False,all_ads,False,[],False,,/r/datascience/comments/17uytmb/anyone_else_a_ds_that_doesnt_actually_do_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/17uytmb/anyone_else_a_ds_that_doesnt_actually_do_ds/,1209066,1699954994.0,0,,False,,,,,,,,,,720,123
,datascience,"Not sure how to approach this, product has been giving increasingly difficult demands on the models, and setting them as goals, with deadlines etc', the benchmark seems to be ""well a human is capable of recognising that this is X, so should our product/feature"", sometimes its possible, but in other times, the contextual knowledge that is required, along with the computation requirements and other difficulties related to the domain and sample conditions make this task delusional.

We used to have an exec with enough background who would shield us from these kinds of requests, he was let go.",t2_b4lh5,False,,0,False,How do you handle Product/Executives who ask too much,[],r/datascience,False,6,fun,0,,,False,t3_17uyqic,False,dark,0.88,,public,13,0,{},,,False,[],,False,False,,{},Career Discussion,False,13,,False,False,self,False,,[],{},,True,,1699954600.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not sure how to approach this, product has been giving increasingly difficult demands on the models, and setting them as goals, with deadlines etc&amp;#39;, the benchmark seems to be &amp;quot;well a human is capable of recognising that this is X, so should our product/feature&amp;quot;, sometimes its possible, but in other times, the contextual knowledge that is required, along with the computation requirements and other difficulties related to the domain and sample conditions make this task delusional.&lt;/p&gt;

&lt;p&gt;We used to have an exec with enough background who would shield us from these kinds of requests, he was let go.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17uyqic,True,,DisWastingMyTime,,12,True,all_ads,False,[],False,,/r/datascience/comments/17uyqic/how_do_you_handle_productexecutives_who_ask_too/,all_ads,False,https://www.reddit.com/r/datascience/comments/17uyqic/how_do_you_handle_productexecutives_who_ask_too/,1209066,1699954600.0,0,,False,,,,,,,,,,596,98
,datascience,"I have created a Content Based Recommender using k-NN to recommend the 5 most similar books within a corpus. The corpus has been processed using nltk and I have applied TF-IDF Vectoriser from sklearn to get in the form of an array. 

It works well, but I need to objectively assess it, and I have decided to use Normalised Discounted Cumulative Gain (NDCG).

How do I assess the test data against the training using NDCG? Do I need to create an extra variable of relevance?",t2_tir3dln2,False,,0,False,For a change in this sub- An actual Data Science question,[],r/datascience,False,6,projects,0,,,False,t3_17uuxxh,False,dark,0.76,,public,25,0,{},,,False,[],,False,False,,{},ML,False,25,,False,False,self,False,,[],{},,True,,1699938505.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have created a Content Based Recommender using k-NN to recommend the 5 most similar books within a corpus. The corpus has been processed using nltk and I have applied TF-IDF Vectoriser from sklearn to get in the form of an array. &lt;/p&gt;

&lt;p&gt;It works well, but I need to objectively assess it, and I have decided to use Normalised Discounted Cumulative Gain (NDCG).&lt;/p&gt;

&lt;p&gt;How do I assess the test data against the training using NDCG? Do I need to create an extra variable of relevance?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17uuxxh,True,,Fun_Elevator_814,,20,True,all_ads,False,[],False,,/r/datascience/comments/17uuxxh/for_a_change_in_this_sub_an_actual_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17uuxxh/for_a_change_in_this_sub_an_actual_data_science/,1209066,1699938505.0,0,,False,,,,,,,,,,473,85
,datascience,"Does anyone have tips on how to improve answers from a document retrieval chain? 
Current set up is got-3.5-turbo, chroma, lang chain, the whole thing is dockerized and hosted on kubernetes. I fed couple of regulation documents to both my bot and AskYourPDF, and the answer I get from AskYourPDF is much better.
I provided a prompt template asking the LLM to be truthful, comprehensive, detail, and provide source to the answers. LLM is set to Temp=0, top_n=3, token_limit=200, using Stuff chain. The answer I get is technically correct but not a lot of context, just one short sentence pulled from the most relevant paragraph, quite concise. However the answer I get from AskYourPDF provides not only correct answer but also with additional details relevant to the question, from various paragraphs throughout the doc. 
I’m wondering what I can do to make my bot provide a correct, comprehensive and contextualized answer?",t2_16kgog,False,,0,False,Retriever chain answer quality,[],r/datascience,False,6,projects,0,,,False,t3_17utoiq,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},ML,False,0,,False,False,self,False,,[],{},,True,,1699934153.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have tips on how to improve answers from a document retrieval chain? 
Current set up is got-3.5-turbo, chroma, lang chain, the whole thing is dockerized and hosted on kubernetes. I fed couple of regulation documents to both my bot and AskYourPDF, and the answer I get from AskYourPDF is much better.
I provided a prompt template asking the LLM to be truthful, comprehensive, detail, and provide source to the answers. LLM is set to Temp=0, top_n=3, token_limit=200, using Stuff chain. The answer I get is technically correct but not a lot of context, just one short sentence pulled from the most relevant paragraph, quite concise. However the answer I get from AskYourPDF provides not only correct answer but also with additional details relevant to the question, from various paragraphs throughout the doc. 
I’m wondering what I can do to make my bot provide a correct, comprehensive and contextualized answer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17utoiq,True,,balpby1989,,2,True,all_ads,False,[],False,,/r/datascience/comments/17utoiq/retriever_chain_answer_quality/,all_ads,False,https://www.reddit.com/r/datascience/comments/17utoiq/retriever_chain_answer_quality/,1209066,1699934153.0,0,,False,,,,,,,,,,923,151
,datascience,"Still doing DS or perhaps in another data related role?

Edit: It appears everyone hates their job.",t2_kcl3tfwe,False,,0,False,Where do you see yourself in 5-10 years?,[],r/datascience,False,6,fun,0,,,False,t3_17un7gs,False,dark,0.92,,public,100,0,{},,,False,[],,False,False,,{},Career Discussion,False,100,,False,False,self,1699929068.0,,[],{},,True,,1699915328.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Still doing DS or perhaps in another data related role?&lt;/p&gt;

&lt;p&gt;Edit: It appears everyone hates their job.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17un7gs,True,,NewEcho2940,,95,True,all_ads,False,[],False,,/r/datascience/comments/17un7gs/where_do_you_see_yourself_in_510_years/,all_ads,False,https://www.reddit.com/r/datascience/comments/17un7gs/where_do_you_see_yourself_in_510_years/,1209066,1699915328.0,0,,False,,,,,,,,,,99,17
,datascience,"Any one have one they recommend? There don't seem to be many decently known packages for this and the Chrome extensions for Jupyter barely work.

Of the genai JupyterLab extensions I've found, this one [https://pypi.org/project/ai-einblick-prompt/](https://pypi.org/project/ai-einblick-prompt/) has been working the best for me. It automatically adds the context from my datasets based on my prompts. I've also Jupyter's [https://pypi.org/project/jupyter-ai/](https://pypi.org/project/jupyter-ai/) which generated good code templates but, didn't like how it was not contextually aware (always had to add in feature names and edit the code) and and I had to use my own OpenAI API key.",t2_1c287my3,False,,0,False,Best GPT Jupyter extensions?,[],r/datascience,False,6,tooling,0,,,False,t3_17udnoq,False,dark,0.74,,public,16,0,{},,,False,[],,False,False,,{},Tools,False,16,,False,False,self,False,,[],{},,True,,1699890876.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Any one have one they recommend? There don&amp;#39;t seem to be many decently known packages for this and the Chrome extensions for Jupyter barely work.&lt;/p&gt;

&lt;p&gt;Of the genai JupyterLab extensions I&amp;#39;ve found, this one &lt;a href=""https://pypi.org/project/ai-einblick-prompt/""&gt;https://pypi.org/project/ai-einblick-prompt/&lt;/a&gt; has been working the best for me. It automatically adds the context from my datasets based on my prompts. I&amp;#39;ve also Jupyter&amp;#39;s &lt;a href=""https://pypi.org/project/jupyter-ai/""&gt;https://pypi.org/project/jupyter-ai/&lt;/a&gt; which generated good code templates but, didn&amp;#39;t like how it was not contextually aware (always had to add in feature names and edit the code) and and I had to use my own OpenAI API key.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17udnoq,True,,mf_it,,5,True,all_ads,False,[],False,,/r/datascience/comments/17udnoq/best_gpt_jupyter_extensions/,all_ads,False,https://www.reddit.com/r/datascience/comments/17udnoq/best_gpt_jupyter_extensions/,1209066,1699890876.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?auto=webp&amp;s=85f19a22cbd85fa784cdb417359d8ff7cda9e394', 'width': 300, 'height': 300}, 'resolutions': [{'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46fa55dd1b1e587ab93bcbbdc6cb2de37b810bf3', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfd7f76ac4c13cdc287edd9856ef0430dbc862a5', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM'}], 'enabled': False}",,,,,,,683,94
,datascience,"Every company says they do it: big tech, century-old IT companies, Fortune 500s, banks, health care systems, government, management consulting, cute-sounding startups ... could they really all be talking about the same data science?

I imagine the experiences, requirements, and technical maturity of data science roles vary widely across its many applications. There is probably no single right way to view the industry landscape. But different perspectives can help us figure out where we fit in.

How do you make sense of the data science landscape?

**UPDATE:** Healthy discussion below distinguishing different data handling roles. However, I'm interested to hear more about *horizontal* differences between industries. See responses by u/mf_it, u/ruben_vanwyk, and u/DSby2021 for inspiration.

For those who say, ""no patterns,"" a challenge: Could it be that the only predictable differences between data science at, say, Pepsi, Mozilla, and CIA is the subject matter? Just switch the words, ""soda,"" ""web page,"" and ""intelligence"" on the job description?",t2_s27ul7aa,False,,0,False,How do you segment the data science industry?,[],r/datascience,False,6,discussion,0,,,False,t3_17ubd29,False,dark,0.92,,public,58,0,{},,,False,[],,False,False,,{},Discussion,False,58,,False,False,self,1699976849.0,,[],{},,True,,1699884359.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Every company says they do it: big tech, century-old IT companies, Fortune 500s, banks, health care systems, government, management consulting, cute-sounding startups ... could they really all be talking about the same data science?&lt;/p&gt;

&lt;p&gt;I imagine the experiences, requirements, and technical maturity of data science roles vary widely across its many applications. There is probably no single right way to view the industry landscape. But different perspectives can help us figure out where we fit in.&lt;/p&gt;

&lt;p&gt;How do you make sense of the data science landscape?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; Healthy discussion below distinguishing different data handling roles. However, I&amp;#39;m interested to hear more about &lt;em&gt;horizontal&lt;/em&gt; differences between industries. See responses by &lt;a href=""/u/mf_it""&gt;u/mf_it&lt;/a&gt;, &lt;a href=""/u/ruben_vanwyk""&gt;u/ruben_vanwyk&lt;/a&gt;, and &lt;a href=""/u/DSby2021""&gt;u/DSby2021&lt;/a&gt; for inspiration.&lt;/p&gt;

&lt;p&gt;For those who say, &amp;quot;no patterns,&amp;quot; a challenge: Could it be that the only predictable differences between data science at, say, Pepsi, Mozilla, and CIA is the subject matter? Just switch the words, &amp;quot;soda,&amp;quot; &amp;quot;web page,&amp;quot; and &amp;quot;intelligence&amp;quot; on the job description?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ubd29,True,,chiqui-bee,,46,True,all_ads,False,[],False,,/r/datascience/comments/17ubd29/how_do_you_segment_the_data_science_industry/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ubd29/how_do_you_segment_the_data_science_industry/,1209066,1699884359.0,0,,False,,,,,,,,,,1059,157
,datascience,"Hey, I'm excited to announce that registration for the Statistics Globe online course on ""Data Manipulation in R Using dplyr &amp; the tidyverse"" has just opened! Click here for more info: [https://statisticsglobe.com/online-course-data-manipulation-r-dplyr-tidyverse](https://statisticsglobe.com/online-course-data-manipulation-r-dplyr-tidyverse)

&amp;#x200B;

Participants get access to:

&amp;#x200B;

\- Over 20 video lectures.

\- A group chat for questions and exchange.

\- Exercises and example projects.

\- R scripts and a large collection of resources.

&amp;#x200B;

After completing the course, you'll be able to efficiently manipulate and analyze data using R, dplyr, and the tidyverse, which will significantly improve your data science skills and career prospects.

&amp;#x200B;

Please let me know in case you have any further comments or questions.

&amp;#x200B;

See you soon in the course!

&amp;#x200B;

Joachim

&amp;#x200B;

\#rstats #dplyr #tidyverse #datamanipulation #datawrangling #datacleaning #dataanalysis #datavisualization #datascience #statistics ",t2_77cigax1,False,,0,False,Data Manipulation in R Using dplyr &amp; the tidyverse Course,[],r/datascience,False,6,,0,,,False,t3_17u9z6f,False,dark,0.29,,public,0,0,{},,,False,[],,False,False,,{},Education,False,0,,False,False,self,False,,[],{},,True,,1699879975.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, I&amp;#39;m excited to announce that registration for the Statistics Globe online course on &amp;quot;Data Manipulation in R Using dplyr &amp;amp; the tidyverse&amp;quot; has just opened! Click here for more info: &lt;a href=""https://statisticsglobe.com/online-course-data-manipulation-r-dplyr-tidyverse""&gt;https://statisticsglobe.com/online-course-data-manipulation-r-dplyr-tidyverse&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Participants get access to:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;- Over 20 video lectures.&lt;/p&gt;

&lt;p&gt;- A group chat for questions and exchange.&lt;/p&gt;

&lt;p&gt;- Exercises and example projects.&lt;/p&gt;

&lt;p&gt;- R scripts and a large collection of resources.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;After completing the course, you&amp;#39;ll be able to efficiently manipulate and analyze data using R, dplyr, and the tidyverse, which will significantly improve your data science skills and career prospects.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Please let me know in case you have any further comments or questions.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;See you soon in the course!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Joachim&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;#rstats #dplyr #tidyverse #datamanipulation #datawrangling #datacleaning #dataanalysis #datavisualization #datascience #statistics &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17u9z6f,True,,JoachimSchork,,4,True,all_ads,False,[],False,,/r/datascience/comments/17u9z6f/data_manipulation_in_r_using_dplyr_the_tidyverse/,all_ads,False,https://www.reddit.com/r/datascience/comments/17u9z6f/data_manipulation_in_r_using_dplyr_the_tidyverse/,1209066,1699879975.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?auto=webp&amp;s=504a4bbc9a6b59f621ec4209eb9b26224ff8cc82', 'width': 1476, 'height': 830}, 'resolutions': [{'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f8f98b9048f929ddc46e0589f1ce6269ccf8717', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=232ce6cc9125d51b609f9fd2520e83d4f750a707', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e230f3caa6a12e0b04cf02f35b6678207c922cb1', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dd5eef602b231a2b6e149b3307bbc18f76d6bb8', 'width': 640, 'height': 359}, {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=18ba3ac873c7aa073e6e0faefed088822be7d78f', 'width': 960, 'height': 539}, {'url': 'https://external-preview.redd.it/KXvLYk3km4uF3YR3ldhdEuMj7qDgiEO-fn-Z-mL20FA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=220a0b076e127bbc4f7d6aa1f279b91ee9459bc2', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'qBO0culhejXFKzv13BkQ5b5qF6jWc0cSZGHPWkJyz9Y'}], 'enabled': False}",,,,,,,1081,130
,datascience,"Hey guys, the company I work for has an app. People transact on our app and they transact on apps with whom we are in direct competition. I would really like to identify our users that have accounts with these competitor apps. My understanding is that there’s no real way to see other installed apps from your app.

Im thinking along the lines of sending a survey out to users and trying to infer from responses if they use competitor apps (how many? How frequently? etc) and then extrapolate - but there are many inherent limitations to these sorts of approaches.

Obviously I don’t want to do anything that breaches privacy both ethically and legally. I’m curious if anyone has found success with this problem. Cheers",t2_xfx8ms4,False,,0,False,App competitor analysis techniques,[],r/datascience,False,6,discussion,0,,,False,t3_17u2hhs,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1699848410.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, the company I work for has an app. People transact on our app and they transact on apps with whom we are in direct competition. I would really like to identify our users that have accounts with these competitor apps. My understanding is that there’s no real way to see other installed apps from your app.&lt;/p&gt;

&lt;p&gt;Im thinking along the lines of sending a survey out to users and trying to infer from responses if they use competitor apps (how many? How frequently? etc) and then extrapolate - but there are many inherent limitations to these sorts of approaches.&lt;/p&gt;

&lt;p&gt;Obviously I don’t want to do anything that breaches privacy both ethically and legally. I’m curious if anyone has found success with this problem. Cheers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17u2hhs,True,,HStuart18,,4,True,all_ads,False,[],False,,/r/datascience/comments/17u2hhs/app_competitor_analysis_techniques/,all_ads,False,https://www.reddit.com/r/datascience/comments/17u2hhs/app_competitor_analysis_techniques/,1209066,1699848410.0,0,,False,,,,,,,,,,719,126
,datascience,"Been a long time since I worked with gradient boosting, trying to come up with a good way to review before using it in a model build",t2_89ar1fajx,False,,0,False,What are your favorite resources for refreshing or upskilling your stats and ML knowledge,[],r/datascience,False,6,,0,,,False,t3_17tz3xg,False,dark,0.96,,public,46,0,{},,,False,[],,False,False,,{},Education,False,46,,False,False,self,False,,[],{},,True,,1699837879.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Been a long time since I worked with gradient boosting, trying to come up with a good way to review before using it in a model build&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17tz3xg,True,,AnxiousEgg6284,,15,True,all_ads,False,[],False,,/r/datascience/comments/17tz3xg/what_are_your_favorite_resources_for_refreshing/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tz3xg/what_are_your_favorite_resources_for_refreshing/,1209066,1699837879.0,0,,False,,,,,,,,,,132,27
,datascience,"Hello all,

Wanted to ask a general question to gauge feelings toward rust or more broadly the usefulness of a lower level, more performant language in Data Science/ML for one's career and workflow.

\*I am going to use 'rust' as a term to describe both rust itself and other lower level, speedy langs. (c, c++, etc.) \*

1. Has anyone used a rust for data science? This could be plotting, EDA, model dev, deployment, or ML research developing at a matrix level?
2. was knowledge of a rust-like lang useful for advancing your career? If yes, what flavor of DS do you work in?
3. Have you seen any advancement in your org or team toward the use of rust? \*

Thank you all.

\*\*\*\* EDIT \*\*\*\*

4. Has anyone noticed the use of custom packages or modules being developed in rust/c++ and used in a python workflow? Is this even considered DS? Or is this more MLE or SWE with an ML flavor? ",t2_4rc2x3g4,False,,0,False,Rust Usefulness in Data Science,[],r/datascience,False,6,tooling,0,,,False,t3_17tyeqb,False,dark,0.81,,public,29,0,{},,,False,[],,False,False,,{},Tools,False,29,,False,False,self,1699838347.0,,[],{},,True,,1699835843.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;Wanted to ask a general question to gauge feelings toward rust or more broadly the usefulness of a lower level, more performant language in Data Science/ML for one&amp;#39;s career and workflow.&lt;/p&gt;

&lt;p&gt;*I am going to use &amp;#39;rust&amp;#39; as a term to describe both rust itself and other lower level, speedy langs. (c, c++, etc.) *&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Has anyone used a rust for data science? This could be plotting, EDA, model dev, deployment, or ML research developing at a matrix level?&lt;/li&gt;
&lt;li&gt;was knowledge of a rust-like lang useful for advancing your career? If yes, what flavor of DS do you work in?&lt;/li&gt;
&lt;li&gt;Have you seen any advancement in your org or team toward the use of rust? *&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thank you all.&lt;/p&gt;

&lt;p&gt;**** EDIT ****&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Has anyone noticed the use of custom packages or modules being developed in rust/c++ and used in a python workflow? Is this even considered DS? Or is this more MLE or SWE with an ML flavor? &lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17tyeqb,True,,Far_Ambassador_6495,,34,True,all_ads,False,[],False,,/r/datascience/comments/17tyeqb/rust_usefulness_in_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tyeqb/rust_usefulness_in_data_science/,1209066,1699835843.0,0,,False,,,,,,,,,,890,164
,datascience," 

Is it possible to become a Data Science Manager or an ML/AI Architect without excelling as a developer? What qualities or backgrounds are typically found in successful Data Science Managers?

I have a Data Science manager who reads headlines from sensational articles and asks the team to implement it. Phrases like 'everyone in the industry is using ML for fraud' or 'use ML to solve x fraud in this company using ML.' They seem to think that just because the term 'fraud' is involved, ML should be used. How can someone effectively manage and architect an ML system without being hands-on, at least for a few years? Your thoughts?",t2_5fbmh3va,False,,0,False,Can you be Data science manager or ML /AI architect without being good developer,[],r/datascience,False,6,projects,0,,,False,t3_17tti4j,False,dark,0.59,,public,4,0,{},,,False,[],,False,False,,{},ML,False,4,,False,False,self,False,,[],{},,True,,1699822530.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to become a Data Science Manager or an ML/AI Architect without excelling as a developer? What qualities or backgrounds are typically found in successful Data Science Managers?&lt;/p&gt;

&lt;p&gt;I have a Data Science manager who reads headlines from sensational articles and asks the team to implement it. Phrases like &amp;#39;everyone in the industry is using ML for fraud&amp;#39; or &amp;#39;use ML to solve x fraud in this company using ML.&amp;#39; They seem to think that just because the term &amp;#39;fraud&amp;#39; is involved, ML should be used. How can someone effectively manage and architect an ML system without being hands-on, at least for a few years? Your thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17tti4j,True,,Excellent_Cost170,,11,True,all_ads,False,[],False,,/r/datascience/comments/17tti4j/can_you_be_data_science_manager_or_ml_ai/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tti4j/can_you_be_data_science_manager_or_ml_ai/,1209066,1699822530.0,0,,False,,,,,,,,,,635,109
,datascience,"Hello everyone,

I'm at a crossroads in my career and am seeking advice to prepare for an important upcoming meeting where I'll be discussing my 3-5 year career objectives, clarifying my role, and identifying the support I might need.

**Background**

I am 18 months into a role as data analyst at a small company specializing in e-commerce logistics, including airfreight and final mile deliveries. My role combines financial accounting with data analysis, primarily using Power BI. I bring a unique combination of skills and experience from the previous more traditional finance postitions in the industry to this role and in my time here have signifcantly uplifted the management reporting. I pride myself on strong problem-solving abilities, intellectual rigor, and a flexible yet methodical work approach.

The company is in a great position with significant growth potential, and I have great faith in our leadership team. I am eager to take a senior postition in the company and to drive a stronger data-driven approach in business analysis and reporting.

**Immediate Challenges and Areas for Discussion**

One of my main challenges is developing strong connections within the company and I often feel 'out of the loop' on key issues.

Additionally, my role lacks clear definition, especially in terms of over lapping responsibilities with the incumbent finance manager who has been with the company for 15 years. This meeting is a crucial opportunity to address this, and I’ve effectively been asked to 'write my own job description'.

Another issue is my tendency to get overly absorbed in project details, sometimes losing sight of the bigger picture. I plan to seek project management support to improve in this area.

While I have strong technical skills and a good understanding of the business, I recognize that I need to enhance my interpersonal skills. I'm committed to the company and keen to succeed but need guidance on these next steps.

I would greatly appreciate any insights, particularly from those who've navigated similar paths or have experience in defining roles and setting long-term objectives in data-centric positions. How did you define your role in a way that aligned with your career goals and company needs? Any tips on improving interpersonal skills in a professional setting?

Thank you for your time and looking forward to your valuable advice!",t2_na00e,False,,0,False,I've been asked to write my own job description - what do I say,[],r/datascience,False,6,fun,0,,,False,t3_17tj3e3,False,dark,0.56,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1699791514.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m at a crossroads in my career and am seeking advice to prepare for an important upcoming meeting where I&amp;#39;ll be discussing my 3-5 year career objectives, clarifying my role, and identifying the support I might need.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I am 18 months into a role as data analyst at a small company specializing in e-commerce logistics, including airfreight and final mile deliveries. My role combines financial accounting with data analysis, primarily using Power BI. I bring a unique combination of skills and experience from the previous more traditional finance postitions in the industry to this role and in my time here have signifcantly uplifted the management reporting. I pride myself on strong problem-solving abilities, intellectual rigor, and a flexible yet methodical work approach.&lt;/p&gt;

&lt;p&gt;The company is in a great position with significant growth potential, and I have great faith in our leadership team. I am eager to take a senior postition in the company and to drive a stronger data-driven approach in business analysis and reporting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Immediate Challenges and Areas for Discussion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of my main challenges is developing strong connections within the company and I often feel &amp;#39;out of the loop&amp;#39; on key issues.&lt;/p&gt;

&lt;p&gt;Additionally, my role lacks clear definition, especially in terms of over lapping responsibilities with the incumbent finance manager who has been with the company for 15 years. This meeting is a crucial opportunity to address this, and I’ve effectively been asked to &amp;#39;write my own job description&amp;#39;.&lt;/p&gt;

&lt;p&gt;Another issue is my tendency to get overly absorbed in project details, sometimes losing sight of the bigger picture. I plan to seek project management support to improve in this area.&lt;/p&gt;

&lt;p&gt;While I have strong technical skills and a good understanding of the business, I recognize that I need to enhance my interpersonal skills. I&amp;#39;m committed to the company and keen to succeed but need guidance on these next steps.&lt;/p&gt;

&lt;p&gt;I would greatly appreciate any insights, particularly from those who&amp;#39;ve navigated similar paths or have experience in defining roles and setting long-term objectives in data-centric positions. How did you define your role in a way that aligned with your career goals and company needs? Any tips on improving interpersonal skills in a professional setting?&lt;/p&gt;

&lt;p&gt;Thank you for your time and looking forward to your valuable advice!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17tj3e3,True,,_nigelburke_,,14,True,all_ads,False,[],False,,/r/datascience/comments/17tj3e3/ive_been_asked_to_write_my_own_job_description/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tj3e3/ive_been_asked_to_write_my_own_job_description/,1209066,1699791514.0,0,,False,,,,,,,,,,2384,380
,datascience,"I have been a freelance Data Scientist for 6 month and I have more job offers than I can manage (I turn down offers every week). 

Some people have written me to get some tips on how to start and get some clients. 
So these are a few things I tried to find clients on Upwork, LinkedIn and in online communities.

1) Look for projects on Upwork. 
Set up a nice profile, showcase your project portfolio, research the market, bid on several projects and be willing to set a cheap rate at the beginning. 
You won't make much money the first month, but you will get exposure, your Upwork rating will improve and you can start to bid on some higher paying jobs. 
In 6 months my rate went up 4 times, so don't think it takes so long to get to a good hourly rate. 

2) Improve and polish your LinkedIn profile. 
Many recruiters will write you here. 
Insert the right keywords on your profile, document your previous work, post something work related every week, if you can. 
This is a long game but pays off because instead of bidding for jobs, in the end the recruiters will start to write you.

3) Join online communities of entrepreneurs.
There are several small businesses that look for Data experts and beyond. They have projects ongoing and want to hire freelancers for a short time. 
You can meet them in these communities. Look for them on Twitter, Discord, Slack, Reddit...
Engage with them, share what you do and soon you will start to get some interest. This type of interaction quickly turns into job opportunities.

4) Write. 
Just create a blog and post regularly. Post about what you do, the tools you have used and so on. Better to post a tutorial, a new tech you tried out, a small model you developed. 
All the successful people I know have this habit. They write and share what they do regularly.

5) Put yourself out there and interact online. 
Maybe one day you share something and it gets retweeted, maybe you pick up a good SEO keyword in your blog, you never know. That's why it's important to increase your exposure. You will increase your chances of getting noticed and potentially land a new client.

6) Be generous 
Once you do the above soon you will be noticed and people will start to contact you. 
They will not offer you a contract. That's not how it works. after all, they don't know you and they don't trust you. But something you wrote hit them. Probably they will ask for your help and advice on a specific issue. 
Give advice on the tech to use, how to solve a problem, how to improve their processes, give as much as you can, be honest and open. Say all you know and you will build trust. 
It's the start of a professional relationship.

7) Be patient
Not all conversations will turn into a job opportunity. Sometimes they lead nowhere, sometimes there is no budget, sometimes it takes months to sign a contract. In my experience maybe 2-3 out of 10 conversations turn into a job offer. 
Accept it. It's normal.

I have published more details about it in an article in [my blog](https://www.tropianhs.com/diary/2023/11/12/data-science-freelance).

I often write about my freelance experience in Data Science on [Twitter](https://twitter.com/tropianhs).",t2_14l2y1,False,,0,False,6 months as a Data Science freelancer,[],r/datascience,False,6,fun,0,,,False,t3_17tit0r,False,dark,0.97,,public,551,0,{},,,False,[],,False,False,,{},Career Discussion,False,551,,False,False,self,False,,[],{},,True,,1699790369.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been a freelance Data Scientist for 6 month and I have more job offers than I can manage (I turn down offers every week). &lt;/p&gt;

&lt;p&gt;Some people have written me to get some tips on how to start and get some clients. 
So these are a few things I tried to find clients on Upwork, LinkedIn and in online communities.&lt;/p&gt;

&lt;p&gt;1) Look for projects on Upwork. 
Set up a nice profile, showcase your project portfolio, research the market, bid on several projects and be willing to set a cheap rate at the beginning. 
You won&amp;#39;t make much money the first month, but you will get exposure, your Upwork rating will improve and you can start to bid on some higher paying jobs. 
In 6 months my rate went up 4 times, so don&amp;#39;t think it takes so long to get to a good hourly rate. &lt;/p&gt;

&lt;p&gt;2) Improve and polish your LinkedIn profile. 
Many recruiters will write you here. 
Insert the right keywords on your profile, document your previous work, post something work related every week, if you can. 
This is a long game but pays off because instead of bidding for jobs, in the end the recruiters will start to write you.&lt;/p&gt;

&lt;p&gt;3) Join online communities of entrepreneurs.
There are several small businesses that look for Data experts and beyond. They have projects ongoing and want to hire freelancers for a short time. 
You can meet them in these communities. Look for them on Twitter, Discord, Slack, Reddit...
Engage with them, share what you do and soon you will start to get some interest. This type of interaction quickly turns into job opportunities.&lt;/p&gt;

&lt;p&gt;4) Write. 
Just create a blog and post regularly. Post about what you do, the tools you have used and so on. Better to post a tutorial, a new tech you tried out, a small model you developed. 
All the successful people I know have this habit. They write and share what they do regularly.&lt;/p&gt;

&lt;p&gt;5) Put yourself out there and interact online. 
Maybe one day you share something and it gets retweeted, maybe you pick up a good SEO keyword in your blog, you never know. That&amp;#39;s why it&amp;#39;s important to increase your exposure. You will increase your chances of getting noticed and potentially land a new client.&lt;/p&gt;

&lt;p&gt;6) Be generous 
Once you do the above soon you will be noticed and people will start to contact you. 
They will not offer you a contract. That&amp;#39;s not how it works. after all, they don&amp;#39;t know you and they don&amp;#39;t trust you. But something you wrote hit them. Probably they will ask for your help and advice on a specific issue. 
Give advice on the tech to use, how to solve a problem, how to improve their processes, give as much as you can, be honest and open. Say all you know and you will build trust. 
It&amp;#39;s the start of a professional relationship.&lt;/p&gt;

&lt;p&gt;7) Be patient
Not all conversations will turn into a job opportunity. Sometimes they lead nowhere, sometimes there is no budget, sometimes it takes months to sign a contract. In my experience maybe 2-3 out of 10 conversations turn into a job offer. 
Accept it. It&amp;#39;s normal.&lt;/p&gt;

&lt;p&gt;I have published more details about it in an article in &lt;a href=""https://www.tropianhs.com/diary/2023/11/12/data-science-freelance""&gt;my blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I often write about my freelance experience in Data Science on &lt;a href=""https://twitter.com/tropianhs""&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17tit0r,True,,tropianhs,,117,True,all_ads,False,[],False,,/r/datascience/comments/17tit0r/6_months_as_a_data_science_freelancer/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tit0r/6_months_as_a_data_science_freelancer/,1209066,1699790369.0,1,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Sbeprygezr6iFb3Wo1SisSl6oesoDS4-5PXl5WlfIcs.jpg?auto=webp&amp;s=5ea679146d68042565a62601f1fec40723fe45a7', 'width': 194, 'height': 194}, 'resolutions': [{'url': 'https://external-preview.redd.it/Sbeprygezr6iFb3Wo1SisSl6oesoDS4-5PXl5WlfIcs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed70b839c84de7977e7d2261af478c59c9a26471', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'RC_M3gVfQtLm30Zj7MKaRVa4jJSe23E7oqs6dh3z-h8'}], 'enabled': False}",,,,,,,3183,560
,datascience,"I'm an employed DS right now, so I haven't been pouring over job posting, but I have specific expertise in one domain area, so I keep an ear to the ground in that industry. From the VERY small sample it seems like the job market might be on the other side of the bottom now? There's still the 10k applications in 3 days problem, but there at least seem to be more job posting. Anyone have any hard evidence for / against? Or just comment on if you agree and we can take in informal poll.",t2_1zkrsyfq,False,,0,False,Is the job market improving?,[],r/datascience,False,6,fun,0,,,False,t3_17tbpwn,False,dark,0.87,,public,56,0,{},,,False,[],,False,False,,{},Career Discussion,False,56,,False,False,self,False,,[],{},,True,,1699760312.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m an employed DS right now, so I haven&amp;#39;t been pouring over job posting, but I have specific expertise in one domain area, so I keep an ear to the ground in that industry. From the VERY small sample it seems like the job market might be on the other side of the bottom now? There&amp;#39;s still the 10k applications in 3 days problem, but there at least seem to be more job posting. Anyone have any hard evidence for / against? Or just comment on if you agree and we can take in informal poll.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17tbpwn,True,,Any-Fig-921,,67,True,all_ads,False,[],False,,/r/datascience/comments/17tbpwn/is_the_job_market_improving/,all_ads,False,https://www.reddit.com/r/datascience/comments/17tbpwn/is_the_job_market_improving/,1209066,1699760312.0,0,,False,,,,,,,,,,487,96
,datascience,"I’m just interested in the thought process and how you’d approach this optimization problem.

Given  limited amount of space in your store, how would you optimize for giving the right  facings for fast-moving products ( to prevent stockouts) but also keeping enough diverse range. 

For the facings recommendation part, I found this Walmart’s patent. 

https://patents.google.com/patent/US20200042914A1/

Thanks",t2_vqwkfiup,False,,0,False,"Brainstorming Q (for physical retail): How would you optimize between maintaining sufficient facings for fast-selling items to avoid stockouts, while also preserving shelf space for a diverse range of slower-moving products? (Range vs Space)",[],r/datascience,False,6,discussion,0,,,False,t3_17t4qwl,False,dark,0.81,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,False,self,False,,[],{},,True,,1699739065.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m just interested in the thought process and how you’d approach this optimization problem.&lt;/p&gt;

&lt;p&gt;Given  limited amount of space in your store, how would you optimize for giving the right  facings for fast-moving products ( to prevent stockouts) but also keeping enough diverse range. &lt;/p&gt;

&lt;p&gt;For the facings recommendation part, I found this Walmart’s patent. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://patents.google.com/patent/US20200042914A1/""&gt;https://patents.google.com/patent/US20200042914A1/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17t4qwl,True,,Living_Teaching9410,,11,True,all_ads,False,[],False,,/r/datascience/comments/17t4qwl/brainstorming_q_for_physical_retail_how_would_you/,all_ads,False,https://www.reddit.com/r/datascience/comments/17t4qwl/brainstorming_q_for_physical_retail_how_would_you/,1209066,1699739065.0,0,,False,,,,,,,,,,411,56
,datascience,"Wanted to share our work on [Tarsier](https://github.com/reworkd/tarsier) here, an open source utility library that enables LLMs like GPT-4 and GPT-4 Vision to browse the web. The library helps answer the following questions:

* How do you map LLM responses back into web elements?
* How can you mark up a page for an LLM to better understand its action space?
* How do you feed a ""screenshot"" to a text-only LLM?

We do this by tagging ""*interactable*"" elements on the page with an ID, enabling the LLM to connect actions to an ID which we can then translate back into web elements. We also use OCR to translate a page screenshot to a spatially encoded text string such that even a text only LLM can understand how to navigate the page.

View a demo and read more on GitHub: [https://github.com/reworkd/tarsier](https://github.com/reworkd/tarsier)",t2_w08ahc6r,False,,0,False,GPT-4 vision utilities to enable web browsing,[],r/datascience,False,6,meta,0,,,False,t3_17t4fvq,False,dark,0.67,,public,2,0,{},,,True,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1699738246.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Wanted to share our work on &lt;a href=""https://github.com/reworkd/tarsier""&gt;Tarsier&lt;/a&gt; here, an open source utility library that enables LLMs like GPT-4 and GPT-4 Vision to browse the web. The library helps answer the following questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How do you map LLM responses back into web elements?&lt;/li&gt;
&lt;li&gt;How can you mark up a page for an LLM to better understand its action space?&lt;/li&gt;
&lt;li&gt;How do you feed a &amp;quot;screenshot&amp;quot; to a text-only LLM?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We do this by tagging &amp;quot;&lt;em&gt;interactable&lt;/em&gt;&amp;quot; elements on the page with an ID, enabling the LLM to connect actions to an ID which we can then translate back into web elements. We also use OCR to translate a page screenshot to a spatially encoded text string such that even a text only LLM can understand how to navigate the page.&lt;/p&gt;

&lt;p&gt;View a demo and read more on GitHub: &lt;a href=""https://github.com/reworkd/tarsier""&gt;https://github.com/reworkd/tarsier&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17t4fvq,True,,asim-shrestha,,2,True,all_ads,False,[],False,,/r/datascience/comments/17t4fvq/gpt4_vision_utilities_to_enable_web_browsing/,all_ads,False,https://www.reddit.com/r/datascience/comments/17t4fvq/gpt4_vision_utilities_to_enable_web_browsing/,1209066,1699738246.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?auto=webp&amp;s=a5f040d28e750df730ec39f670172c604bc41989', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6023b959bb5f016acead3b5165eae4f1ccff2895', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3cd3b4c43cf8adffe01aac66dfaa1870ffc7d94', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9f564ea441a484ef549135bb24896969018459e1', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=54cc08028c73f394c4cc745e30d1f4aa449234c4', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=344aa8bf0ab59ed6270df6ef1fec6426a1416dbc', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a60b4fdb6d37a88fcfd7370f598d2ff44b1d65d', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'H7P7mxgoWPXQJip0tdF8bnO0aWwc9vDk0036ITGcIX8'}], 'enabled': False}",,,,,,,848,140
,datascience,"You likely heard about the recent ChatGPT updates with the possibility to create assistants (aka GPTs) with code generation and interpretation capacities. One of the GPTs provided with this update by OpenAI is a Data Analysis assistant, showing the company already identified this area as a strong application for its tech.

Just by providing a dataset you can start generating some simple or more advanced visualisations, including those needing some data processing or aggregations. This means anyone can interact with a dataset just using plain English.

If you're curious (and have a ChatGPT+ subscription) you can play with this [GPT](https://chat.openai.com/g/g-5CQsMRvyT-international-football-explorer) I created to explore a dataset on International Football Games (aka soccer ;) ).

What makes it strong:

* Interact in simple English, no coding required
* Long context: you can iterate on a plot or analysis as chatGPT keeps memory of the past context
* Capacity to generate plots or run some data processing thanks to its capacity to write and execute Python code.
* You can use ChatGPT's ""knowledge"" to comment on what you observe and give you some hints on trends you observe

I'm personally quite impressed, the results are most of the time correct (you can check the code it generated). Provided the tech was only released a year ago, this is very promising and I can easily imagine such natural language interface being implemented in traditional BI platforms like Tableau or Looker.

It is of course not perfect and we should be cautious when using it. Here are some caveats:

* It struggles with more advanced requests like creating a model. It usually needs mulitple iteration and some technical guidance (e.g. indicating which model to choose) to get to a reasonable result.
* It can make some mistakes that you won't catch unless you have a good understanding of the dataset or check the code (e.g. at some point it ran an analysis on a subset that it generated for a previous analysis while I wanted to run it on the whole dataset). You need to be extra careful with the instructions you give it and double checking the results
* You need to manually upload the datasets for now, which makes non-technical persons still dependent on someone to pull the data for them. Integration with external databases or external apps connected to multiple APIs will soon come to fix that, it is only an integration issue.

It will definitely not take our jobs tomorrow but it will make business stakeholders less reliant on technical persons and might slightly reduce the need for data analysts (the same way tools like Midjourney reduce a bit the dependence on artists for some specific tasks, or ChatGPT for Copywriters).

Below are some examples of how you can easily require for a plot to be created with a first interpretation.

  


https://preview.redd.it/nyts2e5verzb1.png?width=516&amp;format=png&amp;auto=webp&amp;s=781a00caf22a3baae08cff12aa4f632c4e2f6f37

https://preview.redd.it/0j4nkz5verzb1.png?width=719&amp;format=png&amp;auto=webp&amp;s=9fb228e7d5e0d49ab01fc5487a6e093dd2fbd5d0

  
",t2_eu3yx,False,,0,False,ChatGPT becomes a serious contender for exploratory data analysis,[],r/datascience,False,6,tooling,0,140.0,,False,t3_17t04cn,False,dark,0.77,,public,141,0,{},140.0,,True,[],,False,False,,{},Tools,False,141,,False,False,https://b.thumbs.redditmedia.com/Gi_MqvkkPE7Mv0EhRP3ItZFzSqta3F_AvmSnKiNGTfA.jpg,False,,[],{},,True,,1699726304.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;You likely heard about the recent ChatGPT updates with the possibility to create assistants (aka GPTs) with code generation and interpretation capacities. One of the GPTs provided with this update by OpenAI is a Data Analysis assistant, showing the company already identified this area as a strong application for its tech.&lt;/p&gt;

&lt;p&gt;Just by providing a dataset you can start generating some simple or more advanced visualisations, including those needing some data processing or aggregations. This means anyone can interact with a dataset just using plain English.&lt;/p&gt;

&lt;p&gt;If you&amp;#39;re curious (and have a ChatGPT+ subscription) you can play with this &lt;a href=""https://chat.openai.com/g/g-5CQsMRvyT-international-football-explorer""&gt;GPT&lt;/a&gt; I created to explore a dataset on International Football Games (aka soccer ;) ).&lt;/p&gt;

&lt;p&gt;What makes it strong:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Interact in simple English, no coding required&lt;/li&gt;
&lt;li&gt;Long context: you can iterate on a plot or analysis as chatGPT keeps memory of the past context&lt;/li&gt;
&lt;li&gt;Capacity to generate plots or run some data processing thanks to its capacity to write and execute Python code.&lt;/li&gt;
&lt;li&gt;You can use ChatGPT&amp;#39;s &amp;quot;knowledge&amp;quot; to comment on what you observe and give you some hints on trends you observe&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m personally quite impressed, the results are most of the time correct (you can check the code it generated). Provided the tech was only released a year ago, this is very promising and I can easily imagine such natural language interface being implemented in traditional BI platforms like Tableau or Looker.&lt;/p&gt;

&lt;p&gt;It is of course not perfect and we should be cautious when using it. Here are some caveats:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It struggles with more advanced requests like creating a model. It usually needs mulitple iteration and some technical guidance (e.g. indicating which model to choose) to get to a reasonable result.&lt;/li&gt;
&lt;li&gt;It can make some mistakes that you won&amp;#39;t catch unless you have a good understanding of the dataset or check the code (e.g. at some point it ran an analysis on a subset that it generated for a previous analysis while I wanted to run it on the whole dataset). You need to be extra careful with the instructions you give it and double checking the results&lt;/li&gt;
&lt;li&gt;You need to manually upload the datasets for now, which makes non-technical persons still dependent on someone to pull the data for them. Integration with external databases or external apps connected to multiple APIs will soon come to fix that, it is only an integration issue.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It will definitely not take our jobs tomorrow but it will make business stakeholders less reliant on technical persons and might slightly reduce the need for data analysts (the same way tools like Midjourney reduce a bit the dependence on artists for some specific tasks, or ChatGPT for Copywriters).&lt;/p&gt;

&lt;p&gt;Below are some examples of how you can easily require for a plot to be created with a first interpretation.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/nyts2e5verzb1.png?width=516&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=781a00caf22a3baae08cff12aa4f632c4e2f6f37""&gt;https://preview.redd.it/nyts2e5verzb1.png?width=516&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=781a00caf22a3baae08cff12aa4f632c4e2f6f37&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/0j4nkz5verzb1.png?width=719&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fb228e7d5e0d49ab01fc5487a6e093dd2fbd5d0""&gt;https://preview.redd.it/0j4nkz5verzb1.png?width=719&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fb228e7d5e0d49ab01fc5487a6e093dd2fbd5d0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17t04cn,True,,PhJulien,,90,True,all_ads,False,[],False,,/r/datascience/comments/17t04cn/chatgpt_becomes_a_serious_contender_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/17t04cn/chatgpt_becomes_a_serious_contender_for/,1209066,1699726304.0,0,,False,"{'nyts2e5verzb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 164, 'x': 108, 'u': 'https://preview.redd.it/nyts2e5verzb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f760c0141478d32a8c8277a02f95c5e29a05444'}, {'y': 328, 'x': 216, 'u': 'https://preview.redd.it/nyts2e5verzb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=21d743d87575b1e0f5548e55bfb64917e6b1ac0b'}, {'y': 486, 'x': 320, 'u': 'https://preview.redd.it/nyts2e5verzb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e541e82d60882be2d90da174de9fd06bd912401c'}], 's': {'y': 784, 'x': 516, 'u': 'https://preview.redd.it/nyts2e5verzb1.png?width=516&amp;format=png&amp;auto=webp&amp;s=781a00caf22a3baae08cff12aa4f632c4e2f6f37'}, 'id': 'nyts2e5verzb1'}, '0j4nkz5verzb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 112, 'x': 108, 'u': 'https://preview.redd.it/0j4nkz5verzb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a6e2d820d8a315af8eef4d95411c177b35fec73'}, {'y': 225, 'x': 216, 'u': 'https://preview.redd.it/0j4nkz5verzb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d581131adaa235bbd0ed181d66af00c720f6ab5b'}, {'y': 333, 'x': 320, 'u': 'https://preview.redd.it/0j4nkz5verzb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=57da6cec30c657b632a15f0ca1410948eac48ea3'}, {'y': 666, 'x': 640, 'u': 'https://preview.redd.it/0j4nkz5verzb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d0b8f700683252ffa6a05ba96b5ed3d9c84cc3c'}], 's': {'y': 749, 'x': 719, 'u': 'https://preview.redd.it/0j4nkz5verzb1.png?width=719&amp;format=png&amp;auto=webp&amp;s=9fb228e7d5e0d49ab01fc5487a6e093dd2fbd5d0'}, 'id': '0j4nkz5verzb1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5iBWXBIPNZ1gzMk4L0QBBrKYrF9t6uJRzUeOyANQ3XU.jpg?auto=webp&amp;s=127513bdd9414a2bcd22190f5be70ce3be88b423', 'width': 512, 'height': 512}, 'resolutions': [{'url': 'https://external-preview.redd.it/5iBWXBIPNZ1gzMk4L0QBBrKYrF9t6uJRzUeOyANQ3XU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36ba01d73ef12ee5dc37e286f5e80ed1d26fe181', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/5iBWXBIPNZ1gzMk4L0QBBrKYrF9t6uJRzUeOyANQ3XU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d689ad1df7f7f715e69619c2c080d6dff5e1131', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/5iBWXBIPNZ1gzMk4L0QBBrKYrF9t6uJRzUeOyANQ3XU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=77cbf6ec5d14813a250a6dd87b2aa19aa675b020', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'JC1hCgmvroInW6-Db8Ppg36l0yUwRRfgU7qpBr-rrh0'}], 'enabled': False}",,,,,,,3110,473
,datascience,"I was inspired by this previous post. I've also seen a growing interest in a separate Europe (/non-US) thread over the years, so I wanted to start a more up-to-date thread:

[https://www.reddit.com/r/datascience/comments/78zii9/eu\_data\_scientists\_whats\_your\_and\_my\_role\_and/](https://www.reddit.com/r/datascience/comments/78zii9/eu_data_scientists_whats_your_and_my_role_and/)

While not the focus, non-Europeans are of course welcome to chime in. We had a guy from Japan last time - that was very interesting. 😊

I think it's worthwhile to learn from one another and see the salaries but also to see what the different flavours of data scientists, analysts and engineers are out there in the wild. So, do feel free to talk a bit about your work if you can and want to. 🙂

&amp;#x200B;

n.b.: For better comparison, please mention your gross annual income in your country's currency.

**Location:** .  
**Title:** .  
**Compensation (gross):** .  
**Education level**: .  
**Experience:** .  
**Industry/vertical:** .  
**Company size:** .  
**Majority of time spent using (tools):** .  
**Majority of time spent doing (role):** .  
**Flavour:** .",,False,,0,False,Europe salary thread - What's your role and salary?,[],r/datascience,False,6,discussion,0,,,False,t3_17sppgb,False,dark,0.95,,public,285,0,{},,,False,[],,False,False,,{},Discussion,False,285,,False,,self,1699692866.0,,,{},,True,,1699688950.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was inspired by this previous post. I&amp;#39;ve also seen a growing interest in a separate Europe (/non-US) thread over the years, so I wanted to start a more up-to-date thread:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/r/datascience/comments/78zii9/eu_data_scientists_whats_your_and_my_role_and/""&gt;https://www.reddit.com/r/datascience/comments/78zii9/eu_data_scientists_whats_your_and_my_role_and/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;While not the focus, non-Europeans are of course welcome to chime in. We had a guy from Japan last time - that was very interesting. 😊&lt;/p&gt;

&lt;p&gt;I think it&amp;#39;s worthwhile to learn from one another and see the salaries but also to see what the different flavours of data scientists, analysts and engineers are out there in the wild. So, do feel free to talk a bit about your work if you can and want to. 🙂&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;n.b.: For better comparison, please mention your gross annual income in your country&amp;#39;s currency.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Title:&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Compensation (gross):&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Education level&lt;/strong&gt;: .&lt;br/&gt;
&lt;strong&gt;Experience:&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Industry/vertical:&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Company size:&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Majority of time spent using (tools):&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Majority of time spent doing (role):&lt;/strong&gt; .&lt;br/&gt;
&lt;strong&gt;Flavour:&lt;/strong&gt; .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17sppgb,True,,[deleted],,235,True,all_ads,False,[],,dark,/r/datascience/comments/17sppgb/europe_salary_thread_whats_your_role_and_salary/,all_ads,False,https://www.reddit.com/r/datascience/comments/17sppgb/europe_salary_thread_whats_your_role_and_salary/,1209066,1699688950.0,0,,False,,,,,,,,,,1155,157
,datascience,"It is known that most of the data science initiatives fail. For most companies, the return on investment for data science teams is far lesser than a team of data analysts and data engineers working on a business problem. In some orgs, data scientists are now being seen as resource hoggers, some of who have extremely high salaries but haven't delivered anything worthwhile to make a business impact or even to support a business decision.

Other than a few organizations that have been successful in hiring the right talent and also fostering the right ecosystem for data science to flourish, it seems that most companies still lack data maturity. While all of the companies seem to have a ""vision"" to be data-driven, very few of them have an actual plan. In such organisations,  the leadership themselves do not know what problems they want to solve with data science. For the management it is an exercise to have a ""led a data team"" tag in their career profiles. 

The expectation is for the data scientists to find the problems themselves and solve them. Almost everytime, without a proper manager or an SME, the data scientists fail to grasp the business case correctly. Lack of business acumen and the pressure of leadership expectations to deliver on their skillsets, makes them model the problems incorrectly. They end up building low confidence solutions that stakeholders hardly use. Businesses then either go back to their trusted analysts for solutions or convert the data scientists into analysts to get the job done. 

The data scientists are expected to deliver business value, not PPTs and POCs, for the salary they get paid. And if they fail to justify their salaries, it becomes difficult for businesses to keep paying them. When push comes to shove, they're shown the door. 

Data scientists, who were once thought of as strategic hirings, are now slowly becoming expendables. And this isn't because of the market conditions. It is primarily because of the ROI of data scientists compared to other tech roles. And no, a PhD alone does not generate any business value, neither does leetcode grinding, nor does an all-green github profile of ready-made projects from an online certification course the employee completed to become job ready. 

But here's the problem for someone who has to balance between business requirements and a technical team - when evaluated on the basis of value generated, it does not bode well with the data science community in company, who feel that data science is primarily a research job and data scientists should be paid for only research, irrespective of the financial and productivity outcomes.

In such a scenario, how should a data scientist be evaluated for performance?

EDIT: This might not be the case with your employer or the industry you work in.",t2_al1087x2,False,,0,False,How should data science employees be evaluated?,[],r/datascience,False,6,fun,0,,,False,t3_17sjneh,False,dark,0.83,,public,64,0,{},,,False,[],,False,False,,{},Career Discussion,False,64,,False,False,self,1699692117.0,,[],{},,True,,1699666736.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It is known that most of the data science initiatives fail. For most companies, the return on investment for data science teams is far lesser than a team of data analysts and data engineers working on a business problem. In some orgs, data scientists are now being seen as resource hoggers, some of who have extremely high salaries but haven&amp;#39;t delivered anything worthwhile to make a business impact or even to support a business decision.&lt;/p&gt;

&lt;p&gt;Other than a few organizations that have been successful in hiring the right talent and also fostering the right ecosystem for data science to flourish, it seems that most companies still lack data maturity. While all of the companies seem to have a &amp;quot;vision&amp;quot; to be data-driven, very few of them have an actual plan. In such organisations,  the leadership themselves do not know what problems they want to solve with data science. For the management it is an exercise to have a &amp;quot;led a data team&amp;quot; tag in their career profiles. &lt;/p&gt;

&lt;p&gt;The expectation is for the data scientists to find the problems themselves and solve them. Almost everytime, without a proper manager or an SME, the data scientists fail to grasp the business case correctly. Lack of business acumen and the pressure of leadership expectations to deliver on their skillsets, makes them model the problems incorrectly. They end up building low confidence solutions that stakeholders hardly use. Businesses then either go back to their trusted analysts for solutions or convert the data scientists into analysts to get the job done. &lt;/p&gt;

&lt;p&gt;The data scientists are expected to deliver business value, not PPTs and POCs, for the salary they get paid. And if they fail to justify their salaries, it becomes difficult for businesses to keep paying them. When push comes to shove, they&amp;#39;re shown the door. &lt;/p&gt;

&lt;p&gt;Data scientists, who were once thought of as strategic hirings, are now slowly becoming expendables. And this isn&amp;#39;t because of the market conditions. It is primarily because of the ROI of data scientists compared to other tech roles. And no, a PhD alone does not generate any business value, neither does leetcode grinding, nor does an all-green github profile of ready-made projects from an online certification course the employee completed to become job ready. &lt;/p&gt;

&lt;p&gt;But here&amp;#39;s the problem for someone who has to balance between business requirements and a technical team - when evaluated on the basis of value generated, it does not bode well with the data science community in company, who feel that data science is primarily a research job and data scientists should be paid for only research, irrespective of the financial and productivity outcomes.&lt;/p&gt;

&lt;p&gt;In such a scenario, how should a data scientist be evaluated for performance?&lt;/p&gt;

&lt;p&gt;EDIT: This might not be the case with your employer or the industry you work in.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17sjneh,True,,OverratedDataScience,,45,True,all_ads,False,[],False,,/r/datascience/comments/17sjneh/how_should_data_science_employees_be_evaluated/,all_ads,False,https://www.reddit.com/r/datascience/comments/17sjneh/how_should_data_science_employees_be_evaluated/,1209066,1699666736.0,0,,False,,,,,,,,,,2808,468
,datascience,"Just a quick question: what are the best practices in managing data science/analysis? I'm especially interested in different industries.

Who approves? What questions are asked? What documents should be kept?

For context, most of my exposure to DS has been in banking, where there are standard governance requirements (White papers, official approvers, related decisioning, etc). Obviously, this doesn't make sense for every area, but... in a domain where it's easy for practitioners to fool themselves with their statistical practices(p-hacking, etc), how do you maintain quality beyond a non-technical person just getting bludgeoned by the statistics.

&amp;#x200B;",t2_eblvtun2,False,,0,False,Best Practices in Management of Data Science/Analysis,[],r/datascience,False,6,discussion,0,,,False,t3_17shu78,False,dark,0.91,,public,9,0,{},,,False,[],,False,False,,{},Discussion,False,9,,False,False,self,False,,[],{},,True,,1699661406.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just a quick question: what are the best practices in managing data science/analysis? I&amp;#39;m especially interested in different industries.&lt;/p&gt;

&lt;p&gt;Who approves? What questions are asked? What documents should be kept?&lt;/p&gt;

&lt;p&gt;For context, most of my exposure to DS has been in banking, where there are standard governance requirements (White papers, official approvers, related decisioning, etc). Obviously, this doesn&amp;#39;t make sense for every area, but... in a domain where it&amp;#39;s easy for practitioners to fool themselves with their statistical practices(p-hacking, etc), how do you maintain quality beyond a non-technical person just getting bludgeoned by the statistics.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17shu78,True,,Glotto_Gold,,5,True,all_ads,False,[],False,,/r/datascience/comments/17shu78/best_practices_in_management_of_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17shu78/best_practices_in_management_of_data/,1209066,1699661406.0,0,,False,,,,,,,,,,668,96
,datascience,"I have an upcoming Masters level class in data mining and it teaches how to use WEKA. How practical is WEKA in the real world 🌎?? At first glance, it looks quite dated. 

What are some better alternatives that I should look at and learn on the side?",t2_s64wtqtg,False,,0,False,Alternatives to WEKA,[],r/datascience,False,6,tooling,0,,,False,t3_17scgkh,False,dark,0.78,,public,10,0,{},,,False,[],,False,False,,{},Tools,False,10,,False,False,self,False,,[],{},,True,,1699646588.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an upcoming Masters level class in data mining and it teaches how to use WEKA. How practical is WEKA in the real world 🌎?? At first glance, it looks quite dated. &lt;/p&gt;

&lt;p&gt;What are some better alternatives that I should look at and learn on the side?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17scgkh,True,,delzee363,,36,True,all_ads,False,[],False,,/r/datascience/comments/17scgkh/alternatives_to_weka/,all_ads,False,https://www.reddit.com/r/datascience/comments/17scgkh/alternatives_to_weka/,1209066,1699646588.0,0,,False,,,,,,,,,,249,48
,datascience,"Hello DS fam,

I recently joined a team and was assigned a project that the team found difficult and hence didn’t complete for around 1 year. 

I’ve been solely working on this project because I found it interesting for 6-8 weeks and finally made a break through (using a totally different approach than the teams). However, now, I walked the Lead through everything I did and they’re claiming all credit by telling everyone that “they” fixed it and to direct any questions to me.

May sound petty, but how does one navigate such waters?


Edit: thank you all for your advice. It was good to get an outside perspective on the situation. ",t2_5qxvthqm,False,,0,False,"Job advice, dealing with higher ups",[],r/datascience,False,6,fun,0,,,False,t3_17sbvvr,False,dark,0.9,,public,30,0,{},,,False,[],,False,False,,{},Career Discussion,False,30,,False,False,self,1699655750.0,,[],{},,True,,1699645017.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello DS fam,&lt;/p&gt;

&lt;p&gt;I recently joined a team and was assigned a project that the team found difficult and hence didn’t complete for around 1 year. &lt;/p&gt;

&lt;p&gt;I’ve been solely working on this project because I found it interesting for 6-8 weeks and finally made a break through (using a totally different approach than the teams). However, now, I walked the Lead through everything I did and they’re claiming all credit by telling everyone that “they” fixed it and to direct any questions to me.&lt;/p&gt;

&lt;p&gt;May sound petty, but how does one navigate such waters?&lt;/p&gt;

&lt;p&gt;Edit: thank you all for your advice. It was good to get an outside perspective on the situation. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17sbvvr,True,,BullianBear,,30,True,all_ads,False,[],False,,/r/datascience/comments/17sbvvr/job_advice_dealing_with_higher_ups/,all_ads,False,https://www.reddit.com/r/datascience/comments/17sbvvr/job_advice_dealing_with_higher_ups/,1209066,1699645017.0,0,,False,,,,,,,,,,637,112
,datascience,"I am completely fed up with my current company and gearing up to bail around Feb 2024. I want to prepare and make sure my next place is worth staying at for more than a year - so what are your favorite questions to ask during an interview to get the company to reveal their red flags?   


  
",t2_am698,False,,0,False,What questions to ask in an interview to discover a company's red flags?,[],r/datascience,False,6,fun,0,,,False,t3_17s27y7,False,dark,0.97,,public,62,0,{},,,False,[],,False,False,,{},Career Discussion,False,62,,False,False,self,False,,[],{},,True,,1699616561.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am completely fed up with my current company and gearing up to bail around Feb 2024. I want to prepare and make sure my next place is worth staying at for more than a year - so what are your favorite questions to ask during an interview to get the company to reveal their red flags?   &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17s27y7,True,,Mackelday,,39,True,all_ads,False,[],False,,/r/datascience/comments/17s27y7/what_questions_to_ask_in_an_interview_to_discover/,all_ads,False,https://www.reddit.com/r/datascience/comments/17s27y7/what_questions_to_ask_in_an_interview_to_discover/,1209066,1699616561.0,0,,False,,,,,,,,,,293,57
,datascience,https://www.insider.com/robot-crushed-man-death-mistook-him-box-vegetables-south-korea-2023-11?utm_medium=social&amp;utm_source=facebook&amp;utm_campaign=business-sf&amp;fbclid=IwAR1rGAXkb4sKaZRyvbRCZ6rwwunq04aIndfrcTZKppk1KD4b5fzBLrQOc4k   what are you thoughts?,t2_5fbmh3va,False,,0,False,Failure of computer vision model? A robot crushed a man to death after it mistook him for a box of vegetables,[],r/datascience,False,6,projects,0,,,False,t3_17rsf9x,False,dark,0.84,,public,30,0,{},,,False,[],,False,False,,{},ML,False,30,,False,False,self,False,,[],{},,True,,1699578772.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.insider.com/robot-crushed-man-death-mistook-him-box-vegetables-south-korea-2023-11?utm_medium=social&amp;amp;utm_source=facebook&amp;amp;utm_campaign=business-sf&amp;amp;fbclid=IwAR1rGAXkb4sKaZRyvbRCZ6rwwunq04aIndfrcTZKppk1KD4b5fzBLrQOc4k""&gt;https://www.insider.com/robot-crushed-man-death-mistook-him-box-vegetables-south-korea-2023-11?utm_medium=social&amp;amp;utm_source=facebook&amp;amp;utm_campaign=business-sf&amp;amp;fbclid=IwAR1rGAXkb4sKaZRyvbRCZ6rwwunq04aIndfrcTZKppk1KD4b5fzBLrQOc4k&lt;/a&gt;   what are you thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17rsf9x,True,,Excellent_Cost170,,23,True,all_ads,False,[],False,,/r/datascience/comments/17rsf9x/failure_of_computer_vision_model_a_robot_crushed/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rsf9x/failure_of_computer_vision_model_a_robot_crushed/,1209066,1699578772.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?auto=webp&amp;s=72b1b799f64a6d9655a34a050de0d3cbc7242d82', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dc5cd0f829f1e54f082bdfad1da9e8def09d879', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=322fa5eb29a5402b52eed2d5e7e1a0fd18c0f708', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a0203b65918be49930694b11c47d1c1747d75e9', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b62afd4c2c742d58fc74ec2c1a9eb549a6bd1be8', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0fec886e9110d30b0a10fb6e12255b504a73f26c', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/VG6ScXnV5qU8P7QdEgpnmTQXy7X_lRBkPwiyTjSVOYE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96cce3391ec461018005b3a50d6b8a413f62902a', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'TbBUGgqEM21ISI8ygcz7PauF8wsYZWAhFMkTCf9uzro'}], 'enabled': False}",,,,,,,263,5
,datascience,"Figured we can rant a bit. 

For whatever reason, my team has recently hired a few unqualified MBAs to do management work in the data science space and honestly I think it was the biggest fuck up they've ever made. 

So here are the top 5 things I dislike:
1. Condescending micromanagers. It's not enough that you have daily standup, they want to bug you after lunch and before the day is over to get a ""status report"". Like bro fuck off this is data science not supply chain management. 
2. Too many middle managers (Incompetence meets big egos and we have a middle manager)
3. Daily standups. Most data science peojects are better suited for twice weekly check-ins with ad-hoc meetings between ICs as needed. 
4. General imbalance of management to individual contributors. Every project I've been on is like 8 business people and 2 data scientists and it's completely unnecessary. The data scientists do all of the work while the business people circle jerk strategy that doesn't make sense at all in the context of the data and we litterally have to show them why their idea doesn't make sense on every project multipled times, we're basically training them all over time and it's really unnecessary. 
5. I spend way too much time in meetings to be an IC data scientist. I spend 20 to 25 hours a week in meetings on average and I have to actively participate in all of them.... I could accomplish so much more if I had less BS meetings but that would also require having less BS middle managers, etc. 

How about you?",,False,,0,False,Top 5 things you dislike about your team / role / organization,[],r/datascience,False,6,discussion,0,,,False,t3_17rrybm,False,dark,0.91,,public,113,0,{},,,False,[],,False,False,,{},Discussion,False,113,,False,,self,False,,,{},,True,,1699577389.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Figured we can rant a bit. &lt;/p&gt;

&lt;p&gt;For whatever reason, my team has recently hired a few unqualified MBAs to do management work in the data science space and honestly I think it was the biggest fuck up they&amp;#39;ve ever made. &lt;/p&gt;

&lt;p&gt;So here are the top 5 things I dislike:
1. Condescending micromanagers. It&amp;#39;s not enough that you have daily standup, they want to bug you after lunch and before the day is over to get a &amp;quot;status report&amp;quot;. Like bro fuck off this is data science not supply chain management. 
2. Too many middle managers (Incompetence meets big egos and we have a middle manager)
3. Daily standups. Most data science peojects are better suited for twice weekly check-ins with ad-hoc meetings between ICs as needed. 
4. General imbalance of management to individual contributors. Every project I&amp;#39;ve been on is like 8 business people and 2 data scientists and it&amp;#39;s completely unnecessary. The data scientists do all of the work while the business people circle jerk strategy that doesn&amp;#39;t make sense at all in the context of the data and we litterally have to show them why their idea doesn&amp;#39;t make sense on every project multipled times, we&amp;#39;re basically training them all over time and it&amp;#39;s really unnecessary. 
5. I spend way too much time in meetings to be an IC data scientist. I spend 20 to 25 hours a week in meetings on average and I have to actively participate in all of them.... I could accomplish so much more if I had less BS meetings but that would also require having less BS middle managers, etc. &lt;/p&gt;

&lt;p&gt;How about you?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17rrybm,True,,[deleted],,85,True,all_ads,False,[],,dark,/r/datascience/comments/17rrybm/top_5_things_you_dislike_about_your_team_role/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rrybm/top_5_things_you_dislike_about_your_team_role/,1209066,1699577389.0,0,,False,,,,,,,,,,1520,271
,datascience,"I'm taking over a project that will involve receiving 15-20M rows of data monthly, do some basic analysis on them (just sorting/deduping), and then distributing this data to some 3rd party companies.

I have been more on the Data Analyst side of things and while I'm proficient with R, SQL and Python, but I've never had to build a storage/pipeline nor have I worked with this amount of data at once before. It makes sense to use a third party storing solution and then run queries off the cloud. Am I on the right track?

To add to this, the storage must be HIPAA compliant since it will contain Personal Health Info (PHI).

Can anyone please point me in the right direction? Would something like Microsoft Dataverse or ~~Onedrive~~ Azure be useful or am I way off base here?

Thanks!

&amp;#x200B;

&amp;#x200B;",t2_706dl,False,,0,False,Advice on how to store and run queries on large amounts of medical data,[],r/datascience,False,6,network,0,,,False,t3_17rmrok,False,dark,1.0,,public,16,0,{},,,False,[],,False,False,,{},Analysis,False,16,,False,False,self,1699565238.0,,[],{},,True,,1699563245.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m taking over a project that will involve receiving 15-20M rows of data monthly, do some basic analysis on them (just sorting/deduping), and then distributing this data to some 3rd party companies.&lt;/p&gt;

&lt;p&gt;I have been more on the Data Analyst side of things and while I&amp;#39;m proficient with R, SQL and Python, but I&amp;#39;ve never had to build a storage/pipeline nor have I worked with this amount of data at once before. It makes sense to use a third party storing solution and then run queries off the cloud. Am I on the right track?&lt;/p&gt;

&lt;p&gt;To add to this, the storage must be HIPAA compliant since it will contain Personal Health Info (PHI).&lt;/p&gt;

&lt;p&gt;Can anyone please point me in the right direction? Would something like Microsoft Dataverse or &lt;del&gt;Onedrive&lt;/del&gt; Azure be useful or am I way off base here?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17rmrok,True,,mundus108,,24,True,all_ads,False,[],False,,/r/datascience/comments/17rmrok/advice_on_how_to_store_and_run_queries_on_large/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rmrok/advice_on_how_to_store_and_run_queries_on_large/,1209066,1699563245.0,0,,False,,,,,,,,,,813,142
,datascience,What does this mean for us?,t2_si6vdgwe,False,,0,False,Chatgpt can now analyze visualize data from csv/excel file input. Also build models.,[],r/datascience,False,6,discussion,0,,,False,t3_17ri3qk,False,dark,0.9,,public,264,0,{},,,False,[],,False,False,,{},Discussion,False,264,,False,False,self,False,,[],{},,True,,1699550704.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What does this mean for us?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ri3qk,True,,Content_Highlight269,,135,True,all_ads,False,[],False,,/r/datascience/comments/17ri3qk/chatgpt_can_now_analyze_visualize_data_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ri3qk/chatgpt_can_now_analyze_visualize_data_from/,1209066,1699550704.0,0,,False,,,,,,,,,,27,6
,datascience,"Hi r/datascience community,

I hope this post finds you well. I am currently working as a Senior Data Scientist with a background in Electrical Engineering (MSEE degree). I have been grappling with the idea of pursuing a Master's in Data Science to fill in any foundational gaps that might be hindering my work or leading to sporadic instances where I find myself revisiting fundamental concepts. I feel very strong in my mathematics background and took a lot of courses in statistics so I feel confident in understanding obscure content that takes a moment for me to digest. 

While my MSEE degree has equipped me with valuable skills, I can't shake the feeling that there might be some aspects of Data Science where I lack a solid foundation. I just feel like I am missing that extra intangible 'secret sauce' of I do not know what. I'm curious to hear from fellow professionals in the field, especially those who might have taken a similar path or faced a similar dilemma. I have tried doing the IBM Professional Data Science certification boot camp program, but it was just a bunch of feel-good filler from my perspective and work experience level. Maybe I have imposter syndrome still all this time later leaving school.

Here are a few specific questions I'd love to get your insights on:

1. Did you find pursuing an MS in Data Science beneficial even after working as a Senior Data Scientist for a while?

2. If you didn't pursue further education, how did you address any gaps in your foundational knowledge in Data Science?

3. Are there specific areas or concepts that you think are crucial for a Senior Data Scientist, which might be covered more comprehensively in a dedicated Data Science program?

4. For those who have made a similar transition from a different field, how did you bridge the gap and adapt to the demands of Data Science without formal education in the field?

I believe your experiences and advice will be incredibly valuable as I weigh the decision to pursue additional education. Your insights could not only help me but also others who might be in a similar situation.

Thank you in advance for taking the time to share your thoughts!",t2_d0tvi,False,,0,False,I have a MSEE degree working as a Senior Data Scientist after 4 years of work experience and am considering going back to school for a MS in Data Science. Need some insight/advice from a more seasoned individuals.,[],r/datascience,False,6,fun,0,,,False,t3_17rgygl,False,dark,0.88,,public,24,0,{},,,False,[],,False,False,,{},Career Discussion,False,24,,False,False,self,False,,[],{},,True,,1699547723.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt; community,&lt;/p&gt;

&lt;p&gt;I hope this post finds you well. I am currently working as a Senior Data Scientist with a background in Electrical Engineering (MSEE degree). I have been grappling with the idea of pursuing a Master&amp;#39;s in Data Science to fill in any foundational gaps that might be hindering my work or leading to sporadic instances where I find myself revisiting fundamental concepts. I feel very strong in my mathematics background and took a lot of courses in statistics so I feel confident in understanding obscure content that takes a moment for me to digest. &lt;/p&gt;

&lt;p&gt;While my MSEE degree has equipped me with valuable skills, I can&amp;#39;t shake the feeling that there might be some aspects of Data Science where I lack a solid foundation. I just feel like I am missing that extra intangible &amp;#39;secret sauce&amp;#39; of I do not know what. I&amp;#39;m curious to hear from fellow professionals in the field, especially those who might have taken a similar path or faced a similar dilemma. I have tried doing the IBM Professional Data Science certification boot camp program, but it was just a bunch of feel-good filler from my perspective and work experience level. Maybe I have imposter syndrome still all this time later leaving school.&lt;/p&gt;

&lt;p&gt;Here are a few specific questions I&amp;#39;d love to get your insights on:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Did you find pursuing an MS in Data Science beneficial even after working as a Senior Data Scientist for a while?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you didn&amp;#39;t pursue further education, how did you address any gaps in your foundational knowledge in Data Science?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Are there specific areas or concepts that you think are crucial for a Senior Data Scientist, which might be covered more comprehensively in a dedicated Data Science program?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For those who have made a similar transition from a different field, how did you bridge the gap and adapt to the demands of Data Science without formal education in the field?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I believe your experiences and advice will be incredibly valuable as I weigh the decision to pursue additional education. Your insights could not only help me but also others who might be in a similar situation.&lt;/p&gt;

&lt;p&gt;Thank you in advance for taking the time to share your thoughts!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17rgygl,True,,Renzodagreat,,33,True,all_ads,False,[],False,,/r/datascience/comments/17rgygl/i_have_a_msee_degree_working_as_a_senior_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rgygl/i_have_a_msee_degree_working_as_a_senior_data/,1209066,1699547723.0,0,,False,,,,,,,,,,2170,375
,datascience,"I'm going back to school for my 2nd Masters degree that my company is paying for thankfully. I have a technical background from my job in the Navy, and my civilian work has been as a Systems Analyst, Systems Engineer, and now as a Technical Operations Officer. My academic background is a B.S. in Business and an MBA. I had to take College Algebra, Business Calc, and Business Statistics. 

As I head into this Master's program, I have been debating if I should take some CS classes and math classes to prepare for it. My current plan is to take Discrete Math, Calc 1 &amp; 2, Linear Algebra, Intro to Programing, and the one require pre-req of Statistical Computing.

My question is, do I really need any of that math. My advisor has told me all I need is the Statistical Computing before I enter the MSDS program which is designed for students who are making a career change. I have a very basic understanding of Python, and I mean I know enough to copy/paste someone else's code and then sledge hammer into doing what I need it to do with a crap done of googling.

Any advice or insight would be greatly helpful.",t2_9nk0to8s,False,,0,False,Masters in Data Science Pre-course work question,[],r/datascience,False,6,,0,,,False,t3_17rfzhg,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Education,False,0,,False,False,self,False,,[],{},,True,,1699545112.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m going back to school for my 2nd Masters degree that my company is paying for thankfully. I have a technical background from my job in the Navy, and my civilian work has been as a Systems Analyst, Systems Engineer, and now as a Technical Operations Officer. My academic background is a B.S. in Business and an MBA. I had to take College Algebra, Business Calc, and Business Statistics. &lt;/p&gt;

&lt;p&gt;As I head into this Master&amp;#39;s program, I have been debating if I should take some CS classes and math classes to prepare for it. My current plan is to take Discrete Math, Calc 1 &amp;amp; 2, Linear Algebra, Intro to Programing, and the one require pre-req of Statistical Computing.&lt;/p&gt;

&lt;p&gt;My question is, do I really need any of that math. My advisor has told me all I need is the Statistical Computing before I enter the MSDS program which is designed for students who are making a career change. I have a very basic understanding of Python, and I mean I know enough to copy/paste someone else&amp;#39;s code and then sledge hammer into doing what I need it to do with a crap done of googling.&lt;/p&gt;

&lt;p&gt;Any advice or insight would be greatly helpful.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17rfzhg,True,,WanderingAnchor,,33,True,all_ads,False,[],False,,/r/datascience/comments/17rfzhg/masters_in_data_science_precourse_work_question/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rfzhg/masters_in_data_science_precourse_work_question/,1209066,1699545112.0,0,,False,,,,,,,,,,1115,204
,datascience,"How does seniority translate to data science from adjacent industries?

I have 8 years of experience in data analytics, making me a senior individual contributor who is shooting for manager. I lead and mentor other technical staff, and I have plenty of experience programming, scoping, designing, etc. I have an MPA with quantitative coursework, and I am following a rigorous data science self study program. However, I don't get repetitions building models at work, and my portfolio would just be personal projects.

I think I am actually overqualified for many aspects of entry level data scientist roles ... except perhaps for the core data science part! And although I could probably handle important aspects of senior roles, I am not sure I am competitive yet.

Do I aim high? Or do I start at the beginning and move up from within?

Thanks for the opinions.

**UPDATE:** Thanks for the responses and encouragement. Glad people are trying-- and sometimes succeeding-- to get what they are worth. A key insight from the conversation is that unadorned ""Data Scientist"" roles vary widely, and that many may actually be good challenges for mid-level career transitioners.",t2_s27ul7aa,False,,0,False,Translating seniority during career change,[],r/datascience,False,6,fun,0,,,False,t3_17ret5e,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,1699625080.0,,[],{},,True,,1699541948.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How does seniority translate to data science from adjacent industries?&lt;/p&gt;

&lt;p&gt;I have 8 years of experience in data analytics, making me a senior individual contributor who is shooting for manager. I lead and mentor other technical staff, and I have plenty of experience programming, scoping, designing, etc. I have an MPA with quantitative coursework, and I am following a rigorous data science self study program. However, I don&amp;#39;t get repetitions building models at work, and my portfolio would just be personal projects.&lt;/p&gt;

&lt;p&gt;I think I am actually overqualified for many aspects of entry level data scientist roles ... except perhaps for the core data science part! And although I could probably handle important aspects of senior roles, I am not sure I am competitive yet.&lt;/p&gt;

&lt;p&gt;Do I aim high? Or do I start at the beginning and move up from within?&lt;/p&gt;

&lt;p&gt;Thanks for the opinions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; Thanks for the responses and encouragement. Glad people are trying-- and sometimes succeeding-- to get what they are worth. A key insight from the conversation is that unadorned &amp;quot;Data Scientist&amp;quot; roles vary widely, and that many may actually be good challenges for mid-level career transitioners.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ret5e,True,,chiqui-bee,,10,True,all_ads,False,[],False,,/r/datascience/comments/17ret5e/translating_seniority_during_career_change/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ret5e/translating_seniority_during_career_change/,1209066,1699541948.0,0,,False,,,,,,,,,,1172,191
,datascience,"So I have been working as a DS in a global Bank ( same tier as hsbc, Citi not capital one,gs) for close to two years now. The pay is good but the work is mind numbingly slow and I am losing all my motivation to work. I have been put into an intermediary DS pm sort of role and I help guide the development of models.

Most of my work is just documentation and approvals and standards even before we manage to build a prototype we have to go through 100 fucking hoops and clearly redundant processes with glaring repetition of work but no senior management is willing to take a look at streamling that mess. Projects take months often years to complete and it's not like all the models are SOTA

I understand that banking is heavily regulated and I shouldn't expect the amount of independence as one perhaps gets in FAANG but still it feels like 80% of my job is just initiationg approvals and doing documentation. 

On a personal level this is really bringing me down because of recent increase in responsibilities I am not comfortable immediately changing the job role plus the brand looks good on a cv.

Would love to hear about mid career or senior individuals who have gone or are going through similar situations. What did you do? How did you cope? How long did you wait before saying ""fuck it..I want something new""",t2_gje3l6cm,False,,0,False,Feeling disillusioned at work as a DS in banking with ridiculous amounts of approvals and regulations and slow pace of work,[],r/datascience,False,6,fun,0,,,False,t3_17rdtjt,False,dark,0.93,,public,94,0,{},,,False,[],,False,False,,{},Career Discussion,False,94,,False,False,self,False,,[],{},,True,,1699539170.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have been working as a DS in a global Bank ( same tier as hsbc, Citi not capital one,gs) for close to two years now. The pay is good but the work is mind numbingly slow and I am losing all my motivation to work. I have been put into an intermediary DS pm sort of role and I help guide the development of models.&lt;/p&gt;

&lt;p&gt;Most of my work is just documentation and approvals and standards even before we manage to build a prototype we have to go through 100 fucking hoops and clearly redundant processes with glaring repetition of work but no senior management is willing to take a look at streamling that mess. Projects take months often years to complete and it&amp;#39;s not like all the models are SOTA&lt;/p&gt;

&lt;p&gt;I understand that banking is heavily regulated and I shouldn&amp;#39;t expect the amount of independence as one perhaps gets in FAANG but still it feels like 80% of my job is just initiationg approvals and doing documentation. &lt;/p&gt;

&lt;p&gt;On a personal level this is really bringing me down because of recent increase in responsibilities I am not comfortable immediately changing the job role plus the brand looks good on a cv.&lt;/p&gt;

&lt;p&gt;Would love to hear about mid career or senior individuals who have gone or are going through similar situations. What did you do? How did you cope? How long did you wait before saying &amp;quot;fuck it..I want something new&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17rdtjt,True,,Much_Discussion1490,,68,True,all_ads,False,[],False,,/r/datascience/comments/17rdtjt/feeling_disillusioned_at_work_as_a_ds_in_banking/,all_ads,False,https://www.reddit.com/r/datascience/comments/17rdtjt/feeling_disillusioned_at_work_as_a_ds_in_banking/,1209066,1699539170.0,0,,False,,,,,,,,,,1321,242
,datascience,"I am currently working in a management position leading a team of data scientists at a traditional slow growth non tech company in a remote role. I recently got an offer from a privately held Chinese tech company for a IC role that is paying almost same in cash but offers around $56K more (illiquid stocks). I am leaning towards saying No to the Chinese unless they offer significantly more cash. They need me to commute to office 3x a week, take calls at night and likely work way more than current role. I also suspect that I will be one of the more experienced people in that role at this Chinese company than my peers there. Looking for advice from the community.",t2_88p4sjyx,False,,0,False,Career advice,[],r/datascience,False,6,fun,0,,,False,t3_17r6hu5,False,dark,0.82,,public,24,0,{},,,False,[],,False,False,,{},Career Discussion,False,24,,False,False,self,False,,[],{},,True,,1699509839.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently working in a management position leading a team of data scientists at a traditional slow growth non tech company in a remote role. I recently got an offer from a privately held Chinese tech company for a IC role that is paying almost same in cash but offers around $56K more (illiquid stocks). I am leaning towards saying No to the Chinese unless they offer significantly more cash. They need me to commute to office 3x a week, take calls at night and likely work way more than current role. I also suspect that I will be one of the more experienced people in that role at this Chinese company than my peers there. Looking for advice from the community.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17r6hu5,True,,Bath_Flashy,,24,True,all_ads,False,[],False,,/r/datascience/comments/17r6hu5/career_advice/,all_ads,False,https://www.reddit.com/r/datascience/comments/17r6hu5/career_advice/,1209066,1699509839.0,0,,False,,,,,,,,,,668,123
,datascience,"How important are computer science (CS) fundamentals to data science roles   at tech companies? And how central are they to the application  process?

Tech companies like  Google, Meta, and Amazon offer public resources to help  job candidates understand work life and required skills. These resources  often  describe cross-functional teams of engineers, data scientists,  etc.  Advertised roles like ""machine learning engineer"" also seem to  inhabit  the gray area between software development engineer (SDE) and  data  scientist. Of course, these companies offer tech products at huge scale, and at least for SDEs, CS knowledge is a focus.

However,   many data science learning materials focus on the math and techniques for analyzing data and building models, with programming as essentially a  means to those ends.

As  someone  interested in exploring tech, I am wondering if formal study of  data  structures, algorithms, computational complexity, etc., should be  a  bigger part of my diet.

I appreciate your answers. It's helpful to know your connection to this topic too (e.g., recruiter, team member, fellow candidate).

**EDIT:** I take it for granted that folks need to know how to write maintainable code and use programing tools like git, unit tests, etc. By CS fundamentals I am thinking of concepts or design patterns that enable software to scale efficiently. Thanks for clarifying questions.

**UPDATE:** Thanks for all the input. To summarize several great comments drawing from individual professional experience:

&gt; Data Scientists (DS) and ML Engineers (MLE) need different skills; generally these roles are not interchangeable. Large companies may be able to specialize so that DS focus on models and collaborate with MLE for scaling. Smaller companies may have more generalists. CS knowledge requirements may also vary by different areas of a company (e.g., product vs engineering).
&gt;
&gt; A DS with CS knowledge may collaborate better and enjoy more career mobility. However, entry level DS can generally begin with rudimentary CS knowledge and grow on the job.

Couple follow-ups for those who want more:

- The hiring guides I mention focus more on SDE. Seen any good ones for DS?
- I feel like I see more MLE than DS reqs. How does demand compare?",t2_s27ul7aa,False,,0,False,Importance of CS fundamentals for data science roles in tech,[],r/datascience,False,6,fun,0,,,False,t3_17qql6b,False,dark,0.89,,public,60,0,{},,,False,[],,False,False,,{},Career Discussion,False,60,,False,False,self,1699541047.0,,[],{},,True,,1699464103.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How important are computer science (CS) fundamentals to data science roles   at tech companies? And how central are they to the application  process?&lt;/p&gt;

&lt;p&gt;Tech companies like  Google, Meta, and Amazon offer public resources to help  job candidates understand work life and required skills. These resources  often  describe cross-functional teams of engineers, data scientists,  etc.  Advertised roles like &amp;quot;machine learning engineer&amp;quot; also seem to  inhabit  the gray area between software development engineer (SDE) and  data  scientist. Of course, these companies offer tech products at huge scale, and at least for SDEs, CS knowledge is a focus.&lt;/p&gt;

&lt;p&gt;However,   many data science learning materials focus on the math and techniques for analyzing data and building models, with programming as essentially a  means to those ends.&lt;/p&gt;

&lt;p&gt;As  someone  interested in exploring tech, I am wondering if formal study of  data  structures, algorithms, computational complexity, etc., should be  a  bigger part of my diet.&lt;/p&gt;

&lt;p&gt;I appreciate your answers. It&amp;#39;s helpful to know your connection to this topic too (e.g., recruiter, team member, fellow candidate).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I take it for granted that folks need to know how to write maintainable code and use programing tools like git, unit tests, etc. By CS fundamentals I am thinking of concepts or design patterns that enable software to scale efficiently. Thanks for clarifying questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; Thanks for all the input. To summarize several great comments drawing from individual professional experience:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Data Scientists (DS) and ML Engineers (MLE) need different skills; generally these roles are not interchangeable. Large companies may be able to specialize so that DS focus on models and collaborate with MLE for scaling. Smaller companies may have more generalists. CS knowledge requirements may also vary by different areas of a company (e.g., product vs engineering).&lt;/p&gt;

&lt;p&gt;A DS with CS knowledge may collaborate better and enjoy more career mobility. However, entry level DS can generally begin with rudimentary CS knowledge and grow on the job.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Couple follow-ups for those who want more:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The hiring guides I mention focus more on SDE. Seen any good ones for DS?&lt;/li&gt;
&lt;li&gt;I feel like I see more MLE than DS reqs. How does demand compare?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17qql6b,True,,chiqui-bee,,26,True,all_ads,False,[],False,,/r/datascience/comments/17qql6b/importance_of_cs_fundamentals_for_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17qql6b/importance_of_cs_fundamentals_for_data_science/,1209066,1699464103.0,0,,False,,,,,,,,,,2284,358
,datascience,"I gave this talk at PyData NYC last week. It was fun working with devs from various projects (Dask, Arrow, Polars, Spark) in the week leading up to the event. Thought I'd share a re-recording of it here

[https://youtu.be/wKH0-zs2g\_U](https://youtu.be/wKH0-zs2g_U)

This is the result of a couple weeks of work comparing large data frameworks on benchmarks ranging in size 10GB to 10TB. No project wins. It's really interesting analyzing results though.

DuckDB and Dask are the only projects that reliably finish things (although possibly Dask's success here has to do with me knowing Dask better than the others). DuckDB is way faster at small scale (along with Polars). Dask and Spark are generally more robust and performant at large scale, mostly because they're able to parallelize S3 access. Really-good-S3 access seems to be the way you win at real-world cloud performance.

Looking more deeply at Dask results, we're wildly inefficient. There's at least a 2x-5x performance increase to be had here. Given that Dask does about as well as any other project on cloud this really means that \*no one\* has optimized cloud well yet.

This talk also goes into how we attempted to address bias (super hard to do in benchmarks). We had active collaborations with Polars and Spark people (made Polars quite a bit faster during this process actually). See [https://matthewrocklin.com/biased-benchmarks.html](https://matthewrocklin.com/biased-benchmarks.html) for more thoughts.

This also shows the improvement Dask made in the last six months. Dask used to suck at benchmarks. Now it doesn't win, but reliably places among the top. This is due to ...

1. Arrow strings
2. New shuffling algorithms
3. Query optimization

There's a lot of work for projects like Dask and Polars to fix themselves up in this space. They're both moving pretty fast right now. I'm curious to see how they progress in the next few months.

For future work I'd like to expand this out a bit beyond TPC-H. TPC-H is great because they're fairly serious queries (lots of tables, lots of joins) and not micro-benchmarks. We could use broader coverage though. Any ideas?",t2_ay1q1,False,,0,False,"Spark, Dask, DuckDB, Polars: TPC-H Benchmarks at Scale",[],r/datascience,False,6,discussion,0,,,False,t3_17qm6ob,False,dark,0.97,,public,71,0,{},,,False,[],,False,False,,{},Discussion,False,71,,False,False,self,False,,[],{},,True,,1699451814.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I gave this talk at PyData NYC last week. It was fun working with devs from various projects (Dask, Arrow, Polars, Spark) in the week leading up to the event. Thought I&amp;#39;d share a re-recording of it here&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://youtu.be/wKH0-zs2g_U""&gt;https://youtu.be/wKH0-zs2g_U&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the result of a couple weeks of work comparing large data frameworks on benchmarks ranging in size 10GB to 10TB. No project wins. It&amp;#39;s really interesting analyzing results though.&lt;/p&gt;

&lt;p&gt;DuckDB and Dask are the only projects that reliably finish things (although possibly Dask&amp;#39;s success here has to do with me knowing Dask better than the others). DuckDB is way faster at small scale (along with Polars). Dask and Spark are generally more robust and performant at large scale, mostly because they&amp;#39;re able to parallelize S3 access. Really-good-S3 access seems to be the way you win at real-world cloud performance.&lt;/p&gt;

&lt;p&gt;Looking more deeply at Dask results, we&amp;#39;re wildly inefficient. There&amp;#39;s at least a 2x-5x performance increase to be had here. Given that Dask does about as well as any other project on cloud this really means that *no one* has optimized cloud well yet.&lt;/p&gt;

&lt;p&gt;This talk also goes into how we attempted to address bias (super hard to do in benchmarks). We had active collaborations with Polars and Spark people (made Polars quite a bit faster during this process actually). See &lt;a href=""https://matthewrocklin.com/biased-benchmarks.html""&gt;https://matthewrocklin.com/biased-benchmarks.html&lt;/a&gt; for more thoughts.&lt;/p&gt;

&lt;p&gt;This also shows the improvement Dask made in the last six months. Dask used to suck at benchmarks. Now it doesn&amp;#39;t win, but reliably places among the top. This is due to ...&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Arrow strings&lt;/li&gt;
&lt;li&gt;New shuffling algorithms&lt;/li&gt;
&lt;li&gt;Query optimization&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There&amp;#39;s a lot of work for projects like Dask and Polars to fix themselves up in this space. They&amp;#39;re both moving pretty fast right now. I&amp;#39;m curious to see how they progress in the next few months.&lt;/p&gt;

&lt;p&gt;For future work I&amp;#39;d like to expand this out a bit beyond TPC-H. TPC-H is great because they&amp;#39;re fairly serious queries (lots of tables, lots of joins) and not micro-benchmarks. We could use broader coverage though. Any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17qm6ob,True,,mrocklin,,17,True,all_ads,False,[],False,,/r/datascience/comments/17qm6ob/spark_dask_duckdb_polars_tpch_benchmarks_at_scale/,all_ads,False,https://www.reddit.com/r/datascience/comments/17qm6ob/spark_dask_duckdb_polars_tpch_benchmarks_at_scale/,1209066,1699451814.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?auto=webp&amp;s=da7d0b2e1dddb9a541c5e00e32b0c0febbc324d4', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=599f0b55752f80a746571a6d0466f0cdf6c55888', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c171018f1df6b821ac69934e98ca441dddb8e196', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f10e3936368e5aa15f9ccbf80970e40ff6a6857', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'NXJ6LdhKF_lKsbQSg6ourXQ88ir9X8cDbT37Oe33T6o'}], 'enabled': False}",,,,,,,2142,343
,datascience,"Hi guys
Is there anyone already working in the Data Science space in the sustainability/ climate change / improving agriculture in underprivileged countries.
- If yes, how did you get it?
- Is it actually making some positive change
- How is the pay
- What are skillsets other than traditional DS skillsets

PS. I case across a few consulting companies like BCG, McKinsey, etc.",t2_4by5u4cw0,False,,0,False,"Anybody in Sustainability DS, how did you get?",[],r/datascience,False,6,fun,0,,,False,t3_17qdw3a,False,dark,0.93,,public,48,0,{},,,False,[],,False,False,,{},Career Discussion,False,48,,False,False,self,False,,[],{},,True,,1699418083.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys
Is there anyone already working in the Data Science space in the sustainability/ climate change / improving agriculture in underprivileged countries.
- If yes, how did you get it?
- Is it actually making some positive change
- How is the pay
- What are skillsets other than traditional DS skillsets&lt;/p&gt;

&lt;p&gt;PS. I case across a few consulting companies like BCG, McKinsey, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17qdw3a,True,,exploring_lifenow,,17,True,all_ads,False,[],False,,/r/datascience/comments/17qdw3a/anybody_in_sustainability_ds_how_did_you_get/,all_ads,False,https://www.reddit.com/r/datascience/comments/17qdw3a/anybody_in_sustainability_ds_how_did_you_get/,1209066,1699418083.0,0,,False,,,,,,,,,,377,65
,datascience,"(repost because of karma req)

I'm not sure this is within the rules but I'll try.

I'm a high school student in a college-level course. We are having a career-choice assignment where we interview people in our future interests. One of mine is data science. So if anyone could answer like ten questions in dms that would be great. I don't need anything identifiable. I may not be able to get to questions in the next few hours but I'll try my best.",t2_a87umie9,False,,0,False,Q/A interview for a school project,[],r/datascience,False,6,fun,0,,,False,t3_17q2wu7,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1699387103.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;(repost because of karma req)&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not sure this is within the rules but I&amp;#39;ll try.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a high school student in a college-level course. We are having a career-choice assignment where we interview people in our future interests. One of mine is data science. So if anyone could answer like ten questions in dms that would be great. I don&amp;#39;t need anything identifiable. I may not be able to get to questions in the next few hours but I&amp;#39;ll try my best.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17q2wu7,True,,AssumptionNo5436,,4,True,all_ads,False,[],False,,/r/datascience/comments/17q2wu7/qa_interview_for_a_school_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/17q2wu7/qa_interview_for_a_school_project/,1209066,1699387103.0,0,,False,,,,,,,,,,448,83
,datascience,Just curious more than anythin,t2_89ar1fajx,False,,0,False,"If you've worked in multiple DS positions or DS-adjacent positions, what were some of the biggest differences across the positions?",[],r/datascience,False,6,fun,0,,,False,t3_17pyehy,False,dark,0.88,,public,18,0,{},,,False,[],,False,False,,{},Career Discussion,False,18,,False,False,self,False,,[],{},,True,,1699375244.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just curious more than anythin&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17pyehy,True,,AnxiousEgg6284,,12,True,all_ads,False,[],False,,/r/datascience/comments/17pyehy/if_youve_worked_in_multiple_ds_positions_or/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pyehy/if_youve_worked_in_multiple_ds_positions_or/,1209066,1699375244.0,0,,False,,,,,,,,,,30,5
,datascience,"I’m in my first semester in my grad program for data science and I’m writing/working on a research paper involving clustering/topic modeling on fake news and disinformation. I have a dataset containing both honest and fake news articles separated into two separate tables, so I can technically label each article as either honest news and fake news. With the dataset, I created three datasets:
- a sample dataset for testing
- a training dataset of honest news removing the articles that were grabbed for testing
- a training dataset of fake news removing the articles that were grabbed for testing.

From there I went to train two models using LDA Model from Gensim, one for honest news and one for fake news. 

Then I ran the testing dataset against both models to get an output of values that are topics of the individual article and the similarity they are to each model. If the article is more similar to the fake news model, then it flagged for fake news/disinformation. 

My question is that is the fact that I created two different models turn this into a supervised classification solution, rather than a topic modeling solution?",t2_8rwxp4x5,False,,0,False,Did I turn my clustering/topic modeling project into a classification project?,[],r/datascience,False,6,meta,0,,,False,t3_17pwmj0,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Projects,False,5,,False,False,self,False,,[],{},,True,,1699370461.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m in my first semester in my grad program for data science and I’m writing/working on a research paper involving clustering/topic modeling on fake news and disinformation. I have a dataset containing both honest and fake news articles separated into two separate tables, so I can technically label each article as either honest news and fake news. With the dataset, I created three datasets:
- a sample dataset for testing
- a training dataset of honest news removing the articles that were grabbed for testing
- a training dataset of fake news removing the articles that were grabbed for testing.&lt;/p&gt;

&lt;p&gt;From there I went to train two models using LDA Model from Gensim, one for honest news and one for fake news. &lt;/p&gt;

&lt;p&gt;Then I ran the testing dataset against both models to get an output of values that are topics of the individual article and the similarity they are to each model. If the article is more similar to the fake news model, then it flagged for fake news/disinformation. &lt;/p&gt;

&lt;p&gt;My question is that is the fact that I created two different models turn this into a supervised classification solution, rather than a topic modeling solution?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17pwmj0,True,,AndThenAlongCameZeus,,7,True,all_ads,False,[],False,,/r/datascience/comments/17pwmj0/did_i_turn_my_clusteringtopic_modeling_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pwmj0/did_i_turn_my_clusteringtopic_modeling_project/,1209066,1699370461.0,0,,False,,,,,,,,,,1138,195
,datascience,"Hey folks, 

Background story: This semester I'm taking a machine learning class and noticed some aspects of the course were a bit odd.

1. Roughly a third of the class is about logic-based AI, problog, and some niche techniques that are either seldom used or just outright outdated.
2. The teacher made a lot of bold assumptions (not taking into account potential distribution shifts, assuming computational resources are for free \[e.g. **Leave One Out Cross-Validation**\])
3. There was no mention of MLOps or what actually matters for machine learning in production.
4. Deep Learning models were outdated and presented as if though they were SOTA.
5. A lot of evaluation methods or techniques seem to make sense within a research or academic setting but are rather hard to use in the real world or are seldom asked by stakeholders.

(This is a biased opinion based off of 4 internships at various companies)

This is just one class but I'm just wondering if it's common for professors to have a biased opinion while teaching (favouring academic techniques and topics rather than what would be done in the industry)

Also, have you noticed a positive trend towards more down-to-earth topics and classes over the years?

Cheers, 

&amp;#x200B;

&amp;#x200B;",t2_161fpq,False,,0,False,"Did you notice a loss of touch with reality from your college teachers? (w.r.t. modern practices, or what's actually done in the real world)",[],r/datascience,False,6,,0,,,False,t3_17pw6fx,False,dark,0.78,,public,120,0,{},,,False,[],,False,False,,{},Education,False,120,,False,False,self,False,,[],{},,True,,1699369245.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks, &lt;/p&gt;

&lt;p&gt;Background story: This semester I&amp;#39;m taking a machine learning class and noticed some aspects of the course were a bit odd.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Roughly a third of the class is about logic-based AI, problog, and some niche techniques that are either seldom used or just outright outdated.&lt;/li&gt;
&lt;li&gt;The teacher made a lot of bold assumptions (not taking into account potential distribution shifts, assuming computational resources are for free [e.g. &lt;strong&gt;Leave One Out Cross-Validation&lt;/strong&gt;])&lt;/li&gt;
&lt;li&gt;There was no mention of MLOps or what actually matters for machine learning in production.&lt;/li&gt;
&lt;li&gt;Deep Learning models were outdated and presented as if though they were SOTA.&lt;/li&gt;
&lt;li&gt;A lot of evaluation methods or techniques seem to make sense within a research or academic setting but are rather hard to use in the real world or are seldom asked by stakeholders.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(This is a biased opinion based off of 4 internships at various companies)&lt;/p&gt;

&lt;p&gt;This is just one class but I&amp;#39;m just wondering if it&amp;#39;s common for professors to have a biased opinion while teaching (favouring academic techniques and topics rather than what would be done in the industry)&lt;/p&gt;

&lt;p&gt;Also, have you noticed a positive trend towards more down-to-earth topics and classes over the years?&lt;/p&gt;

&lt;p&gt;Cheers, &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17pw6fx,True,,Inquation,,93,True,all_ads,False,[],False,,/r/datascience/comments/17pw6fx/did_you_notice_a_loss_of_touch_with_reality_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pw6fx/did_you_notice_a_loss_of_touch_with_reality_from/,1209066,1699369245.0,0,,False,,,,,,,,,,1259,206
,datascience,I have experimented with tuning the hyperparameters at work but most of the time I have noticed it barely make a significant difference especially tree based models. Just curious to know what’s your experience have been in your production models? How big of a impact you have seen? I usually spend more time in getting the right set of features then tuning. ,t2_773x6aj9,False,,0,False,Does hyper parameter tuning really make sense especially in tree based?,[],r/datascience,False,6,,0,,,False,t3_17pu5iz,False,dark,0.9,,public,51,0,{},,,False,[],,False,False,,{},Education,False,51,,False,False,self,False,,[],{},,True,,1699363307.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have experimented with tuning the hyperparameters at work but most of the time I have noticed it barely make a significant difference especially tree based models. Just curious to know what’s your experience have been in your production models? How big of a impact you have seen? I usually spend more time in getting the right set of features then tuning. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17pu5iz,True,,Love_Tech,,46,True,all_ads,False,[],False,,/r/datascience/comments/17pu5iz/does_hyper_parameter_tuning_really_make_sense/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pu5iz/does_hyper_parameter_tuning_really_make_sense/,1209066,1699363307.0,0,,False,,,,,,,,,,358,62
,datascience,"For anyone who hasn't heard of it, the [Advent of Code](https://adventofcode.com/) is an annual event where coding challenges and puzzles are posted everyday throughout December. The solutions to the puzzles are language agnostic and and are intended as fun story-driven exercises to improve coding in whatever language the user chooses to use.

I am a data scientist and have been coding in R and python for a long time. Recently, I have started using Typescript to work with API building and CI/CD pipelines for my models within my company.

I'm curious whether any other data people are taking part in AoC this year, what languages you are planning to use and what language you think would be most beneficial/fun for me to complete it in!

Obviously, I do not want to do it in R or Python as I am well versed in these, and I think I have enough of a grasp of Typescript to not want to do that either.",t2_g8wyf,False,,0,False,Advent of Code Suggestions,[],r/datascience,False,6,,0,,,False,t3_17pt73u,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Challenges,False,3,,False,False,self,False,,[],{},,True,,1699360161.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For anyone who hasn&amp;#39;t heard of it, the &lt;a href=""https://adventofcode.com/""&gt;Advent of Code&lt;/a&gt; is an annual event where coding challenges and puzzles are posted everyday throughout December. The solutions to the puzzles are language agnostic and and are intended as fun story-driven exercises to improve coding in whatever language the user chooses to use.&lt;/p&gt;

&lt;p&gt;I am a data scientist and have been coding in R and python for a long time. Recently, I have started using Typescript to work with API building and CI/CD pipelines for my models within my company.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m curious whether any other data people are taking part in AoC this year, what languages you are planning to use and what language you think would be most beneficial/fun for me to complete it in!&lt;/p&gt;

&lt;p&gt;Obviously, I do not want to do it in R or Python as I am well versed in these, and I think I have enough of a grasp of Typescript to not want to do that either.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,17pt73u,True,,MyKo101,,4,True,all_ads,False,[],False,,/r/datascience/comments/17pt73u/advent_of_code_suggestions/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pt73u/advent_of_code_suggestions/,1209066,1699360161.0,0,,False,,,,,,,,,,903,162
,datascience,"Hey all,

I recently put ""open to opportunities"" on my linkedin as I am ready to start looking for a new job. Now, I'm getting some 10+ messages a week from technical recruiters about opportunities. Opportunities are all either: Data engineering, Data science, or software engineering related.

In your experience, are engaging with these recruiters an often fruitful experience and are there any good jobs to be had this way? My idea is: if I'm a company of some repute I'm likely not spending money working with a talent agency, so all of the opportunities these men and women represent are those on the low end of desire for a prospective DE, DS, SWE as myself, am I right or wrong and what is your experience? 

Thank you!",t2_i7ayqhxyj,False,,0,False,QQ- Linkedin inmail technical recruiters,[],r/datascience,False,6,fun,0,,,False,t3_17pj1s8,False,dark,0.75,,public,6,0,{},,,False,[],,False,False,,{},Career Discussion,False,6,,False,False,self,False,,[],{},,True,,1699320828.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all,&lt;/p&gt;

&lt;p&gt;I recently put &amp;quot;open to opportunities&amp;quot; on my linkedin as I am ready to start looking for a new job. Now, I&amp;#39;m getting some 10+ messages a week from technical recruiters about opportunities. Opportunities are all either: Data engineering, Data science, or software engineering related.&lt;/p&gt;

&lt;p&gt;In your experience, are engaging with these recruiters an often fruitful experience and are there any good jobs to be had this way? My idea is: if I&amp;#39;m a company of some repute I&amp;#39;m likely not spending money working with a talent agency, so all of the opportunities these men and women represent are those on the low end of desire for a prospective DE, DS, SWE as myself, am I right or wrong and what is your experience? &lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17pj1s8,True,,takemetojupyter,,19,True,all_ads,False,[],False,,/r/datascience/comments/17pj1s8/qq_linkedin_inmail_technical_recruiters/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pj1s8/qq_linkedin_inmail_technical_recruiters/,1209066,1699320828.0,0,,False,,,,,,,,,,726,128
,datascience,"Let's say we have x that has quite large dimension p. So we reduce it to n dimension Ax where A is n by p matrix, with n&lt;&lt;p.

Compressed sensing is basically asking how to recover x from Ax, and what condition on A we need for full recovery of x.

For A, theoretically speaking we can use randomized matrix, but also there's some neat greedy algorithm to recover x when A is special.

Is this compressed sensing in the purview of everyday data science workflow, like in feature engineering process? The answer might be ""not at all"" but I'm a new grad trying to figure out what kind of unique value I can demonstrate to the potential employer and want to know if this can be one of my selling points, 

Or, would the answer be ""if you're not phd/postdoc, don't bother""?

Sorry if this question is dumb. I'd appreciate any insight.",t2_6gxwhbsk,False,,0,False,Is compressed sensing useful in data science?,[],r/datascience,False,6,,0,,,False,t3_17pihhm,False,dark,1.0,,public,13,0,{},,,False,[],,False,False,,{},DE,False,13,,False,False,self,1699319538.0,,[],{},,True,,1699319139.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let&amp;#39;s say we have x that has quite large dimension p. So we reduce it to n dimension Ax where A is n by p matrix, with n&amp;lt;&amp;lt;p.&lt;/p&gt;

&lt;p&gt;Compressed sensing is basically asking how to recover x from Ax, and what condition on A we need for full recovery of x.&lt;/p&gt;

&lt;p&gt;For A, theoretically speaking we can use randomized matrix, but also there&amp;#39;s some neat greedy algorithm to recover x when A is special.&lt;/p&gt;

&lt;p&gt;Is this compressed sensing in the purview of everyday data science workflow, like in feature engineering process? The answer might be &amp;quot;not at all&amp;quot; but I&amp;#39;m a new grad trying to figure out what kind of unique value I can demonstrate to the potential employer and want to know if this can be one of my selling points, &lt;/p&gt;

&lt;p&gt;Or, would the answer be &amp;quot;if you&amp;#39;re not phd/postdoc, don&amp;#39;t bother&amp;quot;?&lt;/p&gt;

&lt;p&gt;Sorry if this question is dumb. I&amp;#39;d appreciate any insight.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,271d2932-70eb-11ee-b552-0a391e3dc147,False,False,False,,[],False,,,,t5_2sptq,False,,,#0dd3bb,17pihhm,True,,RightProfile0,,12,True,all_ads,False,[],False,,/r/datascience/comments/17pihhm/is_compressed_sensing_useful_in_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pihhm/is_compressed_sensing_useful_in_data_science/,1209066,1699319139.0,0,,False,,,,,,,,,,835,153
,datascience,"I have been in a DS/Research role for the last 6 years with Company A. Last week I accepted an offer to join Company B for a significant title and pay bump, and subsequently gave my 2 weeks notice to Company A. My boss at Company A asked if I'd consider doing some on-the-side work after resigning in order to help maintain momentum on my various projects after handover; this is not unprecedented for former team members to do, but to my knowledge all of those who did so were not US-based (and as such the technicalities around contracting might be simpler than here in the US). 

In principle I'm not opposed to picking up a couple hours a week, and indicated such to my boss. HR has already reached out to inquire about a rate, and whether it would be in the same ballpark as my current FTE salary rate. I replied that I'd need to do some research on norms before discussing rates &amp; terms. From what I've gathered, there are some specific considerations involved with 1099 work (which is how I presume it would be set up):

* I'd need to handle my own tax withholding for 1099 income, and also be prepared for a higher tax burden from paying the full FICA rate.
* I'd ideally need to instantiate an LLC and maintain liability insurance for damages in the event something breaks under my watch.
* I'd ideally need to hire an attorney to review the terms of whatever contract I am agreeing to.

Given the above, as well as generally up-charging for off-hours time, I am reading that charging 2x my former FTE rate would be the floor for what I should accept; 3x would be better and fairly standard; 4x is not unheard of (particularly in instances where the contracted employee has deep institutional/domain knowledge).


My questions are: 

1) Is ~3x my FTE rate a reasonable target, or should I adjust my expectations? (my gut says it's not worth my time for anything less, unless I've gotten the wrong impression of what the norms are). 

2) Besides taxes, LLCs and attorney reviews, are there any major considerations I'm overlooking? 

3) Does anyone have any general experience in this sort of arrangement that they'd care to share?

Thanks for any input!",t2_5qa5p,False,,0,False,Questions about part time contracting for a former employer.,[],r/datascience,False,6,fun,0,,,False,t3_17phpkh,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1699316900.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been in a DS/Research role for the last 6 years with Company A. Last week I accepted an offer to join Company B for a significant title and pay bump, and subsequently gave my 2 weeks notice to Company A. My boss at Company A asked if I&amp;#39;d consider doing some on-the-side work after resigning in order to help maintain momentum on my various projects after handover; this is not unprecedented for former team members to do, but to my knowledge all of those who did so were not US-based (and as such the technicalities around contracting might be simpler than here in the US). &lt;/p&gt;

&lt;p&gt;In principle I&amp;#39;m not opposed to picking up a couple hours a week, and indicated such to my boss. HR has already reached out to inquire about a rate, and whether it would be in the same ballpark as my current FTE salary rate. I replied that I&amp;#39;d need to do some research on norms before discussing rates &amp;amp; terms. From what I&amp;#39;ve gathered, there are some specific considerations involved with 1099 work (which is how I presume it would be set up):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I&amp;#39;d need to handle my own tax withholding for 1099 income, and also be prepared for a higher tax burden from paying the full FICA rate.&lt;/li&gt;
&lt;li&gt;I&amp;#39;d ideally need to instantiate an LLC and maintain liability insurance for damages in the event something breaks under my watch.&lt;/li&gt;
&lt;li&gt;I&amp;#39;d ideally need to hire an attorney to review the terms of whatever contract I am agreeing to.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given the above, as well as generally up-charging for off-hours time, I am reading that charging 2x my former FTE rate would be the floor for what I should accept; 3x would be better and fairly standard; 4x is not unheard of (particularly in instances where the contracted employee has deep institutional/domain knowledge).&lt;/p&gt;

&lt;p&gt;My questions are: &lt;/p&gt;

&lt;p&gt;1) Is ~3x my FTE rate a reasonable target, or should I adjust my expectations? (my gut says it&amp;#39;s not worth my time for anything less, unless I&amp;#39;ve gotten the wrong impression of what the norms are). &lt;/p&gt;

&lt;p&gt;2) Besides taxes, LLCs and attorney reviews, are there any major considerations I&amp;#39;m overlooking? &lt;/p&gt;

&lt;p&gt;3) Does anyone have any general experience in this sort of arrangement that they&amp;#39;d care to share?&lt;/p&gt;

&lt;p&gt;Thanks for any input!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17phpkh,True,,usescience,,11,True,all_ads,False,[],False,,/r/datascience/comments/17phpkh/questions_about_part_time_contracting_for_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/17phpkh/questions_about_part_time_contracting_for_a/,1209066,1699316900.0,0,,False,,,,,,,,,,2166,386
,datascience,"If you had to leave an advice for any HR or hiring manager in your domain, what would it be? For e.g. any advice related to shortlisting resumes, evaluating experience, interviewing, etc.",t2_al1087x2,False,,0,False,"If you have to give one piece of advice to HR/hiring managers, what would it be?",[],r/datascience,False,6,fun,0,,,False,t3_17pevh7,False,dark,0.8,,public,25,0,{},,,False,[],,False,False,,{},Career Discussion,False,25,,False,False,self,False,,[],{},,True,,1699309189.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you had to leave an advice for any HR or hiring manager in your domain, what would it be? For e.g. any advice related to shortlisting resumes, evaluating experience, interviewing, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17pevh7,True,,OverratedDataScience,,94,True,all_ads,False,[],False,,/r/datascience/comments/17pevh7/if_you_have_to_give_one_piece_of_advice_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17pevh7/if_you_have_to_give_one_piece_of_advice_to/,1209066,1699309189.0,0,,False,,,,,,,,,,187,32
,datascience,I am currently going through Richard McElreath's Statistical Rethinking and being a primary python user I am trying to mirror it in pymc but getting even simple things can be absurdly difficult. I'm not sure if this is a user error or not.,t2_3kdgnq0f,False,,0,False,Is pymc hard to use or am I just bad?,[],r/datascience,False,6,,0,,,False,t3_17parj6,False,dark,0.96,,public,49,0,{},,,False,[],,False,False,,{},Statistics,False,49,,False,False,self,False,,[],{},,True,,1699298832.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently going through Richard McElreath&amp;#39;s Statistical Rethinking and being a primary python user I am trying to mirror it in pymc but getting even simple things can be absurdly difficult. I&amp;#39;m not sure if this is a user error or not.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,17parj6,True,,Jbor941197,,24,True,all_ads,False,[],False,,/r/datascience/comments/17parj6/is_pymc_hard_to_use_or_am_i_just_bad/,all_ads,False,https://www.reddit.com/r/datascience/comments/17parj6/is_pymc_hard_to_use_or_am_i_just_bad/,1209066,1699298832.0,0,,False,,,,,,,,,,239,43
,datascience,"Hi all, I’m an old school data scientist and full stack engineer and looking for ways to grow in the new GenAI and LLM field. I have been hearing a lot about Postgres vectors for improved model performance but can’t quite understand how to leverage them. Just wanted to know if anyone has used them and if so what models/use cases?",t2_6rx6vac,False,,0,False,Pgvectors Use Application,[],r/datascience,False,6,fun,0,,,False,t3_17p9w8a,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1699296569.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I’m an old school data scientist and full stack engineer and looking for ways to grow in the new GenAI and LLM field. I have been hearing a lot about Postgres vectors for improved model performance but can’t quite understand how to leverage them. Just wanted to know if anyone has used them and if so what models/use cases?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17p9w8a,True,,Short_SNAP,,2,True,all_ads,False,[],False,,/r/datascience/comments/17p9w8a/pgvectors_use_application/,all_ads,False,https://www.reddit.com/r/datascience/comments/17p9w8a/pgvectors_use_application/,1209066,1699296569.0,0,,False,,,,,,,,,,331,61
,datascience,"I am trying a focused approach of applying to select few companies and trying to get hold of hiring manager.

But the recruiters or the team members(I check if they belong to the correct team) simply refuse to tell me and ask me to apply on the portal. I look up titles like Analytics manager, Head, leader, etc.

The numbers game isn't working out, and I am not sure how to network. 

I'm working on my portfolio, but what's the point if I am unable to show to hiring manager/recruiters?",t2_736ioria,False,,0,False,How can I network properly?,[],r/datascience,False,6,fun,0,,,False,t3_17p6oqo,False,dark,0.56,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1699288318.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying a focused approach of applying to select few companies and trying to get hold of hiring manager.&lt;/p&gt;

&lt;p&gt;But the recruiters or the team members(I check if they belong to the correct team) simply refuse to tell me and ask me to apply on the portal. I look up titles like Analytics manager, Head, leader, etc.&lt;/p&gt;

&lt;p&gt;The numbers game isn&amp;#39;t working out, and I am not sure how to network. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on my portfolio, but what&amp;#39;s the point if I am unable to show to hiring manager/recruiters?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17p6oqo,True,,jaegarbong,,15,True,all_ads,False,[],False,,/r/datascience/comments/17p6oqo/how_can_i_network_properly/,all_ads,False,https://www.reddit.com/r/datascience/comments/17p6oqo/how_can_i_network_properly/,1209066,1699288318.0,0,,False,,,,,,,,,,488,90
,datascience,"I am curious to know how many features you all use in your production model without going into over fitting and stability. We currently run few models like RF , xgboost etc with around 200 features to predict user spend in our website. Curious to know what others are doing?",t2_773x6aj9,False,,0,False,How many features are too many features??,[],r/datascience,False,6,,0,,,False,t3_17p5tct,False,dark,0.83,,public,33,0,{},,,False,[],,False,False,,{},Education,False,33,,False,False,self,False,,[],{},,True,,1699285984.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am curious to know how many features you all use in your production model without going into over fitting and stability. We currently run few models like RF , xgboost etc with around 200 features to predict user spend in our website. Curious to know what others are doing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17p5tct,True,,Love_Tech,,70,True,all_ads,False,[],False,,/r/datascience/comments/17p5tct/how_many_features_are_too_many_features/,all_ads,False,https://www.reddit.com/r/datascience/comments/17p5tct/how_many_features_are_too_many_features/,1209066,1699285984.0,0,,False,,,,,,,,,,274,50
,datascience,"dalle3 prompt: data scientist as a sealed action figure

[dalle3 prompt: data scientist as a sealed action figure](https://preview.redd.it/3s37ff2qbqyb1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=e39787d53aa1b3e947e9f0e5ade9c9ca71df3b01)",t2_wvbdt,False,,0,False,Data Scientist action figure (dalle3),[],r/datascience,False,6,,0,140.0,,False,t3_17p2qtc,False,dark,0.76,,public,29,0,{},140.0,,False,[],,False,False,,{},Monday Meme,False,29,,False,False,https://a.thumbs.redditmedia.com/loZPKDZTL0XQ5pE9pSx2GJwHEXEjjWtmjl0sb7hB_P4.jpg,False,,[],{},,True,,1699277358.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;dalle3 prompt: data scientist as a sealed action figure&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3s37ff2qbqyb1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e39787d53aa1b3e947e9f0e5ade9c9ca71df3b01""&gt;dalle3 prompt: data scientist as a sealed action figure&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,6e90f572-70ec-11ee-9bd6-2692ba006635,False,False,False,,[],False,,,,t5_2sptq,False,,,#ff8717,17p2qtc,True,,fulowa,,18,True,all_ads,False,[],False,,/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,all_ads,False,https://www.reddit.com/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,1209066,1699277358.0,0,,False,"{'3s37ff2qbqyb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=60d1fa9a44d86e7cc7662cb4fc25d2248ab94e3e'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05bd9653957f14ee40a1d664fd943d7a81cabd0f'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7a4821f2754ed174926e70c6554e095d43a1c519'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9012d4efbf9b28c1df33118abd7f2e2d1208c9c4'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c53d7f81bbc3afc5c9bc6393544620a0ae7bb8f'}], 's': {'y': 1024, 'x': 1024, 'u': 'https://preview.redd.it/3s37ff2qbqyb1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=e39787d53aa1b3e947e9f0e5ade9c9ca71df3b01'}, 'id': '3s37ff2qbqyb1'}}",,,,,,,,,244,18
,datascience,"TlDr: A DS needs to have functional knowledge about Docker, OOP, FastAPI, Postgres to create relational DB.",t2_9axqyq8u,False,,0,False,How much do you agree with this post (screenshot attached) based on your DS experience?,[],r/datascience,False,6,discussion,0,140.0,,False,t3_17oulta,False,dark,0.92,,public,367,0,{},140.0,,False,[],,True,False,,{},Discussion,False,367,,False,False,https://b.thumbs.redditmedia.com/vWy8OmXwa1dRQ_LtS2q5-jw9lIknnskqDWtg19uuKQo.jpg,False,,[],{},,False,,1699244393.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TlDr: A DS needs to have functional knowledge about Docker, OOP, FastAPI, Postgres to create relational DB.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17oulta,True,,Difficult-Big-3890,,191,True,all_ads,False,[],False,,/r/datascience/comments/17oulta/how_much_do_you_agree_with_this_post_screenshot/,all_ads,False,https://i.redd.it/sfozkw40mnyb1.jpg,1209066,1699244393.0,1,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?auto=webp&amp;s=3e6ed2a863a16ca755af721835cfbaddcbd51ae5', 'width': 1080, 'height': 1704}, 'resolutions': [{'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43f9e03ceec190401274e0482644afbd1b06c350', 'width': 108, 'height': 170}, {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=737b13436f55f17b0a8f38c22141619f71941c9a', 'width': 216, 'height': 340}, {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d763b017e93a7226f9d281fb241cf31352cfdfd', 'width': 320, 'height': 504}, {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec2111005bad4e84035a3c00164dae9e64389c3', 'width': 640, 'height': 1009}, {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=86e7db90c0de99de9c00f86180901f714527e1fd', 'width': 960, 'height': 1514}, {'url': 'https://preview.redd.it/sfozkw40mnyb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e709f845e5b0bd9ca35e3c8f308d1999bc055af', 'width': 1080, 'height': 1704}], 'variants': {}, 'id': 'g4591bnVTmJNL_h2xUVR0uWjYRXCRm3wwH-h8Ri80nE'}], 'enabled': True}",,https://i.redd.it/sfozkw40mnyb1.jpg,,,,,107,17
,datascience,"Currently employed with a title of Data Scientist but really I'm a product analyst building out to Excel on ad hoc projects, mostly around why we aren't making money in that product line. My company is in the third round of layoffs this year and without a plan to improve, I'm expecting to exit, one way or the other, early in 2024.   


I'm feeling woefully under-skilled because I've been underutilized. I haven't put a model into production in three years because we haven't been asked. I have built dashboards that don't get used because managers want to look at the data themselves in Excel. My company has done \_nothing\_ with GenAI, NLP, Deep Learning, Image Processing, all of the significant advances in the last few years. I let myself get comfortable in a job where I could talk about data with people who were scared of it, but as I look at job openings for data scientists I truly don't feel qualified to even apply. I feel like my skills were relevant as of \~2019.  


What should I do in order to become relevant again?",,False,,0,False,"Expecting to be laid-off in Q1, how do I prepare to re-enter the job market?",[],r/datascience,False,6,fun,0,,,False,t3_17o4er9,False,dark,0.93,,public,112,0,{},,,False,[],,False,False,,{},Career Discussion,False,112,,False,,self,False,,,{},,True,,1699158978.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently employed with a title of Data Scientist but really I&amp;#39;m a product analyst building out to Excel on ad hoc projects, mostly around why we aren&amp;#39;t making money in that product line. My company is in the third round of layoffs this year and without a plan to improve, I&amp;#39;m expecting to exit, one way or the other, early in 2024.   &lt;/p&gt;

&lt;p&gt;I&amp;#39;m feeling woefully under-skilled because I&amp;#39;ve been underutilized. I haven&amp;#39;t put a model into production in three years because we haven&amp;#39;t been asked. I have built dashboards that don&amp;#39;t get used because managers want to look at the data themselves in Excel. My company has done _nothing_ with GenAI, NLP, Deep Learning, Image Processing, all of the significant advances in the last few years. I let myself get comfortable in a job where I could talk about data with people who were scared of it, but as I look at job openings for data scientists I truly don&amp;#39;t feel qualified to even apply. I feel like my skills were relevant as of ~2019.  &lt;/p&gt;

&lt;p&gt;What should I do in order to become relevant again?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17o4er9,True,,[deleted],,66,True,all_ads,False,[],,dark,/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,1209066,1699158978.0,0,,False,,,,,,,,,,1036,185
,datascience,"For an interview with a US startup - what should I be aware of? What kind of question should I be asking to form a solid opinion on the [edit] company?

e.g. I don't know much about funding at the different funding stages. What would I want to look at?",t2_4j7ujk5j,False,,0,False,When applying for a start-up - what questions should I ask?,[],r/datascience,False,6,fun,0,,,False,t3_17nwp4y,False,dark,0.9,,public,29,0,{},,,False,[],,False,False,,{},Career Discussion,False,29,,False,False,self,1699139411.0,,[],{},,True,,1699135113.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For an interview with a US startup - what should I be aware of? What kind of question should I be asking to form a solid opinion on the [edit] company?&lt;/p&gt;

&lt;p&gt;e.g. I don&amp;#39;t know much about funding at the different funding stages. What would I want to look at?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17nwp4y,True,,norfkens2,,39,True,all_ads,False,[],False,,/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,all_ads,False,https://www.reddit.com/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,1209066,1699135113.0,0,,False,,,,,,,,,,252,50
,datascience,"This is my first data job and I’m the only data science person there, sorry if the question is kinda obvious.

How would you approach explaining complex transformations if you don’t have anyone in your company who can review your code?

Would it be smart to use graphical tools to illustrate each step and briefly explain methods used, such as right/inner joins? 

I’ve been working on this rather complex analysis in python with many steps and different queries. My project manager told me that he doesn’t feel confident with the results yet, due to the numerous (and sadly unavoidable) data transformation steps.",t2_6q7a2p0c,False,,0,False,How would you explain complex data transformations to others?,[],r/datascience,False,6,discussion,0,,,False,t3_17nlj1t,False,dark,0.84,,public,23,0,{},,,False,[],,False,False,,{},Discussion,False,23,,False,False,self,False,,[],{},,True,,1699104013.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is my first data job and I’m the only data science person there, sorry if the question is kinda obvious.&lt;/p&gt;

&lt;p&gt;How would you approach explaining complex transformations if you don’t have anyone in your company who can review your code?&lt;/p&gt;

&lt;p&gt;Would it be smart to use graphical tools to illustrate each step and briefly explain methods used, such as right/inner joins? &lt;/p&gt;

&lt;p&gt;I’ve been working on this rather complex analysis in python with many steps and different queries. My project manager told me that he doesn’t feel confident with the results yet, due to the numerous (and sadly unavoidable) data transformation steps.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17nlj1t,True,,jeffrey_56,,43,True,all_ads,False,[],False,,/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,1209066,1699104013.0,0,,False,,,,,,,,,,614,102
,datascience,"I'm doing a deep dive on cluster analysis for the given problem I'm working on. Right now, I'm using hierarchical clustering and the data that I have contains 24 features. Naturally, I used t-SNE to visualize the cluster formation and it looks solid but I can't shake the feeling that the actual geometry of the clusters is lost in the translation. 

The reason for wanting to do this is to assist in selecting additional clustering algorithms for evaluation. 

I haven't used PCA yet as I'm worried about the effects of data lost during the dimensionality redux and how it  might skew further analysis.

Does there exist a way to better understand the geometry of clusters? Was my intuition correct about t-SNE possibly altering (or obscuring) the cluster shapes?",t2_131bi6,False,,0,False,"How can someone determine the geometry of their clusters (ie, flat or convex) if the data has high dimensionality?",[],r/datascience,False,6,network,0,,,False,t3_17ngwrb,False,dark,0.81,,public,27,0,{},,,False,[],,False,False,,{},Analysis,False,27,,False,False,self,False,,[],{},,True,,1699085203.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m doing a deep dive on cluster analysis for the given problem I&amp;#39;m working on. Right now, I&amp;#39;m using hierarchical clustering and the data that I have contains 24 features. Naturally, I used t-SNE to visualize the cluster formation and it looks solid but I can&amp;#39;t shake the feeling that the actual geometry of the clusters is lost in the translation. &lt;/p&gt;

&lt;p&gt;The reason for wanting to do this is to assist in selecting additional clustering algorithms for evaluation. &lt;/p&gt;

&lt;p&gt;I haven&amp;#39;t used PCA yet as I&amp;#39;m worried about the effects of data lost during the dimensionality redux and how it  might skew further analysis.&lt;/p&gt;

&lt;p&gt;Does there exist a way to better understand the geometry of clusters? Was my intuition correct about t-SNE possibly altering (or obscuring) the cluster shapes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17ngwrb,True,,WadeEffingWilson,,41,True,all_ads,False,[],False,,/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,1209066,1699085203.0,0,,False,,,,,,,,,,764,128
,datascience,"I've been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be ""not on the list"" as much as possible.

If you had the chance to build a team from scratch, what would you do?",t2_al1087x2,False,,0,False,"If you had a chance to rebuild your DS/DE team, how would you do it?",[],r/datascience,False,6,discussion,0,,,False,t3_17ndvwn,False,dark,0.88,,public,75,0,{},,,False,[],,False,False,,{},Discussion,False,75,,False,False,self,False,,[],{},,True,,1699072139.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be &amp;quot;not on the list&amp;quot; as much as possible.&lt;/p&gt;

&lt;p&gt;If you had the chance to build a team from scratch, what would you do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ndvwn,True,,OverratedDataScience,,58,True,all_ads,False,[],False,,/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,1209066,1699072139.0,0,,False,,,,,,,,,,418,79
,datascience,"I am a data scientist and I report directly to the CEO whom I have a candid rapport with. I have generated a lot of use case and working models in my short tenure. I have no intention to leave my company yet. Recently I received a couple of job offers without interviewing or seeking for jobs. I was thinking of mentioning these attempts during my performance review with the CEO and ask for a higher salary to ""make future attempts harder to accept"". Should I do it? Would it place my neck on the chopping board during hard times?",t2_8gmsjexy,False,,0,False,Should I use poaching attempts to ask for higher salary?,[],r/datascience,False,6,fun,0,,,False,t3_17mzv7z,False,dark,0.89,,public,100,0,{},,,False,[],,False,False,,{},Career Discussion,False,100,,False,False,self,False,,[],{},,True,,1699031293.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a data scientist and I report directly to the CEO whom I have a candid rapport with. I have generated a lot of use case and working models in my short tenure. I have no intention to leave my company yet. Recently I received a couple of job offers without interviewing or seeking for jobs. I was thinking of mentioning these attempts during my performance review with the CEO and ask for a higher salary to &amp;quot;make future attempts harder to accept&amp;quot;. Should I do it? Would it place my neck on the chopping board during hard times?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17mzv7z,True,,Mundane-Astronomer-7,,65,True,all_ads,False,[],False,,/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,all_ads,False,https://www.reddit.com/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,1209066,1699031293.0,0,,False,,,,,,,,,,531,100
,datascience,We have been asked to prepare SMART goals for next year's evaluations .,t2_5fbmh3va,False,,0,False,SMART goal setting does it work for data science,[],r/datascience,False,6,projects,0,,,False,t3_17mt5b2,False,dark,0.58,,public,3,0,{},,,False,[],,False,False,,{},ML,False,3,,False,False,self,False,,[],{},,True,,1699011797.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We have been asked to prepare SMART goals for next year&amp;#39;s evaluations .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17mt5b2,True,,Excellent_Cost170,,11,True,all_ads,False,[],False,,/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,1209066,1699011797.0,0,,False,,,,,,,,,,71,13
,datascience,... and what makes a bad DSM,t2_3op9qx89,False,,0,False,What makes an average Data Science Manager an Excellent DSM?,[],r/datascience,False,6,discussion,0,,,False,t3_17mps8p,False,dark,0.85,,public,29,0,{},,,False,[],,False,False,,{},Discussion,False,29,,False,False,self,False,,[],{},,True,,1698997439.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;... and what makes a bad DSM&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17mps8p,True,,LatterConcentrate6,,21,True,all_ads,False,[],False,,/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,all_ads,False,https://www.reddit.com/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,1209066,1698997439.0,0,,False,,,,,,,,,,28,7
,datascience,"Applying to jobs online is like navigating a maze.

Amidst the special torture that is resume parsing software, the inability to reuse information across different application tracking systems (ATS), and the existence of a certain company that rhymes with every day of the week, it can get pretty frustrating.

I wanted to explore what factors make a job application more or less frustrating.

For example, what industries have the worst application processes? Do big companies ask for more information than small companies? What is it about websites like Workday that make them really hard to use?

To answer these questions, I applied to 250 jobs. One by one. Click by click. No Linkedin Easy Apply, no shortcuts – just straight from the careers page.

I timed how long it took me to go from “apply to job” to “submit application”.

https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&amp;format=png&amp;auto=webp&amp;s=2123533d9d04aabcdd5988471274ee2ed3b98704

Make no mistake: I sacrificed my soul for this post. I created over 83 accounts and spent a total of 11 hours scrolling. I was originally going to do this for 500 companies, but wanted to chop my head off halfway.

I did this for a mix of companies – Fortune 500 to early stage startups, spread out across different industries from software to manufacturing. The *type* of role I applied to was kept constant: engineering / product focused.

https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&amp;format=png&amp;auto=webp&amp;s=f27a52217e85bfade6eb30f0b696914eac7fc270

The outcome? An average of over two and a half minutes per application—162 seconds of your life you'll never get back. But as we dig deeper, you'll discover that these 162 seconds only scratch the surface of an often maddening process.

*Key Takeaways*

* **Average Application Time:** On average, it took a bit over two and a half minutes to apply to a job.
* **Company Size Impact:** If company size doubles, the application time increases by 5%. If company size increases by a factor of 10, then the app time increases by 20%.
* **Industry Influence:** Being a government company is the single largest determinant of a long application, followed closely by aerospace and consulting firms.
* **Longest Application:** The longest application time went to the United States Postal Service (10 minutes and 12 seconds).
* **Shortest Application:** On the other hand, It took me just 17 seconds to apply to Renaissance Technologies.
* **ATS Impact:** Older ATS like Workday and Taleo make job applications as much as 128% longer.

**You can view the spreadsheet with the full raw data** [here](https://mailchi.mp/1a15a90c4aeb/company_raw_data_leadmagnet)

Let's dive in.

# The Setup

There’s no real method to the 250 companies I pick. I’m just typing names into Google and trying to vary it up. Where does Trisha work? What was that billboard I saw? It's all up for grabs.

Here’s the distribution of the 250 companies by size:

https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=6feb536781f5f892ff57aaed0033e716be4c25c4

Some examples of companies in each range:

* 1-500 → Glean, Quizlet, Gumroad
* 500-5,000 → Notion, Dolby, Moloco
* 5,000-50,000 → Airbnb, Genentech, Logitech
* 50,000-100,000 → HP, American Express, Pfizer
* 100,000+ → Wells Fargo, Lockheed Martin, General Motors

And here’s a look at the different types of industries represented:

https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&amp;format=png&amp;auto=webp&amp;s=2234a153954270bd3724029dac51cd270bfaf6ba

I used a mix of Linkedin and Crunchbase for categorization.

Before we get started, if you’d like you can read up on my [methodology](https://docs.google.com/document/d/1A0I9_WBN9zIqwezM6OXqmOl3LPqaq5704EPmGDTDiYI/edit) for applying to each job (aka assumptions I made, what data I chose to submit, and how much effort I put into each application).

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

# What makes a job application so frustrating

Generally speaking, the more frustrating a job application, the longer it takes to complete.

The three main factors that might influence how long a job application is (as measured in my data):

1. **Company size** → I would expect bigger companies to ask more questions.
2. **The ATS that is being used** → I would expect clunkier, older ATS to make job applications longer.
3. **Company industry** → I would expect more “traditional” industries to ask more questions.

We’re going to model the relationship between the above three factors and the amount of time it takes to complete a job application. To do this, we’re going to use a technique called linear regression.

Regression is about the way two measurements change together. It can help us make predictions.

For example, if I add 10 employees to a company, how many seconds will that add to the company’s job application process?

Since we have other factors like ATS and Industry, we will also account for those. For now, though, let’s just focus on each factor one by one.

# Company Size

Let’s first plot the data as is:

https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&amp;format=png&amp;auto=webp&amp;s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199

Yes, I know, this isn’t the most useful graph. I’m going to spruce it up real quick, I promise.

The United States Postal Service has a job application that took over 10 minutes to complete. Navigating their portal felt like using Internet Explorer in 2003:

https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=b7b65699a39f2e4e3c3abadf38875280a673a0d7

Netflix’s application was just 20 seconds - their only mandatory requirements are your resume and basic info.

https://preview.redd.it/sl4fums4wyxb1.png?width=2310&amp;format=png&amp;auto=webp&amp;s=4c0c87299460bd22163f34db1040a56ea3893059

Apple took me 71 seconds, still pretty fast for a company that has over 270,000 employees (PWC, which has a similar number of employees, took me almost six times as long).

Okay, back to the chart. There are a couple of problems with it.

First, the data is not linear. This is a problem if we want to use linear regression.

Second, the company size scale is hard to interpret because of the many data points clumped together near zero (representing all the smaller companies).

We can resolve both these issues with the following insight:

There is a big difference between going from 10 to 100 employees and, say, 10,000 to 10,100 employees. The first represents major changes in company structure: you might actually hire a proper HR team, a bunch of recruiters, and build out your candidate experience. The second, though, is pretty much just business as usual - think of a multinational opening up a satellite office or a regular month of hiring.

Since we want to account for this, our data is better suited to a log scale than a linear scale. I will also transform our Y-axis, the application time, to a log scale because it helps normalize the data.

If we plot both our variables on a log-log scale, we get the below chart:

https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&amp;format=png&amp;auto=webp&amp;s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e

Better right? This is the same data as the last chart, but with different axes that fits the data better, we observe a linear relationship.

We have the usual suspects in the top right: Government organizations, professional services firms, and some of the tech industry dinosaurs.

The variance in application times across smaller companies, like startups, is interesting. For example, many of the startups with longer application times (e.g OpenAI, Posthog, Comma.AI) reference that they are looking for “exceptional” candidates on their careers page. (Note that OpenAI has changed its application since I last analyzed it - it’s now much faster, but when I went through they asked for a mini essay on why you’re exceptional).

One thing that I was expecting to see was competitors mirroring each other’s application times. This is most closely represented with the consulting firms like Deloitte, E&amp;Y, KPMG, etc all clumped together. McKinsey and Bain, the two most prestigious consulting firms, have applications that take longer to complete.

This doesn’t necessarily seem to be the case with the FAANG companies.

We can also calculate the correlation coefficient for this graph. This is a statistical measure of the strength of a linear relationship between two variables. The closer to 1 the value, the stronger the relationship.

For the above data, we get a correlation coefficient of 0.58, which is a moderate to strong association.

Note that on its own, this doesn't tell us anything about causation. But it does start to point us in some type of direction.

It's not rocket science: big companies ask for more stuff. Sometimes they ask for the last 4 digits of your SSN.

https://preview.redd.it/c7g5717bwyxb1.png?width=1512&amp;format=png&amp;auto=webp&amp;s=38c776e46d45d179a6627ba3470fd4f89ca04204

Sometimes they even ask if you’d be okay going through a polygraph:

https://preview.redd.it/1q52rzldwyxb1.png?width=400&amp;format=png&amp;auto=webp&amp;s=b3b8921e055d38e04ee7395e9b982fa50c38f9df

An argument here is that if big companies didn’t have some sort of barriers in their application process, they’d get swarmed with applications.

Consider the fact that Google gets 3 million applications every year. Deloitte gets 2 million. Without some sort of initial friction in the application process, those numbers would be even higher. That friction almost serves as a reliable filter for interest.

If you’re an employer, you don’t really care about the people using a shotgun approach to apply. You want the candidates that have a real interest in the position. On the other hand, if you’re a candidate, the reality is such that the shotgun approach to apply is arguably the most efficient.

So we have this inherent tension between companies and candidates. Candidates want the most bang for their buck, companies don’t want thousands of irrelevant resumes.

And in the middle, we have the plethora of application tracking software that can often be quite old and clunky.

# ATS

Everytime I came face to face with a company that used Workday as their ATS, I died a bit inside. This is because Workday makes you:

1. create a new account every single time
2. redirects you away from the careers page

I defined a redirect as one when the job description is not listed on the same page as the first input box part of the application.

This isn’t a perfectly accurate measure, but it does allow us to differentiate between the modern ATS like Greenhouse and older ones like Workday.

With every ATS, I implicitly had some type of “how easy is this going to be” metric in my head.

We can try to represent this “how easy is this going to be” metric a bit more concretely using the matrix below.

https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&amp;format=png&amp;auto=webp&amp;s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa

Ideally, you want the ATS to be in the bottom left corner. This creates an experience that is low friction and fast.

If we plot application time versus ATS, this is what we get:

https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&amp;format=png&amp;auto=webp&amp;s=8df5c1118f9f0044e2154c8ae63816332ca42d67

The ATS that don’t make you create an account and don’t redirect you are tied to lower application times than the ones that do.

One possibility is that certain companies are more likely to use certain ATS. Big companies might use Workday for better compliance reporting. Same with the industry - maybe B2C software companies use the newer ATS on the market. These would be confounding variables, meaning that we may misinterpret a relationship between the ATS and the application time when in fact there isn’t one (and the real relationship is tied to the industry or size).

So to properly understand whether the ATS actually has an effect on application time, we need to control for our other variables. We’ll do this in the final section when we run a regression including all our variables.

One of the big frustrations surrounding different ATS is that when you upload your resume, you then need to retype out your experience in the boxes because the ATS resume parser did it incorrectly. For example, I went to UC Berkeley but sometimes got this:

https://preview.redd.it/ay21vccnwyxb1.png?width=928&amp;format=png&amp;auto=webp&amp;s=9862b0860c49c87a76b02218f8e4118134acfb89

The only resume parser that didn't seem abysmal was the one from Smart Recruiters. TikTok's resume parser also isn't bad.

Another frustrating experience is tied to inconsistency between the company I'm applying to and the ATS.

https://preview.redd.it/9xzq21vpwyxb1.png?width=350&amp;format=png&amp;auto=webp&amp;s=8432b293be4db0f58770760097df0117b53e667e

A company’s application process is often the first touchpoint you have with their brand. Startups competing for the best talent can't afford extra steps in their process. Apple and Facebook can.

Whilst the average time to complete a job application may only be 162 seconds, the fact that many ATS require steps like account creation and authentication can lead to application fatigue.

It’s not necessarily the explicit amount of time it takes, it’s the steps involved that drain you of energy and make you want to avoid applying to new jobs.

# Industry

Okay, so far we’ve looked at company size and the ATS as a loose indicator of what might make a job application frustrating. What about the company industry?

You would expect industries like banking or professional services to have longer application times, because getting those jobs revolves around having a bunch of credentials which they likely screen for (and ask you to submit) early on in the process.

On the other hand, internet startups I’d expect to be quick and fast. Let’s find out if this is true.

https://preview.redd.it/i7825ssvwyxb1.png?width=4012&amp;format=png&amp;auto=webp&amp;s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b

Hyped up industries like AI and Crypto have shorter application times. As expected, banks and consulting firms care about your GPA and ask you to submit it.

A government company has to basically verify your identity before they can even receive your application, so the process is entirely different and reflected in the submission time.

For many technology companies, the application process is almost like an extension of the company’s brand itself. For example, Plaid (an API first Fintech company), has a neat option where you can actually apply to the job via API:

https://preview.redd.it/px5k5wwxwyxb1.png?width=720&amp;format=png&amp;auto=webp&amp;s=d669e7e47e77e51d48a4867a2d06d27125617ed8

Roblox, a gaming company, allows people to submit job applications from within their [games](https://gamerant.com/roblox-company-interview-job-applicants-in-game/).

We also notice differences between legacy companies and their newer competitors. If we compare legacy banks versus neobanks (like Monzo, Mercury, etc), the legacy players averaged around 250 seconds per job application whereas the neobanks averaged less than 60 seconds.

If you can’t compete on prestige, you need to find other ways. One of those ways can be through asking for less information upfront.

# Putting it together

Now that we've analyzed each variable - the company size, ATS, and the industry - to understand the separate relationship of each to application time, we can use linear regression to understand the *combined* relationships.

This will allow us to determine what factors actually have an impact on the job application time versus which ones might just have had one when we looked at them in isolation.

After some number crunching in R, I get the following results (I’ve only added the statistically significant factors – the ones with the “strongest evidence”):

https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&amp;format=png&amp;auto=webp&amp;s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9

Here’s how you can interpret some of the information above:

* When a job app is for a company that is within the Government industry, the submission time goes up by 366% (assuming the size and ATS are constant). For the aerospace industry, this is 249% (and so on).
* When a job app is for a company using the Workday ATS, the submission times goes up by 128% (assuming the size and industry are constant). For the Phenom ATS, this is 110% (and so on).
* Our only (statistically significant) metric which seems to make job applications faster is the Lever ATS (42% shorter).

Okay, now what about company size?

Well, first up: company size is indeed statistically significant. So there is an effect.

However, its effect is not as strong as most of our other variables. To be precise, here are some ways to interpret our company size coefficient:

* If company size doubles, the app size increases by 5%
* If company size increases by a factor of 10, then the app time increases by 20%

This is a smaller effect size compared to ATS or industry (a 20% increases in app time for a 10x large company is a qualitatively smaller effect size than e.g. a 100% increase in app time for Taleo ATS). So although company size is statistically significant, it is not as strong of a driver as ATS and industry of app time.

# Wrapping it up

Two and a half minutes might not be too long, but it can feel like an eternity when you’re forced to answer the same questions and upload the same documents. Over and over again.

Think about catching a flight. All you want is to get on the jet. Hawaii awaits.

But first: the security line. You have to take your shoes off. You get patted down and your bag gets searched. The gate numbers don’t make sense. And then at the end of it, your flight’s delayed. Congrats.

Applying to a job can feel similar. All you want to do is say aloha to the hiring manager, a real human being.

To even have the remote possibility of making that happen, you need to create an account and password, check your email, retype your entire resume, tell them the color of your skin, and explain why this company you’ve never heard of before is the greatest thing on Earth.

And for what? Most likely for the privilege of receiving an automated email about two weeks later rejecting you.

If we make it tiring and unappealing to look for new opportunities, then we prevent people from doing their best work.

But what would a world where applying took just a few seconds actually look like? Recruiters would get bombarded with resumes. It's possible to argue that job applications taking so long is a feature, not a bug. You get to filter for intent and narrow down your application pool.

Is it fair to shift the burden of screening unqualified candidates onto good candidates that now need to provide so much information? Shouldn’t that burden fall on the recruiter?

The truth is that applying to a job via the careers page is a bit of a rigged game. The odds are not in your favor.

Sometimes, though, all you need is to only be right once.

\*\*\*

If you made it all the way to the bottom, you're a star. This took a while to write. I hope you enjoyed it.

For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox \~once a month.

Any questions and I'll be in the comments :)

\- Shikhar",t2_qr5uf,False,,0,False,I applied to 250 jobs and timed how long each one took,[],r/datascience,False,6,fun,0,73.0,,False,t3_17m8la5,False,dark,0.97,,public,834,0,{},140.0,,True,[],,False,False,,{},Career Discussion,False,834,,False,False,https://b.thumbs.redditmedia.com/DNt0RpQ1RH_umIcC7JCNL51A7JoV_yrQGnF72uaryvA.jpg,1698965355.0,,[],{},,True,,1698945535.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Applying to jobs online is like navigating a maze.&lt;/p&gt;

&lt;p&gt;Amidst the special torture that is resume parsing software, the inability to reuse information across different application tracking systems (ATS), and the existence of a certain company that rhymes with every day of the week, it can get pretty frustrating.&lt;/p&gt;

&lt;p&gt;I wanted to explore what factors make a job application more or less frustrating.&lt;/p&gt;

&lt;p&gt;For example, what industries have the worst application processes? Do big companies ask for more information than small companies? What is it about websites like Workday that make them really hard to use?&lt;/p&gt;

&lt;p&gt;To answer these questions, I applied to 250 jobs. One by one. Click by click. No Linkedin Easy Apply, no shortcuts – just straight from the careers page.&lt;/p&gt;

&lt;p&gt;I timed how long it took me to go from “apply to job” to “submit application”.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2123533d9d04aabcdd5988471274ee2ed3b98704""&gt;https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2123533d9d04aabcdd5988471274ee2ed3b98704&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Make no mistake: I sacrificed my soul for this post. I created over 83 accounts and spent a total of 11 hours scrolling. I was originally going to do this for 500 companies, but wanted to chop my head off halfway.&lt;/p&gt;

&lt;p&gt;I did this for a mix of companies – Fortune 500 to early stage startups, spread out across different industries from software to manufacturing. The &lt;em&gt;type&lt;/em&gt; of role I applied to was kept constant: engineering / product focused.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f27a52217e85bfade6eb30f0b696914eac7fc270""&gt;https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f27a52217e85bfade6eb30f0b696914eac7fc270&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The outcome? An average of over two and a half minutes per application—162 seconds of your life you&amp;#39;ll never get back. But as we dig deeper, you&amp;#39;ll discover that these 162 seconds only scratch the surface of an often maddening process.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Key Takeaways&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Average Application Time:&lt;/strong&gt; On average, it took a bit over two and a half minutes to apply to a job.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Company Size Impact:&lt;/strong&gt; If company size doubles, the application time increases by 5%. If company size increases by a factor of 10, then the app time increases by 20%.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry Influence:&lt;/strong&gt; Being a government company is the single largest determinant of a long application, followed closely by aerospace and consulting firms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Longest Application:&lt;/strong&gt; The longest application time went to the United States Postal Service (10 minutes and 12 seconds).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortest Application:&lt;/strong&gt; On the other hand, It took me just 17 seconds to apply to Renaissance Technologies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ATS Impact:&lt;/strong&gt; Older ATS like Workday and Taleo make job applications as much as 128% longer.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;You can view the spreadsheet with the full raw data&lt;/strong&gt; &lt;a href=""https://mailchi.mp/1a15a90c4aeb/company_raw_data_leadmagnet""&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s dive in.&lt;/p&gt;

&lt;h1&gt;The Setup&lt;/h1&gt;

&lt;p&gt;There’s no real method to the 250 companies I pick. I’m just typing names into Google and trying to vary it up. Where does Trisha work? What was that billboard I saw? It&amp;#39;s all up for grabs.&lt;/p&gt;

&lt;p&gt;Here’s the distribution of the 250 companies by size:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6feb536781f5f892ff57aaed0033e716be4c25c4""&gt;https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6feb536781f5f892ff57aaed0033e716be4c25c4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some examples of companies in each range:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1-500 → Glean, Quizlet, Gumroad&lt;/li&gt;
&lt;li&gt;500-5,000 → Notion, Dolby, Moloco&lt;/li&gt;
&lt;li&gt;5,000-50,000 → Airbnb, Genentech, Logitech&lt;/li&gt;
&lt;li&gt;50,000-100,000 → HP, American Express, Pfizer&lt;/li&gt;
&lt;li&gt;100,000+ → Wells Fargo, Lockheed Martin, General Motors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And here’s a look at the different types of industries represented:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2234a153954270bd3724029dac51cd270bfaf6ba""&gt;https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2234a153954270bd3724029dac51cd270bfaf6ba&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I used a mix of Linkedin and Crunchbase for categorization.&lt;/p&gt;

&lt;p&gt;Before we get started, if you’d like you can read up on my &lt;a href=""https://docs.google.com/document/d/1A0I9_WBN9zIqwezM6OXqmOl3LPqaq5704EPmGDTDiYI/edit""&gt;methodology&lt;/a&gt; for applying to each job (aka assumptions I made, what data I chose to submit, and how much effort I put into each application).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note&lt;/em&gt;&lt;/strong&gt;: For more content like this, &lt;a href=""https://www.careerfair.io/subscribe""&gt;&lt;em&gt;subscribe&lt;/em&gt;&lt;/a&gt; &lt;em&gt;to my newsletter. In a couple of weeks, I&amp;#39;ll be releasing my guide to writing a killer resume.&lt;/em&gt;&lt;/p&gt;

&lt;h1&gt;What makes a job application so frustrating&lt;/h1&gt;

&lt;p&gt;Generally speaking, the more frustrating a job application, the longer it takes to complete.&lt;/p&gt;

&lt;p&gt;The three main factors that might influence how long a job application is (as measured in my data):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Company size&lt;/strong&gt; → I would expect bigger companies to ask more questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The ATS that is being used&lt;/strong&gt; → I would expect clunkier, older ATS to make job applications longer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Company industry&lt;/strong&gt; → I would expect more “traditional” industries to ask more questions.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We’re going to model the relationship between the above three factors and the amount of time it takes to complete a job application. To do this, we’re going to use a technique called linear regression.&lt;/p&gt;

&lt;p&gt;Regression is about the way two measurements change together. It can help us make predictions.&lt;/p&gt;

&lt;p&gt;For example, if I add 10 employees to a company, how many seconds will that add to the company’s job application process?&lt;/p&gt;

&lt;p&gt;Since we have other factors like ATS and Industry, we will also account for those. For now, though, let’s just focus on each factor one by one.&lt;/p&gt;

&lt;h1&gt;Company Size&lt;/h1&gt;

&lt;p&gt;Let’s first plot the data as is:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199""&gt;https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yes, I know, this isn’t the most useful graph. I’m going to spruce it up real quick, I promise.&lt;/p&gt;

&lt;p&gt;The United States Postal Service has a job application that took over 10 minutes to complete. Navigating their portal felt like using Internet Explorer in 2003:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b7b65699a39f2e4e3c3abadf38875280a673a0d7""&gt;https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b7b65699a39f2e4e3c3abadf38875280a673a0d7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Netflix’s application was just 20 seconds - their only mandatory requirements are your resume and basic info.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/sl4fums4wyxb1.png?width=2310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c0c87299460bd22163f34db1040a56ea3893059""&gt;https://preview.redd.it/sl4fums4wyxb1.png?width=2310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c0c87299460bd22163f34db1040a56ea3893059&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Apple took me 71 seconds, still pretty fast for a company that has over 270,000 employees (PWC, which has a similar number of employees, took me almost six times as long).&lt;/p&gt;

&lt;p&gt;Okay, back to the chart. There are a couple of problems with it.&lt;/p&gt;

&lt;p&gt;First, the data is not linear. This is a problem if we want to use linear regression.&lt;/p&gt;

&lt;p&gt;Second, the company size scale is hard to interpret because of the many data points clumped together near zero (representing all the smaller companies).&lt;/p&gt;

&lt;p&gt;We can resolve both these issues with the following insight:&lt;/p&gt;

&lt;p&gt;There is a big difference between going from 10 to 100 employees and, say, 10,000 to 10,100 employees. The first represents major changes in company structure: you might actually hire a proper HR team, a bunch of recruiters, and build out your candidate experience. The second, though, is pretty much just business as usual - think of a multinational opening up a satellite office or a regular month of hiring.&lt;/p&gt;

&lt;p&gt;Since we want to account for this, our data is better suited to a log scale than a linear scale. I will also transform our Y-axis, the application time, to a log scale because it helps normalize the data.&lt;/p&gt;

&lt;p&gt;If we plot both our variables on a log-log scale, we get the below chart:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e""&gt;https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Better right? This is the same data as the last chart, but with different axes that fits the data better, we observe a linear relationship.&lt;/p&gt;

&lt;p&gt;We have the usual suspects in the top right: Government organizations, professional services firms, and some of the tech industry dinosaurs.&lt;/p&gt;

&lt;p&gt;The variance in application times across smaller companies, like startups, is interesting. For example, many of the startups with longer application times (e.g OpenAI, Posthog, Comma.AI) reference that they are looking for “exceptional” candidates on their careers page. (Note that OpenAI has changed its application since I last analyzed it - it’s now much faster, but when I went through they asked for a mini essay on why you’re exceptional).&lt;/p&gt;

&lt;p&gt;One thing that I was expecting to see was competitors mirroring each other’s application times. This is most closely represented with the consulting firms like Deloitte, E&amp;amp;Y, KPMG, etc all clumped together. McKinsey and Bain, the two most prestigious consulting firms, have applications that take longer to complete.&lt;/p&gt;

&lt;p&gt;This doesn’t necessarily seem to be the case with the FAANG companies.&lt;/p&gt;

&lt;p&gt;We can also calculate the correlation coefficient for this graph. This is a statistical measure of the strength of a linear relationship between two variables. The closer to 1 the value, the stronger the relationship.&lt;/p&gt;

&lt;p&gt;For the above data, we get a correlation coefficient of 0.58, which is a moderate to strong association.&lt;/p&gt;

&lt;p&gt;Note that on its own, this doesn&amp;#39;t tell us anything about causation. But it does start to point us in some type of direction.&lt;/p&gt;

&lt;p&gt;It&amp;#39;s not rocket science: big companies ask for more stuff. Sometimes they ask for the last 4 digits of your SSN.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/c7g5717bwyxb1.png?width=1512&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38c776e46d45d179a6627ba3470fd4f89ca04204""&gt;https://preview.redd.it/c7g5717bwyxb1.png?width=1512&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38c776e46d45d179a6627ba3470fd4f89ca04204&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sometimes they even ask if you’d be okay going through a polygraph:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1q52rzldwyxb1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b3b8921e055d38e04ee7395e9b982fa50c38f9df""&gt;https://preview.redd.it/1q52rzldwyxb1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b3b8921e055d38e04ee7395e9b982fa50c38f9df&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An argument here is that if big companies didn’t have some sort of barriers in their application process, they’d get swarmed with applications.&lt;/p&gt;

&lt;p&gt;Consider the fact that Google gets 3 million applications every year. Deloitte gets 2 million. Without some sort of initial friction in the application process, those numbers would be even higher. That friction almost serves as a reliable filter for interest.&lt;/p&gt;

&lt;p&gt;If you’re an employer, you don’t really care about the people using a shotgun approach to apply. You want the candidates that have a real interest in the position. On the other hand, if you’re a candidate, the reality is such that the shotgun approach to apply is arguably the most efficient.&lt;/p&gt;

&lt;p&gt;So we have this inherent tension between companies and candidates. Candidates want the most bang for their buck, companies don’t want thousands of irrelevant resumes.&lt;/p&gt;

&lt;p&gt;And in the middle, we have the plethora of application tracking software that can often be quite old and clunky.&lt;/p&gt;

&lt;h1&gt;ATS&lt;/h1&gt;

&lt;p&gt;Everytime I came face to face with a company that used Workday as their ATS, I died a bit inside. This is because Workday makes you:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;create a new account every single time&lt;/li&gt;
&lt;li&gt;redirects you away from the careers page&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I defined a redirect as one when the job description is not listed on the same page as the first input box part of the application.&lt;/p&gt;

&lt;p&gt;This isn’t a perfectly accurate measure, but it does allow us to differentiate between the modern ATS like Greenhouse and older ones like Workday.&lt;/p&gt;

&lt;p&gt;With every ATS, I implicitly had some type of “how easy is this going to be” metric in my head.&lt;/p&gt;

&lt;p&gt;We can try to represent this “how easy is this going to be” metric a bit more concretely using the matrix below.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa""&gt;https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ideally, you want the ATS to be in the bottom left corner. This creates an experience that is low friction and fast.&lt;/p&gt;

&lt;p&gt;If we plot application time versus ATS, this is what we get:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8df5c1118f9f0044e2154c8ae63816332ca42d67""&gt;https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8df5c1118f9f0044e2154c8ae63816332ca42d67&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The ATS that don’t make you create an account and don’t redirect you are tied to lower application times than the ones that do.&lt;/p&gt;

&lt;p&gt;One possibility is that certain companies are more likely to use certain ATS. Big companies might use Workday for better compliance reporting. Same with the industry - maybe B2C software companies use the newer ATS on the market. These would be confounding variables, meaning that we may misinterpret a relationship between the ATS and the application time when in fact there isn’t one (and the real relationship is tied to the industry or size).&lt;/p&gt;

&lt;p&gt;So to properly understand whether the ATS actually has an effect on application time, we need to control for our other variables. We’ll do this in the final section when we run a regression including all our variables.&lt;/p&gt;

&lt;p&gt;One of the big frustrations surrounding different ATS is that when you upload your resume, you then need to retype out your experience in the boxes because the ATS resume parser did it incorrectly. For example, I went to UC Berkeley but sometimes got this:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ay21vccnwyxb1.png?width=928&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9862b0860c49c87a76b02218f8e4118134acfb89""&gt;https://preview.redd.it/ay21vccnwyxb1.png?width=928&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9862b0860c49c87a76b02218f8e4118134acfb89&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The only resume parser that didn&amp;#39;t seem abysmal was the one from Smart Recruiters. TikTok&amp;#39;s resume parser also isn&amp;#39;t bad.&lt;/p&gt;

&lt;p&gt;Another frustrating experience is tied to inconsistency between the company I&amp;#39;m applying to and the ATS.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/9xzq21vpwyxb1.png?width=350&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8432b293be4db0f58770760097df0117b53e667e""&gt;https://preview.redd.it/9xzq21vpwyxb1.png?width=350&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8432b293be4db0f58770760097df0117b53e667e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A company’s application process is often the first touchpoint you have with their brand. Startups competing for the best talent can&amp;#39;t afford extra steps in their process. Apple and Facebook can.&lt;/p&gt;

&lt;p&gt;Whilst the average time to complete a job application may only be 162 seconds, the fact that many ATS require steps like account creation and authentication can lead to application fatigue.&lt;/p&gt;

&lt;p&gt;It’s not necessarily the explicit amount of time it takes, it’s the steps involved that drain you of energy and make you want to avoid applying to new jobs.&lt;/p&gt;

&lt;h1&gt;Industry&lt;/h1&gt;

&lt;p&gt;Okay, so far we’ve looked at company size and the ATS as a loose indicator of what might make a job application frustrating. What about the company industry?&lt;/p&gt;

&lt;p&gt;You would expect industries like banking or professional services to have longer application times, because getting those jobs revolves around having a bunch of credentials which they likely screen for (and ask you to submit) early on in the process.&lt;/p&gt;

&lt;p&gt;On the other hand, internet startups I’d expect to be quick and fast. Let’s find out if this is true.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/i7825ssvwyxb1.png?width=4012&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b""&gt;https://preview.redd.it/i7825ssvwyxb1.png?width=4012&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hyped up industries like AI and Crypto have shorter application times. As expected, banks and consulting firms care about your GPA and ask you to submit it.&lt;/p&gt;

&lt;p&gt;A government company has to basically verify your identity before they can even receive your application, so the process is entirely different and reflected in the submission time.&lt;/p&gt;

&lt;p&gt;For many technology companies, the application process is almost like an extension of the company’s brand itself. For example, Plaid (an API first Fintech company), has a neat option where you can actually apply to the job via API:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/px5k5wwxwyxb1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d669e7e47e77e51d48a4867a2d06d27125617ed8""&gt;https://preview.redd.it/px5k5wwxwyxb1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d669e7e47e77e51d48a4867a2d06d27125617ed8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Roblox, a gaming company, allows people to submit job applications from within their &lt;a href=""https://gamerant.com/roblox-company-interview-job-applicants-in-game/""&gt;games&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We also notice differences between legacy companies and their newer competitors. If we compare legacy banks versus neobanks (like Monzo, Mercury, etc), the legacy players averaged around 250 seconds per job application whereas the neobanks averaged less than 60 seconds.&lt;/p&gt;

&lt;p&gt;If you can’t compete on prestige, you need to find other ways. One of those ways can be through asking for less information upfront.&lt;/p&gt;

&lt;h1&gt;Putting it together&lt;/h1&gt;

&lt;p&gt;Now that we&amp;#39;ve analyzed each variable - the company size, ATS, and the industry - to understand the separate relationship of each to application time, we can use linear regression to understand the &lt;em&gt;combined&lt;/em&gt; relationships.&lt;/p&gt;

&lt;p&gt;This will allow us to determine what factors actually have an impact on the job application time versus which ones might just have had one when we looked at them in isolation.&lt;/p&gt;

&lt;p&gt;After some number crunching in R, I get the following results (I’ve only added the statistically significant factors – the ones with the “strongest evidence”):&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9""&gt;https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here’s how you can interpret some of the information above:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When a job app is for a company that is within the Government industry, the submission time goes up by 366% (assuming the size and ATS are constant). For the aerospace industry, this is 249% (and so on).&lt;/li&gt;
&lt;li&gt;When a job app is for a company using the Workday ATS, the submission times goes up by 128% (assuming the size and industry are constant). For the Phenom ATS, this is 110% (and so on).&lt;/li&gt;
&lt;li&gt;Our only (statistically significant) metric which seems to make job applications faster is the Lever ATS (42% shorter).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Okay, now what about company size?&lt;/p&gt;

&lt;p&gt;Well, first up: company size is indeed statistically significant. So there is an effect.&lt;/p&gt;

&lt;p&gt;However, its effect is not as strong as most of our other variables. To be precise, here are some ways to interpret our company size coefficient:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If company size doubles, the app size increases by 5%&lt;/li&gt;
&lt;li&gt;If company size increases by a factor of 10, then the app time increases by 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a smaller effect size compared to ATS or industry (a 20% increases in app time for a 10x large company is a qualitatively smaller effect size than e.g. a 100% increase in app time for Taleo ATS). So although company size is statistically significant, it is not as strong of a driver as ATS and industry of app time.&lt;/p&gt;

&lt;h1&gt;Wrapping it up&lt;/h1&gt;

&lt;p&gt;Two and a half minutes might not be too long, but it can feel like an eternity when you’re forced to answer the same questions and upload the same documents. Over and over again.&lt;/p&gt;

&lt;p&gt;Think about catching a flight. All you want is to get on the jet. Hawaii awaits.&lt;/p&gt;

&lt;p&gt;But first: the security line. You have to take your shoes off. You get patted down and your bag gets searched. The gate numbers don’t make sense. And then at the end of it, your flight’s delayed. Congrats.&lt;/p&gt;

&lt;p&gt;Applying to a job can feel similar. All you want to do is say aloha to the hiring manager, a real human being.&lt;/p&gt;

&lt;p&gt;To even have the remote possibility of making that happen, you need to create an account and password, check your email, retype your entire resume, tell them the color of your skin, and explain why this company you’ve never heard of before is the greatest thing on Earth.&lt;/p&gt;

&lt;p&gt;And for what? Most likely for the privilege of receiving an automated email about two weeks later rejecting you.&lt;/p&gt;

&lt;p&gt;If we make it tiring and unappealing to look for new opportunities, then we prevent people from doing their best work.&lt;/p&gt;

&lt;p&gt;But what would a world where applying took just a few seconds actually look like? Recruiters would get bombarded with resumes. It&amp;#39;s possible to argue that job applications taking so long is a feature, not a bug. You get to filter for intent and narrow down your application pool.&lt;/p&gt;

&lt;p&gt;Is it fair to shift the burden of screening unqualified candidates onto good candidates that now need to provide so much information? Shouldn’t that burden fall on the recruiter?&lt;/p&gt;

&lt;p&gt;The truth is that applying to a job via the careers page is a bit of a rigged game. The odds are not in your favor.&lt;/p&gt;

&lt;p&gt;Sometimes, though, all you need is to only be right once.&lt;/p&gt;

&lt;p&gt;***&lt;/p&gt;

&lt;p&gt;If you made it all the way to the bottom, you&amp;#39;re a star. This took a while to write. I hope you enjoyed it.&lt;/p&gt;

&lt;p&gt;For more content like this, &lt;a href=""https://www.careerfair.io/subscribe""&gt;subscribe&lt;/a&gt; to my newsletter. It&amp;#39;s my best content delivered to your inbox ~once a month.&lt;/p&gt;

&lt;p&gt;Any questions and I&amp;#39;ll be in the comments :)&lt;/p&gt;

&lt;p&gt;- Shikhar&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17m8la5,True,,ibsurvivors,,122,True,all_ads,False,[],False,,/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,1209066,1698945535.0,0,,False,"{'c7g5717bwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 53, 'x': 108, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b92c2ec527b4be8934a2abf28dec67d30144710b'}, {'y': 107, 'x': 216, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=47511b53f3251206f50d4a4f5dfddc6bc853ebe3'}, {'y': 159, 'x': 320, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c270dd66e42bd4f3682fdcf8ea1140042d57a4b3'}, {'y': 318, 'x': 640, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b91b2cfc0d9dfb17cb084ee0f3f2ca7e176ecc66'}, {'y': 477, 'x': 960, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bcac018e0eb49b295df0a6b1eca68cd92d34d014'}, {'y': 537, 'x': 1080, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a70b80fffe3c2ab79275cf6a1afc327f7602f9d'}], 's': {'y': 752, 'x': 1512, 'u': 'https://preview.redd.it/c7g5717bwyxb1.png?width=1512&amp;format=png&amp;auto=webp&amp;s=38c776e46d45d179a6627ba3470fd4f89ca04204'}, 'id': 'c7g5717bwyxb1'}, '5l4po6d8wyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e0abfde8c3e42fc920454b3bc579cf32d4671825'}, {'y': 135, 'x': 216, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a26e15b47d77feda6c9137b3f5fc381b4b2d34fe'}, {'y': 200, 'x': 320, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=14fcdc054da260f6c82c6c29e6a16e1c3b540931'}, {'y': 400, 'x': 640, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8adf7bbb7eb97a26197964ac9a0f1045c7310293'}, {'y': 601, 'x': 960, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b54dfc53974efb6deca7046a7bd673635f06b95'}, {'y': 676, 'x': 1080, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01844d3d5fec435f95edb3b59dc4a89f7518a721'}], 's': {'y': 2696, 'x': 4304, 'u': 'https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&amp;format=png&amp;auto=webp&amp;s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e'}, 'id': '5l4po6d8wyxb1'}, 'g2pg1o11xyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d02b172e56c86dc84d86a5fe11485089906b861'}, {'y': 142, 'x': 216, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ceea5b6943309fd3d2e0eb078560ddde8a909d80'}, {'y': 211, 'x': 320, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82824414d7921519d3cd8bb3ce144cf0f64eb5de'}, {'y': 423, 'x': 640, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40d67529fd36aebb85f34df84b795e5dc3172acb'}, {'y': 635, 'x': 960, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a2b0b852fdf0637381b9e4b96b4cf1a90aaae2b9'}, {'y': 714, 'x': 1080, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f78fdbfcac0bc906597c4d49010b1d525507fb3f'}], 's': {'y': 1652, 'x': 2496, 'u': 'https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&amp;format=png&amp;auto=webp&amp;s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9'}, 'id': 'g2pg1o11xyxb1'}, '40iu1ni2wyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 85, 'x': 108, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8839807ad94e17cf83e9723ff662eeceadf60752'}, {'y': 171, 'x': 216, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78bc3ab2ec92a769bb5ff08dad25a56b3163bb8a'}, {'y': 253, 'x': 320, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=24b024402afb7f5b3c3c320b33b3482352cbb5dd'}, {'y': 506, 'x': 640, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a3f0d4bcc0edbb9fa50071b08834281a323f9d8'}, {'y': 760, 'x': 960, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8859e74bb34649bd7a2c5d4711d39c817f082cce'}, {'y': 855, 'x': 1080, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=25c35ac06e9e2dd1457a4f212fa83e5ef9e5479e'}], 's': {'y': 1270, 'x': 1604, 'u': 'https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=b7b65699a39f2e4e3c3abadf38875280a673a0d7'}, 'id': '40iu1ni2wyxb1'}, 'j1nonh9tvyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca713a1dcb4d8cb308156237bb492e8aaa95e892'}, {'y': 134, 'x': 216, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8eb53cef4fb00b23328d22905a163f7ec3ab07eb'}, {'y': 199, 'x': 320, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=742debda879a1266109377abe4713a70b60cce45'}, {'y': 399, 'x': 640, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=089620a5ff9ca22e59377a56d58e34426fbe03af'}, {'y': 598, 'x': 960, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e46746e2101c1b3ce4c5ad5d7f03d63fc358192c'}, {'y': 673, 'x': 1080, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2af732f873655bbc03ebc27d45e59ae4fd56ffb4'}], 's': {'y': 1480, 'x': 2372, 'u': 'https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&amp;format=png&amp;auto=webp&amp;s=2234a153954270bd3724029dac51cd270bfaf6ba'}, 'id': 'j1nonh9tvyxb1'}, 'px5k5wwxwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 82, 'x': 108, 'u': 'https://preview.redd.it/px5k5wwxwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c62d25f6fd096692e181ca01e6c607bcf6ce564'}, {'y': 165, 'x': 216, 'u': 'https://preview.redd.it/px5k5wwxwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e85318b8a131184309d6783665611bc7c4fb3c01'}, {'y': 245, 'x': 320, 'u': 'https://preview.redd.it/px5k5wwxwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b2e2c8d456695d1566b8e0fd0afccc4aca07260'}, {'y': 490, 'x': 640, 'u': 'https://preview.redd.it/px5k5wwxwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8fc200c8f87f5a7a7292c14cce5809bc2ac5e5b'}], 's': {'y': 552, 'x': 720, 'u': 'https://preview.redd.it/px5k5wwxwyxb1.png?width=720&amp;format=png&amp;auto=webp&amp;s=d669e7e47e77e51d48a4867a2d06d27125617ed8'}, 'id': 'px5k5wwxwyxb1'}, 'gv6r6xoqvyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb785e185142f420e24182a1154cf3b4f8dee239'}, {'y': 133, 'x': 216, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5afcfcde41a75088bd7c1c0501dec1c40464b4a6'}, {'y': 198, 'x': 320, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=335a19bfd08fe9aa242a6bf952a9243c47963add'}, {'y': 396, 'x': 640, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e12f0a4da1a8c333126d5aca8a2710b2dbfc242'}, {'y': 595, 'x': 960, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=595c26ac3baca41998a80ae568b14f0394402b04'}, {'y': 669, 'x': 1080, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=40c6307bc688311ebb9e67e92955a4e2b4918948'}], 's': {'y': 1500, 'x': 2420, 'u': 'https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=6feb536781f5f892ff57aaed0033e716be4c25c4'}, 'id': 'gv6r6xoqvyxb1'}, 'pe9zyxmkwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 69, 'x': 108, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbc0051612fd9a633a918aed1da3c3392313937d'}, {'y': 139, 'x': 216, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=435afe2fe2cde6d4f8df37817a37cd210a66430f'}, {'y': 207, 'x': 320, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ce2c3f43bea6739452baf9a5264f22282464ce9'}, {'y': 414, 'x': 640, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ba4fee50775e9d1f5b49d4d24a3f8bbbba3085e'}, {'y': 621, 'x': 960, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0589c87dac8d554ced93a6fd1071d9ef8fbfe4d5'}, {'y': 698, 'x': 1080, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de07e26e0c5b9398004535e068335076fef5d492'}], 's': {'y': 2060, 'x': 3184, 'u': 'https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&amp;format=png&amp;auto=webp&amp;s=8df5c1118f9f0044e2154c8ae63816332ca42d67'}, 'id': 'pe9zyxmkwyxb1'}, 'bvpeu47iwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 87, 'x': 108, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4bc25a90422878a74cbcc020b168b57f9ff5c5d2'}, {'y': 175, 'x': 216, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a301e2f07826433afffe45f9a571ff43f6fbf8f4'}, {'y': 259, 'x': 320, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=12fa039eedfc6755adc172a8daa0561be183cbad'}, {'y': 518, 'x': 640, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a53112c44ac9d286f6ff850086936d8934a6380'}, {'y': 778, 'x': 960, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d62eac8af16368c1c122b1684d2239fc99304765'}, {'y': 875, 'x': 1080, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=220c3349715296d3a4ce9db2511267518bc12234'}], 's': {'y': 1784, 'x': 2200, 'u': 'https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&amp;format=png&amp;auto=webp&amp;s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa'}, 'id': 'bvpeu47iwyxb1'}, 'adj6ge9jvyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 49, 'x': 108, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0efa564522076e00cf3b8286be56bcc2ec0b571'}, {'y': 99, 'x': 216, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd5b2f41768bda4fb1dea0acaa468a7cb08d16c3'}, {'y': 147, 'x': 320, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=64fca4e187d6732b335c5f1c6f5e83dd96372b5b'}, {'y': 295, 'x': 640, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=877a7e456e85cfc27c5fa78895fb994fc91ae684'}, {'y': 443, 'x': 960, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd945fed5363f1963fb90645286f68f9ef8c9b45'}, {'y': 499, 'x': 1080, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=523e7baaac9d1272c30be193e3ca21be2d4dcd94'}], 's': {'y': 1304, 'x': 2820, 'u': 'https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&amp;format=png&amp;auto=webp&amp;s=2123533d9d04aabcdd5988471274ee2ed3b98704'}, 'id': 'adj6ge9jvyxb1'}, 'ay21vccnwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 50, 'x': 108, 'u': 'https://preview.redd.it/ay21vccnwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b773d6197f1963bb658c73efac82120a0fc18a8'}, {'y': 101, 'x': 216, 'u': 'https://preview.redd.it/ay21vccnwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=29673d4595b283b4899c1829e7cea4a59bf5fb0e'}, {'y': 150, 'x': 320, 'u': 'https://preview.redd.it/ay21vccnwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e9c7f025855eaffcfd739d8cada45eb0e103d3a'}, {'y': 300, 'x': 640, 'u': 'https://preview.redd.it/ay21vccnwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3747a1e6e11027c16b4e7b9fafdee2039e2e284'}], 's': {'y': 436, 'x': 928, 'u': 'https://preview.redd.it/ay21vccnwyxb1.png?width=928&amp;format=png&amp;auto=webp&amp;s=9862b0860c49c87a76b02218f8e4118134acfb89'}, 'id': 'ay21vccnwyxb1'}, 'sl4fums4wyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 40, 'x': 108, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f958f74c127f044f82981a378e790c49e11a15b1'}, {'y': 80, 'x': 216, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fadbb448dca93b396507f9ce2b47724b56c3801f'}, {'y': 118, 'x': 320, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=250aa7bdb6f76fa38ad2cac5fe9cb446febed9f5'}, {'y': 237, 'x': 640, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad8b627073b52f90cba3e6455ef8b7baf0ba6c5d'}, {'y': 355, 'x': 960, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e4e02b1d004d1d1cfeff13ee13e10b5ff7af6836'}, {'y': 400, 'x': 1080, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=25813604cf6b6c0aceab7ef63d9c3901b625c713'}], 's': {'y': 856, 'x': 2310, 'u': 'https://preview.redd.it/sl4fums4wyxb1.png?width=2310&amp;format=png&amp;auto=webp&amp;s=4c0c87299460bd22163f34db1040a56ea3893059'}, 'id': 'sl4fums4wyxb1'}, 'sdvfivrzvyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 74, 'x': 108, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e99f98711f8d0213491f0b7917727927a41f3dd'}, {'y': 149, 'x': 216, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0353a031cebdff717c2e8be05e39eac20e5f462d'}, {'y': 221, 'x': 320, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6a4d49b31960618f9521739aa0befb7552b40bb'}, {'y': 442, 'x': 640, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7fbff5e1cfa740f1f5ee06d71fde718f103c31c7'}, {'y': 663, 'x': 960, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=18896af7fcd97e02fbbd762c895a494d1aaeaf04'}, {'y': 746, 'x': 1080, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a8b001c30268c1091913a0faf2270087f5d9c7c2'}], 's': {'y': 2264, 'x': 3276, 'u': 'https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&amp;format=png&amp;auto=webp&amp;s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199'}, 'id': 'sdvfivrzvyxb1'}, '9xzq21vpwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 181, 'x': 108, 'u': 'https://preview.redd.it/9xzq21vpwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=341e11e8732f0bd3a511b80a76ea22b9ebf905e9'}, {'y': 362, 'x': 216, 'u': 'https://preview.redd.it/9xzq21vpwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=57e0396ef0a66e8e9904a68da30c7395ca3311b4'}, {'y': 537, 'x': 320, 'u': 'https://preview.redd.it/9xzq21vpwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9c5f08fd0072b458dbc360dd012df812ab391f4'}], 's': {'y': 588, 'x': 350, 'u': 'https://preview.redd.it/9xzq21vpwyxb1.png?width=350&amp;format=png&amp;auto=webp&amp;s=8432b293be4db0f58770760097df0117b53e667e'}, 'id': '9xzq21vpwyxb1'}, '1q52rzldwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 51, 'x': 108, 'u': 'https://preview.redd.it/1q52rzldwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a65840b25ab96a16aa124a8a7cecfc1287e8415b'}, {'y': 102, 'x': 216, 'u': 'https://preview.redd.it/1q52rzldwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=71b38384688ee4eaaca3f52912b519748bdfcf15'}, {'y': 152, 'x': 320, 'u': 'https://preview.redd.it/1q52rzldwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f997dac69a8fbfef9d5147cc12792ec3d4cc8b1'}], 's': {'y': 190, 'x': 400, 'u': 'https://preview.redd.it/1q52rzldwyxb1.png?width=400&amp;format=png&amp;auto=webp&amp;s=b3b8921e055d38e04ee7395e9b982fa50c38f9df'}, 'id': '1q52rzldwyxb1'}, 'ttn8yd1mvyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 39, 'x': 108, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d606044fd8fd3f5313908ad1194428567f7a447'}, {'y': 78, 'x': 216, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d9834f6d8473f662884ce31cf6d4da5010567ab'}, {'y': 116, 'x': 320, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=73ca2373c238d7581ee885bde0ad37efb9f90c1d'}, {'y': 233, 'x': 640, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1152053a37cc6a5ec6520e96d349a4835561959'}, {'y': 350, 'x': 960, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b010e1d6a8d762620d47a5519ae5476291560f16'}, {'y': 394, 'x': 1080, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5381f2b4d79f7925d40918417085432aa2a2a542'}], 's': {'y': 828, 'x': 2266, 'u': 'https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&amp;format=png&amp;auto=webp&amp;s=f27a52217e85bfade6eb30f0b696914eac7fc270'}, 'id': 'ttn8yd1mvyxb1'}, 'i7825ssvwyxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=be4e90d2d209b57cabf10f06bb326c50d2895e62'}, {'y': 135, 'x': 216, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c4a73bca8cdbb17f979fe8065d13e558703fe27'}, {'y': 201, 'x': 320, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf952eff6478440a288d061cb19680a7ebafe0dc'}, {'y': 402, 'x': 640, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ac4f3d9455c5d4c4f8afdeeb0284fb139ab7250'}, {'y': 603, 'x': 960, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa2ef133feada830c8148ffa3995ded1c8b13dff'}, {'y': 679, 'x': 1080, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=45cf02d7275a328e28a3ec7b35ccbfde4e825555'}], 's': {'y': 2524, 'x': 4012, 'u': 'https://preview.redd.it/i7825ssvwyxb1.png?width=4012&amp;format=png&amp;auto=webp&amp;s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b'}, 'id': 'i7825ssvwyxb1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?auto=webp&amp;s=bbd95f2ed618418523e221ff7c41ba6dd9f9357c', 'width': 1200, 'height': 628}, 'resolutions': [{'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d2d78497c444436ee3852abc1d16b9015582900', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee5de67218e64b1a8a2d0074e79794deb2fdfe59', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1208ab3326e226f1ce06fc0118a968b950ccb0c', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f6b27f6c5034f0e5f9084e9ee514c8477743d62', 'width': 640, 'height': 334}, {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0116da259229cf5a6e961783fd2ca9cd6c557f9b', 'width': 960, 'height': 502}, {'url': 'https://external-preview.redd.it/eSwdItrJS3E9Ig_ezAnCfd0f92B9-nGOnJqjeMTjbn8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=424b98448153dbeb8f5c083fe4d33e1a8fab1934', 'width': 1080, 'height': 565}], 'variants': {}, 'id': 'vIljQHhOnaGyxw1J0M9V8Ba6jkXChTACPR67t5J3Nmc'}], 'enabled': False}",,,,,,,19638,2968
,datascience,"I’m an MS statistician whose gonna be starting a data scientist position soon. I think one of the things I’m the most confident about is my statistical analysis and overarching background I have on methods. I am fairly comfortable I can handle up to 95% of weird data sets, and know how to properly assess assumptions, critically look at data, and choose the right model or tool for the job. I’m even more confident in my ability to present and explain interpretations of results, because that’s what is also emphasized in our applied coursework. With a good background in stats, I’m fairly confident in the actual “doing” of data analysis and wrangling and what not.

But I think the part I’m not really sure about or worried I’ll be bad at is “connecting the dots” between my stats stuff and the business problem. A lot of what I’m worried about is that I can do all of this stuff to understand the data, but if I don’t even understand the context well enough, then my analysis has no path to follow. This ambiguity is something I know I’m going to struggle with, and I’m not sure how I’m going to improve in this area besides talking to more of the stakeholders.

But for any statisticians here who turned to DS, what kind of things did you do to improve this aspect? How did you “connect” the business side to the hard core stats side?",t2_i69qgpqa,False,,0,False,"Statisticians in DS, how did you “connect the dots” between business skills and theory?",[],r/datascience,False,6,discussion,0,,,False,t3_17m7q3j,False,dark,0.94,,public,75,0,{},,,False,[],,False,False,,{},Discussion,False,75,,False,False,self,False,,[],{},,True,,1698943279.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m an MS statistician whose gonna be starting a data scientist position soon. I think one of the things I’m the most confident about is my statistical analysis and overarching background I have on methods. I am fairly comfortable I can handle up to 95% of weird data sets, and know how to properly assess assumptions, critically look at data, and choose the right model or tool for the job. I’m even more confident in my ability to present and explain interpretations of results, because that’s what is also emphasized in our applied coursework. With a good background in stats, I’m fairly confident in the actual “doing” of data analysis and wrangling and what not.&lt;/p&gt;

&lt;p&gt;But I think the part I’m not really sure about or worried I’ll be bad at is “connecting the dots” between my stats stuff and the business problem. A lot of what I’m worried about is that I can do all of this stuff to understand the data, but if I don’t even understand the context well enough, then my analysis has no path to follow. This ambiguity is something I know I’m going to struggle with, and I’m not sure how I’m going to improve in this area besides talking to more of the stakeholders.&lt;/p&gt;

&lt;p&gt;But for any statisticians here who turned to DS, what kind of things did you do to improve this aspect? How did you “connect” the business side to the hard core stats side?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17m7q3j,True,,AdFew4357,,136,True,all_ads,False,[],False,,/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,1209066,1698943279.0,0,,False,,,,,,,,,,1339,244
,datascience,"Or is it essentially seen as marginal? I suspect the larger companies would view it as marginal, and startups up to medium size (with small data teams) would be attracted by this experience. Is that a fair assumption?",t2_3uoce3bn,False,,0,False,Is analytics engineering and business intelligence experience beneficial for seeking DS roles?,[],r/datascience,False,6,fun,0,,,False,t3_17m6b4n,False,dark,0.79,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1698939590.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Or is it essentially seen as marginal? I suspect the larger companies would view it as marginal, and startups up to medium size (with small data teams) would be attracted by this experience. Is that a fair assumption?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17m6b4n,True,,Tender_Figs,,19,True,all_ads,False,[],False,,/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,1209066,1698939590.0,0,,False,,,,,,,,,,217,38
,datascience,"Title. We've given way, for now, to the Data Engineers and Architects to build out pipelines and such and until those are complete, we haven't had a ton of requests coming in.

When things are ""slow"" for your teams, what type of work are you having the junior scientists working on to maintain some level of productivity or skillset building?",t2_10u9hi,False,,0,False,"DS Team Leaders, When requests are slow or little volume, what are you having your team work on in the meantime?",[],r/datascience,False,6,discussion,0,,,False,t3_17m4paw,False,dark,0.91,,public,32,0,{},,,False,[],,False,False,,{},Discussion,False,32,,False,False,self,False,,[],{},,True,,1698935234.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Title. We&amp;#39;ve given way, for now, to the Data Engineers and Architects to build out pipelines and such and until those are complete, we haven&amp;#39;t had a ton of requests coming in.&lt;/p&gt;

&lt;p&gt;When things are &amp;quot;slow&amp;quot; for your teams, what type of work are you having the junior scientists working on to maintain some level of productivity or skillset building?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17m4paw,True,,LionsBSanders20,,37,True,all_ads,False,[],False,,/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,1209066,1698935234.0,0,,False,,,,,,,,,,342,60
,datascience,"Hi , 

I have a dataset with a dependent variable and two explanatory variables. A binary treatment variable and quantitative time since treatment for the cases that received treatment and NA for none-treated cases.  

&amp;#x200B;

Is it possible to include both in a single glmm? 

I'm using glmmtmb in R and the function can only handle NAs by omitting the cases with Na and it would mean here omitting all the non-treated cases from the analysis. 

I'd appreciate your thoughts and ideas.

 

&amp;#x200B;",t2_5cv4sbzc,False,,0,False,running glmm with binary treatment variable and time since treatment,[],r/datascience,False,6,,0,,,False,t3_17m4mmu,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Statistics,False,2,,False,False,self,False,,[],{},,True,,1698935024.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi , &lt;/p&gt;

&lt;p&gt;I have a dataset with a dependent variable and two explanatory variables. A binary treatment variable and quantitative time since treatment for the cases that received treatment and NA for none-treated cases.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is it possible to include both in a single glmm? &lt;/p&gt;

&lt;p&gt;I&amp;#39;m using glmmtmb in R and the function can only handle NAs by omitting the cases with Na and it would mean here omitting all the non-treated cases from the analysis. &lt;/p&gt;

&lt;p&gt;I&amp;#39;d appreciate your thoughts and ideas.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,17m4mmu,True,,TheReal_KindStranger,,5,True,all_ads,False,[],False,,/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,1209066,1698935024.0,0,,False,,,,,,,,,,509,83
,datascience,"We've set up a Pre-Post Test model using the [Causal Impact](https://google.github.io/CausalImpact/CausalImpact.html) package in R, which basically works like this:

* The user feeds it a target and covariates
* The model uses the covariates to predict the target
* It uses the residuals in the post-test period to measure the effect of the change

Great -- except that I'm coming to a challenge I have again and again with statistical models, which is that tiny changes to the model completely change the results.

We are training the models on earlier data and checking the RMSE to ensure goodness of fit before using it on the actual test data, but I can use two models with near-identical RMSEs and have one test be positive and the other be negative.

The conventional wisdom I've always been told was not to peek at your data and not to tweak it once you've run the test, but that feels incorrect to me. My instinct is that, if you tweak your model slightly and get a different result, it's a good indicator that your results are not reproducible.

So I'm curious how other people handle this. I've been considering setting up the model to identify 5 settings with low RMSEs, run them all, and check for consistency of results, but that might be a bit drastic.

How do you other people handle this?",t2_bxdnw,False,,0,False,How do you avoid p-hacking?,[],r/datascience,False,6,,0,,,False,t3_17m2b07,False,dark,0.95,,public,130,0,{},,,False,[],,False,False,,{},Statistics,False,130,,False,False,self,False,,[],{},,True,,1698927897.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We&amp;#39;ve set up a Pre-Post Test model using the &lt;a href=""https://google.github.io/CausalImpact/CausalImpact.html""&gt;Causal Impact&lt;/a&gt; package in R, which basically works like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The user feeds it a target and covariates&lt;/li&gt;
&lt;li&gt;The model uses the covariates to predict the target&lt;/li&gt;
&lt;li&gt;It uses the residuals in the post-test period to measure the effect of the change&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Great -- except that I&amp;#39;m coming to a challenge I have again and again with statistical models, which is that tiny changes to the model completely change the results.&lt;/p&gt;

&lt;p&gt;We are training the models on earlier data and checking the RMSE to ensure goodness of fit before using it on the actual test data, but I can use two models with near-identical RMSEs and have one test be positive and the other be negative.&lt;/p&gt;

&lt;p&gt;The conventional wisdom I&amp;#39;ve always been told was not to peek at your data and not to tweak it once you&amp;#39;ve run the test, but that feels incorrect to me. My instinct is that, if you tweak your model slightly and get a different result, it&amp;#39;s a good indicator that your results are not reproducible.&lt;/p&gt;

&lt;p&gt;So I&amp;#39;m curious how other people handle this. I&amp;#39;ve been considering setting up the model to identify 5 settings with low RMSEs, run them all, and check for consistency of results, but that might be a bit drastic.&lt;/p&gt;

&lt;p&gt;How do you other people handle this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,370e8fc0-70eb-11ee-b58a-86a96bfd3389,False,False,False,,[],False,,,,t5_2sptq,False,,,#94e044,17m2b07,True,,takenorinvalid,,58,True,all_ads,False,[],False,,/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,1209066,1698927897.0,0,,False,,,,,,,,,,1304,228
,datascience,"I'm planning to attend ICML 2024 in person. Can somebody share their experience of attending the conference? Is it worth attending if you don't have any paper to present? If yes, how to get the most out of it?",t2_d1p28kh,False,,0,False,Can somebody share their experience of attending ICML conference?,[],r/datascience,False,6,discussion,0,,,False,t3_17m17c7,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1698923886.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m planning to attend ICML 2024 in person. Can somebody share their experience of attending the conference? Is it worth attending if you don&amp;#39;t have any paper to present? If yes, how to get the most out of it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17m17c7,True,,cpluscplus,,2,True,all_ads,False,[],False,,/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,all_ads,False,https://www.reddit.com/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,1209066,1698923886.0,0,,False,,,,,,,,,,209,39
,datascience,Curious about the DS arena,t2_amfdjuba,False,,0,False,[SERIOUS] What do you not like about your boss or big bosses and how does that affect progress of your organization?,[],r/datascience,False,6,fun,0,,,False,t3_17ltjt8,False,dark,0.83,,public,15,0,{},,,False,[],,False,False,,{},Career Discussion,False,15,,False,False,self,False,,[],{},,True,,1698892684.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Curious about the DS arena&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ltjt8,True,,limedove,,18,True,all_ads,False,[],False,,/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,1209066,1698892684.0,0,,False,,,,,,,,,,26,5
,datascience,"Does that mean my resume made it farther along in the decision process? That maybe I wasn't immediately auto-filtered out? Or does it mean nothing? 

I'm trying to understand how my resume faired against the algorithms... If anyone has tips on that or a library of the latest ""greenlight"" resume algorithm parser buzzwords, please, do share. 

Thanks!",t2_i7ayqhxyj,False,,0,False,"qq - if I receive ""thanks but no thanks"" email months after application...",[],r/datascience,False,6,fun,0,,,False,t3_17lsxof,False,dark,0.81,,public,26,0,{},,,False,[],,False,False,,{},Career Discussion,False,26,,False,False,self,False,,[],{},,True,,1698890866.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does that mean my resume made it farther along in the decision process? That maybe I wasn&amp;#39;t immediately auto-filtered out? Or does it mean nothing? &lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to understand how my resume faired against the algorithms... If anyone has tips on that or a library of the latest &amp;quot;greenlight&amp;quot; resume algorithm parser buzzwords, please, do share. &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17lsxof,True,,takemetojupyter,,12,True,all_ads,False,[],False,,/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,all_ads,False,https://www.reddit.com/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,1209066,1698890866.0,0,,False,,,,,,,,,,351,57
,datascience,"Hi all, I'm an junior data analyst. I'm currently learning all sorts of stats and techniques on my way to improving my skills.

Currently I'm investigating a dataset full of invoices and there are a few questions I'm trying to answer. 

For example how many orders are on time/late based on xyz checks which I've coded.
I've also found cost discrepancies between what was actually done and what was invoiced.

One task I've been assigned is to see what teams are ordering what services and I wanted to approach it with potentially a more nuanced approach.
I have recently been learning the theory and application of Association rules to do the following : 
 
I would like to know if I could split all the orders by teams and then code an association rule algorithm which would mean my results are specific to teams. 
E.g X team order y item and with y item z was also often ordered.


Outside of that is there any other kind of ""fun"" statistically backed learning I could do from invoices? 

Thanks for any advice!",t2_3be1ewd0,False,,0,False,Help me understand if my approach is correct please!,[],r/datascience,False,6,discussion,0,,,False,t3_17lrtkx,False,dark,0.79,,public,8,0,{},,,False,[],,False,False,,{},Discussion,False,8,,False,False,self,False,,[],{},,True,,1698887667.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m an junior data analyst. I&amp;#39;m currently learning all sorts of stats and techniques on my way to improving my skills.&lt;/p&gt;

&lt;p&gt;Currently I&amp;#39;m investigating a dataset full of invoices and there are a few questions I&amp;#39;m trying to answer. &lt;/p&gt;

&lt;p&gt;For example how many orders are on time/late based on xyz checks which I&amp;#39;ve coded.
I&amp;#39;ve also found cost discrepancies between what was actually done and what was invoiced.&lt;/p&gt;

&lt;p&gt;One task I&amp;#39;ve been assigned is to see what teams are ordering what services and I wanted to approach it with potentially a more nuanced approach.
I have recently been learning the theory and application of Association rules to do the following : &lt;/p&gt;

&lt;p&gt;I would like to know if I could split all the orders by teams and then code an association rule algorithm which would mean my results are specific to teams. 
E.g X team order y item and with y item z was also often ordered.&lt;/p&gt;

&lt;p&gt;Outside of that is there any other kind of &amp;quot;fun&amp;quot; statistically backed learning I could do from invoices? &lt;/p&gt;

&lt;p&gt;Thanks for any advice!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17lrtkx,True,,Actual_Plant_862,,5,True,all_ads,False,[],False,,/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,all_ads,False,https://www.reddit.com/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,1209066,1698887667.0,0,,False,,,,,,,,,,1014,180
,datascience,"I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.

I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.

But it seens my initial ideas of contribution were already done...

First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much better than they have already lol

I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.

Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them",t2_7xe340s7,False,,0,False,Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!,[],r/datascience,False,6,meta,0,,,False,t3_17lffnz,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1698854538.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.&lt;/p&gt;

&lt;p&gt;I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.&lt;/p&gt;

&lt;p&gt;But it seens my initial ideas of contribution were already done...&lt;/p&gt;

&lt;p&gt;First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much better than they have already lol&lt;/p&gt;

&lt;p&gt;I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.&lt;/p&gt;

&lt;p&gt;Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17lffnz,True,,SnooPineapples7791,,3,True,all_ads,False,[],False,,/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,all_ads,False,https://www.reddit.com/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,1209066,1698854538.0,0,,False,,,,,,,,,,883,156
,datascience,"I'm a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I'm targeting appeared geared towards product data science. I'd like to hear from data scientists currently working in product roles:

\- How to stand out in terms of past experience, projects, resume, interview, etc?

\- What does a ""product"" data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?

\- What type of specific skills are you looking for outside of the core data science skillset?

I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a ""product"", but I'm not sure if it's directly applicable, especially with regards to customer behavior.",t2_1ns77nex,False,,0,False,How to be Competitive for a Product Data Scientist Role?,[],r/datascience,False,6,fun,0,,,False,t3_17le04v,False,dark,0.86,,public,45,0,{},,,False,[],,False,False,,{},Career Discussion,False,45,,False,False,self,False,seniorflair,[],{},,True,,1698850684.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I&amp;#39;m targeting appeared geared towards product data science. I&amp;#39;d like to hear from data scientists currently working in product roles:&lt;/p&gt;

&lt;p&gt;- How to stand out in terms of past experience, projects, resume, interview, etc?&lt;/p&gt;

&lt;p&gt;- What does a &amp;quot;product&amp;quot; data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?&lt;/p&gt;

&lt;p&gt;- What type of specific skills are you looking for outside of the core data science skillset?&lt;/p&gt;

&lt;p&gt;I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a &amp;quot;product&amp;quot;, but I&amp;#39;m not sure if it&amp;#39;s directly applicable, especially with regards to customer behavior.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,Data Scientist MS|MBA ,[],False,,,,t5_2sptq,False,,,#0079d3,17le04v,True,,DJAlaskaAndrew,,27,True,all_ads,False,[],False,dark,/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,1209066,1698850684.0,0,,False,,,,,,,,,,959,170
,datascience,"Hello folks

For the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work

[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)

hope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!",t2_uamr9xer,False,,0,False,"Metabase, PowerBI and Gooddata capabilities: A comparison",[],r/datascience,False,6,tooling,0,,,False,t3_17l8xdt,False,dark,0.56,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698833994.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello folks&lt;/p&gt;

&lt;p&gt;For the ones of you who manage dashboards or semantic models in UI tools, here&amp;#39;s an article describing 3 popular tools and their capabilities at doing this work&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://dlthub.com/docs/blog/semantic-modeling-tools-comparison""&gt;https://dlthub.com/docs/blog/semantic-modeling-tools-comparison&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;hope you enjoy the read and if you&amp;#39;d like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17l8xdt,True,,Thinker_Assignment,,0,True,all_ads,False,[],False,,/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,1209066,1698833994.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?auto=webp&amp;s=baf5edae6ead07395e7b0f4f43b416bb4f7d2663', 'width': 1017, 'height': 502}, 'resolutions': [{'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aad7f0d66da3e4f493a2e586874be97a7eef7ef2', 'width': 108, 'height': 53}, {'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8721a71c23b0248f369ee7e7bb3470111e9c6c2', 'width': 216, 'height': 106}, {'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d45554e342882523cb3df4a37ebe617641870400', 'width': 320, 'height': 157}, {'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2114b9c84fbc85f25e822d69742996f6aca22f1e', 'width': 640, 'height': 315}, {'url': 'https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7699e43df6a105dd859147cd6d4e730ee0deb64', 'width': 960, 'height': 473}], 'variants': {}, 'id': '8jYk58ZKnFHJb47ZtO42qbrIKmGGyqQijmsQllfJlw4'}], 'enabled': False}",,,,,,,458,59
,datascience,"I've been watching his videos for a while now and being a beginner, I assumed he was pretty good.

However, I've seen a few people criticise him for not knowing what he's talking about, and that he's only good for absolute beginners.",t2_cs54hyd66,False,,0,False,Thoughts on Krish Naik?,[],r/datascience,False,6,,0,,,False,t3_17l3gak,False,dark,0.53,,public,1,0,{},,,False,[],,False,False,,{},Education,False,1,,False,False,self,False,,[],{},,True,,1698810020.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been watching his videos for a while now and being a beginner, I assumed he was pretty good.&lt;/p&gt;

&lt;p&gt;However, I&amp;#39;ve seen a few people criticise him for not knowing what he&amp;#39;s talking about, and that he&amp;#39;s only good for absolute beginners.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17l3gak,True,,Mission-Language8789,,18,True,all_ads,False,[],False,,/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,all_ads,False,https://www.reddit.com/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,1209066,1698810020.0,0,,False,,,,,,,,,,233,42
,datascience,If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..,t2_ayqufd5k,False,,0,False,Why should I learn LangChain? It’s like learning a whole new tool set on top of LLM/Transformer models…,[],r/datascience,False,6,projects,0,,,False,t3_17l11nx,False,dark,0.81,,public,29,0,{},,,False,[],,False,False,,{},ML,False,29,,False,False,self,False,,[],{},,True,,1698802357.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17l11nx,True,,Dependent_Mushroom98,,29,True,all_ads,False,[],False,,/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,1209066,1698802357.0,0,,False,,,,,,,,,,122,25
,datascience,"From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. 

I always assumed that it was 'bad form' to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use ""42"" or ""365"" or ""1234"" all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? ",t2_ghxga,False,,0,False,Data folks of Reddit: How do you choose a random seed?,[],r/datascience,False,6,discussion,0,,,False,t3_17kxd5s,False,dark,0.92,,public,103,0,{},,,False,[],,False,False,,{},Discussion,False,103,,False,False,self,False,,[],{},,True,,1698791634.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. &lt;/p&gt;

&lt;p&gt;I always assumed that it was &amp;#39;bad form&amp;#39; to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use &amp;quot;42&amp;quot; or &amp;quot;365&amp;quot; or &amp;quot;1234&amp;quot; all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17kxd5s,True,,CatOfGrey,,124,True,all_ads,False,[],False,,/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,1209066,1698791634.0,0,,False,,,,,,,,,,483,88
,datascience,I’ll compile answers and write an article with the summary,t2_dif6b393,False,,0,False,Describe the analytics tool of your dreams…,[],r/datascience,False,6,tooling,0,,,False,t3_17kvn2f,False,dark,0.63,,public,4,0,{},,,False,[],,False,False,,{},Tools,False,4,,False,False,self,False,,[],{},,True,,1698787019.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ll compile answers and write an article with the summary&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17kvn2f,True,,ExpressOcelot8977,,25,True,all_ads,False,[],False,,/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,1209066,1698787019.0,0,,False,,,,,,,,,,58,10
,datascience,I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?,t2_dc8euqz6,False,,0,False,Resources for technical interviews with focus on cleaning unstructured data?,[],r/datascience,False,6,fun,0,,,False,t3_17kvm37,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,False,,[],{},,True,,1698786949.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17kvm37,True,,Illustrious-Bed5587,,6,True,all_ads,False,[],False,,/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,1209066,1698786949.0,0,,False,,,,,,,,,,194,31
,datascience,"I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.

I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.

Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.

The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.

Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.

I was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.

There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.

After a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.

Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.

Finally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.

After this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.

I also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).

So, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this.",t2_7q2ap,False,,0,False,"Why some data science interviews suck, as an interviewer...",[],r/datascience,False,6,fun,0,,,False,t3_17kvjmp,False,dark,0.98,,public,223,0,{},,,False,[],,False,False,,{},Career Discussion,False,223,,False,False,self,False,,[],{},,True,,1698786767.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I&amp;#39;d give my experience from the other side of the desk which may go some way to showing why it can be so bad.&lt;/p&gt;

&lt;p&gt;I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.&lt;/p&gt;

&lt;p&gt;Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.&lt;/p&gt;

&lt;p&gt;The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some &amp;#39;calibration&amp;#39; briefing before the interviews; it was too late to speak to HR.&lt;/p&gt;

&lt;p&gt;Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no &amp;#39;calibration&amp;#39; brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.&lt;/p&gt;

&lt;p&gt;I was dropped straight into a &amp;#39;technical&amp;#39; interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.&lt;/p&gt;

&lt;p&gt;There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be &amp;#39;The candidate readily accepts new ideas&amp;#39;. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.&lt;/p&gt;

&lt;p&gt;After a few of these there was the &amp;#39;technical&amp;#39; section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.&lt;/p&gt;

&lt;p&gt;Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.&lt;/p&gt;

&lt;p&gt;Finally there was a group activity and we were supposed to observe the &amp;#39;teamwork&amp;#39; but the team just split the tasks and got on with them individually so there was hardly anything to observe.&lt;/p&gt;

&lt;p&gt;After this the HR bod asked us to complete all the assessments and submit them. Then we&amp;#39;d have a &amp;#39;wash up&amp;#39;. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.&lt;/p&gt;

&lt;p&gt;I also asked about the inappropriate technical questions and they said they didn&amp;#39;t get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).&lt;/p&gt;

&lt;p&gt;So, as you can see, HR ruin everything they touch and hiring is a HR process so it&amp;#39;s terrible. Sorry if you had to go through this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17kvjmp,True,,nth_citizen,,57,True,all_ads,False,[],False,,/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,1209066,1698786767.0,0,,False,,,,,,,,,,3135,556
,datascience,"My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods &amp; neural networks in particular. 

I'm thinking of the Georgia Tech one but would be curious to hear about others.",t2_89ar1fajx,False,,0,False,"If you did an online MSc in Stats and/or DS or something in that area &amp; liked it, what program was it and what did you like about it?",[],r/datascience,False,6,,0,,,False,t3_17ktlc5,False,dark,0.86,,public,14,0,{},,,False,[],,False,False,,{},Education,False,14,,False,False,self,False,,[],{},,True,,1698781586.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My company offers tuition assistance and I&amp;#39;m thinking about going back for a formal degree, but it&amp;#39;d need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there&amp;#39;s gaps in my math and experience with some of the newer ML methods &amp;amp; neural networks in particular. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m thinking of the Georgia Tech one but would be curious to hear about others.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17ktlc5,True,,AnxiousEgg6284,,12,True,all_ads,False,[],False,,/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,1209066,1698781586.0,0,,False,,,,,,,,,,516,98
,datascience,"Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.

So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.

In the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served

DM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all",t2_l386p,False,,0,False,automating ad-hoc SQL requests from stakeholders,[],r/datascience,False,6,tooling,0,,,False,t3_17kpxml,False,dark,0.75,,public,10,0,{},,,False,[],,False,False,,{},Tools,False,10,,False,False,self,False,,[],{},,True,,1698772053.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey y&amp;#39;all, I made a &lt;a href=""https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/""&gt;post&lt;/a&gt; here last month about my team spending too much time on ad-hoc SQL requests.&lt;/p&gt;

&lt;p&gt;So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It&amp;#39;s basically a text to SQL interface for your users. We&amp;#39;re looking for a design partner to use our product for free in exchange for feedback.&lt;/p&gt;

&lt;p&gt;In the original &lt;a href=""https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/""&gt;post&lt;/a&gt; there were concerns with trusting an LLM to produce accurate queries. We think there are too, it&amp;#39;s not perfect yet. That&amp;#39;s why we&amp;#39;d love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served&lt;/p&gt;

&lt;p&gt;DM or comment if you&amp;#39;re interested and we&amp;#39;ll set something up! Would love to hear some feedback, positive or negative, from y&amp;#39;all&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17kpxml,True,,ruckrawjers,,27,True,all_ads,False,[],False,,/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,1209066,1698772053.0,0,,False,,,,,,,,,,1023,149
,datascience,"Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? 

My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren’t able to print summaries like this and I don’t think we should limit ourselves to GLR only for future projects. 

So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I’m not even sure how I would suggest using other algorithms for future business projects if they don’t agree with using a correlation matrix or features of importance to pick the features.",t2_5akq1mi3,False,,0,False,How do you analyze your models?,[],r/datascience,False,6,network,0,,,False,t3_17kp0nu,False,dark,0.94,,public,14,0,{},,,False,[],,False,False,,{},Analysis,False,14,,False,False,self,False,,[],{},,True,,1698769598.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? &lt;/p&gt;

&lt;p&gt;My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren’t able to print summaries like this and I don’t think we should limit ourselves to GLR only for future projects. &lt;/p&gt;

&lt;p&gt;So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I’m not even sure how I would suggest using other algorithms for future business projects if they don’t agree with using a correlation matrix or features of importance to pick the features.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17kp0nu,True,,Dapper-Economy,,36,True,all_ads,False,[],False,,/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,1209066,1698769598.0,0,,False,,,,,,,,,,967,179
,datascience,"Got assigned some TS projects at work and now have kind of carved out this niche at my company. It’s great career-wise but I feel like I’d enjoy working with other ML approaches more. 

Time series at the scale I’m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. 

It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. 

Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?",t2_g7jmnu5,False,,0,False,Anyone else find time series work a little dull?,[],r/datascience,False,6,discussion,0,,,False,t3_17koo01,False,dark,0.94,,public,99,0,{},,,False,[],,False,False,,{},Discussion,False,99,,False,False,self,False,,[],{},,True,,1698768668.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Got assigned some TS projects at work and now have kind of carved out this niche at my company. It’s great career-wise but I feel like I’d enjoy working with other ML approaches more. &lt;/p&gt;

&lt;p&gt;Time series at the scale I’m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. &lt;/p&gt;

&lt;p&gt;It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. &lt;/p&gt;

&lt;p&gt;Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17koo01,True,,_hairyberry_,,62,True,all_ads,False,[],False,,/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,all_ads,False,https://www.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,1209066,1698768668.0,0,,False,,,,,,,,,,709,131
,datascience,"Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.

I'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.

https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa",t2_hcgjj0xo,False,,0,False,What are the possible reasons for validation loss to fluctuate so much?,[],r/datascience,False,6,projects,0,105.0,,False,t3_17kmxnc,False,dark,1.0,,public,5,0,{},140.0,,False,[],,False,False,,{},ML,False,5,,False,False,https://b.thumbs.redditmedia.com/fpweJb1vOAfmPPotR_URI75nCKNS8GeENhE2Rtp6YPU.jpg,False,,[],{},,True,,1698764164.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to  solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular  structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;,  &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is  &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa""&gt;https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17kmxnc,True,,Total-Opposite-8396,,2,True,all_ads,False,[],False,,/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,1209066,1698764164.0,0,,False,"{'gerrkzyzxjxb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e2a5627af7b1c267249de3a3e7f0ff925f0b3aa'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6b403d79031bd86f826c73bfa42c859981b8306'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd5e667d6c545449021465ebfd60cd8bf51b2ee9'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8330db62adf83621f9466ea9aec74bc7c388347c'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=911c8213651e7ab675c2811cc1cf28983a6ae038'}, {'y': 810, 'x': 1080, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1ec96c1e6f9b25fc17e998f016ac3ffafd21c19b'}], 's': {'y': 816, 'x': 1087, 'u': 'https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa'}, 'id': 'gerrkzyzxjxb1'}}",,,,,,,,,754,97
,datascience,Would appreciate other website suggestions too.,t2_bmxqugb8,False,,0,False,Is Upwork a good place to find data science freelance gigs in the UK ?,[],r/datascience,False,6,discussion,0,,,False,t3_17kmu0e,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,False,self,False,,[],{},,True,,1698763882.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Would appreciate other website suggestions too.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17kmu0e,True,,FreakedoutNeurotic98,,14,True,all_ads,False,[],False,,/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,1209066,1698763882.0,0,,False,,,,,,,,,,47,6
,datascience," So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.

For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.

Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.

My question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?

What has been your experience? Has SHAP worked for you in case LM or GLM models?

What are the pitfalls of using SHAP?",t2_1umdosna,False,,0,False,Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?,[],r/datascience,False,6,discussion,0,,,False,t3_17kfjr0,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Discussion,False,6,,False,False,self,False,,[],{},,True,,1698737668.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.&lt;/p&gt;

&lt;p&gt;For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.&lt;/p&gt;

&lt;p&gt;Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.&lt;/p&gt;

&lt;p&gt;My question is : Would a SHAP value applied on top of the Linear regression model discover the same &amp;#39;truth&amp;#39;. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?&lt;/p&gt;

&lt;p&gt;What has been your experience? Has SHAP worked for you in case LM or GLM models?&lt;/p&gt;

&lt;p&gt;What are the pitfalls of using SHAP?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17kfjr0,True,,venkarafa,,5,True,all_ads,False,[],False,,/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,1209066,1698737668.0,0,,False,,,,,,,,,,1093,189
,datascience,I've seen a few people talk cursor [https://cursor.sh/](https://cursor.sh/) for software saying that it was good. Has anyone tried it for data science?  ,t2_c2he9,False,,0,False,Has anyone tried Cursor.sh AI editor for data science?,[],r/datascience,False,6,,0,,,False,t3_17k3svb,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},AI,False,4,,False,False,self,False,,[],{},,True,,1698700202.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve seen a few people talk cursor &lt;a href=""https://cursor.sh/""&gt;https://cursor.sh/&lt;/a&gt; for software saying that it was good. Has anyone tried it for data science?  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,2f731e52-70eb-11ee-bec5-5a5142e6a4d2,False,False,False,,[],False,,,,t5_2sptq,False,,,#46d160,17k3svb,True,,soggypocket,,3,True,all_ads,False,[],False,,/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,1209066,1698700202.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?auto=webp&amp;s=ddd8534bccd1e9ba238ef21b5d0fc7c4c457fb97', 'width': 1280, 'height': 768}, 'resolutions': [{'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7185039b9858f428266b2f6416be37e60f4e6f23', 'width': 108, 'height': 64}, {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c09e7c93e2dddf120954de9f757c970ff207dcce', 'width': 216, 'height': 129}, {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df9fb53b9d7a724ddb7e217e326075f7decdcecc', 'width': 320, 'height': 192}, {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1aeb9824b09f337e027493de1389cc5ec0f4c42a', 'width': 640, 'height': 384}, {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=279b74c69dbc47d261554d71fca84f23354f789f', 'width': 960, 'height': 576}, {'url': 'https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2ae3a7c8bd64d82a6d257c2b53f158916fa969af', 'width': 1080, 'height': 648}], 'variants': {}, 'id': 'I0Ul3MOzbyiZw9IRp9XDSogkzkh7d8CGD6U_MgNb1SA'}], 'enabled': False}",,,,,,,153,22
,datascience,"Are you currently involved in a project that revolves around fulfilling customer requirements? As part of your responsibilities, are you tasked with deploying a functional data science project?

I'm referring to the point at which you determine that the project is prepared for delivery. Is it sufficient to provide a functional model based on a script or notebook, accompanied by a presentation that includes relevant metrics? Or do you also engage in the deployment phase? I'm somewhat perplexed because there is often a request for a ""proof of concept,"" but is functional code alone sufficient to satisfy this requirement?

I am a part of a small team and my team seldom deals with external clients, so I'm unsure about the boundaries between what should be accomplished before transitioning to a production-level stage. ",t2_14y1ku,False,,0,False,Where to Draw the Line between Proof of Concept and Deployment?,[],r/datascience,False,6,meta,0,,,False,t3_17jygyq,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1698686218.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are you currently involved in a project that revolves around fulfilling customer requirements? As part of your responsibilities, are you tasked with deploying a functional data science project?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m referring to the point at which you determine that the project is prepared for delivery. Is it sufficient to provide a functional model based on a script or notebook, accompanied by a presentation that includes relevant metrics? Or do you also engage in the deployment phase? I&amp;#39;m somewhat perplexed because there is often a request for a &amp;quot;proof of concept,&amp;quot; but is functional code alone sufficient to satisfy this requirement?&lt;/p&gt;

&lt;p&gt;I am a part of a small team and my team seldom deals with external clients, so I&amp;#39;m unsure about the boundaries between what should be accomplished before transitioning to a production-level stage. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17jygyq,True,,missing-in-idleness,,8,True,all_ads,False,[],False,,/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,1209066,1698686218.0,0,,False,,,,,,,,,,824,132
,datascience,"I work full time as a data scientist and I have 3 years experience now.  I've become significantly more efficient and experienced and I feel that I could take on more work than my company gives me.  My boss wouldn't mind if I took some extra work on the side, he's very flexible and I was wondering how people find contracts for short term gigs?  Are there any sites in particular people have had success with?  What do you typically bill at?  


Edit:  General vibe I'm getting is that this is a waste of time and after scrolling through the options on Upwork I'm coming to see it that way as well.",t2_9bow4eln,False,,0,False,How does one find freelance or contract work? Short or long term would be fine.,[],r/datascience,False,6,fun,0,,,False,t3_17jxqm8,False,dark,0.88,,public,27,0,{},,,False,[],,False,False,,{},Career Discussion,False,27,,False,False,self,1698699696.0,,[],{},,True,,1698684320.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work full time as a data scientist and I have 3 years experience now.  I&amp;#39;ve become significantly more efficient and experienced and I feel that I could take on more work than my company gives me.  My boss wouldn&amp;#39;t mind if I took some extra work on the side, he&amp;#39;s very flexible and I was wondering how people find contracts for short term gigs?  Are there any sites in particular people have had success with?  What do you typically bill at?  &lt;/p&gt;

&lt;p&gt;Edit:  General vibe I&amp;#39;m getting is that this is a waste of time and after scrolling through the options on Upwork I&amp;#39;m coming to see it that way as well.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17jxqm8,True,,Unhappy_Technician68,,18,True,all_ads,False,[],False,,/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,1209066,1698684320.0,0,,False,,,,True,,,,,,599,112
,datascience,"I'm a data scientist with a pet project that could turn into something more, but I need more computation power. I have a PC with an RTX 2060 SUPER, but it's getting old. I'm considering Colab Pro+, but I prefer to work with VS Code and build my projects as folders rather than notebooks. I've also explored cloud options, but they seem expensive. My last resort is to buy a refurbished 16GB V100, but I'm hoping to find a more affordable solution.",t2_4udseb4x,False,,0,False,"What is the best way to access computation power for a pet project on small LMMs and BERT fine-tuning, without spending a fortune?",[],r/datascience,False,6,discussion,0,,,False,t3_17ju0z8,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698674328.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a data scientist with a pet project that could turn into something more, but I need more computation power. I have a PC with an RTX 2060 SUPER, but it&amp;#39;s getting old. I&amp;#39;m considering Colab Pro+, but I prefer to work with VS Code and build my projects as folders rather than notebooks. I&amp;#39;ve also explored cloud options, but they seem expensive. My last resort is to buy a refurbished 16GB V100, but I&amp;#39;m hoping to find a more affordable solution.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ju0z8,True,,David202023,,8,True,all_ads,False,[],False,,/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,1209066,1698674328.0,0,,False,,,,,,,,,,447,82
,datascience,"I'm really not sure how to summarize this concisely in a neat title, so just let me explain.

At previous lower level jobs, we were organized. We had ticketing tracking systems, step-by-step procedures for all of the commonly done work, we had checklists that people could sign off on as they completed work. And most importantly, even for one-off requests, the primary mode of communication was email. That way, I had the project specifications and/or updates spelled out in front of me that I could refer back to whenever needed.

As I get higher up in the field at different companies, I'm finding the primary mode of communication is virtual meetings. All of the background, specifications, and next steps are given verbally, and I'm sitting here in these meetings furiously trying to write everything down that is being said. What's worse is that the ideas for the projects often aren't fully developed and we have to figure them out so I get a lot of ""do this, actually no, let's do it this way, but I'm actually thinking it would be better to approach it this way....."". AS you can imagine it makes fully understanding the next steps of a given projects difficult. If I use my judgement and approach it the way I feel is best, half the time it's end up not being what management wants and I have to waste their time and mine on rework. 

One of the ways I tried to work around management's brain dumps on me was to recap back to them what the next steps they wanted from me were, but they're ***super busy*** so they always join the meetings late, and as a result we frequently run out of time.  75% of the time I try to message or email them with questions they just don't respond, so the only way I can get any info out of them is via virtual meetings. This is creating an environment for me that makes mistakes easier to happen, and it's turning into a situation where I can do 9 things right, but if I missed or misunderstood the 10th thing, I'm getting crucified for it (meanwhile this is a common occurrence for management but that's a different rant.....) I'm being made to feel like it's a shortcoming of mine for not being able to take down everything accurately.

I know some people can thrive in these conditions. For me, it's tough. I'm definitely a scatterbrain and I try to compensate for this by being as organized as humanly possible, but it's just easier said than done when most everything is being given ONLY verbally. I understand that the higher you go in data science, the less routine and the more exploratory and R&amp;D your work becomes, so having clearly documented procedures becomes less realistic. But if this is the way most of these positions are going to be, I really don't feel like this field is for me.",t2_abhp8o9x,False,,0,False,Are all higher level data science jobs like this?,[],r/datascience,False,6,fun,0,,,False,t3_17jtkgv,False,dark,0.93,,public,213,0,{},,,False,[],,False,False,,{},Career Discussion,False,213,,False,False,self,False,,[],{},,True,,1698673011.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m really not sure how to summarize this concisely in a neat title, so just let me explain.&lt;/p&gt;

&lt;p&gt;At previous lower level jobs, we were organized. We had ticketing tracking systems, step-by-step procedures for all of the commonly done work, we had checklists that people could sign off on as they completed work. And most importantly, even for one-off requests, the primary mode of communication was email. That way, I had the project specifications and/or updates spelled out in front of me that I could refer back to whenever needed.&lt;/p&gt;

&lt;p&gt;As I get higher up in the field at different companies, I&amp;#39;m finding the primary mode of communication is virtual meetings. All of the background, specifications, and next steps are given verbally, and I&amp;#39;m sitting here in these meetings furiously trying to write everything down that is being said. What&amp;#39;s worse is that the ideas for the projects often aren&amp;#39;t fully developed and we have to figure them out so I get a lot of &amp;quot;do this, actually no, let&amp;#39;s do it this way, but I&amp;#39;m actually thinking it would be better to approach it this way.....&amp;quot;. AS you can imagine it makes fully understanding the next steps of a given projects difficult. If I use my judgement and approach it the way I feel is best, half the time it&amp;#39;s end up not being what management wants and I have to waste their time and mine on rework. &lt;/p&gt;

&lt;p&gt;One of the ways I tried to work around management&amp;#39;s brain dumps on me was to recap back to them what the next steps they wanted from me were, but they&amp;#39;re &lt;strong&gt;&lt;em&gt;super busy&lt;/em&gt;&lt;/strong&gt; so they always join the meetings late, and as a result we frequently run out of time.  75% of the time I try to message or email them with questions they just don&amp;#39;t respond, so the only way I can get any info out of them is via virtual meetings. This is creating an environment for me that makes mistakes easier to happen, and it&amp;#39;s turning into a situation where I can do 9 things right, but if I missed or misunderstood the 10th thing, I&amp;#39;m getting crucified for it (meanwhile this is a common occurrence for management but that&amp;#39;s a different rant.....) I&amp;#39;m being made to feel like it&amp;#39;s a shortcoming of mine for not being able to take down everything accurately.&lt;/p&gt;

&lt;p&gt;I know some people can thrive in these conditions. For me, it&amp;#39;s tough. I&amp;#39;m definitely a scatterbrain and I try to compensate for this by being as organized as humanly possible, but it&amp;#39;s just easier said than done when most everything is being given ONLY verbally. I understand that the higher you go in data science, the less routine and the more exploratory and R&amp;amp;D your work becomes, so having clearly documented procedures becomes less realistic. But if this is the way most of these positions are going to be, I really don&amp;#39;t feel like this field is for me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17jtkgv,True,,son_of_tv_c,,100,True,all_ads,False,[],False,,/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,1209066,1698673011.0,0,,False,,,,,,,,,,2745,495
,datascience,"I feel like a lot of kaggle examples use really simple data sets that you don’t ever find in the real world scenarios(like the Titanic data set for instance).

Does anyone know any notebooks/examples that start with really messy data? I really want to see someone go through the process of EDA/Feature engineering with data sets that have more than 20 variables.",t2_495cn7pm,False,,0,False,Favorite ML Example?,[],r/datascience,False,6,projects,0,,,False,t3_17jst3u,False,dark,0.96,,public,101,0,{},,,False,[],,False,False,,{},ML,False,101,,False,False,self,False,,[],{},,True,,1698670711.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I feel like a lot of kaggle examples use really simple data sets that you don’t ever find in the real world scenarios(like the Titanic data set for instance).&lt;/p&gt;

&lt;p&gt;Does anyone know any notebooks/examples that start with really messy data? I really want to see someone go through the process of EDA/Feature engineering with data sets that have more than 20 variables.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17jst3u,True,,Throwawayforgainz99,,43,True,all_ads,False,[],False,,/r/datascience/comments/17jst3u/favorite_ml_example/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jst3u/favorite_ml_example/,1209066,1698670711.0,0,,False,,,,,,,,,,362,62
,datascience,"I’m doing some analysis and part of my data, possibly a very important part, is a text description of a product. I want to determine if there’s a correlation between the product description and performance, but to do this I need to cluster the descriptions into similar groups. I’m thinking text embeddings could be useful, but I’m unsure of which ones to use. Can anyone provide some advice?

Possibly more important, if I’m completely barking up the wrong tree, please let me know. ",t2_7weys85s,False,,0,False,Recommendation for measuring similarity of paragraphs,[],r/datascience,False,6,projects,0,,,False,t3_17jrbh7,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},ML,False,4,,False,False,self,False,,[],{},,True,,1698665709.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m doing some analysis and part of my data, possibly a very important part, is a text description of a product. I want to determine if there’s a correlation between the product description and performance, but to do this I need to cluster the descriptions into similar groups. I’m thinking text embeddings could be useful, but I’m unsure of which ones to use. Can anyone provide some advice?&lt;/p&gt;

&lt;p&gt;Possibly more important, if I’m completely barking up the wrong tree, please let me know. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17jrbh7,True,,Hot-Profession4091,,16,True,all_ads,False,[],False,,/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,1209067,1698665709.0,0,,False,,,,,,,,,,484,83
,datascience,"How is everyone keeping a good work life balance in this industry? Or work in general. 

I am currently doing my masters as a full time DS and also doing certifications as requested by my managers. 

I am forcing myself to sleep earlier, but the daily screen time is just too draining for my eyes to keep up.",t2_8rwg73ro,False,,0,False,Maintaining a work life balance,[],r/datascience,False,6,discussion,0,,,False,t3_17jmq2n,False,dark,0.94,,public,72,0,{},,,False,[],,False,False,,{},Discussion,False,72,,False,False,self,False,,[],{},,True,,1698645630.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How is everyone keeping a good work life balance in this industry? Or work in general. &lt;/p&gt;

&lt;p&gt;I am currently doing my masters as a full time DS and also doing certifications as requested by my managers. &lt;/p&gt;

&lt;p&gt;I am forcing myself to sleep earlier, but the daily screen time is just too draining for my eyes to keep up.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17jmq2n,True,,EstablishmentHead569,,52,True,all_ads,False,[],False,,/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,1209067,1698645630.0,0,,False,,,,,,,,,,308,58
,datascience,"This is the thing I'm struggling most with. Coming from an academic background, the concerns seem to be different but I'm still having trouble articulating exactly how, or what to do to get better at training myself to be more business-ybif that makes sense",t2_89ar1fajx,False,,0,False,How have you approached training yourself to become better at business acumen/context for your DS work?,[],r/datascience,False,6,discussion,0,,,False,t3_17jgck2,False,dark,0.84,,public,20,0,{},,,False,[],,False,False,,{},Discussion,False,20,,False,False,self,False,,[],{},,True,,1698623938.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is the thing I&amp;#39;m struggling most with. Coming from an academic background, the concerns seem to be different but I&amp;#39;m still having trouble articulating exactly how, or what to do to get better at training myself to be more business-ybif that makes sense&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17jgck2,True,,AnxiousEgg6284,,23,True,all_ads,False,[],False,,/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,1209067,1698623938.0,0,,False,,,,,,,,,,257,44
,datascience,"For all intents and purposes its basically a Power BI table with slicers/filters, or a GUI approach of df[(mask1) &amp; (mask2) &amp; (mask3)].sort_values(by='col1') where you can interact with which columns to mask, how to mask them, and how to sort, resulting in a perfectly tailored table.

I have scraped a list of every game on Steam and I have a dataframe of like 180k games and 470+ columns and was thinking how cool it would be if I could make 
every a table as granular as I want it. e.g. find me games from 2008 that have 1000 total ratings and more than 95% steam review with the tag ""FPS"" sorted by the date it came out, and hide the majority of columns.

If something like this doesnt exist but is able to exist in something like Flask (that I have NO knowledge on), let me know. I just wanted to check if the wheel exists before rebuilding it. If what I want really is difficult to do, let me know and I can just make the same thing in Power BI. This will also make me appreciate Power BI as a tool.",t2_81c0tugs,False,,0,False,Python library to interactively filter a dataframe?,[],r/datascience,False,6,tooling,0,,,False,t3_17jg57k,False,dark,0.95,,public,18,0,{},,,False,[],,False,False,,{},Tools,False,18,,False,False,self,False,,[],{},,True,,1698623348.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For all intents and purposes its basically a Power BI table with slicers/filters, or a GUI approach of df[(mask1) &amp;amp; (mask2) &amp;amp; (mask3)].sort_values(by=&amp;#39;col1&amp;#39;) where you can interact with which columns to mask, how to mask them, and how to sort, resulting in a perfectly tailored table.&lt;/p&gt;

&lt;p&gt;I have scraped a list of every game on Steam and I have a dataframe of like 180k games and 470+ columns and was thinking how cool it would be if I could make 
every a table as granular as I want it. e.g. find me games from 2008 that have 1000 total ratings and more than 95% steam review with the tag &amp;quot;FPS&amp;quot; sorted by the date it came out, and hide the majority of columns.&lt;/p&gt;

&lt;p&gt;If something like this doesnt exist but is able to exist in something like Flask (that I have NO knowledge on), let me know. I just wanted to check if the wheel exists before rebuilding it. If what I want really is difficult to do, let me know and I can just make the same thing in Power BI. This will also make me appreciate Power BI as a tool.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17jg57k,True,,lowkeyripper,,18,True,all_ads,False,[],False,,/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,1209067,1698623348.0,0,,False,,,,,,,,,,1013,193
,datascience,"Hey you guys, I have something I am stuck at and need your advice.

Long story shirt in example:
Customer A: likes to buy at the beginning of the month only
Customer B: likes to buy at the end of each week when visited by an agent because he stocks
Customer C: likes to buy at the beginning, middle and end of the month.

And so on, you kinda get the problem.

I want to be able to identify this and I was thinking of a possible solution but I think it lacks experience: Decompose the seasonal component of each retailer’s time series and then cluster retailers whom purchasing seasonal components are similar with kmeans?

If you think this approach is invalid, please feel free to suggest something I could read.

Thanks.",t2_81zrh19oq,False,,0,False,Identifying time series patterns advice,[],r/datascience,False,6,network,0,,,False,t3_17jg3hh,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Analysis,False,2,,False,False,self,False,,[],{},,True,,1698623212.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey you guys, I have something I am stuck at and need your advice.&lt;/p&gt;

&lt;p&gt;Long story shirt in example:
Customer A: likes to buy at the beginning of the month only
Customer B: likes to buy at the end of each week when visited by an agent because he stocks
Customer C: likes to buy at the beginning, middle and end of the month.&lt;/p&gt;

&lt;p&gt;And so on, you kinda get the problem.&lt;/p&gt;

&lt;p&gt;I want to be able to identify this and I was thinking of a possible solution but I think it lacks experience: Decompose the seasonal component of each retailer’s time series and then cluster retailers whom purchasing seasonal components are similar with kmeans?&lt;/p&gt;

&lt;p&gt;If you think this approach is invalid, please feel free to suggest something I could read.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17jg3hh,True,,Careful_Engineer_700,,9,True,all_ads,False,[],False,,/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,all_ads,False,https://www.reddit.com/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,1209067,1698623212.0,0,,False,,,,,,,,,,723,132
,datascience,Hi r/datascience. I am interested to know the educational qualifications/background of the members of the group. Personally I have a Bachelor's degree in Maths + an MBA. Have been working in Banking + Analytics for the last 12 years. I know we have CS graduates in this group and those who have done MS in data science and Analytics. Would be good to know the diverse educational background of others as well.,t2_ap9dvujm,False,,0,False,What's your educational background,[],r/datascience,False,6,fun,0,,,False,t3_17j80cj,False,dark,0.83,,public,49,0,{},,,False,[],,False,False,,{},Career Discussion,False,49,,False,False,self,False,,[],{},,True,,1698600838.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;. I am interested to know the educational qualifications/background of the members of the group. Personally I have a Bachelor&amp;#39;s degree in Maths + an MBA. Have been working in Banking + Analytics for the last 12 years. I know we have CS graduates in this group and those who have done MS in data science and Analytics. Would be good to know the diverse educational background of others as well.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17j80cj,True,,LowLab2791,,175,True,all_ads,False,[],False,,/r/datascience/comments/17j80cj/whats_your_educational_background/,all_ads,False,https://www.reddit.com/r/datascience/comments/17j80cj/whats_your_educational_background/,1209067,1698600838.0,0,,False,,,,,,,,,,409,72
,datascience,"Graduated 5 months ago with a MS in CS. Before I came to the US to pursue my masters, heard from a boat load of people that getting jobs after graduation was easy and that hardly anyone graduated without a couple offers in hand. That sentiment was echoed by other recent grads I met when I got here.

I always wanted to get into DS, so when everyone started looking for internships, I started looking for DS/DA/DE internships specifically. Gave a bunch of interviews, landed an offer in April of 2022. Just an unfortunate decision. The company had a new data science practice with no clear definition of what a Data Scientist does. Being a consulting firm, we basically jump from one case to another and use whatever tech is needed on a case to case basis.
Spent all summer just doing web scraping and OCR extractions. Also, my manager is super condescending and outright rude. He’s told me multiple times that he “can’t believe I have two degrees in Comp. Sci” and at team gatherings and social events, wouldn’t even look me in the eye or acknowledge my existence lol. On the last day of my summer internship, he was in my office literally laughing at my code which btw was based off a snippet he sent me.

Anyway, once this ordeal was done, the world went into a recession and I had to accept a return internship offer. Return internship because I hadn’t proven myself enough to land a full time role yet. Went through another 3 months of abuse and got a full time offer, been working FT for about 4-5 months now. 

At this point I can’t take it anymore. Every day at work I’m putting out fires with the fear that if I fuck up, I’ll either be publicly ridiculed or fired. Consulting being consulting, work life balance is non existent and I had to move to a city where I have no friends and no social life to at least escape the stress.

To all seniors and hiring managers etc, do you think the job market is going to get better? What’s the trend at your company?

EDIT: Thanks for all the support everyone, it’s a tough spot to be in mentally, but I’m thankful for at least have a job. I know so many people who don’t, so complaining sucks. Hopefully things improve for us all soon.",t2_i9fgk8dg,False,,0,False,The job market is so frustrating,[],r/datascience,False,6,fun,0,,,False,t3_17j3qc7,False,dark,0.86,,public,122,0,{},,,False,[],,False,False,,{},Career Discussion,False,122,,False,False,self,1698641722.0,,[],{},,True,,1698588610.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Graduated 5 months ago with a MS in CS. Before I came to the US to pursue my masters, heard from a boat load of people that getting jobs after graduation was easy and that hardly anyone graduated without a couple offers in hand. That sentiment was echoed by other recent grads I met when I got here.&lt;/p&gt;

&lt;p&gt;I always wanted to get into DS, so when everyone started looking for internships, I started looking for DS/DA/DE internships specifically. Gave a bunch of interviews, landed an offer in April of 2022. Just an unfortunate decision. The company had a new data science practice with no clear definition of what a Data Scientist does. Being a consulting firm, we basically jump from one case to another and use whatever tech is needed on a case to case basis.
Spent all summer just doing web scraping and OCR extractions. Also, my manager is super condescending and outright rude. He’s told me multiple times that he “can’t believe I have two degrees in Comp. Sci” and at team gatherings and social events, wouldn’t even look me in the eye or acknowledge my existence lol. On the last day of my summer internship, he was in my office literally laughing at my code which btw was based off a snippet he sent me.&lt;/p&gt;

&lt;p&gt;Anyway, once this ordeal was done, the world went into a recession and I had to accept a return internship offer. Return internship because I hadn’t proven myself enough to land a full time role yet. Went through another 3 months of abuse and got a full time offer, been working FT for about 4-5 months now. &lt;/p&gt;

&lt;p&gt;At this point I can’t take it anymore. Every day at work I’m putting out fires with the fear that if I fuck up, I’ll either be publicly ridiculed or fired. Consulting being consulting, work life balance is non existent and I had to move to a city where I have no friends and no social life to at least escape the stress.&lt;/p&gt;

&lt;p&gt;To all seniors and hiring managers etc, do you think the job market is going to get better? What’s the trend at your company?&lt;/p&gt;

&lt;p&gt;EDIT: Thanks for all the support everyone, it’s a tough spot to be in mentally, but I’m thankful for at least have a job. I know so many people who don’t, so complaining sucks. Hopefully things improve for us all soon.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17j3qc7,True,,Objective-Test5021,,53,True,all_ads,False,[],False,,/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,all_ads,False,https://www.reddit.com/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,1209067,1698588610.0,0,,False,,,,,,,,,,2185,404
,datascience," 

Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot are available but I am planning to add other plots as well like choropleths, temporal graphs, etc.

Also please let me know if you find any issue.

**Pynimate** is available on [pypi](https://pypi.org/project/pynimate/).

[github](https://github.com/julkaar9/pynimate), [documentation](https://julkaar9.github.io/pynimate/)

Quick usage

    import pandas as pd
    from matplotlib import pyplot as plt
    
    import pynimate as nim
    
    df = pd.DataFrame(
        {
            ""time"": [""1960-01-01"", ""1961-01-01"", ""1962-01-01""],
            ""Afghanistan"": [1, 2, 3],
            ""Angola"": [2, 3, 4],
            ""Albania"": [1, 2, 5],
            ""USA"": [5, 3, 4],
            ""Argentina"": [1, 4, 5],
        }
    ).set_index(""time"")
    
    cnv = nim.Canvas()
    bar = nim.Barhplot.from_df(df, ""%Y-%m-%d"", ""2d"")
    bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(""%b, %Y""))
    cnv.add_plot(bar)
    cnv.animate()
    plt.show()

&amp;#x200B;

https://i.redd.it/27xu9yip74xb1.gif

A little more complex example

&amp;#x200B;

https://i.redd.it/kycvoy4u74xb1.gif

(note: I am aware that animating line plots generally doesn't make any sense)",t2_2fepcqe5,False,,0,False,Python package for statistical data animations,[],r/datascience,False,6,meta,0,140.0,,False,t3_17iztuz,False,dark,0.98,,public,172,0,{},140.0,,True,[],,False,False,,{},Projects,False,172,,False,False,https://b.thumbs.redditmedia.com/xu-8dxBsF6ik9JnTR8u-gAz3JiQsTqqZYBkaGvjsPUQ.jpg,False,,[],{},,True,,1698574086.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot are available but I am planning to add other plots as well like choropleths, temporal graphs, etc.&lt;/p&gt;

&lt;p&gt;Also please let me know if you find any issue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pynimate&lt;/strong&gt; is available on &lt;a href=""https://pypi.org/project/pynimate/""&gt;pypi&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/julkaar9/pynimate""&gt;github&lt;/a&gt;, &lt;a href=""https://julkaar9.github.io/pynimate/""&gt;documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Quick usage&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
from matplotlib import pyplot as plt

import pynimate as nim

df = pd.DataFrame(
    {
        &amp;quot;time&amp;quot;: [&amp;quot;1960-01-01&amp;quot;, &amp;quot;1961-01-01&amp;quot;, &amp;quot;1962-01-01&amp;quot;],
        &amp;quot;Afghanistan&amp;quot;: [1, 2, 3],
        &amp;quot;Angola&amp;quot;: [2, 3, 4],
        &amp;quot;Albania&amp;quot;: [1, 2, 5],
        &amp;quot;USA&amp;quot;: [5, 3, 4],
        &amp;quot;Argentina&amp;quot;: [1, 4, 5],
    }
).set_index(&amp;quot;time&amp;quot;)

cnv = nim.Canvas()
bar = nim.Barhplot.from_df(df, &amp;quot;%Y-%m-%d&amp;quot;, &amp;quot;2d&amp;quot;)
bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(&amp;quot;%b, %Y&amp;quot;))
cnv.add_plot(bar)
cnv.animate()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/27xu9yip74xb1.gif""&gt;https://i.redd.it/27xu9yip74xb1.gif&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A little more complex example&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/kycvoy4u74xb1.gif""&gt;https://i.redd.it/kycvoy4u74xb1.gif&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(note: I am aware that animating line plots generally doesn&amp;#39;t make any sense)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17iztuz,True,,julkar9,,24,True,all_ads,False,[],False,,/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,all_ads,False,https://www.reddit.com/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,1209067,1698574086.0,0,,False,"{'27xu9yip74xb1': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=c13b033118c47b0dbf0461db6251e928b6874b7d'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=c9ac8013cfac7796128f652cf5e16559b823ff8b'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=dfb08a79b812438b9c0162ad57d3786510231d0e'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=742e824d84b950ad038602a9785a308512b83abf'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=845f4361cbc8fd3c2f526f9fcdc8e3354c96df9c'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/27xu9yip74xb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=82217bd34ded353db3bc396d60ba7bdbdad3069b'}], 's': {'y': 900, 'gif': 'https://i.redd.it/27xu9yip74xb1.gif', 'mp4': 'https://preview.redd.it/27xu9yip74xb1.gif?format=mp4&amp;s=c5880f32a8a517551ef54bf56cf101c2a0b412ad', 'x': 1600}, 'id': '27xu9yip74xb1'}, 'kycvoy4u74xb1': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=45e931e1adf53433d3f232383b434d6a142f845c'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=6879a314cd8086cb4db7ce0119df56dc606b6d62'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=f52afc76e4e4d8eb3b63b6c1454a9acdc7b3afbe'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=065db7a0a21341223512b2190d4f7422b0682356'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=42f697987bbb0f4691644cc777226e3aed04a8b3'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/kycvoy4u74xb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=f6d477ebf4b000ae8e6899b33f653c30b2d41b46'}], 's': {'y': 720, 'gif': 'https://i.redd.it/kycvoy4u74xb1.gif', 'mp4': 'https://preview.redd.it/kycvoy4u74xb1.gif?format=mp4&amp;s=4320493fdc5af27b9eb0ccf41e6887875b617098', 'x': 1280}, 'id': 'kycvoy4u74xb1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?auto=webp&amp;s=85f19a22cbd85fa784cdb417359d8ff7cda9e394', 'width': 300, 'height': 300}, 'resolutions': [{'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46fa55dd1b1e587ab93bcbbdc6cb2de37b810bf3', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfd7f76ac4c13cdc287edd9856ef0430dbc862a5', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM'}], 'enabled': False}",,,,,,,1295,136
,datascience,"Is there any book , podcast y'all can recommend  to study guesstimatation problem",t2_b5ou545yj,False,,0,False,Guesstimates,[],r/datascience,False,6,discussion,0,,,False,t3_17ixgz7,False,dark,0.71,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1698563428.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there any book , podcast y&amp;#39;all can recommend  to study guesstimatation problem&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17ixgz7,True,,charlesowo445,,3,True,all_ads,False,[],False,,/r/datascience/comments/17ixgz7/guesstimates/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ixgz7/guesstimates/,1209067,1698563428.0,0,,False,,,,,,,,,,81,13
,datascience,"Not sure if the topic is allowed, but I would like to take opinions from senior data scientists and Analytics managers.

I work in finance as data scientist and work involves preparing data in required format,
Doing analysis and building models for products that we have in market , like propensity models for credit cards , credit risk models etc. 
I have worked as an individual contributor till now and have 5 years of experience. I have never managed anyone but have mentored and led few projects individually. 
I have a new offer for an analytics manager with a well known bank and I'll have to manage 6-7 data analysts/scientists and be responsible for the team’s performance. 

The pay jump is decent (40 percent higher than I currently make) and location is much closer to my home.
I don't have any problems with my current job and people I work with are also great. 

I was thinking if anyone else made that jump. 
Is the transition too steep from not managing anyone to 6-7 people?",t2_696693df,False,,0,False,Taking over new role as DS manager,[],r/datascience,False,6,fun,0,,,False,t3_17ivru4,False,dark,0.83,,public,8,0,{},,,False,[],,False,False,,{},Career Discussion,False,8,,False,False,self,False,,[],{},,True,,1698555869.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not sure if the topic is allowed, but I would like to take opinions from senior data scientists and Analytics managers.&lt;/p&gt;

&lt;p&gt;I work in finance as data scientist and work involves preparing data in required format,
Doing analysis and building models for products that we have in market , like propensity models for credit cards , credit risk models etc. 
I have worked as an individual contributor till now and have 5 years of experience. I have never managed anyone but have mentored and led few projects individually. 
I have a new offer for an analytics manager with a well known bank and I&amp;#39;ll have to manage 6-7 data analysts/scientists and be responsible for the team’s performance. &lt;/p&gt;

&lt;p&gt;The pay jump is decent (40 percent higher than I currently make) and location is much closer to my home.
I don&amp;#39;t have any problems with my current job and people I work with are also great. &lt;/p&gt;

&lt;p&gt;I was thinking if anyone else made that jump. 
Is the transition too steep from not managing anyone to 6-7 people?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ivru4,True,,shar72944,,14,True,all_ads,False,[],False,,/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,1209067,1698555869.0,0,,False,,,,,,,,,,991,175
,datascience,"I’ve started applying around for data analyst roles this week and was wondering how people with 1-3 years experience are doing with their job searches

Asking since most posts on here are either like “no experience how do I break in” posts or like PhD data scientists with not much in between",t2_v4vp2q8o,False,,0,False,How’s the DA job market looking for people with experience?,[],r/datascience,False,6,fun,0,,,False,t3_17isfkx,False,dark,0.86,,public,30,0,{},,,False,[],,False,False,,{},Career Discussion,False,30,,False,False,self,False,,[],{},,True,,1698543574.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve started applying around for data analyst roles this week and was wondering how people with 1-3 years experience are doing with their job searches&lt;/p&gt;

&lt;p&gt;Asking since most posts on here are either like “no experience how do I break in” posts or like PhD data scientists with not much in between&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17isfkx,True,,evavibes,,37,True,all_ads,False,[],False,,/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,all_ads,False,https://www.reddit.com/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,1209067,1698543574.0,0,,False,,,,,,,,,,292,52
,datascience,Curious what people are using to keep track of projects and general data/process documentation,t2_7fhzn,False,,0,False,"D.S. / Analytics Directors, What Tools Do You Use to Organize Your Work &amp; Knowledge?",[],r/datascience,False,6,discussion,0,,,False,t3_17imqvk,False,dark,0.57,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698526126.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Curious what people are using to keep track of projects and general data/process documentation&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17imqvk,True,,whispertoke,,11,True,all_ads,False,[],False,,/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,1209067,1698526126.0,0,,False,,,,,,,,,,94,14
,datascience,"Officially I am a Data Scientist. I try to understand my value or worth outside of the government.

What I don't do:
AI, ML, modeling. 

What I do:
Develop new data pipelines,
Data exploration,
Produce data and dashboards from policy and new concepts,
Python, R, SQL, Databricks.


I feel a DS should be doing ML at minimum but our business needs are fast and dirty and the data is dirty. Dirty data = Dirty results is how I view ML stuff.

Edit: Punctuation because I forgot about Reddits mobile formats lol",t2_qp5mu,False,,0,False,"What would you classify my job as? DS, DA, DE, Glorified Excel Monkey",[],r/datascience,False,6,fun,0,,,False,t3_17ih595,False,dark,0.9,,public,89,0,{},,,False,[],,False,False,,{},Career Discussion,False,89,,False,False,self,1698511649.0,,[],{},,True,,1698509809.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Officially I am a Data Scientist. I try to understand my value or worth outside of the government.&lt;/p&gt;

&lt;p&gt;What I don&amp;#39;t do:
AI, ML, modeling. &lt;/p&gt;

&lt;p&gt;What I do:
Develop new data pipelines,
Data exploration,
Produce data and dashboards from policy and new concepts,
Python, R, SQL, Databricks.&lt;/p&gt;

&lt;p&gt;I feel a DS should be doing ML at minimum but our business needs are fast and dirty and the data is dirty. Dirty data = Dirty results is how I view ML stuff.&lt;/p&gt;

&lt;p&gt;Edit: Punctuation because I forgot about Reddits mobile formats lol&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ih595,True,,Yourteararedelicious,,70,True,all_ads,False,[],False,,/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,1209067,1698509809.0,0,,False,,,,,,,,,,508,91
,datascience,"**Tl;dr -** Soon to be transferring over to a DS manager role from an analytics manager, and I do NOT want to be *that* leader. What are some recommended MOOCs, videos, books that can boost my technical knowledge over the next 2-3 months.

I have been on the analytics side for ~10 years, and have a strong foundation of SQL, python, data viz, and analysis, and a solid knowledge of math/stats (can still be improved). I’m lacking in the ML and deployment space, and have a couple months to study up here. Any strong recommendations of courses, videos, or problem sets to work through? (Books are also great, but I am painfully slow and may be more efficient with another medium). Thanks in advance.",t2_wzs4b,False,,0,False,Learning resources for a new DS manager?,[],r/datascience,False,6,fun,0,,,False,t3_17ih45v,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,False,,[],{},,True,,1698509717.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Tl;dr -&lt;/strong&gt; Soon to be transferring over to a DS manager role from an analytics manager, and I do NOT want to be &lt;em&gt;that&lt;/em&gt; leader. What are some recommended MOOCs, videos, books that can boost my technical knowledge over the next 2-3 months.&lt;/p&gt;

&lt;p&gt;I have been on the analytics side for ~10 years, and have a strong foundation of SQL, python, data viz, and analysis, and a solid knowledge of math/stats (can still be improved). I’m lacking in the ML and deployment space, and have a couple months to study up here. Any strong recommendations of courses, videos, or problem sets to work through? (Books are also great, but I am painfully slow and may be more efficient with another medium). Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ih45v,True,,stryder517,,4,True,all_ads,False,[],False,,/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,1209067,1698509717.0,0,,False,,,,,,,,,,699,124
,datascience,"After feedback from many members and discussions within the mod team, we have decided to implement a new Automod rule:

**Rule:** Effective immediately, **users must have at least 10 comment karma** **within** r/datascience **before they can make a top-level submission.**

The desired outcomes are:

1. Reduce pure self-promotion botspam
2. Reduce the number of top-level submissions that belong to the Weekly Sticky thread.

**Please let us know if it appears to be working incorrectly or causing unwanted side effects.**",t2_6kl7i,False,,0,False,[Meta] New Automod Rule - Minimum Comment Karma before Submissions,[],r/datascience,False,6,,0,,,False,t3_17igak2,False,dark,0.97,,public,56,0,{},,,False,[],,False,False,,{},,False,56,,False,False,self,False,modflair,[],{},,True,,1698507343.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;After feedback from many members and discussions within the mod team, we have decided to implement a new Automod rule:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rule:&lt;/strong&gt; Effective immediately, &lt;strong&gt;users must have at least 10 comment karma&lt;/strong&gt; &lt;strong&gt;within&lt;/strong&gt; &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt; &lt;strong&gt;before they can make a top-level submission.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The desired outcomes are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Reduce pure self-promotion botspam&lt;/li&gt;
&lt;li&gt;Reduce the number of top-level submissions that belong to the Weekly Sticky thread.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Please let us know if it appears to be working incorrectly or causing unwanted side effects.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,,False,False,False,PhD | Sr Data Scientist Lead | Biotech,[],False,,,moderator,t5_2sptq,False,,,,17igak2,True,,Omega037,,31,True,all_ads,False,[],False,dark,/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,all_ads,False,https://www.reddit.com/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,1209067,1698507343.0,0,,False,,,,,,,,,,523,79
,datascience,"I’ve been on this board for a few years and noticed a trend. Many people saying they got a MS in DS and complain they only do excel or simple models. Recently, I see a lot of people saying they can’t get DS jobs. Here is the thing, most businesses need a lot more DA then DS. There are so many more basic data needs then complex ones. Most companies I’ve worked for have a ratio of about 5:1 DA to DS. Unless you’re a really strong and savvy DS candidate (smarter then me) you’re probably better off doing DA or SWE. I am a DS director and I spend 80% of my time doing DE and DA because that’s what the business needs.",t2_kcl3tfwe,False,,0,False,PSA: Don’t become DS. Be a DA instead.,[],r/datascience,False,6,fun,0,,,False,t3_17ie7f0,False,dark,0.89,,public,469,0,{},,,False,[],,False,False,,{},Career Discussion,False,469,,False,False,self,False,,[],{},,True,,1698500999.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been on this board for a few years and noticed a trend. Many people saying they got a MS in DS and complain they only do excel or simple models. Recently, I see a lot of people saying they can’t get DS jobs. Here is the thing, most businesses need a lot more DA then DS. There are so many more basic data needs then complex ones. Most companies I’ve worked for have a ratio of about 5:1 DA to DS. Unless you’re a really strong and savvy DS candidate (smarter then me) you’re probably better off doing DA or SWE. I am a DS director and I spend 80% of my time doing DE and DA because that’s what the business needs.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ie7f0,True,,NewEcho2940,,200,True,all_ads,False,[],False,,/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,1209067,1698500999.0,0,,False,,,,,,,,,,618,124
,datascience,"My issue is about doing EDA before or after feature selection. For example. say I have a dataset with tons and tons of features. Am I expected to analyze each and every feature in the dataset before choosing features or can I choose features that ""may"" matter based on logic and examine them there?",,False,,0,False,When do you select features to use for your model?,[],r/datascience,False,6,network,0,,,False,t3_17i4ikr,False,dark,0.84,,public,12,0,{},,,False,[],,False,False,,{},Analysis,False,12,,False,,self,False,,,{},,True,,1698461919.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My issue is about doing EDA before or after feature selection. For example. say I have a dataset with tons and tons of features. Am I expected to analyze each and every feature in the dataset before choosing features or can I choose features that &amp;quot;may&amp;quot; matter based on logic and examine them there?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17i4ikr,True,,[deleted],,22,True,all_ads,False,[],,dark,/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,all_ads,False,https://www.reddit.com/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,1209067,1698461919.0,0,,False,,,,,,,,,,298,54
,datascience,"I was reading through the supplemental material at the end of Blindsight and discovered that Chernoff faces are real. The in-story explanation that human brains are hardwired to read faces and the amount of information that can be encoded into them is suitable for higher dimensional (~18) data, especially given that the subconscious is more adept at processing complex problems than the conscious mind, is interesting enough of a concept, so discovering that it's real makes it even better.

I'm interested to see if they have been utilized before and if they still are in certain industries or niches (outside of customer satisfaction surveys and Wong-Baker scales). The fact that it can encode a high number of dimensions has piqued my interest to see if they can be used successfully and how difficult they are to interpret, for both analysts/statisticians and non-technical parties (stakeholders).",t2_131bi6,False,,0,False,Has anyone successfully used Chernoff faces in any type of analysis (not including what they are and how they convey information)?,[],r/datascience,False,6,discussion,0,,,False,t3_17i2wn6,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1698456518.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was reading through the supplemental material at the end of Blindsight and discovered that Chernoff faces are real. The in-story explanation that human brains are hardwired to read faces and the amount of information that can be encoded into them is suitable for higher dimensional (~18) data, especially given that the subconscious is more adept at processing complex problems than the conscious mind, is interesting enough of a concept, so discovering that it&amp;#39;s real makes it even better.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m interested to see if they have been utilized before and if they still are in certain industries or niches (outside of customer satisfaction surveys and Wong-Baker scales). The fact that it can encode a high number of dimensions has piqued my interest to see if they can be used successfully and how difficult they are to interpret, for both analysts/statisticians and non-technical parties (stakeholders).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17i2wn6,True,,WadeEffingWilson,,0,True,all_ads,False,[],False,,/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,1209067,1698456518.0,2,,False,,,,,,,,,,903,144
,datascience,"Hi there!

I’m working as a Data Analyst in my company and in my team we mostly use SQL and Tableau. I’ve mostly just used these two and Python (via Jupyter notebooks) on occasion to perform data cleaning /transformation for adhoc data sets.

So recently been covering for some other employee and have seemingly gotten myself into potentially being the one having to fix some potential bugs in a ML based Flask application that predicts product prices based on different conditions.

This is made up of 3 GitHub repos:
The model, the data pipelines and a Jupyter notebook containing code related to KMeans.


The data pipeline and model repos contain lots of Python source files with around 1000-1500 lines per file. All in all there could be easily more than 20,000 lines of code. I know this is not a lot but I don’t have experience in dealing with such large code bases.


I don’t have background in ML or product development (I previously worked as a IT BA 2-3 years back before transitioning to a DA role after having used SQL/Tableau for a few years, there is a separate BI team in the company but I’m in a data analyst specific team). 

My question is would it be common for DAs to be called to debug large complex ML web apps? I haven’t seen this in other companies previously. I would have thought this would fall on the product development teams or ML Engineers etc.

And what is the best way for me to start off getting used to the code base and understanding what everything does? The project certainly looks interesting and would make a good entry for me to a ML engineer role in the future or product development role but I’m nervous especially since my probation is ending in 2 weeks and I really don’t wanna f up. There’s no documentation or requirements documented except for a high level architecture diagram of the system.

Looking for advice thanks!



TL:DR;
A data analyst with no experience in product development put in charge to fix bugs for a large ML web app, looking for tips on how best to understand the code base and perform testing especially when there’s no documentation available for this app besides a high level architecture diagram. Also, wondering if it’s common for a data analysts to be asked to debug large ML web applications (flask based).",t2_vvpszem1,False,,0,False,Been put to investigate bugs for new project but no prior exp,[],r/datascience,False,6,meta,0,,,False,t3_17hy5hl,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Projects,False,3,,False,False,self,False,,[],{},,True,,1698442492.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;I’m working as a Data Analyst in my company and in my team we mostly use SQL and Tableau. I’ve mostly just used these two and Python (via Jupyter notebooks) on occasion to perform data cleaning /transformation for adhoc data sets.&lt;/p&gt;

&lt;p&gt;So recently been covering for some other employee and have seemingly gotten myself into potentially being the one having to fix some potential bugs in a ML based Flask application that predicts product prices based on different conditions.&lt;/p&gt;

&lt;p&gt;This is made up of 3 GitHub repos:
The model, the data pipelines and a Jupyter notebook containing code related to KMeans.&lt;/p&gt;

&lt;p&gt;The data pipeline and model repos contain lots of Python source files with around 1000-1500 lines per file. All in all there could be easily more than 20,000 lines of code. I know this is not a lot but I don’t have experience in dealing with such large code bases.&lt;/p&gt;

&lt;p&gt;I don’t have background in ML or product development (I previously worked as a IT BA 2-3 years back before transitioning to a DA role after having used SQL/Tableau for a few years, there is a separate BI team in the company but I’m in a data analyst specific team). &lt;/p&gt;

&lt;p&gt;My question is would it be common for DAs to be called to debug large complex ML web apps? I haven’t seen this in other companies previously. I would have thought this would fall on the product development teams or ML Engineers etc.&lt;/p&gt;

&lt;p&gt;And what is the best way for me to start off getting used to the code base and understanding what everything does? The project certainly looks interesting and would make a good entry for me to a ML engineer role in the future or product development role but I’m nervous especially since my probation is ending in 2 weeks and I really don’t wanna f up. There’s no documentation or requirements documented except for a high level architecture diagram of the system.&lt;/p&gt;

&lt;p&gt;Looking for advice thanks!&lt;/p&gt;

&lt;p&gt;TL:DR;
A data analyst with no experience in product development put in charge to fix bugs for a large ML web app, looking for tips on how best to understand the code base and perform testing especially when there’s no documentation available for this app besides a high level architecture diagram. Also, wondering if it’s common for a data analysts to be asked to debug large ML web applications (flask based).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17hy5hl,True,,Fine_Night_,,8,True,all_ads,False,[],False,,/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,1209067,1698442492.0,0,,False,,,,,,,,,,2283,403
,datascience,"Please elaborate on this. 

Including your role at the company, your day to day tasks, tools and languages you’re using. 

Thank you in advance!",t2_6or8m0hm,False,,0,False,What are your duties as a Data Scientist?,[],r/datascience,False,6,fun,0,,,False,t3_17hwt1l,False,dark,0.67,,public,6,0,{},,,False,[],,False,False,,{},Career Discussion,False,6,,False,False,self,False,,[],{},,True,,1698438807.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Please elaborate on this. &lt;/p&gt;

&lt;p&gt;Including your role at the company, your day to day tasks, tools and languages you’re using. &lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17hwt1l,True,,Judessaa,,8,True,all_ads,False,[],False,,/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,1209067,1698438807.0,0,,False,,,,,,,,,,144,24
,datascience,"From the perspective of someone who has absorbed the frequentist approach pretty well, and is comfortable with it, could you recommend a good book on Bayesian statistics?

Ideally with a focus on A/B testing.

Thanks!",t2_4svflj4i,False,,0,False,Good book on Bayesian statistics?,[],r/datascience,False,6,,0,,,False,t3_17hvuft,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Education,False,5,,False,False,self,False,,[],{},,True,,1698436150.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;From the perspective of someone who has absorbed the frequentist approach pretty well, and is comfortable with it, could you recommend a good book on Bayesian statistics?&lt;/p&gt;

&lt;p&gt;Ideally with a focus on A/B testing.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17hvuft,True,,Renatus_Cartesius,,19,True,all_ads,False,[],False,,/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,1209067,1698436150.0,1,,False,,,,,,,,,,217,35
,datascience,Title,t2_7r2a683l,False,,0,False,What is the worst case of PHDitis that you have seen?,[],r/datascience,False,6,discussion,0,,,False,t3_17hv82d,False,dark,0.38,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1698434435.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Title&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17hv82d,True,,blacksnowboader,,26,True,all_ads,False,[],False,,/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,1209067,1698434435.0,0,,False,,,,,,,,,,5,1
,datascience,"I work at FAANG as a DS manager. Opened up a Data Science position. Less than 24 hours later there were 1000+ applicants. 

I advertised the position on LinkedIn 

It's absolutely crazy. People have managed to get a hold of my personal and professional email address (I don't have these as public but they're a logical combination of first/last name).

I hired in the past, I have never seen anything like this.",t2_8qitkaml,False,,0,False,Didn't realize how insane the market is,[],r/datascience,False,6,fun,0,,,False,t3_17huxxq,False,dark,0.96,,public,707,0,{},,,False,[],,False,False,,{},Career Discussion,False,707,,False,False,self,False,,[],{},,True,,1698433632.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work at FAANG as a DS manager. Opened up a Data Science position. Less than 24 hours later there were 1000+ applicants. &lt;/p&gt;

&lt;p&gt;I advertised the position on LinkedIn &lt;/p&gt;

&lt;p&gt;It&amp;#39;s absolutely crazy. People have managed to get a hold of my personal and professional email address (I don&amp;#39;t have these as public but they&amp;#39;re a logical combination of first/last name).&lt;/p&gt;

&lt;p&gt;I hired in the past, I have never seen anything like this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17huxxq,True,,Vanishing-Rabbit,,234,True,all_ads,False,[],False,,/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,all_ads,False,https://www.reddit.com/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,1209067,1698433632.0,0,,False,,,,,,,,,,411,72
,datascience,"I took courses about pentaho,tableau and machine learning ...where I can find projects with open issues so I can solve it and increase my ability to solve problems in this career ..like open source android or web projects on github with open issues ....is there a specific website for data that I can contribute in and this contribution will have a positive effect in my c.v?",t2_5kyu2hrz,False,,0,False,Where I can find projects to contribute in?,[],r/datascience,False,6,meta,0,,,False,t3_17ht5l1,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},Projects,False,4,,False,False,self,False,,[],{},,True,,1698428793.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I took courses about pentaho,tableau and machine learning ...where I can find projects with open issues so I can solve it and increase my ability to solve problems in this career ..like open source android or web projects on github with open issues ....is there a specific website for data that I can contribute in and this contribution will have a positive effect in my c.v?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17ht5l1,True,,engkhaledeisa,,2,True,all_ads,False,[],False,,/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,1209067,1698428793.0,0,,False,,,,,,,,,,375,66
,datascience,"Unfortunately I have realised that at most jobs 80 percent of my time is spent on Ppt and 5 percent on the actual analysis. I was working in consulting and the best associates were the ones who could make the best presentations. Even at McKinsey, Bain etc my friends seem to mostly involved in making decks all day long. How do I get better at ppt? 
I used to feel that ppt would get redundant and hence didn’t really focus on it. Is it worth it to devote time in learning how to make beautiful ppts or is it a dying software and even investment banking and consulting will shift to something more sane/ AI will make it easy to make excellent ppts?",t2_asz9zryvf,False,,0,False,How to get better at PowerPoint?,[],r/datascience,False,6,discussion,0,,,False,t3_17hlvki,False,dark,0.85,,public,42,0,{},,,False,[],,False,False,,{},Discussion,False,42,,False,False,self,False,,[],{},,True,,1698407781.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Unfortunately I have realised that at most jobs 80 percent of my time is spent on Ppt and 5 percent on the actual analysis. I was working in consulting and the best associates were the ones who could make the best presentations. Even at McKinsey, Bain etc my friends seem to mostly involved in making decks all day long. How do I get better at ppt? 
I used to feel that ppt would get redundant and hence didn’t really focus on it. Is it worth it to devote time in learning how to make beautiful ppts or is it a dying software and even investment banking and consulting will shift to something more sane/ AI will make it easy to make excellent ppts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17hlvki,True,,No_Constant8367,,41,True,all_ads,False,[],False,,/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,1209067,1698407781.0,0,,False,,,,,,,,,,648,123
,datascience,How useful would y'all rate a Six-Sigma certification?,t2_m5ihxgfnw,False,,0,False,Usefulness of Six-Sigma,[],r/datascience,False,6,fun,0,,,False,t3_17hj3ea,False,dark,0.82,,public,30,0,{},,,False,[],,False,False,,{},Career Discussion,False,30,,False,False,self,False,,[],{},,True,,1698396301.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How useful would y&amp;#39;all rate a Six-Sigma certification?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17hj3ea,True,,Slow_Act_4114,,47,True,all_ads,False,[],False,,/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,1209067,1698396301.0,0,,False,,,,,,,,,,54,8
,datascience,"I know this question might be a bit controversial to some but lately I've found myself spending an ungodly amount of time creating slides instead of doing other tasks.

Management wants each new project or idea laid out in meticolous detail in a PowerPoint before signing off on it and granting any type of access to data. Which means I need to create some really good looking PPT decks to even get the chance to explore our available data, it's quite frustrating and I'd rather spend the time doing something else.

By detail I mean like, budget, development timeline, target audience, documentation, blabla, before I even get a chance to look at the data and determine if it's useable in the first place.

Anyone else have this problem?",t2_24el30e,False,,0,False,How much time do you guys spend in PowerPoint?,[],r/datascience,False,6,discussion,0,,,False,t3_17hicpp,False,dark,0.96,,public,68,0,{},,,False,[],,False,False,,{},Discussion,False,68,,False,False,self,False,,[],{},,True,,1698392829.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know this question might be a bit controversial to some but lately I&amp;#39;ve found myself spending an ungodly amount of time creating slides instead of doing other tasks.&lt;/p&gt;

&lt;p&gt;Management wants each new project or idea laid out in meticolous detail in a PowerPoint before signing off on it and granting any type of access to data. Which means I need to create some really good looking PPT decks to even get the chance to explore our available data, it&amp;#39;s quite frustrating and I&amp;#39;d rather spend the time doing something else.&lt;/p&gt;

&lt;p&gt;By detail I mean like, budget, development timeline, target audience, documentation, blabla, before I even get a chance to look at the data and determine if it&amp;#39;s useable in the first place.&lt;/p&gt;

&lt;p&gt;Anyone else have this problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17hicpp,True,,NipponPanda,,105,True,all_ads,False,[],False,,/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,1209067,1698392829.0,0,,False,,,,,,,,,,738,128
,datascience,"We have been exploring the space of ""Streaming Data Observability &amp; Quality"". We do have some thoughts and questions and would love to get members view on them. 

**Q1.** Many vendors are shifting left by moving data quality checks from the warehouse to Kafka / messaging systems. What are the benefits of shifting-left ?

**Q2.** Can you rank the feature set by importance (according to you) ? What other features would you like to see in a streaming data quality tool ?

* Broker observability &amp; pipeline monitoring (events per second, consumer lag etc.)
* Schema checks and Dead Letter Queues (with replayability)
* Validation on data values (numeric distributions &amp; profiling, volume, freshness, segmentation etc.)
* Stream lineage to perform RCA

**Q3.** Who would be an ideal candidate (industry, streaming scale, team size) where there is an urgent need to monitor, observe and validate data in streaming pipelines?  


https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&amp;format=pjpg&amp;auto=webp&amp;s=c1b368112465cfa5be67258dd2a52313cdb4cdb6",t2_kjo9ip66,False,,0,False,Streaming Data Observability &amp; Quality,[],r/datascience,False,6,,0,140.0,,False,t3_17hh6i7,False,dark,0.75,,public,2,0,{},140.0,,False,[],,False,False,,{},DE,False,2,,False,False,https://b.thumbs.redditmedia.com/Tl3w2xVE57vn8u2sLryaGUO3o5v3SwJpK9gLXRV35bE.jpg,False,,[],{},,True,,1698387746.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We have been exploring the space of &amp;quot;Streaming Data Observability &amp;amp; Quality&amp;quot;. We do have some thoughts and questions and would love to get members view on them. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1.&lt;/strong&gt; Many vendors are shifting left by moving data quality checks from the warehouse to Kafka / messaging systems. What are the benefits of shifting-left ?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2.&lt;/strong&gt; Can you rank the feature set by importance (according to you) ? What other features would you like to see in a streaming data quality tool ?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Broker observability &amp;amp; pipeline monitoring (events per second, consumer lag etc.)&lt;/li&gt;
&lt;li&gt;Schema checks and Dead Letter Queues (with replayability)&lt;/li&gt;
&lt;li&gt;Validation on data values (numeric distributions &amp;amp; profiling, volume, freshness, segmentation etc.)&lt;/li&gt;
&lt;li&gt;Stream lineage to perform RCA&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Q3.&lt;/strong&gt; Who would be an ideal candidate (industry, streaming scale, team size) where there is an urgent need to monitor, observe and validate data in streaming pipelines?  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c1b368112465cfa5be67258dd2a52313cdb4cdb6""&gt;https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c1b368112465cfa5be67258dd2a52313cdb4cdb6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,271d2932-70eb-11ee-b552-0a391e3dc147,False,False,False,,[],False,,,,t5_2sptq,False,,,#0dd3bb,17hh6i7,True,,daftpunkapi,,0,True,all_ads,False,[],False,,/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,all_ads,False,https://www.reddit.com/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,1209067,1698387746.0,0,,False,"{'8f1mo89ouowb1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c1ff03b0a58a7987757a789b8a79392392ca36b'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=16ee721cae5ed3376c9cd321dbab4d9b690d06f3'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31c83a672ad8e9e36c9ba7538acc7b1b36bbe5a7'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=da9bdcd63988830159d282a88cef77f608187e33'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=43e032f4157f84d55b1c0d3a477b1e40b2273ad0'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=38787111bc9b002b12b1e2eda3297a42fa9f7479'}], 's': {'y': 7001, 'x': 6998, 'u': 'https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&amp;format=pjpg&amp;auto=webp&amp;s=c1b368112465cfa5be67258dd2a52313cdb4cdb6'}, 'id': '8f1mo89ouowb1'}}",,,,,,,,,1068,150
,datascience,"Hello everyone,

Im a recent Data Science graduate and experimenting with different machine learning models on a various datasets from kaggle. The idea is to be more comfortable with tensorflow (&amp; other libaries) and different datasets. 

Im doing all this on jupyter notebook, is there a tool data scientist use to publish their work. I want to create a online portfolio which i can showcase the different ML implementations in interviews and to recruiters. 

Im using github but was wondering if there specific tools or practices of data scientists which i might aswell implement in my workflow

Thanks",t2_6dwvvfol,False,,0,False,Machine Learning projects on jupyter,[],r/datascience,False,6,meta,0,,,False,t3_17h8k9y,False,dark,0.8,,public,6,0,{},,,False,[],,False,False,,{},Projects,False,6,,False,False,self,False,,[],{},,True,,1698359321.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Im a recent Data Science graduate and experimenting with different machine learning models on a various datasets from kaggle. The idea is to be more comfortable with tensorflow (&amp;amp; other libaries) and different datasets. &lt;/p&gt;

&lt;p&gt;Im doing all this on jupyter notebook, is there a tool data scientist use to publish their work. I want to create a online portfolio which i can showcase the different ML implementations in interviews and to recruiters. &lt;/p&gt;

&lt;p&gt;Im using github but was wondering if there specific tools or practices of data scientists which i might aswell implement in my workflow&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17h8k9y,True,,exodusgg,,13,True,all_ads,False,[],False,,/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,1209067,1698359321.0,0,,False,,,,,,,,,,608,98
,datascience,"Hey guys so I was told that as a data science student I should do things like leetcode as a hobby to help me out to land internships and to make it look better when looking for jobs, I currently have 0 experience in the field, 0 internships, so what could I do to make me stand out in this market? I’m set to graduate may 2024.",t2_jtd97ls18,False,,0,False,Data science student advice,[],r/datascience,False,6,discussion,0,,,False,t3_17h7ri5,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1698357219.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys so I was told that as a data science student I should do things like leetcode as a hobby to help me out to land internships and to make it look better when looking for jobs, I currently have 0 experience in the field, 0 internships, so what could I do to make me stand out in this market? I’m set to graduate may 2024.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17h7ri5,True,,No_Match_7225,,4,True,all_ads,False,[],False,,/r/datascience/comments/17h7ri5/data_science_student_advice/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h7ri5/data_science_student_advice/,1209067,1698357219.0,0,,False,,,,,,,,,,327,67
,datascience,"Hey fellow data folks - Finally, after 17 months of applying for jobs, I’ve found one. The job title is strange, the pay is nothing to brag about (thanks Canada!) but I’m 100% certain of the positive impact it is going to have in my mental health. 

I’m so relieved and nervous and scared but also excited. 

It is tough out there but nothing else to be done other than try! 

Thanks for hearing me out.",t2_1gouw6ih,False,,0,False,Finally!,[],r/datascience,False,6,fun,0,,,False,t3_17h7eav,False,dark,0.96,,public,71,0,{},,,False,[],,False,False,,{},Career Discussion,False,71,,False,False,self,False,,[],{},,True,,1698356251.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey fellow data folks - Finally, after 17 months of applying for jobs, I’ve found one. The job title is strange, the pay is nothing to brag about (thanks Canada!) but I’m 100% certain of the positive impact it is going to have in my mental health. &lt;/p&gt;

&lt;p&gt;I’m so relieved and nervous and scared but also excited. &lt;/p&gt;

&lt;p&gt;It is tough out there but nothing else to be done other than try! &lt;/p&gt;

&lt;p&gt;Thanks for hearing me out.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h7eav,True,,math_stat_gal,,19,True,all_ads,False,[],False,,/r/datascience/comments/17h7eav/finally/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h7eav/finally/,1209067,1698356251.0,0,,False,,,,,,,,,,403,76
,datascience,"So I am currently a junior in school working towards a degree in applied and computational mathematics with a minor in cs, and I was wondering what type of opportunities I should be actively looking for and seeking out in order to be successful. I am trying to apply to data science internships but it is a bit harder this year and I'm not really getting any interviews.   
I am also kind of struggling on understanding what projects I should be doing because a lot of the requirements I see on job postings are very high level topics I just haven't learned yet. For example here is a list of common requirements I have seen:  


* Expertise in statistical methods and experimental design and analysis  
* Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning
* Deployment of microservices and data pipeline and monitoring the performance of Kubernetes application and Data infrastructure.
* Hands-on experience with experimentation design, A/B testing, or probabilistic modeling are a plus!
* Experience with mathematical modeling techniques (e.g., linear and integer programming, statistical modeling, system dynamics modeling) 
* Experience with quantitative analysis of complex systems, probability and statistics  
* Strong background/interest in experimentation, recommendation systems, &amp; data visualization   


I haven't really taken courses on these, and getting started with projects using these high level topics is also pretty challenging since theres a learning curve. I'm just not sure what I should actively be doing since my applications are going nowhere and there's so many topics to learn and study on my own. Just looking for some guidance, any advice is welcome.",t2_fzf2nkwgb,False,,0,False,Aspiring Data scientist who needs some guidance on a career path,[],r/datascience,False,6,fun,0,,,False,t3_17h6bty,False,dark,0.6,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1698353456.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I am currently a junior in school working towards a degree in applied and computational mathematics with a minor in cs, and I was wondering what type of opportunities I should be actively looking for and seeking out in order to be successful. I am trying to apply to data science internships but it is a bit harder this year and I&amp;#39;m not really getting any interviews.&lt;br/&gt;
I am also kind of struggling on understanding what projects I should be doing because a lot of the requirements I see on job postings are very high level topics I just haven&amp;#39;t learned yet. For example here is a list of common requirements I have seen:  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Expertise in statistical methods and experimental design and analysis&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning&lt;/li&gt;
&lt;li&gt;Deployment of microservices and data pipeline and monitoring the performance of Kubernetes application and Data infrastructure.&lt;/li&gt;
&lt;li&gt;Hands-on experience with experimentation design, A/B testing, or probabilistic modeling are a plus!&lt;/li&gt;
&lt;li&gt;Experience with mathematical modeling techniques (e.g., linear and integer programming, statistical modeling, system dynamics modeling) &lt;/li&gt;
&lt;li&gt;Experience with quantitative analysis of complex systems, probability and statistics&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Strong background/interest in experimentation, recommendation systems, &amp;amp; data visualization &lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I haven&amp;#39;t really taken courses on these, and getting started with projects using these high level topics is also pretty challenging since theres a learning curve. I&amp;#39;m just not sure what I should actively be doing since my applications are going nowhere and there&amp;#39;s so many topics to learn and study on my own. Just looking for some guidance, any advice is welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h6bty,True,,Practical-Wing-6143,,4,True,all_ads,False,[],False,,/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,1209067,1698353456.0,0,,False,,,,,,,,,,1727,269
,datascience,What is a typical severance package for manager or director of data science (or data engineering) for US companies. How many weeks severance per years tenure? What did yours look like?,,False,,0,False,"Severance for US-based data science manager, director?",[],r/datascience,False,6,fun,0,,,False,t3_17h5xor,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,,self,1698352658.0,,,{},,True,,1698352407.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What is a typical severance package for manager or director of data science (or data engineering) for US companies. How many weeks severance per years tenure? What did yours look like?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h5xor,True,,[deleted],,10,True,all_ads,False,[],,dark,/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,1209067,1698352407.0,0,,False,,,,,,,,,,184,31
,datascience,"**Data science community, I'm here to tell you about a new platform that's going to revolutionize the way you learn data science: DataWars**

I've been using it for a few weeks now, and I'm absolutely blown away. It's the most immersive and hands-on way to learn data science that I've ever experienced.

With DataWars Live Labs, you can:

* Write code in real time and get immediate feedback on your progress.
* Validate your understanding of key concepts.
* Check the correctness of your code.
* Work on interactive projects that are designed to help you learn and practice.

If you're serious about learning data science, I highly recommend checking out DataWars Live Labs. It's the best way to learn quickly and master the skills you need to succeed.

**Here are a few specific things that I love about DataWars Live Labs:**

* The projects are really well-designed and engaging. They cover a wide range of topics, from Python, data cleaning, and wrangling to machine learning and much more.
* The feedback loop is instant. As you write code, you can see immediately whether it's working correctly. This makes it easy to learn from your mistakes and improve your skills quickly.
* Their Discord server is great.

Overall, I'm extremely impressed with DataWars. It's the best way to learn data science that I've ever used. I highly recommend it to anyone who wants to learn data science quickly and master the skills they need to succeed.",t2_clezfvye,False,,0,False,"If you really want to practice data science with real-world projects, then check out DataWars.",[],r/datascience,False,6,,0,,,False,t3_17gum8s,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},Challenges,False,5,,False,False,self,False,,[],{},,True,,1698320812.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Data science community, I&amp;#39;m here to tell you about a new platform that&amp;#39;s going to revolutionize the way you learn data science: DataWars&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been using it for a few weeks now, and I&amp;#39;m absolutely blown away. It&amp;#39;s the most immersive and hands-on way to learn data science that I&amp;#39;ve ever experienced.&lt;/p&gt;

&lt;p&gt;With DataWars Live Labs, you can:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write code in real time and get immediate feedback on your progress.&lt;/li&gt;
&lt;li&gt;Validate your understanding of key concepts.&lt;/li&gt;
&lt;li&gt;Check the correctness of your code.&lt;/li&gt;
&lt;li&gt;Work on interactive projects that are designed to help you learn and practice.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you&amp;#39;re serious about learning data science, I highly recommend checking out DataWars Live Labs. It&amp;#39;s the best way to learn quickly and master the skills you need to succeed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Here are a few specific things that I love about DataWars Live Labs:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The projects are really well-designed and engaging. They cover a wide range of topics, from Python, data cleaning, and wrangling to machine learning and much more.&lt;/li&gt;
&lt;li&gt;The feedback loop is instant. As you write code, you can see immediately whether it&amp;#39;s working correctly. This makes it easy to learn from your mistakes and improve your skills quickly.&lt;/li&gt;
&lt;li&gt;Their Discord server is great.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Overall, I&amp;#39;m extremely impressed with DataWars. It&amp;#39;s the best way to learn data science that I&amp;#39;ve ever used. I highly recommend it to anyone who wants to learn data science quickly and master the skills they need to succeed.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,17gum8s,True,,Beginning-Scholar105,,4,True,all_ads,False,[],False,,/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,1209067,1698320812.0,0,,False,,,,,,,,,,1441,246
,datascience,"Hello All. Just looking to tap into your expertise and experience 😊

I’m a non-technical Project Management Officer with robust Excel skills and some knowledge about IT Systems. Now, I’m highly interested in becoming a Data Scientist as well and have taken some online courses to get up to speed.

Here’s my dilemma. I don’t have much experience yet with creating PowerBI reports and using Python language. I’m intimidated (yet intrigued) with this complex field.

How can I take on projects to properly apply what I’ve been learning so far? Also, how can I apply for jobs related to this field while still being a beginner (but willing to learn in the job)?

Many thanks in advance for your advices. Thank you 😊",,False,,0,False,How to Apply What I Learn in Data Science and Find a Job?,[],r/datascience,False,6,fun,0,,,False,t3_17h56j2,False,dark,0.25,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,,self,False,,,{},,True,,1698350435.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello All. Just looking to tap into your expertise and experience 😊&lt;/p&gt;

&lt;p&gt;I’m a non-technical Project Management Officer with robust Excel skills and some knowledge about IT Systems. Now, I’m highly interested in becoming a Data Scientist as well and have taken some online courses to get up to speed.&lt;/p&gt;

&lt;p&gt;Here’s my dilemma. I don’t have much experience yet with creating PowerBI reports and using Python language. I’m intimidated (yet intrigued) with this complex field.&lt;/p&gt;

&lt;p&gt;How can I take on projects to properly apply what I’ve been learning so far? Also, how can I apply for jobs related to this field while still being a beginner (but willing to learn in the job)?&lt;/p&gt;

&lt;p&gt;Many thanks in advance for your advices. Thank you 😊&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h56j2,True,,[deleted],,6,True,all_ads,False,[],,dark,/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,1209067,1698350435.0,0,,False,,,,,,,,,,712,123
,datascience,"GBDT allow you to iterate very fast, they require no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.

On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.

Because of those characteristics, [they are winning solutions to all tabular competitions on Kaggle](https://jobs-in-data.com/blog/data-science-skills#sota-ml-models).

And yet, somehow they are not very popular.

On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist))

LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.

It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.

https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=b06cd263e22eb229a6be2df890faba7639d895d7

EDIT \[Answering the main lines of critique\]:

1/ ""Job posting descriptions are written by random people and hence meaningless"":

Granted, there is for sure some noise in the data generation process of writing job descriptions.

But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.

Very few people actually did try to answer this, and I am grateful to them, but none of the explanations seem to be more credible than the statement that GBDTs are indeed underappreciated in the industry.

2/ ""I myself use GBDT all the time so the headline is wrong""This is availability bias. The single person's opinion (or 20 people opinion) vs 10.000 data points.

3/ ""This is more the bias of the Academia""

The job postings are scraped from the industry.

However, I personally think this is the root cause of the phenomenon. Academia shapes the minds of industry practitioners. GBDTs are not interesting enough for Academia because they do not lead to AGI. Doesn't matter if they are super efficient and create lots of value in real life.",t2_h7ibth00,False,,0,False,Why Gradient Boosted Decision Trees are so underappreciated in the industry?,[],r/datascience,False,6,network,0,78.0,,False,t3_17h40ok,False,dark,0.77,,public,100,0,{},140.0,,False,[],,False,False,,{},Analysis,False,100,,False,False,https://b.thumbs.redditmedia.com/gNWFEAWOKlZQt3SQn76JR6pqp_8KHcZeuAucQS883rk.jpg,1698394526.0,,[],{},,True,,1698347424.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;GBDT allow you to iterate very fast, they require no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.&lt;/p&gt;

&lt;p&gt;On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.&lt;/p&gt;

&lt;p&gt;Because of those characteristics, &lt;a href=""https://jobs-in-data.com/blog/data-science-skills#sota-ml-models""&gt;they are winning solutions to all tabular competitions on Kaggle&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And yet, somehow they are not very popular.&lt;/p&gt;

&lt;p&gt;On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: &lt;a href=""https://jobs-in-data.com/blog/machine-learning-vs-data-scientist""&gt;https://jobs-in-data.com/blog/machine-learning-vs-data-scientist&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.&lt;/p&gt;

&lt;p&gt;It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b06cd263e22eb229a6be2df890faba7639d895d7""&gt;https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b06cd263e22eb229a6be2df890faba7639d895d7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EDIT [Answering the main lines of critique]:&lt;/p&gt;

&lt;p&gt;1/ &amp;quot;Job posting descriptions are written by random people and hence meaningless&amp;quot;:&lt;/p&gt;

&lt;p&gt;Granted, there is for sure some noise in the data generation process of writing job descriptions.&lt;/p&gt;

&lt;p&gt;But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.&lt;/p&gt;

&lt;p&gt;Very few people actually did try to answer this, and I am grateful to them, but none of the explanations seem to be more credible than the statement that GBDTs are indeed underappreciated in the industry.&lt;/p&gt;

&lt;p&gt;2/ &amp;quot;I myself use GBDT all the time so the headline is wrong&amp;quot;This is availability bias. The single person&amp;#39;s opinion (or 20 people opinion) vs 10.000 data points.&lt;/p&gt;

&lt;p&gt;3/ &amp;quot;This is more the bias of the Academia&amp;quot;&lt;/p&gt;

&lt;p&gt;The job postings are scraped from the industry.&lt;/p&gt;

&lt;p&gt;However, I personally think this is the root cause of the phenomenon. Academia shapes the minds of industry practitioners. GBDTs are not interesting enough for Academia because they do not lead to AGI. Doesn&amp;#39;t matter if they are super efficient and create lots of value in real life.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17h40ok,True,,pg860,,112,True,all_ads,False,[],False,,/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,1209067,1698347424.0,0,,False,"{'zavuf0qnhlwb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a000694daa3fc3952e01de5edcb60c441377926'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=47c89454d36276bd6207d05dadf5e5ee922a834a'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=579be4fbb475bbf4308631c694f983c2928cb00a'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ed589123c82566895150f9602ea5cade1a1a6717'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=75383f3ffcb0982d7300e638f46cc2a4f507f82c'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=567d0a2746e4eb42207e2ea96681cd9de0cab696'}], 's': {'y': 1440, 'x': 2560, 'u': 'https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=b06cd263e22eb229a6be2df890faba7639d895d7'}, 'id': 'zavuf0qnhlwb1'}}",,,,,,,,,2499,357
,datascience," **How to upskill for data science in 2023, I have 3 years of relevant work experience, plus 7 years total but learning has almost stopped. Could you suggest resources/websites to take profile** ",t2_6x27v0s6,False,,0,False,data science upskilling,[],r/datascience,False,6,fun,0,,,False,t3_17h3hj7,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1698345999.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;How to upskill for data science in 2023, I have 3 years of relevant work experience, plus 7 years total but learning has almost stopped. Could you suggest resources/websites to take profile&lt;/strong&gt; &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h3hj7,True,,Suza_330,,1,True,all_ads,False,[],False,,/r/datascience/comments/17h3hj7/data_science_upskilling/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h3hj7/data_science_upskilling/,1209067,1698345999.0,0,,False,,,,,,,,,,195,32
,datascience,"Hello all, I want to ask to you some questions about Cloud services on the Data Science field.

&amp;#x200B;

Currently I´m working on a marketing agency with around 80 employees, and my team is in charge of the data management, we have been working on an ETL process that cleans data coming from APIs and upload it in Big Query. We scheduled the daily ETL process with Pythonanywhere, but now our client want us to implement a top notch platform to absorb the work of Pythonanywhere. I know that there are some options that I can use as Azure or AWS but my self and my team is complete ignorant of the topic, for those of you that already worked in projects that use this technolgies, which is the best approach to start learn it? are there any courses or certifications that you recomment? for scheduling the run of python code is there a specific module of Azure or AWS that I have to learn?

&amp;#x200B;

Thank you!

&amp;#x200B;

&amp;#x200B;",t2_aynai7tz,False,,0,False,Help! Cloud services on the Data Science field,[],r/datascience,False,6,tooling,0,,,False,t3_17h37bq,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698345242.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, I want to ask to you some questions about Cloud services on the Data Science field.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Currently I´m working on a marketing agency with around 80 employees, and my team is in charge of the data management, we have been working on an ETL process that cleans data coming from APIs and upload it in Big Query. We scheduled the daily ETL process with Pythonanywhere, but now our client want us to implement a top notch platform to absorb the work of Pythonanywhere. I know that there are some options that I can use as Azure or AWS but my self and my team is complete ignorant of the topic, for those of you that already worked in projects that use this technolgies, which is the best approach to start learn it? are there any courses or certifications that you recomment? for scheduling the run of python code is there a specific module of Azure or AWS that I have to learn?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17h37bq,True,,Rebeca_nura,,0,True,all_ads,False,[],False,,/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,1209067,1698345242.0,0,,False,,,,,,,,,,948,170
,datascience,"I am a student getting my masters in applied statistics. I’ve never experienced much with programming but have now found a major passion for it. I have a little over a year left till I finish up my masters. What different programs should I focus on? I am using R with my school and will get great practice with it. I want to be proficient in 2-3 programs when applying for next job when I graduate? What languages do you recommend and where do you recommend learning it from? I love futuristic/forecasting  modeling and looking to get into that type of work. 

Thank you for any help/advice!",t2_9i368f0ha,False,,0,False,Learning programming!,[],r/datascience,False,6,discussion,0,,,False,t3_17h2z94,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698344660.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a student getting my masters in applied statistics. I’ve never experienced much with programming but have now found a major passion for it. I have a little over a year left till I finish up my masters. What different programs should I focus on? I am using R with my school and will get great practice with it. I want to be proficient in 2-3 programs when applying for next job when I graduate? What languages do you recommend and where do you recommend learning it from? I love futuristic/forecasting  modeling and looking to get into that type of work. &lt;/p&gt;

&lt;p&gt;Thank you for any help/advice!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17h2z94,True,,trevor12345677,,6,True,all_ads,False,[],False,,/r/datascience/comments/17h2z94/learning_programming/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h2z94/learning_programming/,1209067,1698344660.0,0,,False,,,,,,,,,,591,107
,datascience,"Hello guys,

I am currently doing a project for my internship. It involves image detection which I have more or less dealt with. The main thing now for me to do is that I have to compare the mass or brightness of each of the blue holes with the reference chart circled red. The blue dots in the red circle have varying uniform opacity and I have to see how the outside blue dots compare with the reference dots. I cannot seem to figure out how to go about doing this. I was thinking of a graph, but it does not seem convenient or maybe a 3d graph(?). I would be grateful if you guys can give me suggestions.

&amp;#x200B;

https://preview.redd.it/jaefgmgh4lwb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=8c03ed5cc6732c8748f548c5742824c952815156",t2_pqlshwwf,False,,0,False,Suggestions for my internship project,[],r/datascience,False,6,meta,0,134.0,,False,t3_17h2bxq,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},Projects,False,0,,False,False,https://a.thumbs.redditmedia.com/CV9HMHpaNUuJHNcwn8d7b_bHJoNjdcs4Y5Ugfmxqnd8.jpg,False,,[],{},,True,,1698342923.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys,&lt;/p&gt;

&lt;p&gt;I am currently doing a project for my internship. It involves image detection which I have more or less dealt with. The main thing now for me to do is that I have to compare the mass or brightness of each of the blue holes with the reference chart circled red. The blue dots in the red circle have varying uniform opacity and I have to see how the outside blue dots compare with the reference dots. I cannot seem to figure out how to go about doing this. I was thinking of a graph, but it does not seem convenient or maybe a 3d graph(?). I would be grateful if you guys can give me suggestions.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/jaefgmgh4lwb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c03ed5cc6732c8748f548c5742824c952815156""&gt;https://preview.redd.it/jaefgmgh4lwb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c03ed5cc6732c8748f548c5742824c952815156&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17h2bxq,True,,SussyAutist,,0,True,all_ads,False,[],False,,/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,1209067,1698342923.0,0,,False,"{'jaefgmgh4lwb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 104, 'x': 108, 'u': 'https://preview.redd.it/jaefgmgh4lwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1b831488d5ad4ff0af1a4e9427d18b39337c872c'}, {'y': 208, 'x': 216, 'u': 'https://preview.redd.it/jaefgmgh4lwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=766367769ec8e749a750a6cd37e2611eff11cf7b'}, {'y': 308, 'x': 320, 'u': 'https://preview.redd.it/jaefgmgh4lwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=50463a3966e9a2dc9c6bb54a24c772cf263b9d64'}, {'y': 616, 'x': 640, 'u': 'https://preview.redd.it/jaefgmgh4lwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3269c9dea05931421fa9e68c927d1a94d8d2b595'}], 's': {'y': 691, 'x': 717, 'u': 'https://preview.redd.it/jaefgmgh4lwb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=8c03ed5cc6732c8748f548c5742824c952815156'}, 'id': 'jaefgmgh4lwb1'}}",,,,,,,,,750,121
,datascience,"I find the data specifications / requirements process to be awful. It's legit one of my least favorite aspects of this job.

For context, I work in an academia-adjacent industry, and I'm typically working with subject matter research experts. They are responsible for writing programming specifications for our projects, which are supposed to serve as an outline for programming and development for the data science team. Sometimes PMs will write them as well. For ex. something like:


    1. Load data from [data source]
    2. Confirm variables `x`, `y`, and `z` are correct data types
    3. Merge data (outer join) with [other dataset]
    	a. output a table of merge %
    4. Deduplicate on ID variable
    5. Filter by ...
    6. etc.
    7. export files to [server location]

As a data scientist, I am supposed to generally follow these steps to produce the result we are looking for. If I disagree with a step, or need to add some logic, I'll go in to the document and edit it. So it's a shared responsibility between my team and the research / project management team. The above steps are a very simplified example - sometimes these types of requirement documents can be like 15 pages long, with a ton of rules and nested logic / requests.

These documents tend to be written in Microsoft Word, which is messy and hard to version control when working across large teams. It's very easy to miss updates and lose track of which specifications have changed.

I can't help but think this process could be so much cleaner and efficient.",t2_1xtk67f5,False,,0,False,"Is it just me, or is the requirements / specifications process a complete nightmare?",[],r/datascience,False,6,discussion,0,,,False,t3_17h23wx,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,True,self,False,,[],{},,True,,1698342308.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I find the data specifications / requirements process to be awful. It&amp;#39;s legit one of my least favorite aspects of this job.&lt;/p&gt;

&lt;p&gt;For context, I work in an academia-adjacent industry, and I&amp;#39;m typically working with subject matter research experts. They are responsible for writing programming specifications for our projects, which are supposed to serve as an outline for programming and development for the data science team. Sometimes PMs will write them as well. For ex. something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. Load data from [data source]
2. Confirm variables `x`, `y`, and `z` are correct data types
3. Merge data (outer join) with [other dataset]
    a. output a table of merge %
4. Deduplicate on ID variable
5. Filter by ...
6. etc.
7. export files to [server location]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a data scientist, I am supposed to generally follow these steps to produce the result we are looking for. If I disagree with a step, or need to add some logic, I&amp;#39;ll go in to the document and edit it. So it&amp;#39;s a shared responsibility between my team and the research / project management team. The above steps are a very simplified example - sometimes these types of requirement documents can be like 15 pages long, with a ton of rules and nested logic / requests.&lt;/p&gt;

&lt;p&gt;These documents tend to be written in Microsoft Word, which is messy and hard to version control when working across large teams. It&amp;#39;s very easy to miss updates and lose track of which specifications have changed.&lt;/p&gt;

&lt;p&gt;I can&amp;#39;t help but think this process could be so much cleaner and efficient.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17h23wx,True,,donhuell,,1,True,all_ads,False,[],False,,/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,1209067,1698342308.0,0,,False,,,,,,,,,,1541,263
,datascience,"Hi folks, I just published an article where I shared some of the tips I've learned based on my research and experience for building a data strategy and leveling up your business. Curious to learn more? Dive in here",t2_8wu7bwpq,False,,0,False,Data Strategy Mastery: Valuable Tips for Data Pros and Companies Aiming to Level Up,[],r/datascience,False,6,,0,93.0,,False,t3_17h10e0,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Education,False,1,,False,False,https://b.thumbs.redditmedia.com/6NCDxcVZbPJuuikhFhFJheI3PH2Bps0lCqJi_WQC9tA.jpg,False,,[],{},,False,,1698339307.0,text,6,,,text,meysamraz.medium.com,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi folks, I just published an article where I shared some of the tips I&amp;#39;ve learned based on my research and experience for building a data strategy and leveling up your business. Curious to learn more? Dive in here&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17h10e0,True,,Alert_Pea_4855,,0,True,all_ads,False,[],False,,/r/datascience/comments/17h10e0/data_strategy_mastery_valuable_tips_for_data_pros/,all_ads,False,https://meysamraz.medium.com/data-strategy-mastery-valuable-tips-for-data-pros-and-companies-aiming-to-level-up-69b17606e7e4,1209067,1698339307.0,0,,False,,link,"{'images': [{'source': {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?auto=webp&amp;s=b6ed06eeb97a52c1945e6e9d540b002638ef3431', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ecad36e43614cb0fe0bcc1d2678c0c66cd8ae58', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=877b6496ae0b916b6272bc7fb7cc2d7e9210b7d5', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddc732be9859fc9a287ff8ac4030bd03b84399c6', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ef82f0cd8526b45b172ad98684ff28ee7744cc7', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed7c8ccc3abaf0053d939bceaea9f3dab53a6cb4', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/J7x_4TdrpYRbC5Tk0KQMklivvv7HAaUVsEclotWlcj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc05c9cba09344cc372822dcbd2bd73ce06f31b4', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'tSK7y3dr6jSBXFMMLvFAne_vgCXbc2lAR8kEfcGpaNs'}], 'enabled': False}",,https://meysamraz.medium.com/data-strategy-mastery-valuable-tips-for-data-pros-and-companies-aiming-to-level-up-69b17606e7e4,,,,,214,39
,datascience,"I am trying to get the residuals to white noise but there are two different behaviors on residuals. Any ideas on how I should transform this? Or what should I do. I tried log/sqrt. Doesn’t really do shit. Dataset is a hourly data for a couple years. The graph behavior is seasonal yearly, and daily aswell. But right now I just care about the yearly. Any advice?",t2_16pd0l0u,False,,0,False,Residuals,[],r/datascience,False,6,network,0,28.0,,False,t3_17h0yms,False,dark,0.38,,public,0,0,{},140.0,,False,[],,True,False,,{},Analysis,False,0,,False,False,https://a.thumbs.redditmedia.com/JqicF8FCnFbGkcNdxJqsEQrCsTjgmwENcWOYsrmYWB0.jpg,False,,[],{},,False,,1698339171.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to get the residuals to white noise but there are two different behaviors on residuals. Any ideas on how I should transform this? Or what should I do. I tried log/sqrt. Doesn’t really do shit. Dataset is a hourly data for a couple years. The graph behavior is seasonal yearly, and daily aswell. But right now I just care about the yearly. Any advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17h0yms,True,,battleaxe37,,7,True,all_ads,False,[],False,,/r/datascience/comments/17h0yms/residuals/,all_ads,False,https://i.redd.it/4f064j4bukwb1.jpg,1209067,1698339171.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?auto=webp&amp;s=fdbe72f2999111d8b6e56938f1feb2811ff6a079', 'width': 4030, 'height': 826}, 'resolutions': [{'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27e1f99a799ac1e7fb10210dab0828ea45cc0491', 'width': 108, 'height': 22}, {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cc1f8a75a65eae682a5df4ccab0daaefff5749a', 'width': 216, 'height': 44}, {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ea862e2a595668ccd44ea89673f9690ec57a9e1', 'width': 320, 'height': 65}, {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f200b1d941601db4fe62a98e0b24b47718e83ea0', 'width': 640, 'height': 131}, {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f59e4be220cca0a8595a98ccb3ce1eb9e5f45a1', 'width': 960, 'height': 196}, {'url': 'https://preview.redd.it/4f064j4bukwb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49a7e391586ae92e8a7bbf19542aa95060618838', 'width': 1080, 'height': 221}], 'variants': {}, 'id': 'zDjGcBOQynDw_5XnMbw8Dp-gI-3Y0ILAc5peC5tpX9g'}], 'enabled': True}",,https://i.redd.it/4f064j4bukwb1.jpg,,,,,362,67
,datascience,Hi! I’m applying to data science/ analytics jobs and internships right now. I have extensive personal and academic projects that I need to put in an online portfolio for hiring managers to see. What do you all recommend for this? Thanks!,t2_hhwehrl8,False,,0,False,What website do I use to make a portfolio?,[],r/datascience,False,6,fun,0,,,False,t3_17h0uio,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,False,self,False,,[],{},,True,,1698338865.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I’m applying to data science/ analytics jobs and internships right now. I have extensive personal and academic projects that I need to put in an online portfolio for hiring managers to see. What do you all recommend for this? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17h0uio,True,,soupqueen6869,,5,True,all_ads,False,[],False,,/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,all_ads,False,https://www.reddit.com/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,1209067,1698338865.0,0,,False,,,,,,,,,,237,41
,datascience,"Hello, can anyone help me out. I want to convert a huge .dta file(~3GB) to .csv file but I am not able to do so using python due to its large size. I also tried on kaggle but it said memory limit exceeded. Can anyone help me out?",t2_tvg76tfz,False,,0,False,Convert Stata(.DTA) files to .csv,[],r/datascience,False,6,tooling,0,,,False,t3_17gzyzp,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698336565.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, can anyone help me out. I want to convert a huge .dta file(~3GB) to .csv file but I am not able to do so using python due to its large size. I also tried on kaggle but it said memory limit exceeded. Can anyone help me out?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17gzyzp,True,,smokeyScraper,,6,True,all_ads,False,[],False,,/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,1209067,1698336565.0,0,,False,,,,,,,,,,229,48
,datascience,"Hello All,

I am a student pursuing an MS in data science. I have done a few projects involving EDA and implemented a few ML algorithms. I am very enthusiastic about researching something and publishing a paper on it. However, I have no idea where to start or how to choose a research topic. Can someone among you guide me on this? At this point, I do not want to pursue a PhD but want to conduct independent research on a topic.",t2_650l3x8ha,False,,0,False,Need guidance to publish a paper,[],r/datascience,False,6,network,0,,,False,t3_17gyvk2,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Analysis,False,3,,False,False,self,False,,[],{},,True,,1698333564.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello All,&lt;/p&gt;

&lt;p&gt;I am a student pursuing an MS in data science. I have done a few projects involving EDA and implemented a few ML algorithms. I am very enthusiastic about researching something and publishing a paper on it. However, I have no idea where to start or how to choose a research topic. Can someone among you guide me on this? At this point, I do not want to pursue a PhD but want to conduct independent research on a topic.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17gyvk2,True,,Eastern-Habit6458,,3,True,all_ads,False,[],False,,/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,1209067,1698333564.0,0,,False,,,,,,,,,,429,82
,datascience,"my first job was as a consultant, doing a mix of implementation and data analytics. 

then i switched to a new job with the data analyst title, but I'm building production R scripts almost exclusively now; not a huge fan of wrangling with my team's complex/sparsely commented codebase and designing 'systems' (our scripts have to integrate with a variety of outside data sources).

I miss doing 'investigations', eg how do we better optimize this product, make more revenue, etc. now it feels like I'm an underpaid backend software engineer (making 85k but seems most SWEs are earning 100k+).

is data analytics in 2023 more similar to SWE? should I have expected this?",t2_gaa4jyzpd,False,,0,False,"I'm a 'data analyst' who in practice is actually just a software engineer. Was I bamboozled, or did I misunderstand the role",[],r/datascience,False,6,fun,0,,,False,t3_17gyevz,False,dark,0.94,,public,170,0,{},,,False,[],,False,False,,{},Career Discussion,False,170,,False,False,self,False,,[],{},,True,,1698332259.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;my first job was as a consultant, doing a mix of implementation and data analytics. &lt;/p&gt;

&lt;p&gt;then i switched to a new job with the data analyst title, but I&amp;#39;m building production R scripts almost exclusively now; not a huge fan of wrangling with my team&amp;#39;s complex/sparsely commented codebase and designing &amp;#39;systems&amp;#39; (our scripts have to integrate with a variety of outside data sources).&lt;/p&gt;

&lt;p&gt;I miss doing &amp;#39;investigations&amp;#39;, eg how do we better optimize this product, make more revenue, etc. now it feels like I&amp;#39;m an underpaid backend software engineer (making 85k but seems most SWEs are earning 100k+).&lt;/p&gt;

&lt;p&gt;is data analytics in 2023 more similar to SWE? should I have expected this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17gyevz,True,,Prestigious_Belt4965,,86,True,all_ads,False,[],False,,/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,1209067,1698332259.0,0,,False,,,,,,,,,,669,112
,datascience,"USF accepted my application for the [MSDI program](https://www.usf.edu/engineering/imse/graduate/ms-data-intelligence.aspx). I'm here considering if I accept the acceptance letter and join in January, or wait until August 2024 to join Georgia Tech's Online Master of Science in Analytics.",t2_7zsucf9u,False,,0,False,Thoughts about MS in Data Intelligence (MSDI) in University of South Florida?,[],r/datascience,False,6,,0,,,False,t3_17gya2d,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Education,False,1,,False,False,self,False,,[],{},,True,,1698331878.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;USF accepted my application for the &lt;a href=""https://www.usf.edu/engineering/imse/graduate/ms-data-intelligence.aspx""&gt;MSDI program&lt;/a&gt;. I&amp;#39;m here considering if I accept the acceptance letter and join in January, or wait until August 2024 to join Georgia Tech&amp;#39;s Online Master of Science in Analytics.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17gya2d,True,,former_pothead,,3,True,all_ads,False,[],False,,/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,1209067,1698331878.0,0,,False,,,,,,,,,,288,36
,datascience,"Sorry if this is a weird question I just need what people with more experience think about my situation. For some context. I am doing a Master in Data Science but finished my degree in biology. I study full time but I have two other classes at the same time this semester. And one of my class is blasting through this book by giving a little over an hr lecture per chapter and plan to finish the book in a semester. It is clear to me the lectures don’t cover all the contents either does not cover some details or leave some parts out.  While you could absolutely give lectures like this, it does take some time to fully grasp all the concepts, especially when I have to do 2 other classes. I feel like I can’t keep up so just wondering how long people here take to study it if they did or if they are familiar with it, hopefully can tell me if what I am feeling is natural within the context I provided or if it is because of my lack of experience in programming. Do I need to get more of my shit together? Or should I feel less shit about having to catch up slower and investing more time hopefully during holidays and stuff.",t2_lj6rgo0gb,False,,0,False,"Intro to Statistical Learning, With Applications in Python (ISLP) How long could it take to study this book?",[],r/datascience,False,6,,0,,,False,t3_17gxa3v,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Education,False,5,,False,False,self,False,,[],{},,True,,1698329031.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sorry if this is a weird question I just need what people with more experience think about my situation. For some context. I am doing a Master in Data Science but finished my degree in biology. I study full time but I have two other classes at the same time this semester. And one of my class is blasting through this book by giving a little over an hr lecture per chapter and plan to finish the book in a semester. It is clear to me the lectures don’t cover all the contents either does not cover some details or leave some parts out.  While you could absolutely give lectures like this, it does take some time to fully grasp all the concepts, especially when I have to do 2 other classes. I feel like I can’t keep up so just wondering how long people here take to study it if they did or if they are familiar with it, hopefully can tell me if what I am feeling is natural within the context I provided or if it is because of my lack of experience in programming. Do I need to get more of my shit together? Or should I feel less shit about having to catch up slower and investing more time hopefully during holidays and stuff.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17gxa3v,True,,Bunshin69,,14,True,all_ads,False,[],False,,/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,1209067,1698329031.0,0,,False,,,,,,,,,,1127,219
,datascience,"Can be in work, as a passion project/academic project, or just an idea. Was it successful? If not, why not? Would love to be inspired &amp; motivated by all of your experiences, and who knows, maybe it’ll help someone think about a current project in a new way.",t2_ct0r9u9d,False,,0,False,"What is the most unique, out of the box, or exciting application of DS you’ve used/thought of?",[],r/datascience,False,6,discussion,0,,,False,t3_17gx6q4,False,dark,0.86,,public,20,0,{},,,False,[],,False,False,,{},Discussion,False,20,,False,False,self,False,,[],{},,True,,1698328791.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can be in work, as a passion project/academic project, or just an idea. Was it successful? If not, why not? Would love to be inspired &amp;amp; motivated by all of your experiences, and who knows, maybe it’ll help someone think about a current project in a new way.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gx6q4,True,,NewManufacturer3888,,16,True,all_ads,False,[],False,,/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,1209067,1698328791.0,0,,False,,,,,,,,,,261,48
,datascience,"Hi everyone, 

I was working on my thesis research when I encountered the concept of Feature Pyramid Network, i have read something about it but still i have some doubts. My main question is: ""What is (or are) the difference(s) with respect to the U-Net architecture?""",t2_n7unu2tp,False,,0,False,Feature Pyramid Network vs U-Net,[],r/datascience,False,6,projects,0,,,False,t3_17gwwlp,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},ML,False,2,,False,False,self,False,,[],{},,True,,1698327969.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;

&lt;p&gt;I was working on my thesis research when I encountered the concept of Feature Pyramid Network, i have read something about it but still i have some doubts. My main question is: &amp;quot;What is (or are) the difference(s) with respect to the U-Net architecture?&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17gwwlp,True,,Distinct-Swan2019,,1,True,all_ads,False,[],False,,/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,1209067,1698327969.0,0,,False,,,,,,,,,,268,46
,datascience,"My brother-in-law(call him James) co-owns a small business with two of his colleagues who provide services to small businesses. These services include website design, marketing(everything from SEO optimization to email lists to whatever), and graphic design. James recently reached out to me to ask if I would do part-time work for them as a data analyst/data scientist. My background is in quantitative political science. I know how to do pretty much everything data scientists do at a low level (ML algorithms, acquiring data, cleaning data, etc.) but I don't know very well how to apply these techniques to a business. So from that, I have two questions: 

1. How are ML algorithms used for businesses? I'll give some examples of how I imagine it working. K-means clustering can be used for targeted advertisements based on the groups customers are put in. Linear regression can be used to predict sales based on some other independent variable. Decision trees can be used to determine what factors might lead to a customer discontinuing the use of a service. Am I on the correct track? Are these incorrect or are there others I am missing? I would love to hear about ways you guys use ML in your job. I know how to do A/B testing conceptually and do a ton of hypothesis testing in my work so that part of the job I am not worried about (and honestly looking at these two methods it seems they will be used more often than ML). 
2. Can data science even be done with small businesses? My main concern is about the quality of the data. It may require me to organize the data which could take a considerable amount of time and might venture into some data engineering spheres in which I really don't have experience. And then will there even be enough data? Is there some critical mass of sales that is needed before one can begin analyzing a company's metrics? I believe most of the people this service works with a smaller companies that might not have the robust data that F500 companies do. 

I hope these two questions make sense. I'm not trying to get quick and dirty information about data science. If I'm pointed in the direction of how to use these algorithms I can research them on my own. I just wanted some advice from people in the field. For reference, I use mostly Stata in my poli sci work, but I can do most of it in Python as well. Stata is just better for the small studies I do lol. ",t2_2i4xkeus,False,,0,False,Freelance Data Science in small businesses,[],r/datascience,False,6,discussion,0,,,False,t3_17gwjgc,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1698326916.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My brother-in-law(call him James) co-owns a small business with two of his colleagues who provide services to small businesses. These services include website design, marketing(everything from SEO optimization to email lists to whatever), and graphic design. James recently reached out to me to ask if I would do part-time work for them as a data analyst/data scientist. My background is in quantitative political science. I know how to do pretty much everything data scientists do at a low level (ML algorithms, acquiring data, cleaning data, etc.) but I don&amp;#39;t know very well how to apply these techniques to a business. So from that, I have two questions: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How are ML algorithms used for businesses? I&amp;#39;ll give some examples of how I imagine it working. K-means clustering can be used for targeted advertisements based on the groups customers are put in. Linear regression can be used to predict sales based on some other independent variable. Decision trees can be used to determine what factors might lead to a customer discontinuing the use of a service. Am I on the correct track? Are these incorrect or are there others I am missing? I would love to hear about ways you guys use ML in your job. I know how to do A/B testing conceptually and do a ton of hypothesis testing in my work so that part of the job I am not worried about (and honestly looking at these two methods it seems they will be used more often than ML). &lt;/li&gt;
&lt;li&gt;Can data science even be done with small businesses? My main concern is about the quality of the data. It may require me to organize the data which could take a considerable amount of time and might venture into some data engineering spheres in which I really don&amp;#39;t have experience. And then will there even be enough data? Is there some critical mass of sales that is needed before one can begin analyzing a company&amp;#39;s metrics? I believe most of the people this service works with a smaller companies that might not have the robust data that F500 companies do. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I hope these two questions make sense. I&amp;#39;m not trying to get quick and dirty information about data science. If I&amp;#39;m pointed in the direction of how to use these algorithms I can research them on my own. I just wanted some advice from people in the field. For reference, I use mostly Stata in my poli sci work, but I can do most of it in Python as well. Stata is just better for the small studies I do lol. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gwjgc,True,,KamdynS7,,7,True,all_ads,False,[],False,,/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,1209067,1698326916.0,0,,False,,,,,,,,,,2404,433
,datascience,"I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.

Please email me at: support@underhive.in.
If you want to help and be one of the first beta clients.
We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.  
Try out: https://underhive.in (please use on Desktop, the mobile version is broken right now)",t2_6qimiaok,False,,0,False,Git Version Controlled Datasets in your own S3,[],r/datascience,False,6,meta,0,66.0,,False,t3_17gwd7z,False,dark,0.67,,public,1,0,{},140.0,,False,[],,True,False,,{},Projects,False,1,,False,False,https://b.thumbs.redditmedia.com/f1OlSBSNNEJZAmwlPIi3HjCS-4n4jYT0TRbIIieQ8qU.jpg,False,,[],{},,False,,1698326392.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.&lt;/p&gt;

&lt;p&gt;Please email me at: &lt;a href=""mailto:support@underhive.in""&gt;support@underhive.in&lt;/a&gt;.
If you want to help and be one of the first beta clients.
We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.&lt;/p&gt;

&lt;p&gt;Try out: &lt;a href=""https://underhive.in""&gt;https://underhive.in&lt;/a&gt; (please use on Desktop, the mobile version is broken right now)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17gwd7z,True,,kaisoma,,5,True,all_ads,False,[],False,,/r/datascience/comments/17gwd7z/git_version_controlled_datasets_in_your_own_s3/,all_ads,False,https://i.redd.it/pkoix1xasjwb1.jpg,1209067,1698326392.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?auto=webp&amp;s=0cfb2bb0fcde155afa9212aadee76fe66d733781', 'width': 1919, 'height': 910}, 'resolutions': [{'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea7444673e01e20b699edc7c4d0ee9950959ff7c', 'width': 108, 'height': 51}, {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06cbd8c2e12a6eae38c22adc6b0fe5b362dca112', 'width': 216, 'height': 102}, {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=caa9d8b538f17b51c3a7f8624746177663ada6e7', 'width': 320, 'height': 151}, {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14aca97e42576634fd0195abe4f21dde48e2caba', 'width': 640, 'height': 303}, {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62bc861e0f50a91e90f9bee7c5786af81c8b9d79', 'width': 960, 'height': 455}, {'url': 'https://preview.redd.it/pkoix1xasjwb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1b6bb9096dfb70ffce217de88741e7a37c77018', 'width': 1080, 'height': 512}], 'variants': {}, 'id': 'RwTIUFrxOqlzdg1MtSnUTZXi5rfvLnvbYHcTXoFYW4g'}], 'enabled': True}",,https://i.redd.it/pkoix1xasjwb1.jpg,,,,,441,75
,datascience,"Hey everybody,  
I started to use KNIME fpr work, but have some issues with it. I am currently taking the DW1 Exam, but I dont have any idea on how to do that. Can someone please help me? using ChatGPT feels like cheating.  
Thanks in advance ",t2_m5ihxgfnw,False,,0,False,Questions for KNIME Users,[],r/datascience,False,6,tooling,0,,,False,t3_17gvhga,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Tools,False,2,,False,False,self,False,,[],{},,True,,1698323664.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everybody,&lt;br/&gt;
I started to use KNIME fpr work, but have some issues with it. I am currently taking the DW1 Exam, but I dont have any idea on how to do that. Can someone please help me? using ChatGPT feels like cheating.&lt;br/&gt;
Thanks in advance &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17gvhga,True,,Slow_Act_4114,,0,True,all_ads,False,[],False,,/r/datascience/comments/17gvhga/questions_for_knime_users/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gvhga/questions_for_knime_users/,1209067,1698323664.0,0,,False,,,,,,,,,,243,46
,datascience,"I've recently did some searches about AI failures, the most catastrophic failure I read about was when [Zillow had to fire 2000 employees](https://www.geekwire.com/2021/zillow-shutter-home-buying-business-lay-off-2k-employees-big-real-estate-bet-falters/). 

I also saw some articles like this [one](https://www.science.org/doi/10.1126/science.aax2342), about biases in health algorithms, but all in all I didn't see much examples that had a measure of how much damage was actually done.

Are there more examples of AI failures on a large scale?",t2_3md3xoyd,False,,0,False,What are some good examples of catastrophic AI failures?,[],r/datascience,False,6,discussion,0,,,False,t3_17gujdu,False,dark,0.95,,public,89,0,{},,,False,[],,False,False,,{},Discussion,False,89,,False,False,self,False,,[],{},,True,,1698320521.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve recently did some searches about AI failures, the most catastrophic failure I read about was when &lt;a href=""https://www.geekwire.com/2021/zillow-shutter-home-buying-business-lay-off-2k-employees-big-real-estate-bet-falters/""&gt;Zillow had to fire 2000 employees&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;I also saw some articles like this &lt;a href=""https://www.science.org/doi/10.1126/science.aax2342""&gt;one&lt;/a&gt;, about biases in health algorithms, but all in all I didn&amp;#39;t see much examples that had a measure of how much damage was actually done.&lt;/p&gt;

&lt;p&gt;Are there more examples of AI failures on a large scale?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gujdu,True,,Maimonatorz,,63,True,all_ads,False,[],False,,/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,1209067,1698320521.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?auto=webp&amp;s=a6a2243892262e8393411d3fad75660c90d2408f', 'width': 2952, 'height': 2588}, 'resolutions': [{'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e45f7c442f2e13ac08b03a554d8ce6d8d4f03a2', 'width': 108, 'height': 94}, {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=956fdece887482fdbec3fc2d8dee724093fbd1a0', 'width': 216, 'height': 189}, {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1ea13da7225f5d93bc97d1eb6224e4f2a47eae8', 'width': 320, 'height': 280}, {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd9651b89be1428872393f2df63bd1f92baaf791', 'width': 640, 'height': 561}, {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dbb849a6674a127a742c174865a17e340a4ce3e2', 'width': 960, 'height': 841}, {'url': 'https://external-preview.redd.it/zONBZXiaY3d4C_EEFRaGYL-SDpECz7GPhCfQBfSyA3k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31b8ca0737d15840b84b3ae5daa31a9affe68cf6', 'width': 1080, 'height': 946}], 'variants': {}, 'id': 'vv1SQd3378N1QgX-P7PekhaXGgraU6Q3kKVMt9rPNGw'}], 'enabled': False}",,,,,,,545,67
,datascience,"Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  **Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.**   


I have seen and found this framework for answering such questions:  


Step1: Ask clarifying questions on problems and constraints 

Step 2: Establish Metrics 

Step 3: Understand your data sources 

Step 4: Explore your data 

Step 5: Data Cleanup 

Step 6: Feature Engineering 

Step 7: Model Selection and training 

Step 8: Deployment 

Step 9: Iterate 

I would love to get inputs on need and usefulness of such frameworks?

&amp;#x200B;",t2_mjdr3ppgq,False,,0,False,Are data science answering frameworks helpful?,[],r/datascience,False,6,,0,,,False,t3_17gtvwl,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Education,False,2,,False,False,self,False,,[],{},,True,,1698318064.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  &lt;strong&gt;Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.&lt;/strong&gt;   &lt;/p&gt;

&lt;p&gt;I have seen and found this framework for answering such questions:  &lt;/p&gt;

&lt;p&gt;Step1: Ask clarifying questions on problems and constraints &lt;/p&gt;

&lt;p&gt;Step 2: Establish Metrics &lt;/p&gt;

&lt;p&gt;Step 3: Understand your data sources &lt;/p&gt;

&lt;p&gt;Step 4: Explore your data &lt;/p&gt;

&lt;p&gt;Step 5: Data Cleanup &lt;/p&gt;

&lt;p&gt;Step 6: Feature Engineering &lt;/p&gt;

&lt;p&gt;Step 7: Model Selection and training &lt;/p&gt;

&lt;p&gt;Step 8: Deployment &lt;/p&gt;

&lt;p&gt;Step 9: Iterate &lt;/p&gt;

&lt;p&gt;I would love to get inputs on need and usefulness of such frameworks?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17gtvwl,True,,First_Beginning6365,,2,True,all_ads,False,[],False,,/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,1209067,1698318064.0,0,,False,,,,,,,,,,842,130
,datascience,"Hello all, I encountered this data analytics / data science challenge at work, wondering how y’all would have solved it.

**Background:**

I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.

Given that we weren't producing the product descriptions ourselves, our focus was on **features we could influence**. We **did not include** aspects such as:

* brand reputation, 
* type of product, 
* price

, even if they were vital factors driving user engagement.

Our attention was instead directed at a few controllable features:

* whether or not the descriptions exceeded a certain length (we could provide feedback on these to vendors)
* whether or not our in-house ML model could categorize the product (affecting its searchability)
* the presence of vendor ratings,
* etc.

To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn't. So, my dataset consisted of all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.

**Approach:**

My next steps? I initiated numerous student t-tests. 

For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What's the engagement disparity between products that had vendor ratings va those that didn’t? 

Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. 

Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren't for UX / political reasons.

**Results:**

With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging.

Yet, the findings weren't consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.

My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.

I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.

**What could I have done differently?**

In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?

I would love to hear your thoughts!",t2_ap3spmczk,False,,0,False,Dealing with features of questionable predictive power and confounding variables,[],r/datascience,False,6,network,0,,,False,t3_17gtslo,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Analysis,False,2,,False,False,self,1698353625.0,,[],{},,True,,1698317713.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, I encountered this data analytics / data science challenge at work, wondering how y’all would have solved it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.&lt;/p&gt;

&lt;p&gt;Given that we weren&amp;#39;t producing the product descriptions ourselves, our focus was on &lt;strong&gt;features we could influence&lt;/strong&gt;. We &lt;strong&gt;did not include&lt;/strong&gt; aspects such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;brand reputation, &lt;/li&gt;
&lt;li&gt;type of product, &lt;/li&gt;
&lt;li&gt;price&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;, even if they were vital factors driving user engagement.&lt;/p&gt;

&lt;p&gt;Our attention was instead directed at a few controllable features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;whether or not the descriptions exceeded a certain length (we could provide feedback on these to vendors)&lt;/li&gt;
&lt;li&gt;whether or not our in-house ML model could categorize the product (affecting its searchability)&lt;/li&gt;
&lt;li&gt;the presence of vendor ratings,&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn&amp;#39;t. So, my dataset consisted of all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Approach:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;My next steps? I initiated numerous student t-tests. &lt;/p&gt;

&lt;p&gt;For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What&amp;#39;s the engagement disparity between products that had vendor ratings va those that didn’t? &lt;/p&gt;

&lt;p&gt;Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. &lt;/p&gt;

&lt;p&gt;Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren&amp;#39;t for UX / political reasons.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Results:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging.&lt;/p&gt;

&lt;p&gt;Yet, the findings weren&amp;#39;t consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.&lt;/p&gt;

&lt;p&gt;My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.&lt;/p&gt;

&lt;p&gt;I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What could I have done differently?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?&lt;/p&gt;

&lt;p&gt;I would love to hear your thoughts!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17gtslo,True,,Glum-Bat8771,,4,True,all_ads,False,[],False,,/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,1209067,1698317713.0,0,,False,,,,,,,,,,3889,614
,datascience,"I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. 

Any additional skills I need to learn?",t2_m26htnjnl,False,,0,False,How to qualify for a job in Data Science,[],r/datascience,False,6,fun,0,,,False,t3_17gtgb0,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1698316319.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. &lt;/p&gt;

&lt;p&gt;Any additional skills I need to learn?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17gtgb0,True,,cinderbl0ckgardener,,3,True,all_ads,False,[],False,,/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,1209067,1698316319.0,0,,False,,,,,,,,,,281,47
,datascience,"I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.

The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.

I'm looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS ([Missing Data Imputation using Generative Adversarial Nets](https://arxiv.org/abs/1806.02920)) and [MissForest](https://academic.oup.com/bioinformatics/article/28/1/112/219101). Does anybody have any other suggestions of imputers that might work?",t2_qgew7u,False,,0,False,Imputation of multiple missing values,[],r/datascience,False,6,tooling,0,,,False,t3_17gqxzh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698305124.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.&lt;/p&gt;

&lt;p&gt;The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS (&lt;a href=""https://arxiv.org/abs/1806.02920""&gt;Missing Data Imputation using Generative Adversarial Nets&lt;/a&gt;) and &lt;a href=""https://academic.oup.com/bioinformatics/article/28/1/112/219101""&gt;MissForest&lt;/a&gt;. Does anybody have any other suggestions of imputers that might work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17gqxzh,True,,ChrisReynolds83,,1,True,all_ads,False,[],False,,/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,1209067,1698305124.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?auto=webp&amp;s=8efe489c05609f1626bbb44354c77840623707de', 'width': 1200, 'height': 700}, 'resolutions': [{'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc9575b410002edc2df3c5b5b0355fefedc7baa8', 'width': 108, 'height': 63}, {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbce7f303173724d23fb33cd3fc636c04c72b290', 'width': 216, 'height': 126}, {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1043d604105157f56a615cc59bb14d7ae64653f', 'width': 320, 'height': 186}, {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45', 'width': 640, 'height': 373}, {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76aed6fd51086798b2d415a7d57562c967db4111', 'width': 960, 'height': 560}, {'url': 'https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46129c06d8fad9a58fff9740c079e13d4e829213', 'width': 1080, 'height': 630}], 'variants': {}, 'id': 'q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss'}], 'enabled': False}",,,,,,,1111,169
,datascience,I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?,t2_ii3qs0uq,False,,0,False,How can you learn to find the insights,[],r/datascience,False,6,discussion,0,,,False,t3_17gpxlq,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698300755.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gpxlq,True,,SaiyWolf,,6,True,all_ads,False,[],False,,/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,1209067,1698300755.0,0,,False,,,,,,,,,,151,26
,datascience,"I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?",t2_jnnvdz39c,False,,0,False,having a second job on 1099,[],r/datascience,False,6,fun,0,,,False,t3_17goc84,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1698294457.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I&amp;#39;m doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17goc84,True,,daufoi21,,5,True,all_ads,False,[],False,,/r/datascience/comments/17goc84/having_a_second_job_on_1099/,all_ads,False,https://www.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/,1209067,1698294457.0,0,,False,,,,,,,,,,397,80
,datascience,"My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. 

Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?",t2_4oockqg5s,False,,0,False,A/B test in real life,[],r/datascience,False,6,discussion,0,,,False,t3_17go3pk,False,dark,0.98,,public,74,0,{},,,False,[],,False,False,,{},Discussion,False,74,,False,False,self,False,,[],{},,True,,1698293599.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn&amp;#39;t conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. &lt;/p&gt;

&lt;p&gt;Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17go3pk,True,,furioncruz,,39,True,all_ads,False,[],False,,/r/datascience/comments/17go3pk/ab_test_in_real_life/,all_ads,False,https://www.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/,1209067,1698293599.0,0,,False,,,,,,,,,,647,122
,datascience,I’m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I’m pursuing right now also promised placement opportunities but I do not want to wait till the end…,t2_o9iya5e7,False,,0,False,How to proceed…,[],r/datascience,False,6,fun,0,,,False,t3_17gn7d8,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1698290490.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I’m pursuing right now also promised placement opportunities but I do not want to wait till the end…&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17gn7d8,True,,LegitimateAd4716,,3,True,all_ads,False,[],False,,/r/datascience/comments/17gn7d8/how_to_proceed/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/,1209067,1698290490.0,0,,False,,,,,,,,,,307,60
,datascience,"&amp;#x200B;

I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are ""less wrong"" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 ""means something""), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!

My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.

https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32",t2_9yzncc2e,False,,0,False,"Evaluation Metric Flowchart (possibly handy, interested in feedback!)",[],r/datascience,False,6,discussion,0,77.0,,False,t3_17gn08a,False,dark,0.76,,public,2,0,{},140.0,,True,[],,False,False,,{},Discussion,False,2,,False,False,https://b.thumbs.redditmedia.com/C6FsdcbioThGINeCCFjlbVQ1pb184byUS-UeLLkTbLs.jpg,False,,[],{},,True,,1698289874.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I&amp;#39;m ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There&amp;#39;s obviously innumerable choices one could make for metrics, so the bias here is picking ones that are &amp;quot;less wrong&amp;quot; (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 &amp;quot;means something&amp;quot;), and have some popular acceptance. Sharing here in case it&amp;#39;s helpful, and also I&amp;#39;m interested in others poking holes in the choices I made (if something seems egregious enough)!&lt;/p&gt;

&lt;p&gt;My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32""&gt;https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gn08a,True,,jshkk,,0,True,all_ads,False,[],False,,/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,1209067,1698289874.0,0,,False,"{'7nplhw2npgwb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=030c67234c4f1eab22019470c0c1ca689e587b78'}, {'y': 120, 'x': 216, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4778be88b74770c29cfba8eb985952477d7e668d'}, {'y': 178, 'x': 320, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2575007f8ef0e519f6657b3807e6a8eef7520277'}, {'y': 356, 'x': 640, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6807bc711553c64a5d8a096d501ce856e4c4cb53'}, {'y': 534, 'x': 960, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b91e51da19d7ecac8dd06a18ef275289f9ba9fa'}, {'y': 601, 'x': 1080, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3c8caebe3c3b31aa7899791907ab558296754139'}], 's': {'y': 3990, 'x': 7162, 'u': 'https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32'}, 'id': '7nplhw2npgwb1'}}",,,,,,,,,1235,181
,datascience,We work in an items per hr setting with 100's of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.,t2_m4d1tjfvl,False,,0,False,Reducing Goals Using Dats,[],r/datascience,False,6,meta,0,,,False,t3_17gkbw1,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1698281777.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We work in an items per hr setting with 100&amp;#39;s of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17gkbw1,True,,Time_Law_2659,,0,True,all_ads,False,[],False,,/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,1209067,1698281777.0,0,,False,,,,,,,,,,518,99
,datascience,"I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?

Red flags include:

* No data / inaccessible data / data flying around in Excel
* Management is not ""ML literate""
* More work dealing with red tape than actual work
* 2x more managers than workers driving projects
* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it
* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.
* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day
* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)

My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025",t2_am698,False,,0,False,How to survive at nightmare employer?,[],r/datascience,False,6,fun,0,,,False,t3_17gfqqp,False,dark,0.95,,public,134,0,{},,,False,[],,False,False,,{},Career Discussion,False,134,,False,False,self,1698270328.0,,[],{},,True,,1698269551.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I&amp;#39;m slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?&lt;/p&gt;

&lt;p&gt;Red flags include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;No data / inaccessible data / data flying around in Excel&lt;/li&gt;
&lt;li&gt;Management is not &amp;quot;ML literate&amp;quot;&lt;/li&gt;
&lt;li&gt;More work dealing with red tape than actual work&lt;/li&gt;
&lt;li&gt;2x more managers than workers driving projects&lt;/li&gt;
&lt;li&gt;Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it&lt;/li&gt;
&lt;li&gt;No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.&lt;/li&gt;
&lt;li&gt;Because we work directly in prod, we don&amp;#39;t have permission to save our processed data to tables or csv&amp;#39;s - it must be done in memory every single day&lt;/li&gt;
&lt;li&gt;No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can&amp;#39;t download unapproved libraries or pre-trained models without security review (even just for exploration)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17gfqqp,True,,Mackelday,,72,True,all_ads,False,[],False,,/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,1209067,1698269551.0,0,,False,,,,,,,,,,1259,239
,datascience,"Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.

If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.

Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a ""big bucket"" structure in which everything is kept in the same place?",t2_9pje88yp,False,,0,False,Vector DB directory structuring - ideal?,[],r/datascience,False,6,discussion,0,,,False,t3_17gej5o,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698266491.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.&lt;/p&gt;

&lt;p&gt;If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what&amp;#39;s queried.&lt;/p&gt;

&lt;p&gt;Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a &amp;quot;big bucket&amp;quot; structure in which everything is kept in the same place?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17gej5o,True,,LucasSaysHello,,0,True,all_ads,False,[],False,,/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,1209067,1698266491.0,0,,False,,,,,,,,,,620,111
,datascience," For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.

This is what the course page says : 

Student Learning Outcomes: 

Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.

Detailed Content: 

Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems – applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation – applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle – primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  


  
I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?",t2_k6fzzm72,False,,0,False,Is a Convex Optimization class good for Data Science?,[],r/datascience,False,6,,0,,,False,t3_17gc0b4,False,dark,0.91,,public,33,0,{},,,False,[],,False,False,,{},Education,False,33,,False,False,self,False,,[],{},,True,,1698259755.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For context, I am a Master&amp;#39;s student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.&lt;/p&gt;

&lt;p&gt;This is what the course page says : &lt;/p&gt;

&lt;p&gt;Student Learning Outcomes: &lt;/p&gt;

&lt;p&gt;Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.&lt;/p&gt;

&lt;p&gt;Detailed Content: &lt;/p&gt;

&lt;p&gt;Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems – applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation – applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle – primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  &lt;/p&gt;

&lt;p&gt;I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17gc0b4,True,,VastDragonfruit847,,22,True,all_ads,False,[],False,,/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,1209067,1698259755.0,0,,False,,,,,,,,,,2260,304
,datascience," Hey there, fellow data science people,

I'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.

Here's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.

And last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. 

Thank you a lot in advance",t2_ec0fi5ob,False,,0,False,Cloud computing trends in data science,[],r/datascience,False,6,,0,,,False,t3_17g9mzj,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Education,False,1,,False,False,self,False,,[],{},,True,,1698253498.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there, fellow data science people,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I&amp;#39;m having a bit of a struggle finding my first gig.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s where I need advice. I&amp;#39;m curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I&amp;#39;m learning a cloud platform that&amp;#39;ll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.&lt;/p&gt;

&lt;p&gt;And last but not least, I&amp;#39;m all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. &lt;/p&gt;

&lt;p&gt;Thank you a lot in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17g9mzj,True,,lucasso13,,1,True,all_ads,False,[],False,,/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,1209067,1698253498.0,0,,False,,,,,,,,,,873,161
,datascience,"I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. 

One reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?",t2_3kdgnq0f,False,,0,False,Learning Cloud Platforms,[],r/datascience,False,6,fun,0,,,False,t3_17g8iu2,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Career Discussion,False,7,,False,False,self,False,,[],{},,True,,1698250622.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer&amp;#39;s life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it&amp;#39;s so different from data science where we focus on concepts vs tools. &lt;/p&gt;

&lt;p&gt;One reason Im curious is if you&amp;#39;re the head of an analytics department how do you manage all of this? How would you know how much work something is?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17g8iu2,True,,Jbor941197,,0,True,all_ads,False,[],False,,/r/datascience/comments/17g8iu2/learning_cloud_platforms/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/,1209067,1698250622.0,0,,False,,,,,,,,,,574,106
,datascience,"I know you would have heard so many people asking this question, but please bear with me.

I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any ""algorithm"" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.",t2_9llh8x8t,False,,0,False,What is the most suitable model for my problem?,[],r/datascience,False,6,discussion,0,,,False,t3_17g8cbj,False,dark,0.92,,public,9,0,{},,,False,[],,False,False,,{},Discussion,False,9,,False,False,self,False,,[],{},,True,,1698250152.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know you would have heard so many people asking this question, but please bear with me.&lt;/p&gt;

&lt;p&gt;I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp;amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don&amp;#39;t know how to go about selelcting a model that suits the data the most because I don&amp;#39;t have enough experience to just select any model based on experience and I didn&amp;#39;t find any &amp;quot;algorithm&amp;quot; which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17g8cbj,True,,jakeblack06,,9,True,all_ads,False,[],False,,/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,1209067,1698250152.0,1,,False,,,,,,,,,,786,147
,datascience,"I have a company page and branding package set up on LinkedIn – is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?

Some details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.",t2_883ga,False,,0,False,Worthwhile to post personal and pro-bono projects under my company page in order to list experience?,[],r/datascience,False,6,fun,0,,,False,t3_17g7vsr,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Career Discussion,False,2,,False,False,self,False,,[],{},,True,,1698248991.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a company page and branding package set up on LinkedIn – is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?&lt;/p&gt;

&lt;p&gt;Some details: I&amp;#39;m a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I&amp;#39;ve created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17g7vsr,True,,CarbonHero,,0,True,all_ads,False,[],False,,/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,1209067,1698248991.0,0,,False,,,,,,,,,,558,91
,datascience,"I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don’t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can’t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone’s thoughts?",t2_d97itlol,False,,0,False,Is the future of data science drag and drop?,[],r/datascience,False,6,discussion,0,,,False,t3_17g7kqf,False,dark,0.78,,public,119,0,{},,,False,[],,False,False,,{},Discussion,False,119,,False,False,self,False,,[],{},,True,,1698248160.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don’t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can’t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone’s thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17g7kqf,True,,cptsanderzz,,144,True,all_ads,False,[],False,,/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,1209067,1698248160.0,0,,False,,,,,,,,,,522,98
,datascience,"Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?

Additionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. ",t2_3uoce3bn,False,,0,False,How do you maintain motivation in your data role?,[],r/datascience,False,6,discussion,0,,,False,t3_17g6gbt,False,dark,0.91,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,False,self,False,,[],{},,True,,1698245141.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?&lt;/p&gt;

&lt;p&gt;Additionally, how do you maintain motivation when you&amp;#39;re working with a domain that you don&amp;#39;t like? Not tolerate, generally don&amp;#39;t like. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17g6gbt,True,,Tender_Figs,,8,True,all_ads,False,[],False,,/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,1209067,1698245141.0,0,,False,,,,,,,,,,460,73
,datascience,"&amp;#x200B;

[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b)

I've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?

Edit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.",t2_hcgjj0xo,False,,0,False,Need help understanding if the model here is overfitting or not.,[],r/datascience,False,6,network,0,48.0,,False,t3_17g55zm,False,dark,0.82,,public,7,0,{},140.0,,False,[],,False,False,,{},Analysis,False,7,,False,False,https://b.thumbs.redditmedia.com/xtw4EAc8CYsFFqHXS6MxDctZLMU8Ncxdd7yk5ULOV_c.jpg,1698242330.0,,[],{},,True,,1698241481.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b""&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been training this model and what I&amp;#39;m seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I&amp;#39;ve never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?&lt;/p&gt;

&lt;p&gt;Edit: I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;, &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17g55zm,True,,Total-Opposite-8396,,13,True,all_ads,False,[],False,,/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,1209067,1698241481.0,0,,False,"{'4cikjimrrcwb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 37, 'x': 108, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7771c425ef8e85b6d0257d24ff7eb2dd6c3f633b'}, {'y': 74, 'x': 216, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a0d072e224adc11e96db3e8c55a7c923bdd4f12'}, {'y': 110, 'x': 320, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=306b25854215a1dcd4f8d1e734e8cb762e9fb9b0'}, {'y': 221, 'x': 640, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31b3bdc29a5930780065a694881c62cacf1ddc2f'}, {'y': 331, 'x': 960, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d90194b0c01dfa4582192355dc0653ea409462a'}, {'y': 373, 'x': 1080, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d31555d54e47b347278ab81e74b9305b216e588f'}], 's': {'y': 534, 'x': 1546, 'u': 'https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b'}, 'id': '4cikjimrrcwb1'}}",,,,,,,,,1089,148
,datascience,Any company size (please include in response if possible).,,False,,0,False,"Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?",[],r/datascience,False,6,fun,0,,,False,t3_17g41qs,False,dark,0.6,,public,5,0,{},,,False,[],,False,False,,{},Career Discussion,False,5,,False,,self,False,,,{},,True,,1698238322.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Any company size (please include in response if possible).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17g41qs,True,,[deleted],,23,True,all_ads,False,[],,dark,/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,1209067,1698238322.0,0,,False,,,,,,,,,,58,9
,datascience,"Hey there. 
We are going to start working with Google sheets and podio.
We wanted to know which tool would be easier to learn and start working with. 
We are still beginners and we don't have access to paid versions and I got confused searching online.

What would be the pros and cons of using each tool. 

Thanks in advance.",t2_e9y297r4,False,,0,False,Choosing between google data studio (Looker studio now I guess) and Tableau.,[],r/datascience,False,6,tooling,0,,,False,t3_17g1rz7,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698230230.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there. 
We are going to start working with Google sheets and podio.
We wanted to know which tool would be easier to learn and start working with. 
We are still beginners and we don&amp;#39;t have access to paid versions and I got confused searching online.&lt;/p&gt;

&lt;p&gt;What would be the pros and cons of using each tool. &lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17g1rz7,True,,sigma_chungus,,3,True,all_ads,False,[],False,,/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,1209067,1698230230.0,0,,False,,,,,,,,,,326,60
,datascience,"Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.

1. I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)
2. The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.

&amp;#x200B;

https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;format=png&amp;auto=webp&amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58

Do share any experiences or suggestions!",t2_c2ajt49e,False,,0,False,"[P][R] Test-Val scores, how much difference isn't problematic.",[],r/datascience,False,6,projects,0,,,False,t3_17g01rn,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},ML,False,3,,False,False,self,False,,[],{},,True,,1698222484.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello folks, I&amp;#39;m working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I&amp;#39;m using a densenet121 and on a chest x-ray dataset.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it&amp;#39;s obvious but any visual insights from your side? (Attaching plot below)&lt;/li&gt;
&lt;li&gt;The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58""&gt;https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do share any experiences or suggestions!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17g01rn,True,,ade17_in,,0,True,all_ads,False,[],False,,/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,all_ads,False,https://www.reddit.com/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,1209067,1698222484.0,0,,False,"{'nseqy1mw5bwb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 79, 'x': 108, 'u': 'https://preview.redd.it/nseqy1mw5bwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=092bc7878e652493ab2260ccf9d6ab2c9bbea107'}, {'y': 159, 'x': 216, 'u': 'https://preview.redd.it/nseqy1mw5bwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=886f635604373da0bf03a3e7abaf511f21e3ba0c'}, {'y': 236, 'x': 320, 'u': 'https://preview.redd.it/nseqy1mw5bwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=74d0e6889b44444b1be07e30de9d108a927e935d'}], 's': {'y': 427, 'x': 577, 'u': 'https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;format=png&amp;auto=webp&amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58'}, 'id': 'nseqy1mw5bwb1'}}",,,,,,,,,900,133
,datascience,I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety,t2_3cw1ph2g,False,,0,False,I am intern and i hate Tableau. Can u give some copium?,[],r/datascience,False,6,discussion,0,,,False,t3_17fzssg,False,dark,0.86,,public,95,0,{},,,False,[],,False,False,,{},Discussion,False,95,,False,False,self,False,,[],{},,True,,1698221359.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17fzssg,True,,One_Ad_3499,,81,True,all_ads,False,[],False,,/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,1209067,1698221359.0,0,,False,,,,,,,,,,268,54
,datascience,"As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it's not ""advanced prompt engineering""?",t2_4n4wgk9f,False,,0,False,The role of data scientists in NLP,[],r/datascience,False,6,discussion,0,,,False,t3_17fytrb,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1698216935.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it&amp;#39;s not &amp;quot;advanced prompt engineering&amp;quot;?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17fytrb,True,,mint_warios,,22,True,all_ads,False,[],False,,/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,1209067,1698216935.0,0,,False,,,,,,,,,,457,75
,datascience,"Data Scientists of Reddit, what’s the tech Stack do you use? If you are working in MAANG companies or dealing with huge huge amounts of data, does normal machine learning algorithms work? Is Big Data stack( Hadoop, Spark..) part of your daily drive ? Do you use any other programming language, except Python/R for day to day usage? Are there any tools or technologies that are very useful but major part of the data people don’t know?

I’m Masters in Data Science student, I’m just wondering how real world works, all my projects/assignments just involve python, sklearn library and a famous dataset from kaggle.",t2_j4v8me41,False,,0,False,Tech Stack,[],r/datascience,False,6,discussion,0,,,False,t3_17fw3zm,False,dark,0.95,,public,47,0,{},,,False,[],,False,False,,{},Discussion,False,47,,False,False,self,False,,[],{},,True,,1698206237.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data Scientists of Reddit, what’s the tech Stack do you use? If you are working in MAANG companies or dealing with huge huge amounts of data, does normal machine learning algorithms work? Is Big Data stack( Hadoop, Spark..) part of your daily drive ? Do you use any other programming language, except Python/R for day to day usage? Are there any tools or technologies that are very useful but major part of the data people don’t know?&lt;/p&gt;

&lt;p&gt;I’m Masters in Data Science student, I’m just wondering how real world works, all my projects/assignments just involve python, sklearn library and a famous dataset from kaggle.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17fw3zm,True,,PerceptionHot9236,,52,True,all_ads,False,[],False,,/r/datascience/comments/17fw3zm/tech_stack/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fw3zm/tech_stack/,1209067,1698206237.0,0,,False,,,,,,,,,,612,104
,datascience,"i know this technique called keras tuner for tuning the model's hyperparameters . and then i also found that using for loop we can also select number of layers . and then i heard of this keras classifier that is used to search optimum number of layers and one more technique i head of is NAS Neural Network Search .   


keras tuner vs ( keras classifier ) keras.wrappers.scikit-learn.kerasClassifier vs neural network search (NAS)

can someone please help me with the difference among these three and what cases each can be considered ?",t2_86g0b57ij,False,,0,False,keras tuner vs keras classifier vs neural network search,[],r/datascience,False,6,projects,0,,,False,t3_17fthoj,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},ML,False,3,,False,False,self,False,,[],{},,True,,1698198080.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;i know this technique called keras tuner for tuning the model&amp;#39;s hyperparameters . and then i also found that using for loop we can also select number of layers . and then i heard of this keras classifier that is used to search optimum number of layers and one more technique i head of is NAS Neural Network Search .   &lt;/p&gt;

&lt;p&gt;keras tuner vs ( keras classifier ) keras.wrappers.scikit-learn.kerasClassifier vs neural network search (NAS)&lt;/p&gt;

&lt;p&gt;can someone please help me with the difference among these three and what cases each can be considered ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17fthoj,True,,MaAleem,,2,True,all_ads,False,[],False,,/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,1209067,1698198080.0,0,,False,,,,,,,,,,537,92
,datascience," I have an older coworker and a manager both from the same culture who doesn't have much experience in data science. They've been focused on dashboarding but have been given the title of 'data scientist.' They often mention 'analysis paralysis' when discussions about strategy arise. When I speak about ML feasibility analysis, or when I insist on spending time studying the data to understand the problem, or when I emphasize asking what the stakeholder actually wants instead of just creating something and trying to sell it to them, there's resistance. They typically aren't the ones doing the hands-on work. They seem to prefer just doing things. Even when there's a data quality issue, they just plow through. Has that been your experience? People who say ""analysis paralysis"" often don't actually do things; they just sit on the side or take credit when things work out.",t2_5fbmh3va,False,,0,False,"Tired of armchair coworker and armchair manager saying ""Analysis paralysis""",[],r/datascience,False,6,,0,,,False,t3_17fsjf2,False,dark,0.93,,public,180,0,{},,,False,[],,False,False,,{},Challenges,False,180,,False,False,self,False,,[],{},,True,,1698195276.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an older coworker and a manager both from the same culture who doesn&amp;#39;t have much experience in data science. They&amp;#39;ve been focused on dashboarding but have been given the title of &amp;#39;data scientist.&amp;#39; They often mention &amp;#39;analysis paralysis&amp;#39; when discussions about strategy arise. When I speak about ML feasibility analysis, or when I insist on spending time studying the data to understand the problem, or when I emphasize asking what the stakeholder actually wants instead of just creating something and trying to sell it to them, there&amp;#39;s resistance. They typically aren&amp;#39;t the ones doing the hands-on work. They seem to prefer just doing things. Even when there&amp;#39;s a data quality issue, they just plow through. Has that been your experience? People who say &amp;quot;analysis paralysis&amp;quot; often don&amp;#39;t actually do things; they just sit on the side or take credit when things work out.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,17fsjf2,True,,Excellent_Cost170,,104,True,all_ads,False,[],False,,/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,1209067,1698195276.0,0,,False,,,,,,,,,,876,145
,datascience,"Please don't take this post seriously, but I can't help but think that those guys who work at OpenAI, Midjourney,  Google, whatever, despite being Data Scientists just like me (for 6 years, not someone trying to break in), are delivering stuff that I would never be able to, even though we have the same titles on LinkedIn? 

I mean, I'm totally okay with with calling myself a mediocre data Scientist as it is pretty much a choice that I made by enjoying my free time instead of studying my ass off and going for a PhD, but still. Saying that OpenAI staff and myself both are data Scientist feels like saying Messi and some player from a local amateur team are both soccer players.",t2_yqjml,False,,0,False,Do you ever feel dumb when you see data scientists doing exceptional stuff when you are just there doing mundane data-stuff?,[],r/datascience,False,6,discussion,0,,,False,t3_17fjgzu,False,dark,0.96,,public,273,0,{},,,False,[],,False,False,,{},Discussion,False,273,,False,False,self,False,,[],{},,True,,1698171644.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Please don&amp;#39;t take this post seriously, but I can&amp;#39;t help but think that those guys who work at OpenAI, Midjourney,  Google, whatever, despite being Data Scientists just like me (for 6 years, not someone trying to break in), are delivering stuff that I would never be able to, even though we have the same titles on LinkedIn? &lt;/p&gt;

&lt;p&gt;I mean, I&amp;#39;m totally okay with with calling myself a mediocre data Scientist as it is pretty much a choice that I made by enjoying my free time instead of studying my ass off and going for a PhD, but still. Saying that OpenAI staff and myself both are data Scientist feels like saying Messi and some player from a local amateur team are both soccer players.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17fjgzu,True,,CadeOCarimbo,,71,False,all_ads,False,[],False,,/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,1209067,1698171644.0,0,,False,,,,,,,,,,682,124
,datascience,"Hi everyone,

I'm currently working on an LDA Topic Modeling project applied to a specific field. Essentially, I want to label different subcategories within this field. The data I'm dealing with is relatively complex and messy.

While I'm aware of the ongoing challenge of automatic topic modeling, which still requires human judgment and supervision after topics have been generated, I've read that certain metrics attempt to replace human judgment when it comes to evaluating the coherence of words within a topic (like C\_V metric). Thus, they need to be maximized (I suppose?).

However, I've also read that the most crucial consideration, in the end, is to create topics that are understandable to humans.

I find myself in a situation where I have a larger number of topics, let's say 7 &lt; k &lt; 10, where the Coherence metric (C\_V) peaks at 0.48, which, based on what I've read, seems like a good score. However, what happens is that, for the most, the topics themselves do not make sense at all. 

In contrast, when I set my number of topics to 3-4, I have much more interpretable topics. This might be because of the implication of summarization, which means fewer topics that gather more latent topics within the same topic.

Considering that this project is being revised by a professor, how can I justify what is going on? I know that there's specific literature out there stating that Coherence is not an entirely reliable judgement parameter, but haven't managed to find anything consistent. 

Thank you.",t2_c0ghewdh,False,,0,False,"In the context of topic modeling, what should be done when the highest coherence value, given a specific 'k' value and a particular metric, does not result in interpretable topics?",[],r/datascience,False,6,meta,0,,,False,t3_17fjeyw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1698171508.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently working on an LDA Topic Modeling project applied to a specific field. Essentially, I want to label different subcategories within this field. The data I&amp;#39;m dealing with is relatively complex and messy.&lt;/p&gt;

&lt;p&gt;While I&amp;#39;m aware of the ongoing challenge of automatic topic modeling, which still requires human judgment and supervision after topics have been generated, I&amp;#39;ve read that certain metrics attempt to replace human judgment when it comes to evaluating the coherence of words within a topic (like C_V metric). Thus, they need to be maximized (I suppose?).&lt;/p&gt;

&lt;p&gt;However, I&amp;#39;ve also read that the most crucial consideration, in the end, is to create topics that are understandable to humans.&lt;/p&gt;

&lt;p&gt;I find myself in a situation where I have a larger number of topics, let&amp;#39;s say 7 &amp;lt; k &amp;lt; 10, where the Coherence metric (C_V) peaks at 0.48, which, based on what I&amp;#39;ve read, seems like a good score. However, what happens is that, for the most, the topics themselves do not make sense at all. &lt;/p&gt;

&lt;p&gt;In contrast, when I set my number of topics to 3-4, I have much more interpretable topics. This might be because of the implication of summarization, which means fewer topics that gather more latent topics within the same topic.&lt;/p&gt;

&lt;p&gt;Considering that this project is being revised by a professor, how can I justify what is going on? I know that there&amp;#39;s specific literature out there stating that Coherence is not an entirely reliable judgement parameter, but haven&amp;#39;t managed to find anything consistent. &lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17fjeyw,True,,hasty-beaver,,2,True,all_ads,False,[],False,,/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,1209067,1698171508.0,0,,False,,,,,,,,,,1523,254
,datascience,Does anyone have experience consulting for small businesses like coffee shops or even smaller stores? There's a store near me that I would love to offer my services to for free -- but not sure how I can present myself as being useful to them and wanting them to actually work with me.,t2_wrq0o,False,,0,False,Consulting for coffee shops,[],r/datascience,False,6,fun,0,,,False,t3_17ffp2f,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},Career Discussion,False,4,,False,False,self,False,,[],{},,True,,1698161842.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have experience consulting for small businesses like coffee shops or even smaller stores? There&amp;#39;s a store near me that I would love to offer my services to for free -- but not sure how I can present myself as being useful to them and wanting them to actually work with me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17ffp2f,True,,cooljackiex,,10,True,all_ads,False,[],False,,/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,1209067,1698161842.0,0,,False,,,,,,,,,,284,53
,datascience,"Hi Folks,

Looking for some advice, have an ecommerce store, decent volume of data in 10m orders over the past few years etc. \~ 10GB of data.

Was looking to get the data into data studio (looker), crashed. Then looked at power bi, crashed on publishing just the order data (\~1GB)

Are there alternatives? What would the best sync to a reporting tool be?",t2_i8ztjwd5,False,,0,False,"Mysql to ""Big Data""",[],r/datascience,False,6,,0,,,False,t3_17fdltj,False,dark,0.64,,public,4,0,{},,,False,[],,False,False,,{},Coding,False,4,,False,False,self,False,,[],{},,True,,1698156235.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Folks,&lt;/p&gt;

&lt;p&gt;Looking for some advice, have an ecommerce store, decent volume of data in 10m orders over the past few years etc. ~ 10GB of data.&lt;/p&gt;

&lt;p&gt;Was looking to get the data into data studio (looker), crashed. Then looked at power bi, crashed on publishing just the order data (~1GB)&lt;/p&gt;

&lt;p&gt;Are there alternatives? What would the best sync to a reporting tool be?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,17fdltj,True,,RandomBarry,,21,True,all_ads,False,[],False,,/r/datascience/comments/17fdltj/mysql_to_big_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fdltj/mysql_to_big_data/,1209067,1698156235.0,0,,False,,,,,,,,,,356,64
,datascience,"Hey folks

over at [https://pypi.org/project/dlt/](https://pypi.org/project/dlt/) we added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -&gt; analytics copying can go up to 30x faster over a classic sqlite connector.

Read about the benchmark comparison and the underlying technology here: [https://dlthub.com/docs/blog/dlt-arrow-loading](https://dlthub.com/docs/blog/dlt-arrow-loading)

One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine or batch on extraction. Code example how to use: [https://dlthub.com/docs/examples/connector\_x\_arrow/](https://dlthub.com/docs/examples/connector_x_arrow/)

By adding this support, we also enable these sources:[https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas](https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas)

If you need help, don't miss the gpt helper link at the bottom of our docs or the slack link at the top.

Feedback is very welcome!

&amp;#x200B;",t2_uamr9xer,False,,0,False,ConnectorX + Arrow + dlt loading: Up to 30x speed gains in test,[],r/datascience,False,6,tooling,0,,,False,t3_17fbj3u,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698150271.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks&lt;/p&gt;

&lt;p&gt;over at &lt;a href=""https://pypi.org/project/dlt/""&gt;https://pypi.org/project/dlt/&lt;/a&gt; we added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -&amp;gt; analytics copying can go up to 30x faster over a classic sqlite connector.&lt;/p&gt;

&lt;p&gt;Read about the benchmark comparison and the underlying technology here: &lt;a href=""https://dlthub.com/docs/blog/dlt-arrow-loading""&gt;https://dlthub.com/docs/blog/dlt-arrow-loading&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine or batch on extraction. Code example how to use: &lt;a href=""https://dlthub.com/docs/examples/connector_x_arrow/""&gt;https://dlthub.com/docs/examples/connector_x_arrow/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By adding this support, we also enable these sources:&lt;a href=""https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas""&gt;https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you need help, don&amp;#39;t miss the gpt helper link at the bottom of our docs or the slack link at the top.&lt;/p&gt;

&lt;p&gt;Feedback is very welcome!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17fbj3u,True,,Thinker_Assignment,,0,True,all_ads,False,[],False,,/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,all_ads,False,https://www.reddit.com/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,1209067,1698150271.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?auto=webp&amp;s=85f19a22cbd85fa784cdb417359d8ff7cda9e394', 'width': 300, 'height': 300}, 'resolutions': [{'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46fa55dd1b1e587ab93bcbbdc6cb2de37b810bf3', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfd7f76ac4c13cdc287edd9856ef0430dbc862a5', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM'}], 'enabled': False}",,,,,,,1126,128
,datascience,"&amp;#x200B;

I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data specifically here I am applying machine learning to drive asset allocation in an investmen portfolio

[https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model](https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model)

&amp;#x200B;",t2_lifp3d8p7,False,,0,False,Machine learning for Asset Allocation and long/short decisions in a Tactical Asset Allocation Strategy,[],r/datascience,False,6,projects,0,,,False,t3_17f7jo6,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},ML,False,1,,False,False,self,False,,[],{},,True,,1698134349.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;d love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I&amp;#39;d love to hear any thoughts on Machine Learning directly applicable to time-series data specifically here I am applying machine learning to drive asset allocation in an investmen portfolio&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model""&gt;https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17f7jo6,True,,QFA_official,,0,True,all_ads,False,[],False,,/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,1209067,1698134349.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?auto=webp&amp;s=8d957213a8434bb310a42619dbc654fb6655388c', 'width': 1000, 'height': 423}, 'resolutions': [{'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65b5893dd7697c82ed3affa1368c859e63ad8a1f', 'width': 108, 'height': 45}, {'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d64f1a8d5e8b5feae507771450e0300f3f49707', 'width': 216, 'height': 91}, {'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c3a77294791d77e10b26b489026fde2db8b4c99', 'width': 320, 'height': 135}, {'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=50edda9bd79ae168a9cb91c2649f240ba4a80866', 'width': 640, 'height': 270}, {'url': 'https://external-preview.redd.it/IJUQA4kFkgQN-79ajr8v6HqamVcq6a0pWNlKcQWM1Ls.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd7682d02831e1dcaf22987f59e4cba0e65abd74', 'width': 960, 'height': 406}], 'variants': {}, 'id': '8tkJd0TbvS7fZQr46HrK6USEnExSh7fEqm50YtiETMo'}], 'enabled': False}",,,,,,,662,58
,datascience,Anyone having experience in this sector? Looking for a seasoned data scientist in this sector,t2_h85pxeiwh,False,,0,False,Data science in floriculture/horticulture,[],r/datascience,False,6,projects,0,,,False,t3_17f6c47,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},ML,False,1,,False,False,self,False,,[],{},,True,,1698129106.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone having experience in this sector? Looking for a seasoned data scientist in this sector&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17f6c47,True,,Efficient-Middle-701,,1,True,all_ads,False,[],False,,/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,all_ads,False,https://www.reddit.com/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,1209067,1698129106.0,0,,False,,,,,,,,,,93,15
,datascience,"Hi Everyone,

Recently, I have been doing a task related to paraphrasing in writing tones. Specifically, I'm trying to fine-tune the pre-trained model (text generation model) to create a model capable of rewriting according to the transmitted tone.

Currently, I am trying to crawl data (about 1500 samples) for training. However, the results were not as good as I thought. I'm currently quite stuck, can you guys suggest to me some research or open-source or pre-trained models that you've tried?

Thank you

P/s: model I have tried

[https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic](https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic)

[https://huggingface.co/Vamsi/T5\_Paraphrase\_Paws](https://huggingface.co/Vamsi/T5_Paraphrase_Paws)

[https://huggingface.co/humarin/chatgpt\_paraphraser\_on\_T5\_base](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base)",t2_6cetklvl,False,,0,False,[Discussion] Paraphrase for Writing Tone,[],r/datascience,False,6,,0,,,False,t3_17f3whi,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},AI,False,0,,False,False,self,False,,[],{},,True,,1698119886.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;

&lt;p&gt;Recently, I have been doing a task related to paraphrasing in writing tones. Specifically, I&amp;#39;m trying to fine-tune the pre-trained model (text generation model) to create a model capable of rewriting according to the transmitted tone.&lt;/p&gt;

&lt;p&gt;Currently, I am trying to crawl data (about 1500 samples) for training. However, the results were not as good as I thought. I&amp;#39;m currently quite stuck, can you guys suggest to me some research or open-source or pre-trained models that you&amp;#39;ve tried?&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;

&lt;p&gt;P/s: model I have tried&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic""&gt;https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://huggingface.co/Vamsi/T5_Paraphrase_Paws""&gt;https://huggingface.co/Vamsi/T5_Paraphrase_Paws&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base""&gt;https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,2f731e52-70eb-11ee-bec5-5a5142e6a4d2,False,False,False,,[],False,,,,t5_2sptq,False,,,#46d160,17f3whi,True,,unknow_from_vietnam,,0,True,all_ads,False,[],False,,/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,all_ads,False,https://www.reddit.com/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,1209067,1698119886.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?auto=webp&amp;s=d0be1127ce5f79f82e948ab8cf96e7210cb6be1a', 'width': 1200, 'height': 648}, 'resolutions': [{'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=426608452fb9896e13faf3927088eff2f627b403', 'width': 108, 'height': 58}, {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b087c0785d84c60389bb1655f2ae98cb6f248ffd', 'width': 216, 'height': 116}, {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=302eaab41bd4a8b53bfa9061b3ac9140b505d2da', 'width': 320, 'height': 172}, {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f1dc3a4e793990bd41aa7d500a77bda02a577a8', 'width': 640, 'height': 345}, {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d9232b9dbd57fad170f7fe8ef7a8a9dd15ac2bd6', 'width': 960, 'height': 518}, {'url': 'https://external-preview.redd.it/Ki-ySKqPYoVB810RDNEcpSDJ5eaLWtKb9nFryfAioJE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46b0b248ceceee525161b9c7014ca6179262b962', 'width': 1080, 'height': 583}], 'variants': {}, 'id': '8Fr77lFd7Gnv94R4vPukgxG6yPtiiDq5OFz_y3a-gpQ'}], 'enabled': False}",,,,,,,933,90
,datascience,"Would be nice to understand frameworks , experiment types, how to determine what experiment to use , and where and when to apply them to a saas company and help them prioritize a roadmap against it. 
",t2_xo4dr,False,,0,False,Anyone have a good blog or resource on Product-led experimentation?,[],r/datascience,False,6,network,0,,,False,t3_17f02jx,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Analysis,False,1,,False,False,self,1698109573.0,,[],{},,True,,1698108373.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Would be nice to understand frameworks , experiment types, how to determine what experiment to use , and where and when to apply them to a saas company and help them prioritize a roadmap against it. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17f02jx,True,,citizenofacceptance,,8,True,all_ads,False,[],False,,/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,all_ads,False,https://www.reddit.com/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,1209067,1698108373.0,0,,False,,,,,,,,,,200,36
,datascience,"I've got the task to estimate the sales level of a store in a place near a mall and a office area. Would like to know if somebody here has made a similar task reacently or has any idea of how can i get an estimation.

I have data of 6 more stores of the same company (sales, transactions, area fo the store, #people near a 15 minute isochrone, if the stores are near offices, colleges, residential areas, etc).

I've been planning to run a regression model or a decision tree and later use trained model to estimate the sales level of the new position, but just having 6 stores makes it hard to have a consistent estimation.

What other options could i do to have a good estimation of this new position? what other things i have to consider o look for to have as data in my model? is there any framework for this kind of task?

Thanks!",t2_6ihag2sc,False,,0,False,Estimating sales of a new store,[],r/datascience,False,6,,0,,,False,t3_17ew2w4,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Challenges,False,2,,False,False,self,False,,[],{},,True,,1698097522.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve got the task to estimate the sales level of a store in a place near a mall and a office area. Would like to know if somebody here has made a similar task reacently or has any idea of how can i get an estimation.&lt;/p&gt;

&lt;p&gt;I have data of 6 more stores of the same company (sales, transactions, area fo the store, #people near a 15 minute isochrone, if the stores are near offices, colleges, residential areas, etc).&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been planning to run a regression model or a decision tree and later use trained model to estimate the sales level of the new position, but just having 6 stores makes it hard to have a consistent estimation.&lt;/p&gt;

&lt;p&gt;What other options could i do to have a good estimation of this new position? what other things i have to consider o look for to have as data in my model? is there any framework for this kind of task?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,417296a0-70eb-11ee-8c58-122e95e91c4c,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffd635,17ew2w4,True,,bbmr__95,,4,True,all_ads,False,[],False,,/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,1209065,1698097522.0,0,,False,,,,,,,,,,835,160
,datascience,"Hello there,

I'm an undergrad student that is currently working on a Kaggle dataset and I want to document my progression and be able to share it as I go. In addition, I'd really want to get involved with the DS community. Now, I do have deficiency in certain tools like GitHub which is a place I could post my work. However, I do also want to be able to include it in my resume as I think it would make it more appealing for recruiters in the future. What is the best way to go about this? Just create a reddit or LinkedIn Post (like a progress post) or simply just have it up on GitHub and learn how to use the tool ? Thank you in advance for your suggestions.",t2_8dsh3icl,False,,0,False,Best way to go about showing progress as work is done to a dataset,[],r/datascience,False,6,,0,,,False,t3_17euytw,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Education,False,2,,False,False,self,False,,[],{},,True,,1698094791.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m an undergrad student that is currently working on a Kaggle dataset and I want to document my progression and be able to share it as I go. In addition, I&amp;#39;d really want to get involved with the DS community. Now, I do have deficiency in certain tools like GitHub which is a place I could post my work. However, I do also want to be able to include it in my resume as I think it would make it more appealing for recruiters in the future. What is the best way to go about this? Just create a reddit or LinkedIn Post (like a progress post) or simply just have it up on GitHub and learn how to use the tool ? Thank you in advance for your suggestions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17euytw,True,,Notgen3ric,,7,True,all_ads,False,[],False,,/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,all_ads,False,https://www.reddit.com/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,1209065,1698094791.0,0,,False,,,,,,,,,,663,132
,datascience,"I am currently undergoing Apprenticeships programme for ML, and looking for projects in our organization.

""Demand Transference and Substititabilty"" in retail food stores is one of the ideas that came up. So i am trying to find on how to implement it and if we have all the required data before finalising the project selection. 

Any resources or information would be great :)",t2_4pgpyc7y,False,,0,False,Any pointers / resources on how one would implement a ML model for product demand transference and substititabilty,[],r/datascience,False,6,projects,0,,,False,t3_17eug5a,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},ML,False,2,,False,False,self,False,,[],{},,True,,1698093478.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently undergoing Apprenticeships programme for ML, and looking for projects in our organization.&lt;/p&gt;

&lt;p&gt;&amp;quot;Demand Transference and Substititabilty&amp;quot; in retail food stores is one of the ideas that came up. So i am trying to find on how to implement it and if we have all the required data before finalising the project selection. &lt;/p&gt;

&lt;p&gt;Any resources or information would be great :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17eug5a,True,,FrozenSoul90,,2,True,all_ads,False,[],False,,/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,1209065,1698093478.0,0,,False,,,,,,,,,,377,63
,datascience,"Ok so, I was hired as a senior member of a pre-existing data science team. I now manage a few other team members (who were there before me). They are all contractors and their day rate is HIGH. They are all 'Data Scientists' and graduates.

I'm older. I've done lots of technical roles and I'm not really sure what my official title is. I can do data science but I really just build stuff. I've done Data Engineering in the past, MLOps, DevOps, Cloud etc. I'm a jack of all trades, master of none.

Now, I know what ***I think*** a 'Data Scientist' should be able to do:

1. Pandas, Numpy, Scikit learn, matplotlib blah blah blah
2. Version control (Git)
3. Managing virtual environments
4. Debugging within an IDE
5. Scoping out a project, ideation, exploration
6. Report writing skills/communication skills
7. Some exposure to clean code conventions (PEP-8)
8. Some exposure to SQL like syntax
9. bit of linux would be cool (I can teach them)
10. bit of cloud would be cool (I can teach them)

I've had to mentor the team HARD. Most of the team did not know what Git was, most of the team had never debugged their code, never made a venv. In fact I have had to teach them steps 1-5. That would be fine if they were now hitting the ground running, but the moment I stop mentoring them, the productivity stops. No initiative.

And yet, I want to hire externally. I want to give them the opportunity to apply but I just know they won't measure up against the talent pool out there. I've hired Data Scientists before and I know how good people are out there.

Am I totally wrong? Do I need to cut them some slack? Anyone got any comments?

edit: spelling",t2_315ygt,False,,0,False,Contractors who are called Data Scientists but can't do what I'd expect. What to do next.,[],r/datascience,False,6,fun,0,,,False,t3_17eu3rm,False,dark,0.94,,public,208,0,{},,,False,[],,False,False,,{},Career Discussion,False,208,,False,False,self,1698095922.0,,[],{},,True,,1698092618.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ok so, I was hired as a senior member of a pre-existing data science team. I now manage a few other team members (who were there before me). They are all contractors and their day rate is HIGH. They are all &amp;#39;Data Scientists&amp;#39; and graduates.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m older. I&amp;#39;ve done lots of technical roles and I&amp;#39;m not really sure what my official title is. I can do data science but I really just build stuff. I&amp;#39;ve done Data Engineering in the past, MLOps, DevOps, Cloud etc. I&amp;#39;m a jack of all trades, master of none.&lt;/p&gt;

&lt;p&gt;Now, I know what &lt;strong&gt;&lt;em&gt;I think&lt;/em&gt;&lt;/strong&gt; a &amp;#39;Data Scientist&amp;#39; should be able to do:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pandas, Numpy, Scikit learn, matplotlib blah blah blah&lt;/li&gt;
&lt;li&gt;Version control (Git)&lt;/li&gt;
&lt;li&gt;Managing virtual environments&lt;/li&gt;
&lt;li&gt;Debugging within an IDE&lt;/li&gt;
&lt;li&gt;Scoping out a project, ideation, exploration&lt;/li&gt;
&lt;li&gt;Report writing skills/communication skills&lt;/li&gt;
&lt;li&gt;Some exposure to clean code conventions (PEP-8)&lt;/li&gt;
&lt;li&gt;Some exposure to SQL like syntax&lt;/li&gt;
&lt;li&gt;bit of linux would be cool (I can teach them)&lt;/li&gt;
&lt;li&gt;bit of cloud would be cool (I can teach them)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;#39;ve had to mentor the team HARD. Most of the team did not know what Git was, most of the team had never debugged their code, never made a venv. In fact I have had to teach them steps 1-5. That would be fine if they were now hitting the ground running, but the moment I stop mentoring them, the productivity stops. No initiative.&lt;/p&gt;

&lt;p&gt;And yet, I want to hire externally. I want to give them the opportunity to apply but I just know they won&amp;#39;t measure up against the talent pool out there. I&amp;#39;ve hired Data Scientists before and I know how good people are out there.&lt;/p&gt;

&lt;p&gt;Am I totally wrong? Do I need to cut them some slack? Anyone got any comments?&lt;/p&gt;

&lt;p&gt;edit: spelling&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17eu3rm,True,,wagwagtail,,197,True,all_ads,False,[],False,,/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,1209065,1698092618.0,0,,False,,,,,,,,,,1652,305
,datascience,"There's been a lot of chatter about AI, specifically things like LLAMA 2, GPT-4, etc. But, what have been some recent advancements not in the AI sphere that are important in Data Science?",t2_53gvtiyo,False,,0,False,"Outside of Generative AI, what are the big advances currently happening in Data Science?",[],r/datascience,False,6,discussion,0,,,False,t3_17esy03,False,dark,0.9,,public,48,0,{},,,False,[],,False,False,,{},Discussion,False,48,,False,False,self,False,,[],{},,True,,1698089666.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There&amp;#39;s been a lot of chatter about AI, specifically things like LLAMA 2, GPT-4, etc. But, what have been some recent advancements not in the AI sphere that are important in Data Science?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17esy03,True,,htii_,,34,True,all_ads,False,[],False,,/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,all_ads,False,https://www.reddit.com/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,1209065,1698089666.0,0,,False,,,,,,,,,,187,33
,datascience,"Separating things like meetings and actually sitting down and writing code/working through problems, what's your workload like?

I work for an academic department and I can't tell if things are...off lol. It's my first real job btw. ",t2_mdynsqo1s,False,,0,False,How many hours do other data analysts work?,[],r/datascience,False,6,fun,0,,,False,t3_17erxid,False,dark,0.42,,public,0,0,{},,,False,[],,False,False,,{},Career Discussion,False,0,,False,False,self,False,,[],{},,True,,1698087154.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Separating things like meetings and actually sitting down and writing code/working through problems, what&amp;#39;s your workload like?&lt;/p&gt;

&lt;p&gt;I work for an academic department and I can&amp;#39;t tell if things are...off lol. It&amp;#39;s my first real job btw. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17erxid,True,,DellSucksTbh,,8,True,all_ads,False,[],False,,/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,all_ads,False,https://www.reddit.com/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,1209065,1698087154.0,0,,False,,,,,,,,,,233,37
,datascience,"I have talked this previously, that like, I am working as a data analyst but is it worth to learn graph database. I got some comments that saying master SQL first, then learn other tools. For me, learning a new fun tool is for my free time so I thought, OK, I will just try it. It is been a month almost and came back to think like,,, I don't feel the graph database is that much worth to learn especially if I consider the size of the market.

However, maybe, if there's a PG extension that adds graph analytics to PG database, which I use everyday, it would be fun because I can actually utilize it with my PG data. Apache AGE is an open-source PG extension that really solves the problem that I'm having right now. I will leave the [github link](https://github.com/apache/age) and a [webinar link](https://us06web.zoom.us/webinar/register/2516980853755/WN_mzhlCggCQ_ytIxiGb9ioTg) that they (I guess Apache Foundation?) organize like bi-weekly. For those who are having same thought process with me, I think you guys also can just try? What do you think?",t2_59z60tud,False,,0,False,PG extension (Apache AGE) for adding graph analytics functionality,[],r/datascience,False,6,tooling,0,,,False,t3_17eriso,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Tools,False,1,,False,False,self,False,,[],{},,True,,1698086112.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have talked this previously, that like, I am working as a data analyst but is it worth to learn graph database. I got some comments that saying master SQL first, then learn other tools. For me, learning a new fun tool is for my free time so I thought, OK, I will just try it. It is been a month almost and came back to think like,,, I don&amp;#39;t feel the graph database is that much worth to learn especially if I consider the size of the market.&lt;/p&gt;

&lt;p&gt;However, maybe, if there&amp;#39;s a PG extension that adds graph analytics to PG database, which I use everyday, it would be fun because I can actually utilize it with my PG data. Apache AGE is an open-source PG extension that really solves the problem that I&amp;#39;m having right now. I will leave the &lt;a href=""https://github.com/apache/age""&gt;github link&lt;/a&gt; and a &lt;a href=""https://us06web.zoom.us/webinar/register/2516980853755/WN_mzhlCggCQ_ytIxiGb9ioTg""&gt;webinar link&lt;/a&gt; that they (I guess Apache Foundation?) organize like bi-weekly. For those who are having same thought process with me, I think you guys also can just try? What do you think?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17eriso,True,,oh5oh5,,0,True,all_ads,False,[],False,,/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,1209065,1698086112.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?auto=webp&amp;s=a4a9678ee6d4fee3ad114c4e3f4c60bd3a9878b9', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c61ccf87e96ae7f1e62a23e0d3e0edaf1e9231ad', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c3d8c63135c41a9e9b540db64704378fc6d327a', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc77ff3491686199af775da523847897c7960e45', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ced5be128d162387dc23847553096ba7a82d98e4', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=280b511ee72232f7f9af49618992ae1faf180cb0', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/3qLWaHB72-aNQu6FqcxITz9lByzkf8IppAI_7rEEX-4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=796899fab0653df124ea60ce9b1a3e08173916ad', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'SJvZ9bFaaSdT-WOtIPVpyQVNRTxT1PIoiuA3-IrbPYc'}], 'enabled': False}",,,,,,,1056,179
,datascience,I’m looking to discover new relationships that exist in the relational database and then generate ingestion script to populate a graph database. Are there tools already exhausting for this and what are their limitations? Can we he new LLMs come to rescue?,t2_ayqufd5k,False,,0,False,Relational database to graph database using NLP/LLM?,[],r/datascience,False,6,meta,0,,,False,t3_17erhca,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1698086005.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m looking to discover new relationships that exist in the relational database and then generate ingestion script to populate a graph database. Are there tools already exhausting for this and what are their limitations? Can we he new LLMs come to rescue?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17erhca,True,,Dependent_Mushroom98,,0,True,all_ads,False,[],False,,/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,all_ads,False,https://www.reddit.com/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,1209065,1698086005.0,0,,False,,,,,,,,,,255,42
,datascience,"In my present company we are just chasing ad hoc analytical  work - these never gets into production. The processes are very ad hoc, not streamlined, no structure to it, running from personal notebooks. It’s very demoralizing to see models developed from 2017 that are in production and have not been refreshed thought the data it used for inference is constantly changing as my company looks at market finance data. 

I’m wondering what are other good companies to look out for that are either applying best practices in DS/ML and not just the talk or building product/services. 

I understand recent news in GenAI is sparking lot of conversations but which companies out there are grabbing it by the horns and taking the lead? Perhaps if you are fortunate to work for one such company you may want to share your story. Appreciate your insights very much!",t2_ayqufd5k,False,,0,False,"Besides FAANG, what other companies out there are doing actual DS or MLE work?",[],r/datascience,False,6,fun,0,,,False,t3_17er8bt,False,dark,0.73,,public,17,0,{},,,False,[],,False,False,,{},Career Discussion,False,17,,False,False,self,False,,[],{},,True,,1698085365.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my present company we are just chasing ad hoc analytical  work - these never gets into production. The processes are very ad hoc, not streamlined, no structure to it, running from personal notebooks. It’s very demoralizing to see models developed from 2017 that are in production and have not been refreshed thought the data it used for inference is constantly changing as my company looks at market finance data. &lt;/p&gt;

&lt;p&gt;I’m wondering what are other good companies to look out for that are either applying best practices in DS/ML and not just the talk or building product/services. &lt;/p&gt;

&lt;p&gt;I understand recent news in GenAI is sparking lot of conversations but which companies out there are grabbing it by the horns and taking the lead? Perhaps if you are fortunate to work for one such company you may want to share your story. Appreciate your insights very much!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17er8bt,True,,Dependent_Mushroom98,,17,True,all_ads,False,[],False,,/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,all_ads,False,https://www.reddit.com/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,1209065,1698085365.0,0,,False,,,,,,,,,,856,146
,datascience,"Currently on a job search, and of course many DS roles are seeking prediction/forecasting skills. Can anyone recommend an overview of different predictive techniques? It could be an article, video, book, or even your own explanation.

There are so many things one could learn about regression, machine learning, etc. and I would find it useful to have some sort of organizing framework for various methods of prediction.

Thanks!",t2_9111ukf4,False,,0,False,Good survey of predictive techniques?,[],r/datascience,False,6,,0,,,False,t3_17epzut,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Education,False,0,,False,False,self,1698088665.0,,[],{},,True,,1698082160.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently on a job search, and of course many DS roles are seeking prediction/forecasting skills. Can anyone recommend an overview of different predictive techniques? It could be an article, video, book, or even your own explanation.&lt;/p&gt;

&lt;p&gt;There are so many things one could learn about regression, machine learning, etc. and I would find it useful to have some sort of organizing framework for various methods of prediction.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17epzut,True,,ConsiderationRoyal87,,5,True,all_ads,False,[],False,,/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,all_ads,False,https://www.reddit.com/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,1209065,1698082160.0,0,,False,,,,,,,,,,429,68
,datascience,"My work primarily stores data in a full databases. Pandas has a lot of similar functionality to SQL in regards to the ability to group data and preform calculations, even being able to take full on SQL queries to import data. Do you guys do all your calculations in the query itself, or in python after the data has been imported? What about with grouping data?",t2_2o12zv3,False,,0,False,What do you do in SQL vs Pandas?,[],r/datascience,False,6,tooling,0,,,False,t3_17eot80,False,dark,0.93,,public,63,0,{},,,False,[],,False,False,,{},Tools,False,63,,False,False,self,False,,[],{},,True,,1698079172.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My work primarily stores data in a full databases. Pandas has a lot of similar functionality to SQL in regards to the ability to group data and preform calculations, even being able to take full on SQL queries to import data. Do you guys do all your calculations in the query itself, or in python after the data has been imported? What about with grouping data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17eot80,True,,Alucard2051,,64,True,all_ads,False,[],False,,/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,1209065,1698079172.0,0,,False,,,,,,,,,,361,66
,datascience,"Hi i am working on this a project and its a module of a huge project where i have to write code  to parse address provided.

I was first using Libpostal but for the provided data, libpostal is not effiecient and i want to create my custom parsing.

I am trying to use regex but it seems very complicated. Can anyone help me if there’s any other way .

I found it is possible using NLP with spaCy.

Please guide",t2_jprjjprw,False,,0,False,Address parsing with NLP or with regex,[],r/datascience,False,6,projects,0,,,False,t3_17enm4q,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},ML,False,0,,False,False,self,1698095309.0,,[],{},,True,,1698076188.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi i am working on this a project and its a module of a huge project where i have to write code  to parse address provided.&lt;/p&gt;

&lt;p&gt;I was first using Libpostal but for the provided data, libpostal is not effiecient and i want to create my custom parsing.&lt;/p&gt;

&lt;p&gt;I am trying to use regex but it seems very complicated. Can anyone help me if there’s any other way .&lt;/p&gt;

&lt;p&gt;I found it is possible using NLP with spaCy.&lt;/p&gt;

&lt;p&gt;Please guide&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,#878a8c,17enm4q,True,,Pristine-Sound-484,,14,True,all_ads,False,[],False,,/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,all_ads,False,https://www.reddit.com/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,1209065,1698076188.0,0,,False,,,,,,,,,,410,80
,datascience,"Hello,

I'm updating my Portfolio to get back to DS. Working on a project I'd like to put the algorithm into an interface. Is it better to try and do it using other programming languages like JavaScript or Python is sufficient using Flask or Streamlit ? ",t2_fd92duw8,False,,0,False,Project Interface.,[],r/datascience,False,6,meta,0,,,False,t3_17en64n,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1698075041.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m updating my Portfolio to get back to DS. Working on a project I&amp;#39;d like to put the algorithm into an interface. Is it better to try and do it using other programming languages like JavaScript or Python is sufficient using Flask or Streamlit ? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17en64n,True,,Individual-School-07,,2,True,all_ads,False,[],False,,/r/datascience/comments/17en64n/project_interface/,all_ads,False,https://www.reddit.com/r/datascience/comments/17en64n/project_interface/,1209065,1698075041.0,0,,False,,,,,,,,,,254,46
,datascience,I am a software engineer with 10yo experience. Can someone recommend a good Data Science program? I am willing to spend 3-6 months to get a deep understanding of the fundamentals.,t2_42tqv1mr,False,,0,False,Looking for a Data Science Program,[],r/datascience,False,6,,0,,,False,t3_17em9tn,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Education,False,0,,False,False,self,False,,[],{},,True,,1698072836.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a software engineer with 10yo experience. Can someone recommend a good Data Science program? I am willing to spend 3-6 months to get a deep understanding of the fundamentals.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17em9tn,True,,h3dgyy,,3,True,all_ads,False,[],False,,/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,all_ads,False,https://www.reddit.com/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,1209065,1698072836.0,0,,False,,,,,,,,,,179,31
,datascience,"I am a director and I feel like I barely do ""Data Science"" any more. My job is mostly about working with engineers and architects to facilitate data collection and data tools (python, spark) for my team. Is this relevant for career advancement or do I need to refocus more on hard skills and learning new stuff.",t2_kcl3tfwe,False,,0,False,What do fellow Data Science Directors do?,[],r/datascience,False,6,fun,0,,,False,t3_17el93s,False,dark,0.95,,public,83,0,{},,,False,[],,False,False,,{},Career Discussion,False,83,,False,False,self,False,,[],{},,True,,1698070046.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a director and I feel like I barely do &amp;quot;Data Science&amp;quot; any more. My job is mostly about working with engineers and architects to facilitate data collection and data tools (python, spark) for my team. Is this relevant for career advancement or do I need to refocus more on hard skills and learning new stuff.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17el93s,True,,NewEcho2940,,41,True,all_ads,False,[],False,,/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,all_ads,False,https://www.reddit.com/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,1209065,1698070046.0,0,,False,,,,,,,,,,311,57
,datascience,"So I need to explore an odd problem. We have an old dataset of interview sessions (its not our dataset). It works as follows.

The candidate comes in, goes through several rounds of interviews (from 1 - 5) each with its own interviewer. (We know the number of interviewers)

After each round, the candidate rates the interviewer (score from 0 to 5). (We do not have this data)

Finally, an overall score is calculated for the entire interview session based on the ratings for each round. (We know the overall score but we do not know how it was calculated)

So essentially, the dataset is roughly off the form:

session_id, score, [interviewer_id1, interviewer_id2, interviewer_id3 ...] (This list is unordered)

The question is: given a particular interviewer_id, is it possible to determine whether he generally got positive or negative ratings?

For context, I write software and don't know much beyond stats 101 so I would appreciate any and all pointers. I would ordinarily say no to the above question but I have met people who've been able to pull signals out of noise so it behoves me to ask.

Thanks.",t2_rz22aza,False,,0,False,Wondering whether the following problem is workable?,[],r/datascience,False,6,discussion,0,,,False,t3_17eirhz,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698062724.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I need to explore an odd problem. We have an old dataset of interview sessions (its not our dataset). It works as follows.&lt;/p&gt;

&lt;p&gt;The candidate comes in, goes through several rounds of interviews (from 1 - 5) each with its own interviewer. (We know the number of interviewers)&lt;/p&gt;

&lt;p&gt;After each round, the candidate rates the interviewer (score from 0 to 5). (We do not have this data)&lt;/p&gt;

&lt;p&gt;Finally, an overall score is calculated for the entire interview session based on the ratings for each round. (We know the overall score but we do not know how it was calculated)&lt;/p&gt;

&lt;p&gt;So essentially, the dataset is roughly off the form:&lt;/p&gt;

&lt;p&gt;session_id, score, [interviewer_id1, interviewer_id2, interviewer_id3 ...] (This list is unordered)&lt;/p&gt;

&lt;p&gt;The question is: given a particular interviewer_id, is it possible to determine whether he generally got positive or negative ratings?&lt;/p&gt;

&lt;p&gt;For context, I write software and don&amp;#39;t know much beyond stats 101 so I would appreciate any and all pointers. I would ordinarily say no to the above question but I have met people who&amp;#39;ve been able to pull signals out of noise so it behoves me to ask.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17eirhz,True,,grchelp2018,,3,True,all_ads,False,[],False,,/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,1209065,1698062724.0,0,,False,,,,,,,,,,1109,189
,datascience,"Happy monday guys! 

Quick question – what do you do on light days where you don’t have much(or any) work and want to maintain your productivity, especially when working from home? 

I would love to increase my theory/stress on learning new skills! So if you’re one who reads books/blogs would love to know what you guys read or any book recommendations

Cheers guys, have a great week!",t2_7xxtza3n,False,,0,False,Productivity help,[],r/datascience,False,6,discussion,0,,,False,t3_17eh6kb,False,dark,0.57,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1698056978.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Happy monday guys! &lt;/p&gt;

&lt;p&gt;Quick question – what do you do on light days where you don’t have much(or any) work and want to maintain your productivity, especially when working from home? &lt;/p&gt;

&lt;p&gt;I would love to increase my theory/stress on learning new skills! So if you’re one who reads books/blogs would love to know what you guys read or any book recommendations&lt;/p&gt;

&lt;p&gt;Cheers guys, have a great week!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17eh6kb,True,,Asleep-Fun-6508,,6,True,all_ads,False,[],False,,/r/datascience/comments/17eh6kb/productivity_help/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eh6kb/productivity_help/,1209065,1698056978.0,0,,False,,,,,,,,,,386,67
,datascience,"I’m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet…",t2_e4r051p5,False,,0,False,Which features/factors help determine the likelihood of developing tooth decay?,[],r/datascience,False,6,meta,0,,,False,t3_17egh5m,False,dark,0.2,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1698054033.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet…&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17egh5m,True,,Mysterious_Run_5081,,4,True,all_ads,False,[],False,,/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,1209065,1698054033.0,0,,False,,,,,,,,,,230,36
,datascience,"# A real-world case study of performance optimization in Numpy

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).

&amp;#x200B;

[ How to Optimize Multidimensional Numpy Array Operations with Numexpr. Photo Credit: Created by Author, Canva. ](https://preview.redd.it/r24q1n674yvb1.png?width=1387&amp;format=png&amp;auto=webp&amp;s=ab8950800797f55f538fdb1343df6d275bd07152)

This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use [Numexpr expressions](https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions) in multidimensional Numpy arrays to achieve substantial performance improvements.

There aren't many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.

# Introduction

Recently, while reviewing some of my old work, I stumbled upon this piece of code:

    def predict(X, w, b):
        z = np.dot(X, w)
        y_hat = sigmoid(z)
        y_pred = np.zeros((y_hat.shape[0], 1))
    
        for i in range(y_hat.shape[0]):
            if y_hat[i, 0] &lt; 0.5:
                y_pred[i, 0] = 0
            else:
                y_pred[i, 0] = 1
        return y_pred

This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning.

But heavens, who would use a `for loop` to iterate over Numpy ndarray?

You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior.

That's right, the person who wrote this code was me when I was younger.

With a sense of responsibility, I plan to rewrite this code with the Numexpr library today.

Along the way, I will show you how to use Numexpr and Numexpr's `where` expression in multidimensional Numpy arrays to achieve significant performance improvements.

## Code Implementation

If you are not familiar with the basic usage of Numexpr, you can refer to this article:

[https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/)

This article uses a real-world example to demonstrate the specific usage of Numexpr's API and expressions in Numpy and Pandas.

*where(bool, number1, number2): number* *- number1 if the bool condition is true, number2 otherwise.*

The above is the usage of the where expression in Numpy.

When dealing with matrix data, you may used to using Pandas `DataFrame`. But since the `eval` method of Pandas does not support the `where` expression, you can only choose to use Numexpr in multidimensional Numpy ndarray.

Don't worry, I'll explain it to you right away.

Before starting, we need to import the necessary packages and implement a `generate_ndarray` method to generate a specific size ndarray for testing:

    from typing import Callable
    import time
    
    import numpy as np
    import numexpr as ne
    import matplotlib.pyplot as plt
    
    rng = np.random.default_rng(seed=4000)
    
    def generate_ndarray(rows: int) -&gt; np.ndarray:
        result_array = rng.random((rows, 1))
        return result_array

First, we generate a matrix of 200 rows to see if it is the test data we want:

    In:  arr = generate_ndarray(200)
         print(f""The dimension of this array: {arr.ndim}"")
         print(f""The shape of this array: {arr.shape}"")
    
    
    Out: The dimension of this array: 2
         The shape of this array: (200, 1)

To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape `(200, 1)` Of course, you can also test other shapes of ndarray according to your needs.

Then, we start writing the specific use of Numexpr in the `numexpr_to_binary` method:

* First, we use the index to separate the columns that need to be processed.
* Then, use the where expression of Numexpr to process the values.
* Finally, merge the processed columns with other columns to generate the required results.

Since the ndarray's shape here is `(200, 1)`, there is only one column, so I add a new dimension.

The code is as follows:

    def numexpr_to_binary(np_array: np.ndarray) -&gt; np.ndarray:
        temp = np_array[:, 0]
        temp = ne.evaluate(""where(temp&lt;0.5, 0, 1)"")
        return temp[:, np.newaxis]

We can test the result with an array of 10 rows to see if it is what I want:

    arr = generate_ndarray(10)
    result = numexpr_to_binary(arr)
    
    mapping = np.column_stack((arr, result))
    mapping

[ I test an array of 10 rows and the result is what I want. Image by Author ](https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;format=png&amp;auto=webp&amp;s=d6977cc422be66a8c37980554c1478e76d2d326c)

Look, the match is correct. Our task is completed.

The entire process can be demonstrated with the following figure:

&amp;#x200B;

[ The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author ](https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;format=png&amp;auto=webp&amp;s=df44481e44b2dc48b3acd522b51327b9030e2335)

## Performance Comparison

After the code implementation, we need to compare the Numexpr implementation version with the previous `for each` implementation version to confirm that there has been a performance improvement.

First, we implement a `numexpr_example` method. This method is based on the implementation of Numexpr:

    def numexpr_example(rows: int) -&gt; np.ndarray:
        orig_arr = generate_ndarray(rows)
        the_result = numexpr_to_binary(orig_arr)
        return the_result

Then, we need to supplement a `for_loop_example` method. This method refers to the original code I need to rewrite and is used as a performance benchmark:

    def for_loop_example(rows: int) -&gt; np.ndarray:
        the_arr = generate_ndarray(rows)
        for i in range(the_arr.shape[0]):
            if the_arr[i][0] &lt; 0.5:
                the_arr[i][0] = 0
            else:
                the_arr[i][0] = 1
        return the_arr

Then, I wrote a test method `time_method`. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts:

    def time_method(method: Callable):
        time_dict = dict()
        for i in range(9):
            begin = time.perf_counter()
            rows = 10 ** i
            method(rows)
            end = time.perf_counter()
            time_dict[i] = end - begin
        return time_dict

We test the numexpr version and the `for_loop` version separately, and use `matplotlib` to draw the time required for different amounts of data:

    t_m = time_method(for_loop_example)
    t_m_2 = time_method(numexpr_example)
    plt.plot(t_m.keys(), t_m.values(), c=""red"", linestyle=""solid"")
    plt.plot(t_m_2.keys(), t_m_2.values(), c=""green"", linestyle=""dashed"")
    plt.legend([""for loop"", ""numexpr""])
    plt.xlabel(""exponent"")
    plt.ylabel(""time"")
    plt.show()

[ The Numexpr version of the implementation has a huge performance improvement. Image by Author ](https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;format=png&amp;auto=webp&amp;s=d508bddb500f8065c75921c1905f14e414ccf932)

It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement.

## Conclusion

After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement.

This article mainly uses two features of Numexpr:

1. Numexpr allows calculations to be performed in a vectorized manner.
2. During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.

Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me.

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).",t2_9r8ft2a0,False,,0,False,How to Optimize Multidimensional Numpy Array Operations with Numexpr,[],r/datascience,False,6,,0,93.0,,False,t3_17egeux,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},Coding,False,2,,False,False,https://b.thumbs.redditmedia.com/bVSQy67lM6KFb-o8nRKeJvIBP8TdwnEgDfNjXQbap2s.jpg,1698064078.0,,[],{},,True,,1698053752.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;A real-world case study of performance optimization in Numpy&lt;/h1&gt;

&lt;p&gt;This article was originally published on my personal blog &lt;a href=""https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/""&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/r24q1n674yvb1.png?width=1387&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ab8950800797f55f538fdb1343df6d275bd07152""&gt; How to Optimize Multidimensional Numpy Array Operations with Numexpr. Photo Credit: Created by Author, Canva. &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use &lt;a href=""https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions""&gt;Numexpr expressions&lt;/a&gt; in multidimensional Numpy arrays to achieve substantial performance improvements.&lt;/p&gt;

&lt;p&gt;There aren&amp;#39;t many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.&lt;/p&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Recently, while reviewing some of my old work, I stumbled upon this piece of code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def predict(X, w, b):
    z = np.dot(X, w)
    y_hat = sigmoid(z)
    y_pred = np.zeros((y_hat.shape[0], 1))

    for i in range(y_hat.shape[0]):
        if y_hat[i, 0] &amp;lt; 0.5:
            y_pred[i, 0] = 0
        else:
            y_pred[i, 0] = 1
    return y_pred
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning.&lt;/p&gt;

&lt;p&gt;But heavens, who would use a &lt;code&gt;for loop&lt;/code&gt; to iterate over Numpy ndarray?&lt;/p&gt;

&lt;p&gt;You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior.&lt;/p&gt;

&lt;p&gt;That&amp;#39;s right, the person who wrote this code was me when I was younger.&lt;/p&gt;

&lt;p&gt;With a sense of responsibility, I plan to rewrite this code with the Numexpr library today.&lt;/p&gt;

&lt;p&gt;Along the way, I will show you how to use Numexpr and Numexpr&amp;#39;s &lt;code&gt;where&lt;/code&gt; expression in multidimensional Numpy arrays to achieve significant performance improvements.&lt;/p&gt;

&lt;h2&gt;Code Implementation&lt;/h2&gt;

&lt;p&gt;If you are not familiar with the basic usage of Numexpr, you can refer to this article:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/""&gt;https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This article uses a real-world example to demonstrate the specific usage of Numexpr&amp;#39;s API and expressions in Numpy and Pandas.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;where(bool, number1, number2): number&lt;/em&gt; &lt;em&gt;- number1 if the bool condition is true, number2 otherwise.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The above is the usage of the where expression in Numpy.&lt;/p&gt;

&lt;p&gt;When dealing with matrix data, you may used to using Pandas &lt;code&gt;DataFrame&lt;/code&gt;. But since the &lt;code&gt;eval&lt;/code&gt; method of Pandas does not support the &lt;code&gt;where&lt;/code&gt; expression, you can only choose to use Numexpr in multidimensional Numpy ndarray.&lt;/p&gt;

&lt;p&gt;Don&amp;#39;t worry, I&amp;#39;ll explain it to you right away.&lt;/p&gt;

&lt;p&gt;Before starting, we need to import the necessary packages and implement a &lt;code&gt;generate_ndarray&lt;/code&gt; method to generate a specific size ndarray for testing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Callable
import time

import numpy as np
import numexpr as ne
import matplotlib.pyplot as plt

rng = np.random.default_rng(seed=4000)

def generate_ndarray(rows: int) -&amp;gt; np.ndarray:
    result_array = rng.random((rows, 1))
    return result_array
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First, we generate a matrix of 200 rows to see if it is the test data we want:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In:  arr = generate_ndarray(200)
     print(f&amp;quot;The dimension of this array: {arr.ndim}&amp;quot;)
     print(f&amp;quot;The shape of this array: {arr.shape}&amp;quot;)


Out: The dimension of this array: 2
     The shape of this array: (200, 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape &lt;code&gt;(200, 1)&lt;/code&gt; Of course, you can also test other shapes of ndarray according to your needs.&lt;/p&gt;

&lt;p&gt;Then, we start writing the specific use of Numexpr in the &lt;code&gt;numexpr_to_binary&lt;/code&gt; method:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First, we use the index to separate the columns that need to be processed.&lt;/li&gt;
&lt;li&gt;Then, use the where expression of Numexpr to process the values.&lt;/li&gt;
&lt;li&gt;Finally, merge the processed columns with other columns to generate the required results.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the ndarray&amp;#39;s shape here is &lt;code&gt;(200, 1)&lt;/code&gt;, there is only one column, so I add a new dimension.&lt;/p&gt;

&lt;p&gt;The code is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def numexpr_to_binary(np_array: np.ndarray) -&amp;gt; np.ndarray:
    temp = np_array[:, 0]
    temp = ne.evaluate(&amp;quot;where(temp&amp;lt;0.5, 0, 1)&amp;quot;)
    return temp[:, np.newaxis]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can test the result with an array of 10 rows to see if it is what I want:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;arr = generate_ndarray(10)
result = numexpr_to_binary(arr)

mapping = np.column_stack((arr, result))
mapping
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d6977cc422be66a8c37980554c1478e76d2d326c""&gt; I test an array of 10 rows and the result is what I want. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Look, the match is correct. Our task is completed.&lt;/p&gt;

&lt;p&gt;The entire process can be demonstrated with the following figure:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=df44481e44b2dc48b3acd522b51327b9030e2335""&gt; The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Performance Comparison&lt;/h2&gt;

&lt;p&gt;After the code implementation, we need to compare the Numexpr implementation version with the previous &lt;code&gt;for each&lt;/code&gt; implementation version to confirm that there has been a performance improvement.&lt;/p&gt;

&lt;p&gt;First, we implement a &lt;code&gt;numexpr_example&lt;/code&gt; method. This method is based on the implementation of Numexpr:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def numexpr_example(rows: int) -&amp;gt; np.ndarray:
    orig_arr = generate_ndarray(rows)
    the_result = numexpr_to_binary(orig_arr)
    return the_result
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, we need to supplement a &lt;code&gt;for_loop_example&lt;/code&gt; method. This method refers to the original code I need to rewrite and is used as a performance benchmark:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def for_loop_example(rows: int) -&amp;gt; np.ndarray:
    the_arr = generate_ndarray(rows)
    for i in range(the_arr.shape[0]):
        if the_arr[i][0] &amp;lt; 0.5:
            the_arr[i][0] = 0
        else:
            the_arr[i][0] = 1
    return the_arr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, I wrote a test method &lt;code&gt;time_method&lt;/code&gt;. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def time_method(method: Callable):
    time_dict = dict()
    for i in range(9):
        begin = time.perf_counter()
        rows = 10 ** i
        method(rows)
        end = time.perf_counter()
        time_dict[i] = end - begin
    return time_dict
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We test the numexpr version and the &lt;code&gt;for_loop&lt;/code&gt; version separately, and use &lt;code&gt;matplotlib&lt;/code&gt; to draw the time required for different amounts of data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;t_m = time_method(for_loop_example)
t_m_2 = time_method(numexpr_example)
plt.plot(t_m.keys(), t_m.values(), c=&amp;quot;red&amp;quot;, linestyle=&amp;quot;solid&amp;quot;)
plt.plot(t_m_2.keys(), t_m_2.values(), c=&amp;quot;green&amp;quot;, linestyle=&amp;quot;dashed&amp;quot;)
plt.legend([&amp;quot;for loop&amp;quot;, &amp;quot;numexpr&amp;quot;])
plt.xlabel(&amp;quot;exponent&amp;quot;)
plt.ylabel(&amp;quot;time&amp;quot;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d508bddb500f8065c75921c1905f14e414ccf932""&gt; The Numexpr version of the implementation has a huge performance improvement. Image by Author &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement.&lt;/p&gt;

&lt;p&gt;This article mainly uses two features of Numexpr:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Numexpr allows calculations to be performed in a vectorized manner.&lt;/li&gt;
&lt;li&gt;During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me.&lt;/p&gt;

&lt;p&gt;This article was originally published on my personal blog &lt;a href=""https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/""&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,17egeux,True,,qtalen,,1,True,all_ads,False,[],False,,/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,all_ads,False,https://www.reddit.com/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,1209065,1698053752.0,0,,False,"{'i5trs6h79xvb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 78, 'x': 108, 'u': 'https://preview.redd.it/i5trs6h79xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c265d077c76d74f45c5cb125f9355561a7f5e03b'}, {'y': 156, 'x': 216, 'u': 'https://preview.redd.it/i5trs6h79xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=543d74bdf357b325082cbe4cb60187df5cd783c0'}, {'y': 231, 'x': 320, 'u': 'https://preview.redd.it/i5trs6h79xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed7c629584bc9b778eb0e7d678bb40a828d31a2f'}], 's': {'y': 430, 'x': 595, 'u': 'https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;format=png&amp;auto=webp&amp;s=d508bddb500f8065c75921c1905f14e414ccf932'}, 'id': 'i5trs6h79xvb1'}, 'aw26lp8q8xvb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 82, 'x': 108, 'u': 'https://preview.redd.it/aw26lp8q8xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=82706ba0390facc4e733375417b45445f7c662a1'}, {'y': 165, 'x': 216, 'u': 'https://preview.redd.it/aw26lp8q8xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22228f5dad76a4b48ca4e453156a2901bb54b88e'}, {'y': 245, 'x': 320, 'u': 'https://preview.redd.it/aw26lp8q8xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e786249aa06a8e8f13a6a851ec5fe5987fe8eac'}, {'y': 490, 'x': 640, 'u': 'https://preview.redd.it/aw26lp8q8xvb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e8af89b6cbada268340bfd9195964ebdbf23bd67'}], 's': {'y': 701, 'x': 915, 'u': 'https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;format=png&amp;auto=webp&amp;s=df44481e44b2dc48b3acd522b51327b9030e2335'}, 'id': 'aw26lp8q8xvb1'}, 'r24q1n674yvb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aecb3555e64f8a91d18098d7a590df334e914973'}, {'y': 143, 'x': 216, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4887aa200906b3ad3351f555ed8ffb7cfebb0d3'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=633e830499b83a2b99e2d148d3b7d85b117e41af'}, {'y': 426, 'x': 640, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=60662b1da6eee8d758e63f4038d3f808ff3fac73'}, {'y': 639, 'x': 960, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=55e3bee81e42e0c9aa309b45c5b16ba342f13c06'}, {'y': 719, 'x': 1080, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6b865d7cab7c9cf76cb713eef7c45433ff49d312'}], 's': {'y': 924, 'x': 1387, 'u': 'https://preview.redd.it/r24q1n674yvb1.png?width=1387&amp;format=png&amp;auto=webp&amp;s=ab8950800797f55f538fdb1343df6d275bd07152'}, 'id': 'r24q1n674yvb1'}, 'o1h5bwdn8xvb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 73, 'x': 108, 'u': 'https://preview.redd.it/o1h5bwdn8xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4122e67f9a4134bc9caf07a853c9778f36b525c'}, {'y': 146, 'x': 216, 'u': 'https://preview.redd.it/o1h5bwdn8xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d2086eaad1fc13fb23f5e326b05ba6d0b3a44da'}, {'y': 216, 'x': 320, 'u': 'https://preview.redd.it/o1h5bwdn8xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb3d5913b3730778257fc3e0713c166604658b00'}], 's': {'y': 238, 'x': 351, 'u': 'https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;format=png&amp;auto=webp&amp;s=d6977cc422be66a8c37980554c1478e76d2d326c'}, 'id': 'o1h5bwdn8xvb1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?auto=webp&amp;s=366216577b9b38ba41452286b2fcf4f2c68c9636', 'width': 1387, 'height': 924}, 'resolutions': [{'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e0120bd33f146716d9a9571e26276d1f7f86fb93', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=939e7da9c16e695695b1ad59dec1d4e6e8d683d6', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a4456f1d0041d99b553a235dbd71d4165addac3', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b2b091715dcd26bde14ed92aaf499316d099b9', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57b2c9250bad68102634450d43d77c65d882e11e', 'width': 960, 'height': 639}, {'url': 'https://external-preview.redd.it/uiwdTJerETCwCpUIgHQSBF4mQJT7rPyLZF2NSGKldx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d2393289abf0d2b8b91de65ffb3765a8ecc5bb9e', 'width': 1080, 'height': 719}], 'variants': {}, 'id': 'i2JEOSQeihCf3kK3-z6ZS0cLg5Reifzq6bHfNWMCWZA'}], 'enabled': False}",,,,,,,8420,1065
,datascience,"
I'm using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.

In all cases I can see a few problems:

* gaps with no data (tried filling in - red)
* a sudden drop in sentiment from 15th June

How would you go about doing a forecast on that data? What's advice can you give?",t2_p5mn5,False,,0,False,How to do a time series forecast on sentiment?,[],r/datascience,False,6,network,0,61.0,,False,t3_17ef06x,False,dark,0.4,,public,0,0,{},140.0,,False,[],,True,False,,{},Analysis,False,0,,False,False,https://b.thumbs.redditmedia.com/WVitn7UQ_KK50or7nZNLFexKfEsa9oqTz9ydUHoR7mU.jpg,False,,[],{},,False,,1698047310.0,text,6,,,text,i.redd.it,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.&lt;/p&gt;

&lt;p&gt;In all cases I can see a few problems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;gaps with no data (tried filling in - red)&lt;/li&gt;
&lt;li&gt;a sudden drop in sentiment from 15th June&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How would you go about doing a forecast on that data? What&amp;#39;s advice can you give?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17ef06x,True,,balackdynamite,,9,True,all_ads,False,[],False,,/r/datascience/comments/17ef06x/how_to_do_a_time_series_forecast_on_sentiment/,all_ads,False,https://i.redd.it/slcxmqkgqwvb1.jpg,1209065,1698047310.0,0,,False,,image,"{'images': [{'source': {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?auto=webp&amp;s=92f4adefc340461d5b346528a0ac48e18272ffae', 'width': 1346, 'height': 590}, 'resolutions': [{'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a59853d709cfaf43116abf21e4a61164807a291a', 'width': 108, 'height': 47}, {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d2ea73ee19a02bd0878210aa1d324b707583d7a', 'width': 216, 'height': 94}, {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24e7349a27d3405c3ad02c9d91a102811361898a', 'width': 320, 'height': 140}, {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a83ddb812aa4c693bc4ff58e82cb30cc2fb95855', 'width': 640, 'height': 280}, {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc0584193145d099f4cd5b55fa7f3c65e81d853', 'width': 960, 'height': 420}, {'url': 'https://preview.redd.it/slcxmqkgqwvb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3acf9ea24d74a5f29f52ecca6fad47c7815ca8fe', 'width': 1080, 'height': 473}], 'variants': {}, 'id': '7tobCBYAmnS3TUnXCDGrbiRB9HPiDqsVsi3Gwy9VYAI'}], 'enabled': True}",,https://i.redd.it/slcxmqkgqwvb1.jpg,,,,,330,62
,datascience,"I am studying a master’s in data science and working as a “junior data scientist” as my first ever job at a start up. Problem is, even though I have ended the more “data science” part of my degree (ML, advanced math/statistics etc.), at work, I’m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don’t remember anything from them. 

I’m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there’s no way I can make it past any of them because of the discrepency between my title and actual experience.",t2_m826ekr,False,,0,False,"Title not matching tasks, am I making it a big deal?",[],r/datascience,False,6,fun,0,,,False,t3_17eeucx,False,dark,0.57,,public,1,0,{},,,False,[],,False,False,,{},Career Discussion,False,1,,False,False,self,False,,[],{},,True,,1698046517.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am studying a master’s in data science and working as a “junior data scientist” as my first ever job at a start up. Problem is, even though I have ended the more “data science” part of my degree (ML, advanced math/statistics etc.), at work, I’m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don’t remember anything from them. &lt;/p&gt;

&lt;p&gt;I’m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there’s no way I can make it past any of them because of the discrepency between my title and actual experience.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,b026063c-d780-11e7-aba9-0e030591a4b4,False,False,False,,[],False,,,,t5_2sptq,False,,,#0079d3,17eeucx,True,,Utterizi,,11,True,all_ads,False,[],False,,/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,1209065,1698046517.0,0,,False,,,,,,,,,,727,132
,datascience,"Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . 
So the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?",t2_b5ou545yj,False,,0,False,Hey guys how is mongodb for analytics,[],r/datascience,False,6,tooling,0,,,False,t3_17ebi8s,False,dark,0.25,,public,0,0,{},,,False,[],,False,False,,{},Tools,False,0,,False,False,self,False,,[],{},,True,,1698033083.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . 
So the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17ebi8s,True,,charlesowo445,,1,True,all_ads,False,[],False,,/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,1209065,1698033083.0,0,,False,,,,,,,,,,334,73
,datascience,"I'm a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it's not out there, etc. Looking to help :)",t2_80ydgoh1,False,,0,False,What problems would you like to be solved?,[],r/datascience,False,6,meta,0,,,False,t3_17eafwm,False,dark,0.61,,public,9,0,{},,,True,[],,False,False,,{},Projects,False,9,,False,False,self,1698030264.0,,[],{},,True,,1698029544.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it&amp;#39;s not out there, etc. Looking to help :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17eafwm,True,,ResponsibleGazelle76,,43,True,all_ads,False,[],False,,/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,all_ads,False,https://www.reddit.com/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,1209065,1698029544.0,0,,False,,,,,,,,,,243,42
,datascience,"Not talking folks who work off linux servers or VMs, I'm talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)

I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.

I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.

Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.

Not against going back to Anaconda, but I'm curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.",t2_rrh4y,False,,0,False,Native Linux Users: How do you setup your DS Environment?,[],r/datascience,False,6,tooling,0,,,False,t3_17e7m1p,False,dark,0.78,,public,10,0,{},,,False,[],,False,False,,{},Tools,False,10,,False,False,self,False,,[],{},,True,,1698020773.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not talking folks who work off linux servers or VMs, I&amp;#39;m talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)&lt;/p&gt;

&lt;p&gt;I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.&lt;/p&gt;

&lt;p&gt;I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.&lt;/p&gt;

&lt;p&gt;Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.&lt;/p&gt;

&lt;p&gt;Not against going back to Anaconda, but I&amp;#39;m curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17e7m1p,True,,feldomatic,,24,True,all_ads,False,[],False,,/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,1209065,1698020773.0,0,,False,,,,,,,,,,857,152
,datascience,"I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren't technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.

That being said, a ton of programs for DS out there including the one I'm taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.

&amp;#x200B;

Just a rant, I've been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?

Edit: most people are assuming I want to immediately jump into a DS role. I do not. I plan on being an analyst or some other entry level adjacent role before for a few years before switching to DS or DE.

I think most any undergraduate would fall flat on their face besides the most technical and self taught alongside their classes if they jumped into DS from the getgo, assuming someone with even a year more experience doesn't beat you to the punch first.


If you disagree with something I, or anyone else says in here, instead of down voting to all oblivion tell myself or that person you disagree with *why* they're wrong and need to switch their viewpoint. I'll be making a summary of the points I've seen in here in a few days for people to look through in the future.

----------------------------------------------------------------------------------

Here's the summary of points I've seen made here that have convinced me to switch to CS/Stats minor for anyone in the future who might also have the same question whether or not to choose or switch away from a DS undergrad degree. If I missed anything shoot me a message.

1. CS/Stats is a much more flexible degree path, if the landscape of data as a whole changes, this degree structure is going to be vastly more resistant to changes in what a ""Data Scientist"" even is in the labor market. This choice will also set you up much post for grad school.

2. DS degree graduates, no matter how quality the program is, will be passed in comparison to a CS major. Pre-conceived notions are hard to change and DS degrees are very new / lack a generalized structure compared to CS and Stats majors that more or less have an expected outcome quality in graduates.

3. DS degree graduates as a result of the lack of a single path / consistent course training, *will have gaps in basic skills/knowledge CS/Stats minor graduates won't*. It's best to embrace the filter classes of CS degrees to make sure you aren't falling flat on your face if you get into a DS role.

4. Whether you're choosing something more programming focused like Data Engineering, or something more research / statistically focused like a Data Scientist, CS/Stats will just flat out prepare you better for those jobs while keeping your options open for other roles in CompSci if you end up changing your mind.

5. DS degrees are fine if you plan on being an Analyst, but then again, there are a lot of other non-technical degrees that can become analysts.

6. Projects are not weighted as heavily as people might think, recruiters most likely will not be looking at them unless in very specific scenarios which is why having a better base of CS/Stats tends to work out better.

7. Some aspects of CS degrees will suck but in the grand scheme of being more marketable, the difference in prestige and chances of landing a job vs a DS degree is significant enough to switch degrees or choose CS/Stats to begin with. 

8. In a summarized sense, getting a CS/Stats minor focus is a more pure form of what DS courses should be, but aren't.

Thanks to everyone who didn't just downvote the post and wrote their own perspective, I'll be talking with a counselor to switch to CS &amp; Stats minor tomorrow.

And good luck to anyone in the future coming to this post for answers, it is worth choosing a CS degree and if you have any questions and you're coming through here months or years from now, read through the comments on here to make sure you're making the best decisions for your career.",,False,,0,False,The obsession/hate for DS undergrad degrees,[],r/datascience,False,6,,0,,,False,t3_17e02jy,False,dark,0.68,,public,27,0,{},,,False,[],,False,False,,{},Education,False,27,,False,,self,1698098429.0,,,{},,True,,1697999994.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren&amp;#39;t technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.&lt;/p&gt;

&lt;p&gt;That being said, a ton of programs for DS out there including the one I&amp;#39;m taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Just a rant, I&amp;#39;ve been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?&lt;/p&gt;

&lt;p&gt;Edit: most people are assuming I want to immediately jump into a DS role. I do not. I plan on being an analyst or some other entry level adjacent role before for a few years before switching to DS or DE.&lt;/p&gt;

&lt;p&gt;I think most any undergraduate would fall flat on their face besides the most technical and self taught alongside their classes if they jumped into DS from the getgo, assuming someone with even a year more experience doesn&amp;#39;t beat you to the punch first.&lt;/p&gt;

&lt;p&gt;If you disagree with something I, or anyone else says in here, instead of down voting to all oblivion tell myself or that person you disagree with &lt;em&gt;why&lt;/em&gt; they&amp;#39;re wrong and need to switch their viewpoint. I&amp;#39;ll be making a summary of the points I&amp;#39;ve seen in here in a few days for people to look through in the future.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Here&amp;#39;s the summary of points I&amp;#39;ve seen made here that have convinced me to switch to CS/Stats minor for anyone in the future who might also have the same question whether or not to choose or switch away from a DS undergrad degree. If I missed anything shoot me a message.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;CS/Stats is a much more flexible degree path, if the landscape of data as a whole changes, this degree structure is going to be vastly more resistant to changes in what a &amp;quot;Data Scientist&amp;quot; even is in the labor market. This choice will also set you up much post for grad school.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DS degree graduates, no matter how quality the program is, will be passed in comparison to a CS major. Pre-conceived notions are hard to change and DS degrees are very new / lack a generalized structure compared to CS and Stats majors that more or less have an expected outcome quality in graduates.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DS degree graduates as a result of the lack of a single path / consistent course training, &lt;em&gt;will have gaps in basic skills/knowledge CS/Stats minor graduates won&amp;#39;t&lt;/em&gt;. It&amp;#39;s best to embrace the filter classes of CS degrees to make sure you aren&amp;#39;t falling flat on your face if you get into a DS role.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Whether you&amp;#39;re choosing something more programming focused like Data Engineering, or something more research / statistically focused like a Data Scientist, CS/Stats will just flat out prepare you better for those jobs while keeping your options open for other roles in CompSci if you end up changing your mind.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DS degrees are fine if you plan on being an Analyst, but then again, there are a lot of other non-technical degrees that can become analysts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Projects are not weighted as heavily as people might think, recruiters most likely will not be looking at them unless in very specific scenarios which is why having a better base of CS/Stats tends to work out better.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some aspects of CS degrees will suck but in the grand scheme of being more marketable, the difference in prestige and chances of landing a job vs a DS degree is significant enough to switch degrees or choose CS/Stats to begin with. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In a summarized sense, getting a CS/Stats minor focus is a more pure form of what DS courses should be, but aren&amp;#39;t.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thanks to everyone who didn&amp;#39;t just downvote the post and wrote their own perspective, I&amp;#39;ll be talking with a counselor to switch to CS &amp;amp; Stats minor tomorrow.&lt;/p&gt;

&lt;p&gt;And good luck to anyone in the future coming to this post for answers, it is worth choosing a CS degree and if you have any questions and you&amp;#39;re coming through here months or years from now, read through the comments on here to make sure you&amp;#39;re making the best decisions for your career.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51,False,False,False,,[],False,,,,t5_2sptq,False,,,#00a6a5,17e02jy,True,,[deleted],,110,True,all_ads,False,[],,dark,/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,all_ads,False,https://www.reddit.com/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,1209065,1697999994.0,0,,False,,,,,,,,,,4386,778
,datascience,"To all the data science professionals, enthusiasts and learners, do y'all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? 

I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there's also R, C++ and other languages that sometimes come into the picture. 

This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. 

Also, if you use any resources which are popular, please share in the comments.",t2_eac1tyvg,False,,0,False,Do you remember the syntax of the tools you use?,[],r/datascience,False,6,tooling,0,,,False,t3_17e01li,False,dark,0.84,,public,36,0,{},,,False,[],,False,False,,{},Tools,False,36,,False,False,self,False,,[],{},,True,,1697999917.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;To all the data science professionals, enthusiasts and learners, do y&amp;#39;all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? &lt;/p&gt;

&lt;p&gt;I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there&amp;#39;s also R, C++ and other languages that sometimes come into the picture. &lt;/p&gt;

&lt;p&gt;This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. &lt;/p&gt;

&lt;p&gt;Also, if you use any resources which are popular, please share in the comments.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17e01li,True,,Aware_Value4603,,36,True,all_ads,False,[],False,,/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,all_ads,False,https://www.reddit.com/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,1209065,1697999917.0,0,,False,,,,,,,,,,840,141
,datascience,Hi I'm fairly new to Data Science and I'm only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?,t2_7jw3rp26,False,,0,False,How do you guys practise using MySQL,[],r/datascience,False,6,tooling,0,,,False,t3_17dtmqe,False,dark,0.95,,public,152,0,{},,,False,[],,False,False,,{},Tools,False,152,,False,False,self,False,,[],{},,True,,1697982303.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi I&amp;#39;m fairly new to Data Science and I&amp;#39;m only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17dtmqe,True,,jumpi3y,,77,True,all_ads,False,[],False,,/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,all_ads,False,https://www.reddit.com/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,1209065,1697982303.0,0,,False,,,,,,,,,,311,56
,datascience,"Drop the top subReddits and discord communities where the top data scientists and data analysts hang out. What content do they consume, what are the talking about, how do I sign up?",t2_8fm83pcq,False,,0,False,Where do the data nerds hang out?,[],r/datascience,False,6,discussion,0,,,False,t3_17deo3d,False,dark,0.91,,public,182,0,{},,,False,[],,False,False,,{},Discussion,False,182,,False,False,self,False,,[],{},,True,,1697928378.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Drop the top subReddits and discord communities where the top data scientists and data analysts hang out. What content do they consume, what are the talking about, how do I sign up?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,#1a1a1b,17deo3d,True,,_CynicalCyanide,,93,True,all_ads,False,[],False,,/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,all_ads,False,https://www.reddit.com/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,1209065,1697928378.0,0,,False,,,,,,,,,,181,32
,datascience,"Hi, I came upon [this post in Linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7121482516829507584?utm_source=share&amp;utm_medium=member_android), in which a guy talks about how handling errors with imputing means or zero have many flaws (changes distributions, alters summary statistics, inflates/deflates specific values), and instead suggests to use this library called ""MissForest"" imputer to handle errors using a random forest algorithm.

**My question is, are there any reasons to be skeptical about this post?** I believe there should be, since I have not really heard of other well established reference books talking about using Random Forest to handle errors over imputation using mean or zero.

My own speculation is that, unless your data has missing values that are in the hundreds or take up a significant portion of your entire dataset, using the mean/zero imputation is computationally cheaper while delivering similar results as the Random Forest algorithm.

I am more curious about whether this proposed solution has flaws in its methodology itself.",t2_emlzkj7y,False,,0,False,Is handling errors with Random Forest more superior compared to mean or zero imputation?,[],r/datascience,False,6,tooling,0,,,False,t3_17d6ufx,False,dark,0.9,,public,23,0,{},,,False,[],,False,False,,{},Tools,False,23,,False,False,self,1697911189.0,,[],{},,True,,1697906883.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I came upon &lt;a href=""https://www.linkedin.com/feed/update/urn:li:activity:7121482516829507584?utm_source=share&amp;amp;utm_medium=member_android""&gt;this post in Linkedin&lt;/a&gt;, in which a guy talks about how handling errors with imputing means or zero have many flaws (changes distributions, alters summary statistics, inflates/deflates specific values), and instead suggests to use this library called &amp;quot;MissForest&amp;quot; imputer to handle errors using a random forest algorithm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My question is, are there any reasons to be skeptical about this post?&lt;/strong&gt; I believe there should be, since I have not really heard of other well established reference books talking about using Random Forest to handle errors over imputation using mean or zero.&lt;/p&gt;

&lt;p&gt;My own speculation is that, unless your data has missing values that are in the hundreds or take up a significant portion of your entire dataset, using the mean/zero imputation is computationally cheaper while delivering similar results as the Random Forest algorithm.&lt;/p&gt;

&lt;p&gt;I am more curious about whether this proposed solution has flaws in its methodology itself.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17d6ufx,True,,Odd_Discipline9354,,7,True,all_ads,False,[],False,,/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,all_ads,False,https://www.reddit.com/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,1209065,1697906883.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/k_0RwgzGsKvWQjjSG-mGo5x3d-Q0zNzsLR-s4tZ7V6o.jpg?auto=webp&amp;s=c77da2db74dec69321f94ee5bb1a4292610efb9b', 'width': 800, 'height': 848}, 'resolutions': [{'url': 'https://external-preview.redd.it/k_0RwgzGsKvWQjjSG-mGo5x3d-Q0zNzsLR-s4tZ7V6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54bc485f67d2a26242d04207b79422f440eed884', 'width': 108, 'height': 114}, {'url': 'https://external-preview.redd.it/k_0RwgzGsKvWQjjSG-mGo5x3d-Q0zNzsLR-s4tZ7V6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=72b6418b5061fd4157acc25418e55947eea29e12', 'width': 216, 'height': 228}, {'url': 'https://external-preview.redd.it/k_0RwgzGsKvWQjjSG-mGo5x3d-Q0zNzsLR-s4tZ7V6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=761a19a97a97c0c2694601a9c6a7e3c6afe8b2d5', 'width': 320, 'height': 339}, {'url': 'https://external-preview.redd.it/k_0RwgzGsKvWQjjSG-mGo5x3d-Q0zNzsLR-s4tZ7V6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92e88e3da0a4252f9b859525b916d7f3e05fdf4f', 'width': 640, 'height': 678}], 'variants': {}, 'id': 'KsaNzfSc1tkJaIBYqoagNEpJ_0XKBg_52Dqxdy2pVM0'}], 'enabled': False}",,,,,,,1083,152
,datascience,"I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it's more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment.",t2_6eex6cns,False,,0,False,Is pytorch not good for production,[],r/datascience,False,6,tooling,0,,,False,t3_17d3aze,False,dark,0.93,,public,82,0,{},,,False,[],,False,False,,{},Tools,False,82,,False,False,self,False,,[],{},,True,,1697897062.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it&amp;#39;s more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,#a06324,17d3aze,True,,ssiddharth408,,62,True,all_ads,False,[],False,,/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,all_ads,False,https://www.reddit.com/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,1209065,1697897062.0,0,,False,,,,,,,,,,406,67
,datascience,"I am a sales operations analyst -by name- and I do what a typical junior data scientist does, I am an analyst from a team of four, I am the only one with exposure to proper statistical analyses and machine learning.

One colleague of mine -my mentor- has been at the company for a year before me, and he knows some python and is good at SQL. He is no where near my level at those two, but he’s a god-level suck-up! 
He can stay at the office after hours for no compensation just cause our manager said he needed to see something that would normally take a whole day to achieve, asked at 5:00 pm and needed to be ready in the morning.

The problem is raised because of a project I was leading, I automated the process of making routes for sales agents, I made it assign a 1 to retailers if we visit today will more likely make an order. I made it for the region I am operating in only -more on that later- and I also used clustering to get them the best routes possible in terms of likelihood to order and geographic coordinates. It made the success rate go from 40% to a big fat 60%. My manager appreciated that as much and thought its a great idea to make it for all regions, I designed an ab test and will run it for 2 weeks, as we have biweekly seasonality.

I prepared analyses for the test results and it was time for a meeting with other managers to discuss what it achieved. This was the forst time this team was doing an ab test, since I am the only one who actually understand it, I owned it.

When I shows the numbers, one region showed insignificant results, and I found that its seasonality is not biweekly, rather monthly and the mode of operations there is different, and it was -my mentor’s- region.

My manager said: why are you complicating things? Man, show me some pivot tables of agents who worked without your model and the ones who worked with and who is better, I disagreed as their performances might include other factors that are not controlled by mt model, pricing and geography and the agent himself.

My mentor already has the pivots ready, presented the numbers and he was happy.

After, my manager rambelled on for half an hour about my attitude and pointed out every thing that I fis wrong since I started working in the company, and assigned him as anentor to me, stating how much of an inpact on my coding skills and analytical skills he will add.

We started working in projexts together and had to take his way of doing things, and I don’t like how he lets me do all the work and take credit for it.

I started looking for new jobs and no luck the market is really tough especially that I know little tools, power bi and its dax, excel and python and sql.

What should i learn to get jobs as a junior data scientist? While searching, what should I do about my situation?",t2_81zrh19oq,False,,0,False,"Soooo, my manager thinks it’s a good idea to assign a mentor on me,",[],r/datascience,False,6,discussion,0,,,False,t3_17d2v13,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697895746.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a sales operations analyst -by name- and I do what a typical junior data scientist does, I am an analyst from a team of four, I am the only one with exposure to proper statistical analyses and machine learning.&lt;/p&gt;

&lt;p&gt;One colleague of mine -my mentor- has been at the company for a year before me, and he knows some python and is good at SQL. He is no where near my level at those two, but he’s a god-level suck-up! 
He can stay at the office after hours for no compensation just cause our manager said he needed to see something that would normally take a whole day to achieve, asked at 5:00 pm and needed to be ready in the morning.&lt;/p&gt;

&lt;p&gt;The problem is raised because of a project I was leading, I automated the process of making routes for sales agents, I made it assign a 1 to retailers if we visit today will more likely make an order. I made it for the region I am operating in only -more on that later- and I also used clustering to get them the best routes possible in terms of likelihood to order and geographic coordinates. It made the success rate go from 40% to a big fat 60%. My manager appreciated that as much and thought its a great idea to make it for all regions, I designed an ab test and will run it for 2 weeks, as we have biweekly seasonality.&lt;/p&gt;

&lt;p&gt;I prepared analyses for the test results and it was time for a meeting with other managers to discuss what it achieved. This was the forst time this team was doing an ab test, since I am the only one who actually understand it, I owned it.&lt;/p&gt;

&lt;p&gt;When I shows the numbers, one region showed insignificant results, and I found that its seasonality is not biweekly, rather monthly and the mode of operations there is different, and it was -my mentor’s- region.&lt;/p&gt;

&lt;p&gt;My manager said: why are you complicating things? Man, show me some pivot tables of agents who worked without your model and the ones who worked with and who is better, I disagreed as their performances might include other factors that are not controlled by mt model, pricing and geography and the agent himself.&lt;/p&gt;

&lt;p&gt;My mentor already has the pivots ready, presented the numbers and he was happy.&lt;/p&gt;

&lt;p&gt;After, my manager rambelled on for half an hour about my attitude and pointed out every thing that I fis wrong since I started working in the company, and assigned him as anentor to me, stating how much of an inpact on my coding skills and analytical skills he will add.&lt;/p&gt;

&lt;p&gt;We started working in projexts together and had to take his way of doing things, and I don’t like how he lets me do all the work and take credit for it.&lt;/p&gt;

&lt;p&gt;I started looking for new jobs and no luck the market is really tough especially that I know little tools, power bi and its dax, excel and python and sql.&lt;/p&gt;

&lt;p&gt;What should i learn to get jobs as a junior data scientist? While searching, what should I do about my situation?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17d2v13,True,,Careful_Engineer_700,,16,True,all_ads,False,[],False,,/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,all_ads,False,https://www.reddit.com/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,1209065,1697895746.0,0,,False,,,,,,,,,,2806,531
,datascience,"I've been studying for Data Analyst roles for a while now, and I'm really looking forward to working with data. I was just wondering how often companies outsource for entry-level data analyst roles? Because this role is usually remote or hybrid, I think that a lot of companies probably are, but they're hard to find or most likely prefer locals than to outsource.   
Before I started, I did my own research and met with 8 accomplished Data Analysts/ Scientists/ Engineers Mentors from US/Canada/Germany/UK in The Mentoring Club and confirmed how I would start and learn to transition to this role.  


I talked to them and confirmed that the best skills to acquire would be   
Excel, SQL, Python or R (or Both), Power BI or Tableau (or Both)  


I started with very basic SQL in Khan Academy and SQLZoo and I enjoyed it a lot and confirmed my love to transition to working with Data. 

After that, I took the IBM Data Analyst Professional Certificate (almost everyone I talked to was against taking the Google Data Analytics Certificate) which covered SQL, Python, IBM Cognos, and EDA.

Then I took DataCamp's Data Analyst in SQL to further hone my skills in SQL, I feel more confident with my SQL skills after taking this course.

Now, I'm currently taking DataCamp's Data Analyst in Power BI course and am about 70% done with it.

On every single course, I really love what I'm learning and enjoying it so far. I really love working with data. Whenever I solve a ""problem"" from my courses, I feel very satisfied like an itch in the brain is gone. Every time I make an amazing visual in Power BI, I actually smile and feel proud. Every time I learn something new I actually love it. When I first used ""Key Influencers"" in Power BI, I was so amazed and really wanted to work more with this feature.

&amp;#x200B;

My current problem is, that I don't really want to work as a Data Analyst for a company in my country, but rather as a full-time remote for a company in the US, Canada, or Europe even without benefits, even at minimum wage, as long as they give me 40 hours per week, growth in skills, and opportunity to train/learn.

So I'm just wondering how viable would that be in your experience with your companies, do you work remotely with people from other countries in entry-level roles?",t2_outi7,False,,0,False,How often do companies outsource for entry-level data roles?,[],r/datascience,False,6,discussion,0,,,False,t3_17czsvd,False,dark,0.81,,public,13,0,{},,,False,[],,False,False,,{},Discussion,False,13,,False,False,self,False,,[],{},,True,,1697885152.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been studying for Data Analyst roles for a while now, and I&amp;#39;m really looking forward to working with data. I was just wondering how often companies outsource for entry-level data analyst roles? Because this role is usually remote or hybrid, I think that a lot of companies probably are, but they&amp;#39;re hard to find or most likely prefer locals than to outsource.&lt;br/&gt;
Before I started, I did my own research and met with 8 accomplished Data Analysts/ Scientists/ Engineers Mentors from US/Canada/Germany/UK in The Mentoring Club and confirmed how I would start and learn to transition to this role.  &lt;/p&gt;

&lt;p&gt;I talked to them and confirmed that the best skills to acquire would be&lt;br/&gt;
Excel, SQL, Python or R (or Both), Power BI or Tableau (or Both)  &lt;/p&gt;

&lt;p&gt;I started with very basic SQL in Khan Academy and SQLZoo and I enjoyed it a lot and confirmed my love to transition to working with Data. &lt;/p&gt;

&lt;p&gt;After that, I took the IBM Data Analyst Professional Certificate (almost everyone I talked to was against taking the Google Data Analytics Certificate) which covered SQL, Python, IBM Cognos, and EDA.&lt;/p&gt;

&lt;p&gt;Then I took DataCamp&amp;#39;s Data Analyst in SQL to further hone my skills in SQL, I feel more confident with my SQL skills after taking this course.&lt;/p&gt;

&lt;p&gt;Now, I&amp;#39;m currently taking DataCamp&amp;#39;s Data Analyst in Power BI course and am about 70% done with it.&lt;/p&gt;

&lt;p&gt;On every single course, I really love what I&amp;#39;m learning and enjoying it so far. I really love working with data. Whenever I solve a &amp;quot;problem&amp;quot; from my courses, I feel very satisfied like an itch in the brain is gone. Every time I make an amazing visual in Power BI, I actually smile and feel proud. Every time I learn something new I actually love it. When I first used &amp;quot;Key Influencers&amp;quot; in Power BI, I was so amazed and really wanted to work more with this feature.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My current problem is, that I don&amp;#39;t really want to work as a Data Analyst for a company in my country, but rather as a full-time remote for a company in the US, Canada, or Europe even without benefits, even at minimum wage, as long as they give me 40 hours per week, growth in skills, and opportunity to train/learn.&lt;/p&gt;

&lt;p&gt;So I&amp;#39;m just wondering how viable would that be in your experience with your companies, do you work remotely with people from other countries in entry-level roles?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17czsvd,True,,X_Drake,,13,True,all_ads,False,[],False,,/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,all_ads,False,https://www.reddit.com/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,1209065,1697885152.0,0,,False,,,,,,,,,,2295,407
,datascience,"Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. 

 I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  

If you could give me just a rough overview of how you approach a computer vision problem that'll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.

Also, there might be some knowledge gaps that I have, I feel like I have em, but I don't know what I don't know at this point. So, I just need someone who can maybe channel me in the right direction.",t2_hcgjj0xo,False,,0,False,Need some practical advice on choosing from different CNN model architectures.,[],r/datascience,False,6,discussion,0,,,False,t3_17cy5av,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697878087.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone. I would just like to discuss a few things. I&amp;#39;ve spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. &lt;/p&gt;

&lt;p&gt;I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  &lt;/p&gt;

&lt;p&gt;If you could give me just a rough overview of how you approach a computer vision problem that&amp;#39;ll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.&lt;/p&gt;

&lt;p&gt;Also, there might be some knowledge gaps that I have, I feel like I have em, but I don&amp;#39;t know what I don&amp;#39;t know at this point. So, I just need someone who can maybe channel me in the right direction.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17cy5av,True,,Total-Opposite-8396,,2,True,all_ads,False,[],False,,/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,1209065,1697878087.0,0,,False,,,,,,,,,,2068,350
,datascience,"I am studying Python and R to work in Data, and my mentor said that I should learn Java. I think it is regards to Machine Learning, but Python has an extensive libraries that helps offset it short fall. The problem that I can never finish a crash course book on Python is it's speed, but I read that NumPy and Pandas help make it faster. So my question is, what benefits are there to learn Java for Data Science if I see majority of people learn Python and most certification for data professions used Python and/or R?",t2_6npgrd5e,False,,0,False,Why should I learn Java if Python have libraries offset it shortfall?,[],r/datascience,False,6,,0,,,False,t3_17cv8nq,False,dark,0.84,,public,87,0,{},,,False,[],,False,False,,{},Coding,False,87,,False,False,self,False,,[],{},,True,,1697865801.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am studying Python and R to work in Data, and my mentor said that I should learn Java. I think it is regards to Machine Learning, but Python has an extensive libraries that helps offset it short fall. The problem that I can never finish a crash course book on Python is it&amp;#39;s speed, but I read that NumPy and Pandas help make it faster. So my question is, what benefits are there to learn Java for Data Science if I see majority of people learn Python and most certification for data professions used Python and/or R?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4ab9c418-70eb-11ee-8a37-4a495429ae82,False,False,False,,[],False,,,,t5_2sptq,False,,,#ffb000,17cv8nq,True,,Accomplished_Ad_5697,,77,True,all_ads,False,[],False,,/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,1209065,1697865801.0,0,,False,,,,,,,,,,518,98
,datascience,"Hi, I am trying to solve finance-related quadratic optimization problem using CVXPY python library. I have a maximize objective function with a Beta variable which is subject to certain constraints. I am getting the output for Beta values from 1-10. But at certain beta values (e.g., 0, 1), the output is optimally inaccurate and the objective is not even satisfying constraints. Why would the program give solutions which does not satisfy constraints? More generally, can someone recommend some literature to solve such problems?",t2_fl3qw8g3,False,,0,False,Help needed with a quadratic optimization problem,[],r/datascience,False,6,discussion,0,,,False,t3_17cnntn,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697841766.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am trying to solve finance-related quadratic optimization problem using CVXPY python library. I have a maximize objective function with a Beta variable which is subject to certain constraints. I am getting the output for Beta values from 1-10. But at certain beta values (e.g., 0, 1), the output is optimally inaccurate and the objective is not even satisfying constraints. Why would the program give solutions which does not satisfy constraints? More generally, can someone recommend some literature to solve such problems?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17cnntn,True,,BeginningDeer4329,,2,True,all_ads,False,[],False,,/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,1209065,1697841766.0,0,,False,,,,,,,,,,530,83
,datascience,"I'm building a product that integrates with your codebases and takes your database metadata to create dynamic documentation of your data. Every time someone makes a new code change that affects the data, you're updated with how the code change altered tables, labels, cols, etc.

Let me know if you'd like to try it out. I'll send you a link and would love to get your feedback.

I'll provide a repo and public postgres database that you can connect to demo (if you don't have one that you want to connect).",t2_cqdfu7nf4,False,,0,False,Inviting initial users for dynamic data documentation tool,[],r/datascience,False,6,tooling,0,,,False,t3_17clbmx,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Tooling,False,3,,False,False,self,False,,[],{},,True,,1697835580.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building a product that integrates with your codebases and takes your database metadata to create dynamic documentation of your data. Every time someone makes a new code change that affects the data, you&amp;#39;re updated with how the code change altered tables, labels, cols, etc.&lt;/p&gt;

&lt;p&gt;Let me know if you&amp;#39;d like to try it out. I&amp;#39;ll send you a link and would love to get your feedback.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ll provide a repo and public postgres database that you can connect to demo (if you don&amp;#39;t have one that you want to connect).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,17clbmx,True,,Different-General700,,5,True,all_ads,False,[],False,,/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,1209065,1697835580.0,0,,False,,,,,,,,,,507,91
,datascience,"I am trying to determine the amount of confounding and predictive power of the current experimental design is?  
I just started working on a project helping out with a test campaign of a fairly complicated system at my company. There are many variables that can be independently tuned, and there is a test series planned to 'qualify' the engine against its specification requirements.   


One of the objectives of the test series is to quantify the 'coefficient of influence' of a number of factors. Because of the number of factors involved, a full factorial DOE is out of the question, and because there are many objectives in the test series, its difficult to even design a nice, neat experimental design that follows canonical fractional factorial designs.   


We do have a test matrix built, and i was wondering if there is a way to just analyze what the predictive power of the current test matrix is in the first place. We know and accept that there will be some degree of confounding two-variable and three-variable + interaction effects in the main effects, which is alright for us. Is there a way to analyze what the amount of confounding and predictive power of the current experimental design is?  


Knowing the current capability and limitations of our experimental designs would be very helpful it turns out i need to propose alteration of our test matrix (which can be costly)  


I don't have any real statistics background, and i don't think our company would pay for a software like minitab and i don't know how to use such a software either.   


Any guidance on this problem would be most appreciated.   
",t2_5r8dd6x3,False,,0,False,Help with analysis of incomplete experimental design,[],r/datascience,False,6,network,0,,,False,t3_17cie3b,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Analysis,False,1,,False,False,self,False,,[],{},,True,,1697827588.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to determine the amount of confounding and predictive power of the current experimental design is?&lt;br/&gt;
I just started working on a project helping out with a test campaign of a fairly complicated system at my company. There are many variables that can be independently tuned, and there is a test series planned to &amp;#39;qualify&amp;#39; the engine against its specification requirements.   &lt;/p&gt;

&lt;p&gt;One of the objectives of the test series is to quantify the &amp;#39;coefficient of influence&amp;#39; of a number of factors. Because of the number of factors involved, a full factorial DOE is out of the question, and because there are many objectives in the test series, its difficult to even design a nice, neat experimental design that follows canonical fractional factorial designs.   &lt;/p&gt;

&lt;p&gt;We do have a test matrix built, and i was wondering if there is a way to just analyze what the predictive power of the current test matrix is in the first place. We know and accept that there will be some degree of confounding two-variable and three-variable + interaction effects in the main effects, which is alright for us. Is there a way to analyze what the amount of confounding and predictive power of the current experimental design is?  &lt;/p&gt;

&lt;p&gt;Knowing the current capability and limitations of our experimental designs would be very helpful it turns out i need to propose alteration of our test matrix (which can be costly)  &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t have any real statistics background, and i don&amp;#39;t think our company would pay for a software like minitab and i don&amp;#39;t know how to use such a software either.   &lt;/p&gt;

&lt;p&gt;Any guidance on this problem would be most appreciated.   &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,8addf236-d780-11e7-932d-0e90af9dfe6e,False,False,False,,[],False,,,,t5_2sptq,False,,,#dadada,17cie3b,True,,Usual-Goat,,4,True,all_ads,False,[],False,,/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,1209065,1697827588.0,0,,False,,,,,,,,,,1628,275
,datascience,"How would you encode information into improbable events? For example, if you could influence the outcome of a roulette wheel or lottery draw, over as long a period as necessary, what would be the most efficient way of encoding data into the outcomes?

Perhaps a better example would be drawing from a deck of a million unique cards, and only yelling yahtzee when a specific one is drawn. Say you can add a few extra of the card to the deck whenever you want and boost the probability slightly. That would theoretically increase the frequency of the yahtzees from the right timescale perspective.

So if our hero does a million shuffled drawings a day, he might get 0-3 yahtzees. With careful timing, you can slip an extra card into the deck whenever you want, doubling his probability for the next drawing.

How would you encode as much data as possible in the frequency of this man yelling yahtzee?",t2_4ud69uvr,False,,0,False,Can you fit a code in a gamble?,[],r/datascience,False,6,meta,0,,,False,t3_17cgmof,False,dark,0.44,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697822794.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How would you encode information into improbable events? For example, if you could influence the outcome of a roulette wheel or lottery draw, over as long a period as necessary, what would be the most efficient way of encoding data into the outcomes?&lt;/p&gt;

&lt;p&gt;Perhaps a better example would be drawing from a deck of a million unique cards, and only yelling yahtzee when a specific one is drawn. Say you can add a few extra of the card to the deck whenever you want and boost the probability slightly. That would theoretically increase the frequency of the yahtzees from the right timescale perspective.&lt;/p&gt;

&lt;p&gt;So if our hero does a million shuffled drawings a day, he might get 0-3 yahtzees. With careful timing, you can slip an extra card into the deck whenever you want, doubling his probability for the next drawing.&lt;/p&gt;

&lt;p&gt;How would you encode as much data as possible in the frequency of this man yelling yahtzee?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,481ee318-d77d-11e7-a4a3-0e8624d7129a,False,False,False,,[],False,,,,t5_2sptq,False,,,#7193ff,17cgmof,True,,LiterateSeagull,,20,True,all_ads,False,[],False,,/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,1209065,1697822794.0,0,,False,,,,,,,,,,899,158
,datascience,"In my entire career, I have never had a single manager that provided any value to me personally. Here's a recap of all of the managers I've had in my career. 


1. Terrific manager. Hired me, made me feel welcome, immediately left the company two weeks after I started



2. Replaced first manager, and immediately put me on performance improvement plan to try and get rid of me. Would find formatting errors, any sort of mistake or human error at all to tell me that I was a sloppy employee. Completely ignored any benefit I provided, and had no interest in working with me. Just wanted to build their own team, and I was in their way because I was already there


3. Hired me, and instead letting me get oriented into my role, decided to do what she called ""trial by fire"", just throw me into the deep and and see if I sink or swim. I excelled in my position, did everything better than expected, received praise often, but passed up for a promotion because only one person can be promoted. 


4. Completely incompetent, never actually did any of the subject that they were managing a team for. Ended up being fired for sexual harassment against many women on our team 



5. Came from another team to replace previous manager, gave me mountains of work and impossible goals and expectations to achieve, and even when achieving them, made up a bunch of excuses as to why I can't be promoted that made no sense. Glass ceiling, basically, can't be promoted unless you tell me that you want to be promoted, and X amount of years have passed, need X amount of outstanding performance reviews, etc


6. Actually a really good manager and all around good person. For the first year, great to work under them, they let me get situated in the role, let me get exposure to many different teams and departments, let me explore and provided coaching. However, after the first year, became very lazy as a manager. Never at their desk, always driving somewhere, scheduling meetings and then being 15 plus minutes late to them because again, they are driving somewhere, or not doing their job. Became extremely lazy and let errors slip through their fingers, and blame team members for them. Began making excuses when people wanted to be promoted 


7. The director above the previous manager in bullet point above. Completely worthless leader who came aboard to replace another director, and their first mission was to interrogate everyone on the team, and determine if their career goals were to stay in their current position. Anyone who desired career growth, or wanted to move up into management, or had career aspirations was immediately let go because they're ""Not a fit for our organizational goals"" 



The most common thing I have seen is that it is impossible to get promoted. Most positions at analyst level are designed so that no one can proceed into other positions because they want you to stay exactly where you are currently and not move up, they try to make it as difficult as possible for you to move up into other roles in the company. If you don't want to sit exactly where you are for at least 5 to 10 years, you're a bad employee, and there is no way to be promoted.",t2_dmawn6hx,False,,0,False,I have never had a manager in my entire career that provided any value to me,[],r/datascience,False,6,discussion,0,,,False,t3_17cfb97,False,dark,0.89,#dadada,public,258,0,{},,d898d418-70eb-11ee-81d7-36bf4b44216b,False,[],,False,False,,{},Discussion,False,258,,False,False,self,False,,[],{},,True,,1697819256.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my entire career, I have never had a single manager that provided any value to me personally. Here&amp;#39;s a recap of all of the managers I&amp;#39;ve had in my career. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Terrific manager. Hired me, made me feel welcome, immediately left the company two weeks after I started&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Replaced first manager, and immediately put me on performance improvement plan to try and get rid of me. Would find formatting errors, any sort of mistake or human error at all to tell me that I was a sloppy employee. Completely ignored any benefit I provided, and had no interest in working with me. Just wanted to build their own team, and I was in their way because I was already there&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hired me, and instead letting me get oriented into my role, decided to do what she called &amp;quot;trial by fire&amp;quot;, just throw me into the deep and and see if I sink or swim. I excelled in my position, did everything better than expected, received praise often, but passed up for a promotion because only one person can be promoted. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Completely incompetent, never actually did any of the subject that they were managing a team for. Ended up being fired for sexual harassment against many women on our team &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Came from another team to replace previous manager, gave me mountains of work and impossible goals and expectations to achieve, and even when achieving them, made up a bunch of excuses as to why I can&amp;#39;t be promoted that made no sense. Glass ceiling, basically, can&amp;#39;t be promoted unless you tell me that you want to be promoted, and X amount of years have passed, need X amount of outstanding performance reviews, etc&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Actually a really good manager and all around good person. For the first year, great to work under them, they let me get situated in the role, let me get exposure to many different teams and departments, let me explore and provided coaching. However, after the first year, became very lazy as a manager. Never at their desk, always driving somewhere, scheduling meetings and then being 15 plus minutes late to them because again, they are driving somewhere, or not doing their job. Became extremely lazy and let errors slip through their fingers, and blame team members for them. Began making excuses when people wanted to be promoted &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The director above the previous manager in bullet point above. Completely worthless leader who came aboard to replace another director, and their first mission was to interrogate everyone on the team, and determine if their career goals were to stay in their current position. Anyone who desired career growth, or wanted to move up into management, or had career aspirations was immediately let go because they&amp;#39;re &amp;quot;Not a fit for our organizational goals&amp;quot; &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The most common thing I have seen is that it is impossible to get promoted. Most positions at analyst level are designed so that no one can proceed into other positions because they want you to stay exactly where you are currently and not move up, they try to make it as difficult as possible for you to move up into other roles in the company. If you don&amp;#39;t want to sit exactly where you are for at least 5 to 10 years, you&amp;#39;re a bad employee, and there is no way to be promoted.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,Junior,[],False,,,,t5_2sptq,False,,,,17cfb97,True,,InevitableTraining69,,134,True,all_ads,False,[],False,dark,/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,1209065,1697819256.0,0,,False,,,,,,,,,,3178,565
,datascience,"I know this is likely to be controversial but I wanted to open up the discussion.

I think most problems and datasets should be split by time rather than uniform iid sampling for train-valid-test.

I almost always get pushback when I suggest this because it makes cross-validation more difficult to implement and can reduce the training dataset size in some folds.

Most people will say it's not necessary to split by time (e.g. test set in the future relative to train) because there is no time-wise dependency. However, the problem is that almost every data distribution involving human interactions will tend to shift over time and contain some dependency.

Let me give you one example: Let's say we have a web app that lets users submit a picture of an animal and we predict whether it's a dog or not. This seems like a simple problem where you could split by iid because there can't be any data leakage, right?

But if you think about it, the distribution of photos that get submitted is likely to change over time. It could be from new dog breeds becoming more popular, or from a shift in the types of users that use the platform and the dogs they submit. It could even be due to new phones/cameras being used, or people start posing their photos slightly differently or maybe covid hits and now your service is only getting indoor photos with different lighting whereas previously you got mostly outdoor shots.

These are all hypothetical examples and you could come up with a million different ones. The point being that the distribution of data for many many (most?) problems will change over time and our goal is almost always to train on historical data and predict on future unseen data.

So with that context, I think it often makes sense to at least test a time-split approach and observe whether there's a difference with simple iid CV approach. I think you could possibly be surprised by the result.",t2_w13qq97a,False,,0,False,Dataset splitting by time &amp; why you should do it,[],r/datascience,False,6,discussion,0,,,False,t3_17cce10,False,dark,0.82,,public,25,0,{},,,False,[],,False,False,,{},Discussion,False,25,,False,False,self,1697812122.0,,[],{},,True,,1697811549.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know this is likely to be controversial but I wanted to open up the discussion.&lt;/p&gt;

&lt;p&gt;I think most problems and datasets should be split by time rather than uniform iid sampling for train-valid-test.&lt;/p&gt;

&lt;p&gt;I almost always get pushback when I suggest this because it makes cross-validation more difficult to implement and can reduce the training dataset size in some folds.&lt;/p&gt;

&lt;p&gt;Most people will say it&amp;#39;s not necessary to split by time (e.g. test set in the future relative to train) because there is no time-wise dependency. However, the problem is that almost every data distribution involving human interactions will tend to shift over time and contain some dependency.&lt;/p&gt;

&lt;p&gt;Let me give you one example: Let&amp;#39;s say we have a web app that lets users submit a picture of an animal and we predict whether it&amp;#39;s a dog or not. This seems like a simple problem where you could split by iid because there can&amp;#39;t be any data leakage, right?&lt;/p&gt;

&lt;p&gt;But if you think about it, the distribution of photos that get submitted is likely to change over time. It could be from new dog breeds becoming more popular, or from a shift in the types of users that use the platform and the dogs they submit. It could even be due to new phones/cameras being used, or people start posing their photos slightly differently or maybe covid hits and now your service is only getting indoor photos with different lighting whereas previously you got mostly outdoor shots.&lt;/p&gt;

&lt;p&gt;These are all hypothetical examples and you could come up with a million different ones. The point being that the distribution of data for many many (most?) problems will change over time and our goal is almost always to train on historical data and predict on future unseen data.&lt;/p&gt;

&lt;p&gt;So with that context, I think it often makes sense to at least test a time-split approach and observe whether there&amp;#39;s a difference with simple iid CV approach. I think you could possibly be surprised by the result.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17cce10,True,,Ty4Readin,,49,True,all_ads,False,[],False,,/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,all_ads,False,https://www.reddit.com/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,1209065,1697811549.0,0,,False,,,,,,,,,,1915,335
,datascience,"I’ve been working as a DS for a couple of years now and would like to share my thoughts on the role(s).


- Big corp: Benefits and salary good but can get stuck in deploying large products where your hard earned skills aren’t used. Best place to be during new projects where you accumulate alot of skills from SWE, IT and more.


- Consulting: Not Big4 but what I’ve experienced is basically BI and DE. The managers have no idea what DS is and just regurgitates names of cloud services. Compensation model is outdated and not realistic for DS. 


What are your experiences?",t2_cl2gh7jh,False,,0,False,Thoughts on DS roles,[],r/datascience,False,6,discussion,0,,,False,t3_17c78g5,False,dark,0.91,,public,26,0,{},,,False,[],,False,False,,{},Discussion,False,26,,False,False,self,False,,[],{},,True,,1697794539.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been working as a DS for a couple of years now and would like to share my thoughts on the role(s).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Big corp: Benefits and salary good but can get stuck in deploying large products where your hard earned skills aren’t used. Best place to be during new projects where you accumulate alot of skills from SWE, IT and more.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Consulting: Not Big4 but what I’ve experienced is basically BI and DE. The managers have no idea what DS is and just regurgitates names of cloud services. Compensation model is outdated and not realistic for DS. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What are your experiences?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17c78g5,True,,Stochastic_berserker,,15,True,all_ads,False,[],False,,/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,all_ads,False,https://www.reddit.com/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,1209065,1697794539.0,0,,False,,,,,,,,,,573,103
,datascience,"In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don't see much talk about this skill/use case of analytics. So curious to hear other's thoughts and experiences. Do you concur? Why or why not?

PS: I understand it's probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don't fall in this category. Pls feel free to bunk this too!",t2_9axqyq8u,False,,0,False,Do you use CRUD or like apps to bridge the gap between business users and DS/DA teams?,[],r/datascience,False,6,discussion,0,,,False,t3_17c2u6b,False,dark,0.82,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,1697782002.0,,[],{},,True,,1697776462.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don&amp;#39;t see much talk about this skill/use case of analytics. So curious to hear other&amp;#39;s thoughts and experiences. Do you concur? Why or why not?&lt;/p&gt;

&lt;p&gt;PS: I understand it&amp;#39;s probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don&amp;#39;t fall in this category. Pls feel free to bunk this too!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17c2u6b,True,,Difficult-Big-3890,,17,True,all_ads,False,[],False,,/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,all_ads,False,https://www.reddit.com/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,1209065,1697776462.0,0,,False,,,,,,,,,,581,105
,datascience,"Hello, 

I’ve been reading up some articles from kaggle and blogs about data imputation. I’m wondering if there’s a complete guide that introduces all the methods to data imputation. I’m interested to see all the pros and cons and the usage of different situations. 

Thanks for sharing!",t2_snz8uvf5,False,,0,False,Any data imputation technique shares?,[],r/datascience,False,6,discussion,0,,,False,t3_17c0z6e,False,dark,0.83,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,False,self,False,,[],{},,True,,1697770197.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, &lt;/p&gt;

&lt;p&gt;I’ve been reading up some articles from kaggle and blogs about data imputation. I’m wondering if there’s a complete guide that introduces all the methods to data imputation. I’m interested to see all the pros and cons and the usage of different situations. &lt;/p&gt;

&lt;p&gt;Thanks for sharing!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17c0z6e,True,,EthicalArtisan,,15,True,all_ads,False,[],False,,/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,all_ads,False,https://www.reddit.com/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,1209065,1697770197.0,0,,False,,,,,,,,,,287,47
,datascience,"Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won't suit my current job. I'm thinking S3, but wondering if anyone has a better idea. Haven't used Git LFS either so curious about this one too. Cheers",t2_xfx8ms4,False,,0,False,Sharing large files for collaboration,[],r/datascience,False,6,discussion,0,,,False,t3_17bxccu,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697759392.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won&amp;#39;t suit my current job. I&amp;#39;m thinking S3, but wondering if anyone has a better idea. Haven&amp;#39;t used Git LFS either so curious about this one too. Cheers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bxccu,True,,HStuart18,,3,True,all_ads,False,[],False,,/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,1209065,1697759392.0,0,,False,,,,,,,,,,361,70
,datascience,"In my past work I've become familiar with various techniques for *predictive* modeling--NNs, of course, but also more ""classical"" methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I've loved using sklearn and nltk, and I haven't even gotten to using pytorch yet).

All that said, I haven't worked as much so far with *explanatory* modeling and I'm looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What's more, in the explanatory environment, there's a much greater emphasis on *model interpretability*--that is to say, models like NNs or even random forests that can get kind of ""black boxy"" are disfavored compared to simpler models with much more straightforward interpretability.

So what's the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??",t2_jzcyr,False,,0,False,Predictive vs Explanatory modeling,[],r/datascience,False,6,discussion,0,,,False,t3_17bqhb0,False,dark,0.87,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,False,self,False,,[],{},,True,,1697741452.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my past work I&amp;#39;ve become familiar with various techniques for &lt;em&gt;predictive&lt;/em&gt; modeling--NNs, of course, but also more &amp;quot;classical&amp;quot; methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I&amp;#39;ve loved using sklearn and nltk, and I haven&amp;#39;t even gotten to using pytorch yet).&lt;/p&gt;

&lt;p&gt;All that said, I haven&amp;#39;t worked as much so far with &lt;em&gt;explanatory&lt;/em&gt; modeling and I&amp;#39;m looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What&amp;#39;s more, in the explanatory environment, there&amp;#39;s a much greater emphasis on &lt;em&gt;model interpretability&lt;/em&gt;--that is to say, models like NNs or even random forests that can get kind of &amp;quot;black boxy&amp;quot; are disfavored compared to simpler models with much more straightforward interpretability.&lt;/p&gt;

&lt;p&gt;So what&amp;#39;s the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bqhb0,True,,19andoverlol,,25,True,all_ads,False,[],False,,/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,1209065,1697741452.0,0,,False,,,,,,,,,,1143,171
,datascience,"I have a very broad question about building a model using xgboost and feature selection. 

As an example, let’s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score &gt; x. 

In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it’s due to random chance. 

My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.",t2_hs2uczj7,False,,0,False,Wrong data in dataset,[],r/datascience,False,6,discussion,0,,,False,t3_17bobx9,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697735878.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a very broad question about building a model using xgboost and feature selection. &lt;/p&gt;

&lt;p&gt;As an example, let’s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score &amp;gt; x. &lt;/p&gt;

&lt;p&gt;In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it’s due to random chance. &lt;/p&gt;

&lt;p&gt;My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bobx9,True,,Kilroy_was_here__,,2,True,all_ads,False,[],False,,/r/datascience/comments/17bobx9/wrong_data_in_dataset/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bobx9/wrong_data_in_dataset/,1209065,1697735878.0,0,,False,,,,,,,,,,686,129
,datascience,"Mods, where are you? There are countless posts every week with questions that were answered already.  

Should I learn Python? 
Masters degree worth it?
Job market sucks, what projects should I do?

All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren’t even phrased correctly.

All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.",t2_4udseb4x,False,,0,False,[rant] Required - A designated tread for transitioning to DS and repeating questions,[],r/datascience,False,6,discussion,0,,,False,t3_17bmc70,False,dark,0.81,,public,46,0,{},,,False,[],,False,False,,{},Discussion,False,46,,False,False,self,False,,[],{},,True,,1697730631.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Mods, where are you? There are countless posts every week with questions that were answered already.  &lt;/p&gt;

&lt;p&gt;Should I learn Python? 
Masters degree worth it?
Job market sucks, what projects should I do?&lt;/p&gt;

&lt;p&gt;All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren’t even phrased correctly.&lt;/p&gt;

&lt;p&gt;All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bmc70,True,,David202023,,25,True,all_ads,False,[],False,,/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,1209065,1697730631.0,0,,False,,,,,,,,,,777,135
,datascience,"I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.",t2_k17nck5e2,False,,0,False,Use cases of Advanced Math in Data Science and Machine Learning,[],r/datascience,False,6,discussion,0,,,False,t3_17bg00y,False,dark,0.9,,public,31,0,{},,,False,[],,False,False,,{},Discussion,False,31,,False,False,self,1697711887.0,,[],{},,True,,1697711491.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bg00y,True,,honghuiying,,20,True,all_ads,False,[],False,,/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,1209065,1697711491.0,0,,False,,,,,,,,,,478,88
,datascience,"&amp;#x200B;

## Python

Undoubtedly, **the uncrowned king** of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching, **is Python**. This is down to several reasons; the three most important among them are its **maturity**, the enormous **community**, and, last but not least, a **vast array of robust third-party libraries**. But even if Python is a magnanimous sovereign that many developers love, it doesn’t mean that there can’t be contenders occasionally.

## Julia

Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a **friendly syntax**, offers **efficient mathematical computations** out of the box, at a **performance on par with compiled languages**. And thus, [**Julia**](https://julialang.org/) was born (here’s a manifesto explaining [**why**](https://julialang.org/blog/2012/02/why-we-created-julia/) in more detail). Its first version was launched a bit more than eleven years ago.

## Our choice

Many in-depth comparisons of Python and Julia on the web (such as [**this one**](https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac) or [**this**](https://www.turing.com/kb/julia-vs-python)) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia’s growing popularity, we are sure more will follow. In the rest of this blog post, however, let’s explore why we picked Julia for our purposes. And that’s not to say that we don’t use Python for data science. On the contrary, we **often run analyses in both ecosystems simultaneously** to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.

## The advantages of Julia

So what makes Julia so compelling to us?

## Language features

Julia has:

* a friendly, easy-to-read (and write) syntax;
*  a flexible and expressive (part static, part dynamic) type system;
*  powerful mathematical notations, such as built-in vector and matrix operations;
*  efficient [**multiple dispatches**](https://en.wikipedia.org/wiki/Multiple_dispatch), a form of function polymorphism working with runtime types;
*  convenient and reliable parallel computing facilities;
*  meta-programming with macros and generated functions.

## Fast code execution

Julia compiles the source code to **native binary at runtime** via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer; **the benefits start to shine when a piece of code is run multiple times**. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.

## Built-in package management

Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of **stable and well-designed packages** is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.

## Interactive tools

Julia offers an **advanced** [**REPL**](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) with all the goodies of an interpreted language environment. These include:

* code and variable inspection,
*  code completion,
*  an interactive debugger,
*  benchmarking and profiling tools,
*  and a built-in help system.

**With third-party libraries, it can also be extended** with [**syntax highlighting**](https://github.com/KristofferC/OhMyREPL.jl), [**source code lookup**](https://github.com/tkf/InteractiveCodeSearch.jl) (even for base libraries), automatic [**code reload**](https://timholy.github.io/Revise.jl/stable/), and many more exciting, modern features.

All these together make Julia an **ideal environment for rapid prototyping**.

## From prototyping to production code

Because of the high-level interactive tools and fast code execution, **the transition from a rapid prototype to production-ready code can be as continuous as you’d like**. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.

Thanks to its friendly syntax and built-in package management, **the road to maintainable code is well paved**. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.

As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.

## The disadvantages of Julia

That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:

* the very powerful tool of broadcasting and vectorization can be intimidating at first;
* [**time to first plot**](https://discourse.julialang.org/t/time-to-first-plot-clarification/58534) can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;
*  many packages never reach a stable state or just become unmaintained; others are poorly designed or written;
* [**releasing a binary package**](https://github.com/JuliaLang/PackageCompiler.jl) can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.

## Summary

In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.

Still, in the past years, **Julia has proved to be our reliable and faithful companion**. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!",t2_gbypvyyx9,False,,0,False,Programming language for machine learning and data analysis – Our choice,[],r/datascience,False,6,discussion,0,,,False,t3_17bf3cx,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697707699.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;h2&gt;Python&lt;/h2&gt;

&lt;p&gt;Undoubtedly, &lt;strong&gt;the uncrowned king&lt;/strong&gt; of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching, &lt;strong&gt;is Python&lt;/strong&gt;. This is down to several reasons; the three most important among them are its &lt;strong&gt;maturity&lt;/strong&gt;, the enormous &lt;strong&gt;community&lt;/strong&gt;, and, last but not least, a &lt;strong&gt;vast array of robust third-party libraries&lt;/strong&gt;. But even if Python is a magnanimous sovereign that many developers love, it doesn’t mean that there can’t be contenders occasionally.&lt;/p&gt;

&lt;h2&gt;Julia&lt;/h2&gt;

&lt;p&gt;Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a &lt;strong&gt;friendly syntax&lt;/strong&gt;, offers &lt;strong&gt;efficient mathematical computations&lt;/strong&gt; out of the box, at a &lt;strong&gt;performance on par with compiled languages&lt;/strong&gt;. And thus, &lt;a href=""https://julialang.org/""&gt;&lt;strong&gt;Julia&lt;/strong&gt;&lt;/a&gt; was born (here’s a manifesto explaining &lt;a href=""https://julialang.org/blog/2012/02/why-we-created-julia/""&gt;&lt;strong&gt;why&lt;/strong&gt;&lt;/a&gt; in more detail). Its first version was launched a bit more than eleven years ago.&lt;/p&gt;

&lt;h2&gt;Our choice&lt;/h2&gt;

&lt;p&gt;Many in-depth comparisons of Python and Julia on the web (such as &lt;a href=""https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac""&gt;&lt;strong&gt;this one&lt;/strong&gt;&lt;/a&gt; or &lt;a href=""https://www.turing.com/kb/julia-vs-python""&gt;&lt;strong&gt;this&lt;/strong&gt;&lt;/a&gt;) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia’s growing popularity, we are sure more will follow. In the rest of this blog post, however, let’s explore why we picked Julia for our purposes. And that’s not to say that we don’t use Python for data science. On the contrary, we &lt;strong&gt;often run analyses in both ecosystems simultaneously&lt;/strong&gt; to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.&lt;/p&gt;

&lt;h2&gt;The advantages of Julia&lt;/h2&gt;

&lt;p&gt;So what makes Julia so compelling to us?&lt;/p&gt;

&lt;h2&gt;Language features&lt;/h2&gt;

&lt;p&gt;Julia has:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a friendly, easy-to-read (and write) syntax;&lt;/li&gt;
&lt;li&gt; a flexible and expressive (part static, part dynamic) type system;&lt;/li&gt;
&lt;li&gt; powerful mathematical notations, such as built-in vector and matrix operations;&lt;/li&gt;
&lt;li&gt; efficient &lt;a href=""https://en.wikipedia.org/wiki/Multiple_dispatch""&gt;&lt;strong&gt;multiple dispatches&lt;/strong&gt;&lt;/a&gt;, a form of function polymorphism working with runtime types;&lt;/li&gt;
&lt;li&gt; convenient and reliable parallel computing facilities;&lt;/li&gt;
&lt;li&gt; meta-programming with macros and generated functions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Fast code execution&lt;/h2&gt;

&lt;p&gt;Julia compiles the source code to &lt;strong&gt;native binary at runtime&lt;/strong&gt; via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer; &lt;strong&gt;the benefits start to shine when a piece of code is run multiple times&lt;/strong&gt;. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.&lt;/p&gt;

&lt;h2&gt;Built-in package management&lt;/h2&gt;

&lt;p&gt;Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of &lt;strong&gt;stable and well-designed packages&lt;/strong&gt; is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.&lt;/p&gt;

&lt;h2&gt;Interactive tools&lt;/h2&gt;

&lt;p&gt;Julia offers an &lt;strong&gt;advanced&lt;/strong&gt; &lt;a href=""https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop""&gt;&lt;strong&gt;REPL&lt;/strong&gt;&lt;/a&gt; with all the goodies of an interpreted language environment. These include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;code and variable inspection,&lt;/li&gt;
&lt;li&gt; code completion,&lt;/li&gt;
&lt;li&gt; an interactive debugger,&lt;/li&gt;
&lt;li&gt; benchmarking and profiling tools,&lt;/li&gt;
&lt;li&gt; and a built-in help system.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;With third-party libraries, it can also be extended&lt;/strong&gt; with &lt;a href=""https://github.com/KristofferC/OhMyREPL.jl""&gt;&lt;strong&gt;syntax highlighting&lt;/strong&gt;&lt;/a&gt;, &lt;a href=""https://github.com/tkf/InteractiveCodeSearch.jl""&gt;&lt;strong&gt;source code lookup&lt;/strong&gt;&lt;/a&gt; (even for base libraries), automatic &lt;a href=""https://timholy.github.io/Revise.jl/stable/""&gt;&lt;strong&gt;code reload&lt;/strong&gt;&lt;/a&gt;, and many more exciting, modern features.&lt;/p&gt;

&lt;p&gt;All these together make Julia an &lt;strong&gt;ideal environment for rapid prototyping&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;From prototyping to production code&lt;/h2&gt;

&lt;p&gt;Because of the high-level interactive tools and fast code execution, &lt;strong&gt;the transition from a rapid prototype to production-ready code can be as continuous as you’d like&lt;/strong&gt;. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.&lt;/p&gt;

&lt;p&gt;Thanks to its friendly syntax and built-in package management, &lt;strong&gt;the road to maintainable code is well paved&lt;/strong&gt;. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.&lt;/p&gt;

&lt;p&gt;As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.&lt;/p&gt;

&lt;h2&gt;The disadvantages of Julia&lt;/h2&gt;

&lt;p&gt;That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the very powerful tool of broadcasting and vectorization can be intimidating at first;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://discourse.julialang.org/t/time-to-first-plot-clarification/58534""&gt;&lt;strong&gt;time to first plot&lt;/strong&gt;&lt;/a&gt; can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;&lt;/li&gt;
&lt;li&gt; many packages never reach a stable state or just become unmaintained; others are poorly designed or written;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JuliaLang/PackageCompiler.jl""&gt;&lt;strong&gt;releasing a binary package&lt;/strong&gt;&lt;/a&gt; can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.&lt;/p&gt;

&lt;p&gt;Still, in the past years, &lt;strong&gt;Julia has proved to be our reliable and faithful companion&lt;/strong&gt;. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bf3cx,True,,CursorInsight,,18,True,all_ads,False,[],False,,/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,1209065,1697707699.0,1,,False,,,,,,,,,,6920,982
,datascience,"Hi all,

I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.

Do you know why gaze angular error is not used as loss as well?

&amp;#x200B;

\[Edit\]

I tried now angular error as loss and it is really terrible. 

Like L1 loss results in a gaze angle error of around 2°, while my custom loss is resulting in errors around 50°. I though about using multi-loss approach, for example l1 + angular error to consider the depth length. What do you guys think of that?",t2_8hi7gpok,False,,0,False,Different loss function than evaluation metric,[],r/datascience,False,6,projects,0,,,False,t3_17becn2,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Projects,False,3,,False,False,self,1697811936.0,,[],{},,True,,1697704437.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.&lt;/p&gt;

&lt;p&gt;Do you know why gaze angular error is not used as loss as well?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;[Edit]&lt;/p&gt;

&lt;p&gt;I tried now angular error as loss and it is really terrible. &lt;/p&gt;

&lt;p&gt;Like L1 loss results in a gaze angle error of around 2°, while my custom loss is resulting in errors around 50°. I though about using multi-loss approach, for example l1 + angular error to consider the depth length. What do you guys think of that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17becn2,True,,mesheaa,,2,True,all_ads,False,[],False,,/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,all_ads,False,https://www.reddit.com/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,1209065,1697704437.0,0,,False,,,,,,,,,,833,154
,datascience,"Hi everyone!  
Is it possible to create a market timing strategy using unsupervised learning? 

Let's find out.

Relevant Topics:

* Used S&amp;P500 data
* Segmenting Time series using Online Change Detection Point
* Clustering segments with KMeans
* Risk Allocation
* Value at Risk

Here's the notebook:  
[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&amp;M",t2_81hr0pq4,False,,0,False,Market Timing &amp; Risk Management - Portfolio allocation,[],r/datascience,False,6,projects,0,,,False,t3_17bdzis,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697702807.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;
Is it possible to create a market timing strategy using unsupervised learning? &lt;/p&gt;

&lt;p&gt;Let&amp;#39;s find out.&lt;/p&gt;

&lt;p&gt;Relevant Topics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Used S&amp;amp;P500 data&lt;/li&gt;
&lt;li&gt;Segmenting Time series using Online Change Detection Point&lt;/li&gt;
&lt;li&gt;Clustering segments with KMeans&lt;/li&gt;
&lt;li&gt;Risk Allocation&lt;/li&gt;
&lt;li&gt;Value at Risk&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here&amp;#39;s the notebook:&lt;br/&gt;
&lt;a href=""https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook""&gt;https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Every and each comment / feedback is greatly appreciated!&lt;/p&gt;

&lt;p&gt;Thank you!&lt;br/&gt;
M&amp;amp;M&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17bdzis,True,,MandM-DataScience,,0,True,all_ads,False,[],False,,/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,all_ads,False,https://www.reddit.com/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,1209065,1697702807.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/pGkUiqnzs5jbCTZHIr5iqbS-02twocrs_Rcv-L6QkD8.jpg?auto=webp&amp;s=22521ebf2516bed4d65862aff258ed16364f9bc0', 'width': 100, 'height': 100}, 'resolutions': [], 'variants': {}, 'id': '1jf__EqbE3dYF9fUHKWvv0as9QmxITBOHBbPBchNPHQ'}], 'enabled': False}",,,,,,,552,60
,datascience,"Hi! I am currently working on a binary classification model for a highly imbalanced dataset with lots of missing values in there. I tried using multiple techniques for resampling (Random, SMOTE, and SMOTETomak) and imputation (MICE), as well as a bit of tweaking of class weights and loss function, but still I am not able to get higher than this.

CatBoost Accuracy:  0.843492894540015
              precision    recall  f1-score   support

         0.0       0.95      0.87      0.91      4775
         1.0       0.36      0.62      0.46       573

    accuracy                           0.84      5348
   macro avg       0.66      0.74      0.68      5348
weighted avg       0.89      0.84      0.86      5348

Any ideas on what can I also try considering such results and above mentioned trials? Any feature engineering techniques that I might not know? 

Also one of the interesting things about dataset is relatively large amount of categorical features - 30 out of 140 (two of them have 2k different options, others are in the range from 3 to 30). I used multiple different methods for encoding here depending on the amount of categories - One Hot, Binary and Target.

One of the main issues of the dataset is lack of context so I'm mostly trying to improve both precision and recall (and f1 as a result) at least to somewhat degree.

Thanks in advance for any possible ideas?",t2_uitvt,False,,0,False,Advice on imbalanced datasets with many missing values,[],r/datascience,False,6,discussion,0,,,False,t3_17b3lup,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697668940.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I am currently working on a binary classification model for a highly imbalanced dataset with lots of missing values in there. I tried using multiple techniques for resampling (Random, SMOTE, and SMOTETomak) and imputation (MICE), as well as a bit of tweaking of class weights and loss function, but still I am not able to get higher than this.&lt;/p&gt;

&lt;p&gt;CatBoost Accuracy:  0.843492894540015
              precision    recall  f1-score   support&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     0.0       0.95      0.87      0.91      4775
     1.0       0.36      0.62      0.46       573

accuracy                           0.84      5348
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;macro avg       0.66      0.74      0.68      5348
weighted avg       0.89      0.84      0.86      5348&lt;/p&gt;

&lt;p&gt;Any ideas on what can I also try considering such results and above mentioned trials? Any feature engineering techniques that I might not know? &lt;/p&gt;

&lt;p&gt;Also one of the interesting things about dataset is relatively large amount of categorical features - 30 out of 140 (two of them have 2k different options, others are in the range from 3 to 30). I used multiple different methods for encoding here depending on the amount of categories - One Hot, Binary and Target.&lt;/p&gt;

&lt;p&gt;One of the main issues of the dataset is lack of context so I&amp;#39;m mostly trying to improve both precision and recall (and f1 as a result) at least to somewhat degree.&lt;/p&gt;

&lt;p&gt;Thanks in advance for any possible ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17b3lup,True,,_degamus_,,5,True,all_ads,False,[],False,,/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,all_ads,False,https://www.reddit.com/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,1209065,1697668940.0,0,,False,,,,,,,,,,1383,211
,datascience,"Do you still perform technical duties or is it nonstop meetings and people management? If it's the latter, do you miss the hands-on technical aspects or is it better on the leadership side?",t2_131bi6,False,,0,False,"Those that have moved from a technical position to a leadership/supervisory position, do you regret it?",[],r/datascience,False,6,discussion,0,,,False,t3_17b32vd,False,dark,0.94,,public,47,0,{},,,False,[],,False,False,,{},Discussion,False,47,,False,False,self,False,,[],{},,True,,1697667537.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you still perform technical duties or is it nonstop meetings and people management? If it&amp;#39;s the latter, do you miss the hands-on technical aspects or is it better on the leadership side?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17b32vd,True,,WadeEffingWilson,,40,True,all_ads,False,[],False,,/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,all_ads,False,https://www.reddit.com/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,1209065,1697667537.0,0,,False,,,,,,,,,,189,33
,datascience,"So I’m trying to build a model to find some inappropriate payments. So I have the data of all payments made, however, some of them were audited while the vast majority aren’t. 

The ones that aren’t audited are just automatically approved while the ones that are audited are approved or rejected based on auditors judgment. So my plan is to just use all the payments that has been audited as the population and ignore the payments that have never been audited since they don’t really tell us much.  

So probably about 1% of payments are audited and if that about 7% are rejected. 

Now the issue is that most of the payments that were rejected were for minor issues. Maybe the person who’s entered the payment made a slight typo for the invoice number, so that was rejected and they had to resubmit it, or something minor. 

Those payments aren’t abiding by some minor rules and they need to be rejected and resubmitted after being corrected. They’re wrong but not really worth the time because we aren’t saving any money. Unfortunately, that’s about 70% of rejected payments. 

Now the other 30% is where the real savings is happening, potential fraud, the accountant mistyped the amount to be paid or whatever. And that’s what I’m really trying to find, if I find the others that’s cool but doesn’t really do much. 

How would I go about selecting my data for that. Would I just ignore the 60% of rejected payments that aren’t that big of a deal and proceed without. If so, would I also reduce the number the number of payments that were accepted as well by 60%. 

Or any alternative suggestions?",t2_8cjp70ft,False,,0,False,Binary classification question?,[],r/datascience,False,6,discussion,0,,,False,t3_17b2d08,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697665699.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I’m trying to build a model to find some inappropriate payments. So I have the data of all payments made, however, some of them were audited while the vast majority aren’t. &lt;/p&gt;

&lt;p&gt;The ones that aren’t audited are just automatically approved while the ones that are audited are approved or rejected based on auditors judgment. So my plan is to just use all the payments that has been audited as the population and ignore the payments that have never been audited since they don’t really tell us much.  &lt;/p&gt;

&lt;p&gt;So probably about 1% of payments are audited and if that about 7% are rejected. &lt;/p&gt;

&lt;p&gt;Now the issue is that most of the payments that were rejected were for minor issues. Maybe the person who’s entered the payment made a slight typo for the invoice number, so that was rejected and they had to resubmit it, or something minor. &lt;/p&gt;

&lt;p&gt;Those payments aren’t abiding by some minor rules and they need to be rejected and resubmitted after being corrected. They’re wrong but not really worth the time because we aren’t saving any money. Unfortunately, that’s about 70% of rejected payments. &lt;/p&gt;

&lt;p&gt;Now the other 30% is where the real savings is happening, potential fraud, the accountant mistyped the amount to be paid or whatever. And that’s what I’m really trying to find, if I find the others that’s cool but doesn’t really do much. &lt;/p&gt;

&lt;p&gt;How would I go about selecting my data for that. Would I just ignore the 60% of rejected payments that aren’t that big of a deal and proceed without. If so, would I also reduce the number the number of payments that were accepted as well by 60%. &lt;/p&gt;

&lt;p&gt;Or any alternative suggestions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17b2d08,True,,CaptainVJ,,1,True,all_ads,False,[],False,,/r/datascience/comments/17b2d08/binary_classification_question/,all_ads,False,https://www.reddit.com/r/datascience/comments/17b2d08/binary_classification_question/,1209065,1697665699.0,0,,False,,,,,,,,,,1599,282
,datascience,"I'm a data scientist with 5 yoe now, and I've never needed to implement a tree, a linked list, a graph, a stack, or a queue. If I need a decision tree, I use a package like sklearn. If I'm doing graph analysis, typically I treat it like a matrix. I don't even have any idea what models might need a queue, but maybe that's really important for data processing or training somewhere?

&amp;#x200B;

Have any of you really needed to implement these data structures, or do you just use packages that are using them under the hood? Would I actually be meaningfully better at my day to day job if I knew when and how to use a linked list or a stack?",t2_50gkezqw,False,,0,False,Will Understanding Advanced Data Structures Make Me a Better Data Scientist?,[],r/datascience,False,6,discussion,0,,,False,t3_17az6v2,False,dark,0.86,,public,26,0,{},,,False,[],,False,False,,{},Discussion,False,26,,False,False,self,False,,[],{},,True,,1697657516.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a data scientist with 5 yoe now, and I&amp;#39;ve never needed to implement a tree, a linked list, a graph, a stack, or a queue. If I need a decision tree, I use a package like sklearn. If I&amp;#39;m doing graph analysis, typically I treat it like a matrix. I don&amp;#39;t even have any idea what models might need a queue, but maybe that&amp;#39;s really important for data processing or training somewhere?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Have any of you really needed to implement these data structures, or do you just use packages that are using them under the hood? Would I actually be meaningfully better at my day to day job if I knew when and how to use a linked list or a stack?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17az6v2,True,,EagerMonkey,,13,True,all_ads,False,[],False,,/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,all_ads,False,https://www.reddit.com/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,1209065,1697657516.0,0,,False,,,,,,,,,,644,124
,datascience,"I've been offered the opportunity to transfer to my firm's IT department after I expressed interested in and demonstrated proficiency in data science (coming from a quantitative but not pure DS department). The IT department doesn't have a specific data science ""role"" though -- only software developer and business analyst. Given I want to eventually settle into a pure data scientist role -- and pursue a Masters in such (I'm 24) -- which of these two roles would you choose if you were taking a career-level view? 

In the software dev role, I'd get hands-on experience with writing code everyday, but it would be chiefly in a software development environment -- not data science. With the BA role, I would have hands-on experience with product management and dashboarding and Confluence, but not so much writing code. I'm torn. I just ultimately want to be in a role where I can dive into datasets everyday and always have a numpy-pandas-matplotlib-sklearn environment open on my computer.

Any advice would be greatly appreciated! Thanks so much.",t2_m1lpv0ife,False,,0,False,"What's better as a data scientist ""precursor role"": a software developer or a business analyst?",[],r/datascience,False,6,discussion,0,,,False,t3_17ay21z,False,dark,0.86,,public,40,0,{},,,False,[],,False,False,,{},Discussion,False,40,,False,False,self,False,,[],{},,True,,1697654659.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been offered the opportunity to transfer to my firm&amp;#39;s IT department after I expressed interested in and demonstrated proficiency in data science (coming from a quantitative but not pure DS department). The IT department doesn&amp;#39;t have a specific data science &amp;quot;role&amp;quot; though -- only software developer and business analyst. Given I want to eventually settle into a pure data scientist role -- and pursue a Masters in such (I&amp;#39;m 24) -- which of these two roles would you choose if you were taking a career-level view? &lt;/p&gt;

&lt;p&gt;In the software dev role, I&amp;#39;d get hands-on experience with writing code everyday, but it would be chiefly in a software development environment -- not data science. With the BA role, I would have hands-on experience with product management and dashboarding and Confluence, but not so much writing code. I&amp;#39;m torn. I just ultimately want to be in a role where I can dive into datasets everyday and always have a numpy-pandas-matplotlib-sklearn environment open on my computer.&lt;/p&gt;

&lt;p&gt;Any advice would be greatly appreciated! Thanks so much.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ay21z,True,,Turbulent-City-9377,,42,True,all_ads,False,[],False,,/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,1209065,1697654659.0,0,,False,,,,,,,,,,1051,173
,datascience,"Hello everyone! I am currently working in digital marketing (I’m entry level) and I have a degree in data analytics. I would like to be able to combine both fields, and I’m looking for any good project ideas to do so (preferably using R or Python). Any ideas are helpful!",t2_fnqyenrh,False,,0,False,Project ideas that combine Data Science (Data Analytics) and Digital Marketing,[],r/datascience,False,6,projects,0,,,False,t3_17ax0xj,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1697651995.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone! I am currently working in digital marketing (I’m entry level) and I have a degree in data analytics. I would like to be able to combine both fields, and I’m looking for any good project ideas to do so (preferably using R or Python). Any ideas are helpful!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ax0xj,True,,The_powerful_onion,,4,True,all_ads,False,[],False,,/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,1209065,1697651995.0,0,,False,,,,,,,,,,271,50
,datascience,"The bulk of this subreddit is filled with people trying to break into data science, completing certifications and getting MS degrees from diploma mills but with no real guidance. Oftentimes the advice I see here is from people without DS jobs trying to help other people without DS jobs on projects etc. It's more or less blind leading the blind.

Here's an insider perspective from me. I'm a hiring manager at an F50 financial services company you've probably heard of, I've been working for \~4 years and I'll share how entry-level roles actually get hired into.

There's a few different pathways. I've listed them in order of where the bulk of our candidate pool and current hires comes from

1. We pick MS students from very specific programs that we trust. These programs have been around for a while, we have a relationship with the school and have a good idea of the curriculum. Georgia Tech, Columbia, UVa, UC Berkeley, UW Seattle, NCSU are some universities we hire from. We don't come back every year to hire, just the years that we need positions filled. Sometimes you'll look around at teams here and 40% of them went to the same program. They're stellar hires. The programs that we hire from are incredibly competitive to get into, are not diploma mills, and most importantly, their programs have been around longer than the DS hype. How does the hiring process work? We just reach out to the career counselor at the school, they put out an interest list for students who want to work for us, we flip through the resumes and pick the students we like to interview. It's very streamlined both for us as an employer and for the student. Although I didn't come from this path (I was a referred by a friend during the hiring boom and just have a PhD), I'm actively involved in the hiring efforts.
2. We host hackathons every year for students to participate in. The winners of these hackathons typically get brought back to interview for internship positions, and if they perform well we pick them up as full time hires.
3. Generic career fairs at universities. If you go a to a university, you've probably seen career fairs with companies that come to recruit.
4. Referrals from our current employees. Typically they refer a candidate to us, we interview them, and if we like them, we'll punt them over to the recruiter to get the process started for hiring them. Typically the hiring manager has seen the resume before the recruiter has because the resume came straight to their inbox from one of their colleagues
5. Internal mobility of someone who shows promise but just needs an opportunity. We've already worked with them in some capacity, know them to be bright, and are willing to give them a shot even if they don't have the skills.
6. Far and away the worst and hardest way to get a job, our recruiter sends us their resume after screening candidates who applied online through the job portal. Our recruiters know more or less what to look for (I'm thankful ours are not trash)

This is true not just for our company but a lot of large companies broadly. I know Home Depot, Microsoft and few other large retail companies some of my network works at hire candidates this way.

Is it fair to the general population? No. But as employees at a company we have limited resources to put into finding quality candidates and we typically use pathways that we know work, and work well in generating high quality hires.

EDIT: Some actionable advice for those who are feeling disheartened. I'll add just a couple of points here:

1. If you already have your MS in this field or a related one and are looking for a job, reach out to your network. Go to the career fairs at your university and see if you can get some data-adjacent job in finance, marketing, operations or sales where you might be working with data scientists. Then you can try to transition internally into the roles that might be interesting to you.
2. There are also non-profit data organizations like Data Kind and others. They have working data scientists already volunteering time there, you can get involved, get some real world experience with non-profit data sets and leverage that to set yourself apart. It's a fantastic way to get some experience AND build your professional network.
3. Work on an open-source library and making it better. You'll learn some best practices. If you make it through the online hiring screen, this will really set you apart from other candidates
4. If you are pre MS and just figuring out where you want to go, research the program's career outcomes before picking a school. No school can guarantee you a job, but many have strong alumni and industry networks that make finding a job way easier. Do not go just because it looks like it's easy to get into. If it's easy to get into, it means that they're a new program who came in with the hype train

EDIT 2: I think some people are getting the wrong idea about ""prestige"" where the companies I'm aware of only hire from Ivies or public universities that are as strong as Ivies. That's not always the case - some schools have deliberately cultivated relationships with employers to generate a talent pipeline for their students. They're not always a top 10 school, but programs with very strong industry connections.

For example, Penn State is an example of a school with very strong industry ties to companies in NJ, PA and NY for engineering students. These students can go to job fairs or sign up for company interest lists for their degree program at their schools, talk directly to working alumni and recruiters and get their resume in front of a hiring manager that way. It's about the relationship that the university has cultivated to the local industries that hire and their ability to generate candidates that can feed that talent pipeline.",t2_j65u2bg31,False,,0,False,Where are all the entry level jobs? Which MS program should I go for? Some tips from a hiring manager at an F50,[],r/datascience,False,6,discussion,0,,,False,t3_17avmi5,False,dark,0.92,,public,299,0,{},,,False,[],,False,False,,{},Discussion,False,299,,False,False,self,1697713310.0,,[],{},,True,,1697648432.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The bulk of this subreddit is filled with people trying to break into data science, completing certifications and getting MS degrees from diploma mills but with no real guidance. Oftentimes the advice I see here is from people without DS jobs trying to help other people without DS jobs on projects etc. It&amp;#39;s more or less blind leading the blind.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s an insider perspective from me. I&amp;#39;m a hiring manager at an F50 financial services company you&amp;#39;ve probably heard of, I&amp;#39;ve been working for ~4 years and I&amp;#39;ll share how entry-level roles actually get hired into.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s a few different pathways. I&amp;#39;ve listed them in order of where the bulk of our candidate pool and current hires comes from&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We pick MS students from very specific programs that we trust. These programs have been around for a while, we have a relationship with the school and have a good idea of the curriculum. Georgia Tech, Columbia, UVa, UC Berkeley, UW Seattle, NCSU are some universities we hire from. We don&amp;#39;t come back every year to hire, just the years that we need positions filled. Sometimes you&amp;#39;ll look around at teams here and 40% of them went to the same program. They&amp;#39;re stellar hires. The programs that we hire from are incredibly competitive to get into, are not diploma mills, and most importantly, their programs have been around longer than the DS hype. How does the hiring process work? We just reach out to the career counselor at the school, they put out an interest list for students who want to work for us, we flip through the resumes and pick the students we like to interview. It&amp;#39;s very streamlined both for us as an employer and for the student. Although I didn&amp;#39;t come from this path (I was a referred by a friend during the hiring boom and just have a PhD), I&amp;#39;m actively involved in the hiring efforts.&lt;/li&gt;
&lt;li&gt;We host hackathons every year for students to participate in. The winners of these hackathons typically get brought back to interview for internship positions, and if they perform well we pick them up as full time hires.&lt;/li&gt;
&lt;li&gt;Generic career fairs at universities. If you go a to a university, you&amp;#39;ve probably seen career fairs with companies that come to recruit.&lt;/li&gt;
&lt;li&gt;Referrals from our current employees. Typically they refer a candidate to us, we interview them, and if we like them, we&amp;#39;ll punt them over to the recruiter to get the process started for hiring them. Typically the hiring manager has seen the resume before the recruiter has because the resume came straight to their inbox from one of their colleagues&lt;/li&gt;
&lt;li&gt;Internal mobility of someone who shows promise but just needs an opportunity. We&amp;#39;ve already worked with them in some capacity, know them to be bright, and are willing to give them a shot even if they don&amp;#39;t have the skills.&lt;/li&gt;
&lt;li&gt;Far and away the worst and hardest way to get a job, our recruiter sends us their resume after screening candidates who applied online through the job portal. Our recruiters know more or less what to look for (I&amp;#39;m thankful ours are not trash)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is true not just for our company but a lot of large companies broadly. I know Home Depot, Microsoft and few other large retail companies some of my network works at hire candidates this way.&lt;/p&gt;

&lt;p&gt;Is it fair to the general population? No. But as employees at a company we have limited resources to put into finding quality candidates and we typically use pathways that we know work, and work well in generating high quality hires.&lt;/p&gt;

&lt;p&gt;EDIT: Some actionable advice for those who are feeling disheartened. I&amp;#39;ll add just a couple of points here:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If you already have your MS in this field or a related one and are looking for a job, reach out to your network. Go to the career fairs at your university and see if you can get some data-adjacent job in finance, marketing, operations or sales where you might be working with data scientists. Then you can try to transition internally into the roles that might be interesting to you.&lt;/li&gt;
&lt;li&gt;There are also non-profit data organizations like Data Kind and others. They have working data scientists already volunteering time there, you can get involved, get some real world experience with non-profit data sets and leverage that to set yourself apart. It&amp;#39;s a fantastic way to get some experience AND build your professional network.&lt;/li&gt;
&lt;li&gt;Work on an open-source library and making it better. You&amp;#39;ll learn some best practices. If you make it through the online hiring screen, this will really set you apart from other candidates&lt;/li&gt;
&lt;li&gt;If you are pre MS and just figuring out where you want to go, research the program&amp;#39;s career outcomes before picking a school. No school can guarantee you a job, but many have strong alumni and industry networks that make finding a job way easier. Do not go just because it looks like it&amp;#39;s easy to get into. If it&amp;#39;s easy to get into, it means that they&amp;#39;re a new program who came in with the hype train&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;EDIT 2: I think some people are getting the wrong idea about &amp;quot;prestige&amp;quot; where the companies I&amp;#39;m aware of only hire from Ivies or public universities that are as strong as Ivies. That&amp;#39;s not always the case - some schools have deliberately cultivated relationships with employers to generate a talent pipeline for their students. They&amp;#39;re not always a top 10 school, but programs with very strong industry connections.&lt;/p&gt;

&lt;p&gt;For example, Penn State is an example of a school with very strong industry ties to companies in NJ, PA and NY for engineering students. These students can go to job fairs or sign up for company interest lists for their degree program at their schools, talk directly to working alumni and recruiters and get their resume in front of a hiring manager that way. It&amp;#39;s about the relationship that the university has cultivated to the local industries that hire and their ability to generate candidates that can feed that talent pipeline.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17avmi5,True,,Consistent-Design-57,,149,True,all_ads,False,[],False,,/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,all_ads,False,https://www.reddit.com/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,1209065,1697648432.0,0,,False,,,,,,,,,,5816,1022
,datascience,"How often do you guys use calculus and linear algebra for your work? I've heard that for data science, especially machine learning, that it's important to understand linear algebra and calculus, but how true is this statement? I've taken some stats and probability courses in college for my minor, but haven't taken anything past calc 1 or linear algebra. Are these must-haves for your day to day work?",t2_15170zpy,False,,0,False,Question for Data Scientists in their day to day work,[],r/datascience,False,6,discussion,0,,,False,t3_17aveed,False,dark,0.43,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697647855.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How often do you guys use calculus and linear algebra for your work? I&amp;#39;ve heard that for data science, especially machine learning, that it&amp;#39;s important to understand linear algebra and calculus, but how true is this statement? I&amp;#39;ve taken some stats and probability courses in college for my minor, but haven&amp;#39;t taken anything past calc 1 or linear algebra. Are these must-haves for your day to day work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17aveed,True,,7sidedleaf,,16,True,all_ads,False,[],False,,/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,all_ads,False,https://www.reddit.com/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,1209065,1697647855.0,0,,False,,,,,,,,,,402,68
,datascience,"I was a DS in an insurance company (essentially a pricing analyst), I was doing a lot of XGB and GLM models etc. It was enjoyable but I have a degree in DS so I always wanted to move into something which would project me into more complex/cool modelling.

Anyway, my question, I moved to London and am now looking for a new job but the currently tough market is looking for much more experience than I currently have in data science related work (I have 1 year). Would taking a Pricing Analyst role (doing the same algorithms as before) hurt my progression or help it in the eventual goal of being in something machine learning related down the line.

I think it would strengthen my prediction models, but at the same time I wouldn't be exercising what I did in my MSc degree. What do you think?",t2_2qi2mssd,False,,0,False,Pricing Analysis Career Progression to Data Science,[],r/datascience,False,6,discussion,0,,,False,t3_17atfvp,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697642782.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was a DS in an insurance company (essentially a pricing analyst), I was doing a lot of XGB and GLM models etc. It was enjoyable but I have a degree in DS so I always wanted to move into something which would project me into more complex/cool modelling.&lt;/p&gt;

&lt;p&gt;Anyway, my question, I moved to London and am now looking for a new job but the currently tough market is looking for much more experience than I currently have in data science related work (I have 1 year). Would taking a Pricing Analyst role (doing the same algorithms as before) hurt my progression or help it in the eventual goal of being in something machine learning related down the line.&lt;/p&gt;

&lt;p&gt;I think it would strengthen my prediction models, but at the same time I wouldn&amp;#39;t be exercising what I did in my MSc degree. What do you think?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17atfvp,True,,cdtmh,,2,True,all_ads,False,[],False,,/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,1209065,1697642782.0,0,,False,,,,,,,,,,795,148
,datascience,"Can anyone explain why many companies asking for LLM experience for data scientist roles?  
It wasn't there like 6-8 months ago, now around %70 of the job descriptions asking for that and it goes like Python, SQL and LLM. Looks a bit weird to be honest.  
What are they doing, creating their own chatgpt?  
",t2_agbj58l8,False,,0,False,LLM domination on job descriptions,[],r/datascience,False,6,discussion,0,,,False,t3_17ar38i,False,dark,0.96,,public,175,0,{},,,False,[],,False,False,,{},Discussion,False,175,,False,False,self,False,,[],{},,True,,1697636463.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can anyone explain why many companies asking for LLM experience for data scientist roles?&lt;br/&gt;
It wasn&amp;#39;t there like 6-8 months ago, now around %70 of the job descriptions asking for that and it goes like Python, SQL and LLM. Looks a bit weird to be honest.&lt;br/&gt;
What are they doing, creating their own chatgpt?  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ar38i,True,,jujuman1313,,71,True,all_ads,False,[],False,,/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,1209065,1697636463.0,0,,False,,,,,,,,,,307,54
,datascience,"I am Data analyst with 2 years of experience and in the companies that I have work, I have not had any experience with data processing in cloud services. I am interested in learn Azure, AWS or Google cloud for data science and get the certifications. Could you tell me what is better, and how important are those certificates in my career path?.
Thanks!!!",t2_6x15zleg,False,,0,False,Microsoft Azure,[],r/datascience,False,6,discussion,0,,,False,t3_17aq5r0,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697633813.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am Data analyst with 2 years of experience and in the companies that I have work, I have not had any experience with data processing in cloud services. I am interested in learn Azure, AWS or Google cloud for data science and get the certifications. Could you tell me what is better, and how important are those certificates in my career path?.
Thanks!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17aq5r0,True,,RecoverMotor,,1,True,all_ads,False,[],False,,/r/datascience/comments/17aq5r0/microsoft_azure/,all_ads,False,https://www.reddit.com/r/datascience/comments/17aq5r0/microsoft_azure/,1209065,1697633813.0,0,,False,,,,,,,,,,355,64
,datascience," I'm about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.

I'm currently exploring career opportunities in the US and other international locations. I'm curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!

Thank you in advance!",t2_cvvcrwpx,False,,0,False,Graduate US/International Career Opportunities,[],r/datascience,False,6,discussion,0,,,False,t3_17amx3l,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697622838.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently exploring career opportunities in the US and other international locations. I&amp;#39;m curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!&lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17amx3l,True,,CanberraMogul,,0,True,all_ads,False,[],False,,/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,all_ads,False,https://www.reddit.com/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,1209065,1697622838.0,0,,False,,,,,,,,,,581,96
,datascience,"Why does the DAGitty ""Testable Dependencies"" function only describe independencies, but not spurious correlations?

&amp;#x200B;

E.g, if I have B-&gt;A&lt;-C,

DAGitty just tells me that

B ⊥ C is the only testable (in)dependency

Why shouldn't we expect also

B⊥̸C|A

(i.e, B and C have a spurious correlation given A)?",t2_8nq7249f,False,,0,False,"DAGitty Question: Testable Implications only describes independencies, but not dependencies",[],r/datascience,False,6,discussion,0,,,False,t3_17alwcz,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,1697628721.0,,[],{},,True,,1697618580.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Why does the DAGitty &amp;quot;Testable Dependencies&amp;quot; function only describe independencies, but not spurious correlations?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;E.g, if I have B-&amp;gt;A&amp;lt;-C,&lt;/p&gt;

&lt;p&gt;DAGitty just tells me that&lt;/p&gt;

&lt;p&gt;B ⊥ C is the only testable (in)dependency&lt;/p&gt;

&lt;p&gt;Why shouldn&amp;#39;t we expect also&lt;/p&gt;

&lt;p&gt;B⊥̸C|A&lt;/p&gt;

&lt;p&gt;(i.e, B and C have a spurious correlation given A)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17alwcz,True,,zurdosios,,0,True,all_ads,False,[],False,,/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,all_ads,False,https://www.reddit.com/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,1209065,1697618580.0,0,,False,,,,,,,,,,321,49
,datascience,"I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. 

The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.

My problem is how can I show this in my recruiters such that they don't just ignore my personal projects section. ",t2_736ioria,False,,0,False,How can I show knowledge in topics I haven't worked on professionally?,[],r/datascience,False,6,projects,0,,,False,t3_17alvvb,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Projects,False,4,,False,False,self,False,,[],{},,True,,1697618520.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. &lt;/p&gt;

&lt;p&gt;The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.&lt;/p&gt;

&lt;p&gt;My problem is how can I show this in my recruiters such that they don&amp;#39;t just ignore my personal projects section. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17alvvb,True,,jaegarbong,,3,True,all_ads,False,[],False,,/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,all_ads,False,https://www.reddit.com/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,1209065,1697618520.0,0,,False,,,,,,,,,,524,91
,datascience,"Hello everyone 

I hope you have an amazing day so far.

I want to create a model to predict/estimate furl consumption of ships for their voyages. I'm thinking to consider weight,wind speed, wind direction etc. Any suggestions of what model should I create?",t2_9ckg2920,False,,0,False,Fuel consumption,[],r/datascience,False,6,projects,0,,,False,t3_17alfw3,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697616556.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone &lt;/p&gt;

&lt;p&gt;I hope you have an amazing day so far.&lt;/p&gt;

&lt;p&gt;I want to create a model to predict/estimate furl consumption of ships for their voyages. I&amp;#39;m thinking to consider weight,wind speed, wind direction etc. Any suggestions of what model should I create?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17alfw3,True,,NFTHUNTERXX,,4,True,all_ads,False,[],False,,/r/datascience/comments/17alfw3/fuel_consumption/,all_ads,False,https://www.reddit.com/r/datascience/comments/17alfw3/fuel_consumption/,1209065,1697616556.0,0,,False,,,,,,,,,,257,43
,datascience,"So i’m working on a project that forecasts sales of products in a series. Curious to know the best approach to model “cascaded” products i.e old version of the series when the new one launches.
Using a Recursive multistep regression approach to forecast with some features

Appreciate the help, thanks 🙏🏼",t2_7xxtza3n,False,,0,False,Forecasting sales,[],r/datascience,False,6,discussion,0,,,False,t3_17al968,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697615792.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i’m working on a project that forecasts sales of products in a series. Curious to know the best approach to model “cascaded” products i.e old version of the series when the new one launches.
Using a Recursive multistep regression approach to forecast with some features&lt;/p&gt;

&lt;p&gt;Appreciate the help, thanks 🙏🏼&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17al968,True,,Asleep-Fun-6508,,4,True,all_ads,False,[],False,,/r/datascience/comments/17al968/forecasting_sales/,all_ads,False,https://www.reddit.com/r/datascience/comments/17al968/forecasting_sales/,1209065,1697615792.0,0,,False,,,,,,,,,,304,51
,datascience,"Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? 

I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?",t2_f1x3eywqz,False,,0,False,What are some of the best library frameworks to use for speech2text and text2speech AI chatbot,[],r/datascience,False,6,discussion,0,,,False,t3_17al56s,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697615321.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? &lt;/p&gt;

&lt;p&gt;I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17al56s,True,,redd-dev,,0,True,all_ads,False,[],False,,/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,1209065,1697615321.0,0,,False,,,,,,,,,,415,66
,datascience,"I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you'll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can't do anything beyond Leetcode easy, my mind just doesn't accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don't practice that problem in every few days. 

Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?",t2_7tvt0u4s,False,,0,False,Shit scared of Leetcode!,[],r/datascience,False,6,discussion,0,,,False,t3_17ajqwd,False,dark,0.88,,public,54,0,{},,,False,[],,False,False,,{},Discussion,False,54,,False,False,self,False,,[],{},,True,,1697609542.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you&amp;#39;ll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can&amp;#39;t do anything beyond Leetcode easy, my mind just doesn&amp;#39;t accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don&amp;#39;t practice that problem in every few days. &lt;/p&gt;

&lt;p&gt;Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ajqwd,True,,treaty_tonvis,,55,True,all_ads,False,[],False,,/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,1209065,1697609542.0,0,,False,,,,,,,,,,753,135
,datascience,"Anyone done something on XAI where you use SHAP and Anchor model to explain your model?

I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so",t2_l6htd,False,,0,False,What's the best way to implement Shaq and Anchor (XAI) techniques,[],r/datascience,False,6,projects,0,,,False,t3_17ajf0e,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697608224.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone done something on XAI where you use SHAP and Anchor model to explain your model?&lt;/p&gt;

&lt;p&gt;I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ajf0e,True,,IamFromNigeria,,0,True,all_ads,False,[],False,,/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,1209065,1697608224.0,0,,False,,,,,,,,,,195,38
,datascience,Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate’s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.,t2_ajfuo,False,,0,False,What makes a good take home?,[],r/datascience,False,6,discussion,0,,,False,t3_17ai9df,False,dark,0.55,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697603857.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate’s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ai9df,True,,Rcpiv,,34,True,all_ads,False,[],False,,/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,1209065,1697603857.0,0,,False,,,,,,,,,,267,47
,datascience,I’m looking to clustering on a dimensionally reduced dataset of 3D vectors. I’ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I’m looking for. I also tried using dbscan but I’ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I’d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.,t2_2pxniisp,False,,0,False,Performance issues with dbscan,[],r/datascience,False,6,discussion,0,,,False,t3_17adx4s,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697590581.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m looking to clustering on a dimensionally reduced dataset of 3D vectors. I’ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I’m looking for. I also tried using dbscan but I’ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I’d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17adx4s,True,,spx416,,6,True,all_ads,False,[],False,,/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,all_ads,False,https://www.reddit.com/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,1209065,1697590581.0,0,,False,,,,,,,,,,487,85
,datascience,I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters,t2_8xfzxrs0,False,,0,False,Where do you start if you are new to mathematical models,[],r/datascience,False,6,discussion,0,,,False,t3_17ad4og,False,dark,0.94,,public,14,0,{},,,False,[],,False,False,,{},Discussion,False,14,,False,False,self,False,,[],{},,True,,1697588385.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17ad4og,True,,relativefluffy,,10,True,all_ads,False,[],False,,/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,all_ads,False,https://www.reddit.com/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,1209065,1697588385.0,0,,False,,,,,,,,,,267,48
,datascience," 

Hey!

**Startup:**

\- Apply Script dot com ""Connect business and data professionals via pre-recorded standardized video interviews.""

**More details:**

**Problems with Traditional Hiring**

\- Outdated: The current method of conducting interviews has become overly complex and outdated.

\- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.

\- Expensive: The man-hours invested by HR and engineering teams are costly.

\- Constraining: Interviews are fixed to specific times and locations.

\- Cumbersome: The experience is challenging for both businesses and professionals.

**Our Solution**

\+ Talent Identification: We find top talent that matches your job post.

\+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.

\+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.

\+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.

\+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.

\+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.

\+ Transparency: Applicants receive immediate feedback on their applications to avoid being ""ghosted.""

**Life cycle stage:**

\- Validation: Currently looking to run our ***#1st pilot B2B*** with our first client.

**My role:**

\- Founder

**Goals for this month:**

\- Secure my first client for the pilot.

\- Obtain feedback from both the employee and business sides.

\- Optimize the product based on the feedback received.

**How can I** **help?**

\- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.

\- in the USA.

Thx for the feedback ;)",t2_qrm5o,False,,0,False,Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals,[],r/datascience,False,6,projects,0,,,False,t3_17aba8j,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697583330.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Startup:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Apply Script dot com &amp;quot;Connect business and data professionals via pre-recorded standardized video interviews.&amp;quot;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;More details:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problems with Traditional Hiring&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Outdated: The current method of conducting interviews has become overly complex and outdated.&lt;/p&gt;

&lt;p&gt;- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.&lt;/p&gt;

&lt;p&gt;- Expensive: The man-hours invested by HR and engineering teams are costly.&lt;/p&gt;

&lt;p&gt;- Constraining: Interviews are fixed to specific times and locations.&lt;/p&gt;

&lt;p&gt;- Cumbersome: The experience is challenging for both businesses and professionals.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Our Solution&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;+ Talent Identification: We find top talent that matches your job post.&lt;/p&gt;

&lt;p&gt;+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.&lt;/p&gt;

&lt;p&gt;+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.&lt;/p&gt;

&lt;p&gt;+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.&lt;/p&gt;

&lt;p&gt;+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.&lt;/p&gt;

&lt;p&gt;+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.&lt;/p&gt;

&lt;p&gt;+ Transparency: Applicants receive immediate feedback on their applications to avoid being &amp;quot;ghosted.&amp;quot;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Life cycle stage:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Validation: Currently looking to run our &lt;strong&gt;&lt;em&gt;#1st pilot B2B&lt;/em&gt;&lt;/strong&gt; with our first client.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My role:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Founder&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goals for this month:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Secure my first client for the pilot.&lt;/p&gt;

&lt;p&gt;- Obtain feedback from both the employee and business sides.&lt;/p&gt;

&lt;p&gt;- Optimize the product based on the feedback received.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How can I&lt;/strong&gt; &lt;strong&gt;help?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.&lt;/p&gt;

&lt;p&gt;- in the USA.&lt;/p&gt;

&lt;p&gt;Thx for the feedback ;)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17aba8j,True,,glassAlloy,,0,True,all_ads,False,[],False,,/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,all_ads,False,https://www.reddit.com/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,1209065,1697583330.0,0,,False,,,,,,,,,,2093,293
,datascience,"Just recently graduated in May with a BS statistics from texas a&amp;m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I'm almost done with the meta coursera front-end prof certificate and I'm gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I've thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn't get any traffic, maybe it'll look good on a resume.

I'm disenchanted with it all, I'm hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn't a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as ""pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference"", I'm not asking any questions. It's just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says ""I'm of value"" and ""people can rely on me"", and knowing people. Especially when employers aren't going to ask my professors how I was like,  I imagine I'll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I'm just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I'm pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can't get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don't mind taking tests, and I know how to live with a low overhead (I don't buy stuff I don't need). I know what really matters, your basic needs, family, a few good friends. Ok, that's not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don't.",t2_qorbr809,False,,0,False,I'm giving up finding a job. I feel like I'll have better luck applying to PhD programs. This is a rant.,[],r/datascience,False,6,discussion,0,,,False,t3_17aba8a,False,dark,0.83,,public,151,0,{},,,False,[],,False,False,,{},Discussion,False,151,,False,False,self,1697588397.0,,[],{},,True,,1697583329.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just recently graduated in May with a BS statistics from texas a&amp;amp;m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I&amp;#39;m almost done with the meta coursera front-end prof certificate and I&amp;#39;m gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I&amp;#39;ve thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn&amp;#39;t get any traffic, maybe it&amp;#39;ll look good on a resume.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m disenchanted with it all, I&amp;#39;m hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn&amp;#39;t a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as &amp;quot;pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference&amp;quot;, I&amp;#39;m not asking any questions. It&amp;#39;s just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says &amp;quot;I&amp;#39;m of value&amp;quot; and &amp;quot;people can rely on me&amp;quot;, and knowing people. Especially when employers aren&amp;#39;t going to ask my professors how I was like,  I imagine I&amp;#39;ll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I&amp;#39;m just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I&amp;#39;m pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can&amp;#39;t get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don&amp;#39;t mind taking tests, and I know how to live with a low overhead (I don&amp;#39;t buy stuff I don&amp;#39;t need). I know what really matters, your basic needs, family, a few good friends. Ok, that&amp;#39;s not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don&amp;#39;t.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17aba8a,True,,Sea-Bodybuilder-1277,,153,True,all_ads,False,[],False,,/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,all_ads,False,https://www.reddit.com/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,1209065,1697583329.0,1,,False,,,,,,,,,,3246,577
,datascience,"Hey y'all, I have a 15 minute interview coming up with Kodiak.ai (Kodiak Robotics). Wondering what it's about. Any help is greatly appreciated!",t2_fz837yyr,False,,0,False,Anyone got interview call from Kodiak Robotics?,[],r/datascience,False,6,discussion,0,,,False,t3_17aahht,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697581240.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey y&amp;#39;all, I have a 15 minute interview coming up with Kodiak.ai (Kodiak Robotics). Wondering what it&amp;#39;s about. Any help is greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17aahht,True,,Chadsmithbass,,3,True,all_ads,False,[],False,,/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,all_ads,False,https://www.reddit.com/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,1209065,1697581240.0,0,,False,,,,,,,,,,143,23
,datascience,"Hello all,

 I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.

I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?",t2_6cbsdgdj,False,,0,False,Moving to Big Tech from big government contractor,[],r/datascience,False,6,discussion,0,,,False,t3_17a9bma,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697578283.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.&lt;/p&gt;

&lt;p&gt;I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a9bma,True,,Administrative_Bar46,,2,True,all_ads,False,[],False,,/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,1209065,1697578283.0,0,,False,,,,,,,,,,662,122
,datascience," 

Hello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!

1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?
2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?
3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?

Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!""",t2_hhycptpk,False,,0,False,Seeking Advice on Machine Learning Algorithm Selection for Competitions,[],r/datascience,False,6,discussion,0,,,False,t3_17a6t46,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697571824.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, fellow data science enthusiasts! I&amp;#39;m participating in some machine learning competitions and I&amp;#39;m looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?&lt;/li&gt;
&lt;li&gt;What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?&lt;/li&gt;
&lt;li&gt;Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a6t46,True,,After_Reception1696,,1,True,all_ads,False,[],False,,/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,1209065,1697571824.0,0,,False,,,,,,,,,,1004,148
,datascience,"I am aware of a few tools that aid in converting XGBoost decision trees to ""if-then"" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?",t2_8qqebrm9,False,,0,False,"Converting XGBoost decision models to ""if-then"" statements",[],r/datascience,False,6,discussion,0,,,False,t3_17a6ken,False,dark,0.87,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,False,self,False,,[],{},,True,,1697571198.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am aware of a few tools that aid in converting XGBoost decision trees to &amp;quot;if-then&amp;quot; statements. I&amp;#39;m curious if anyone has experience with this approach, and how feasible/successful was the outcome?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a6ken,True,,MultiPass10,,17,True,all_ads,False,[],False,,/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,1209065,1697571198.0,0,,False,,,,,,,,,,198,32
,datascience,"I'm building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.

I thought about 2 solutions:

1. sample data for each product in a way that keeps 'outliers' in dataset (i.e. spikes for visibility and dips to get notified that maybe it's time to buy it). Not sure if it's easy 
2. get rid of data points for which data trends flat based on moving average

&amp;#x200B;

Any better idea that is easy to implement?

&amp;#x200B;",t2_5iv2njiq,False,,0,False,Time series data filtering - keep outliers and remove only flat trend,[],r/datascience,False,6,discussion,0,,,False,t3_17a5u8t,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697569289.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.&lt;/p&gt;

&lt;p&gt;I thought about 2 solutions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;sample data for each product in a way that keeps &amp;#39;outliers&amp;#39; in dataset (i.e. spikes for visibility and dips to get notified that maybe it&amp;#39;s time to buy it). Not sure if it&amp;#39;s easy &lt;/li&gt;
&lt;li&gt;get rid of data points for which data trends flat based on moving average&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any better idea that is easy to implement?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a5u8t,True,,ratatsnow,,1,True,all_ads,False,[],False,,/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,1209065,1697569289.0,0,,False,,,,,,,,,,544,97
,datascience,I'm looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It's mostly for myself to test my knowledge. Anything from regression types to p values and much more.,t2_k79vgi4,False,,0,False,Does anyone have a good glossary for data science?,[],r/datascience,False,6,discussion,0,,,False,t3_17a5thj,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697569244.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It&amp;#39;s mostly for myself to test my knowledge. Anything from regression types to p values and much more.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a5thj,True,,TheOmerAngi,,1,True,all_ads,False,[],False,,/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,1209065,1697569244.0,0,,False,,,,,,,,,,213,36
,datascience,"Specifically for Kentucky but I'm trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this [comment](https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&amp;utm_medium=web2x&amp;context=3), but can't figure out what it would be for a single state's off off year election

&amp;#x200B;",t2_fa0st,False,,0,False,Live 2023 Election Results (Also Future Results),[],r/datascience,False,6,projects,0,,,False,t3_17a5plc,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697568957.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Specifically for Kentucky but I&amp;#39;m trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this &lt;a href=""https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3""&gt;comment&lt;/a&gt;, but can&amp;#39;t figure out what it would be for a single state&amp;#39;s off off year election&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a5plc,True,,KobeOrNotKobe,,0,True,all_ads,False,[],False,,/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,1209065,1697568957.0,0,,False,,,,,,,,,,411,52
,datascience,"**TL;DR:**

Below, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?

**Background:**

I've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.

**Regression algorithm:**

I used to work at a data science company where we would run studies we called ""regression hill climbs"", where we would iterate like this:

1. identify the output factor (AKA ""dependent variable""); in this case, it would be energy level on a given day
2. for every input factor (AKA ""independent variable"", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor
3. start with an empty ""model"", a set of independent variables
4. start with a correlation between model and dependent variable of 0
5. repeat until no more variables are selected to add to the model:
   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) 
   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)
   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)

This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). 

**Why it matters:**

For instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.

Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.

**What I'm looking for:**

A code library -- presumably in python -- that is built to perform such a ""regression hill climb"", and allow for the various thresholds and other settings to be specified.

Does anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?

Thanks!",t2_1why,False,,0,False,"Q: How to extract learnings from my spreadsheets, beyond simple correlations?",[],r/datascience,False,6,discussion,0,,,False,t3_17a2wb4,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697561640.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Below, I describe the info I&amp;#39;m tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don&amp;#39;t. &lt;strong&gt;My question is, does this algorithm already exist in some code library?&lt;/strong&gt; Or do I have to code it myself?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Regression algorithm:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I used to work at a data science company where we would run studies we called &amp;quot;regression hill climbs&amp;quot;, where we would iterate like this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;identify the output factor (AKA &amp;quot;dependent variable&amp;quot;); in this case, it would be energy level on a given day&lt;/li&gt;
&lt;li&gt;for every input factor (AKA &amp;quot;independent variable&amp;quot;, e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor&lt;/li&gt;
&lt;li&gt;start with an empty &amp;quot;model&amp;quot;, a set of independent variables&lt;/li&gt;
&lt;li&gt;start with a correlation between model and dependent variable of 0&lt;/li&gt;
&lt;li&gt;repeat until no more variables are selected to add to the model:

&lt;ol&gt;
&lt;li&gt;filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) &lt;/li&gt;
&lt;li&gt;of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model&amp;#39;s variables (to best predict the dependent variable)&lt;/li&gt;
&lt;li&gt;select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For instance, if I have nights where I&amp;#39;m more disciplined overall -- say, when I don&amp;#39;t drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there&amp;#39;s a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.&lt;/p&gt;

&lt;p&gt;Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it&amp;#39;s very hard to isolate it as a factor; this algorithm helps.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A code library -- presumably in python -- that is built to perform such a &amp;quot;regression hill climb&amp;quot;, and allow for the various thresholds and other settings to be specified.&lt;/p&gt;

&lt;p&gt;Does anyone know of such a library? Or, is there something different I should do, or some way I&amp;#39;m misunderstanding the problem?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a2wb4,True,,brw12,,2,True,all_ads,False,[],False,,/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,1209065,1697561640.0,0,,False,,,,,,,,,,3250,553
,datascience,"Hi all,

&amp;#x200B;

I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.   
Has anyone tried them or what do you guys think of them?  
I saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.

&amp;#x200B;

Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.

&amp;#x200B;

Appreciate the input or help.",t2_3gvpw9l,False,,0,False,How good are the Linkedin Learning Paths?,[],r/datascience,False,6,discussion,0,,,False,t3_17a25ns,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697559655.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.&lt;br/&gt;
Has anyone tried them or what do you guys think of them?&lt;br/&gt;
I saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Appreciate the input or help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17a25ns,True,,forgotendream,,4,True,all_ads,False,[],False,,/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,all_ads,False,https://www.reddit.com/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,1209065,1697559655.0,2,,False,,,,,,,,,,867,150
,datascience,"Hi,   


We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   


Thank you",t2_97o8m0l,False,,0,False,Should data-scientists look for their own datasets or be provided by the hiring company?,[],r/datascience,False,6,discussion,0,,,False,t3_179ztob,False,dark,0.62,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697553394.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,   &lt;/p&gt;

&lt;p&gt;We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   &lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179ztob,True,,Cryptocheets,,11,True,all_ads,False,[],False,,/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,all_ads,False,https://www.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,1209065,1697553394.0,0,,False,,,,,,,,,,431,75
,datascience,"Hey Guys,  
It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   


Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  


\-  


For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ",t2_13im86,False,,0,False,Shared Public Contextual Database for RAG,[],r/datascience,False,6,discussion,0,,,False,t3_179z4yq,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697551500.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Guys,&lt;br/&gt;
It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo&amp;#39;d vector dbs.   &lt;/p&gt;

&lt;p&gt;Do you guys think there&amp;#39;s any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone&amp;#39;s raving about today)  &lt;/p&gt;

&lt;p&gt;-  &lt;/p&gt;

&lt;p&gt;For context, I&amp;#39;m building a social media product we&amp;#39;re users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche&amp;#39;s classification string. Essentially we&amp;#39;re aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179z4yq,True,,niksteel123,,1,True,all_ads,False,[],False,,/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,all_ads,False,https://www.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,1209065,1697551500.0,0,,False,,,,,,,,,,1368,228
,datascience,"This has happened to me twice now, dunno if it’s a new trend in recruitment processes. I’m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I’m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master’s in a computational quantitative field and so know the stats/theory behind most models).

 I didn’t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn’t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. 

Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it’s hard to find time to interview, which is the main reason I don’t want a super dragged out process)",t2_ls91v62g,False,,0,False,What does it mean to get a take-home assignment before screening call?,[],r/datascience,False,6,discussion,0,,,False,t3_179yve1,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,1697551029.0,,[],{},,True,,1697550765.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This has happened to me twice now, dunno if it’s a new trend in recruitment processes. I’m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I’m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master’s in a computational quantitative field and so know the stats/theory behind most models).&lt;/p&gt;

&lt;p&gt;I didn’t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn’t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. &lt;/p&gt;

&lt;p&gt;Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it’s hard to find time to interview, which is the main reason I don’t want a super dragged out process)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179yve1,True,,Whole-Ad-8370,,6,True,all_ads,False,[],False,,/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,all_ads,False,https://www.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,1209065,1697550765.0,0,,False,,,,,,,,,,1086,195
,datascience,"Hi Folks

I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).

Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.

I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.

Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  


&amp;#x200B;",t2_auxp06r9,False,,0,False,Moving to USA or Staying in UAE,[],r/datascience,False,6,discussion,0,,,False,t3_179uwm2,False,dark,0.84,,public,65,0,{},,,False,[],,False,False,,{},Discussion,False,65,,False,False,self,False,,[],{},,True,,1697537235.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Folks&lt;/p&gt;

&lt;p&gt;I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).&lt;/p&gt;

&lt;p&gt;Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don&amp;#39;t want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.&lt;/p&gt;

&lt;p&gt;I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don&amp;#39;t have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.&lt;/p&gt;

&lt;p&gt;Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179uwm2,True,,Round_Inflation_2199,,81,True,all_ads,False,[],False,,/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,all_ads,False,https://www.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,1209065,1697537235.0,0,,False,,,,,,,,,,961,194
,datascience,"Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.

The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.

Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.

How would you recommend approaching this task?",t2_lku7zyn1c,False,,0,False,Predict maximum capacity of parking lots,[],r/datascience,False,6,projects,0,,,False,t3_179ub5l,False,dark,0.78,,public,15,0,{},,,False,[],,False,False,,{},Projects,False,15,,False,False,self,False,,[],{},,True,,1697534713.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.&lt;/p&gt;

&lt;p&gt;The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It&amp;#39;s important to note that historically, none of the parking lots have probably reached their maximum capacity.&lt;/p&gt;

&lt;p&gt;Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.&lt;/p&gt;

&lt;p&gt;How would you recommend approaching this task?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,179ub5l,True,,VGFenohmen,,35,True,all_ads,False,[],False,,/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,all_ads,False,https://www.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,1209065,1697534713.0,0,,False,,,,,,,,,,964,164
,datascience,"Hey fellow Redditors!

Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!

In this discussion, we delve into the concept of ""features"" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.

# 💡 What's a Feature?  

In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.

 The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. 

# 📊 Analyzing the appropriate time series

The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. 

**Unmasking forgery through speed analysis**

Let’s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**

Now, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won’t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature’s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**

Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.

Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.

In theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**

From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.

# 🔍 Describing Time Series with Scalar Values 

 We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.

Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.

To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.

Two lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.

In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.

On the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.

These are the basic features we utilize for analysis.

Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! 💬🕺🏽💻",t2_gbypvyyx9,False,,0,False,Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values,[],r/datascience,False,6,discussion,0,,,False,t3_179u12d,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697533471.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey fellow Redditors!&lt;/p&gt;

&lt;p&gt;Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!&lt;/p&gt;

&lt;p&gt;In this discussion, we delve into the concept of &amp;quot;features&amp;quot; in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.&lt;/p&gt;

&lt;h1&gt;💡 What&amp;#39;s a Feature?&lt;/h1&gt;

&lt;p&gt;In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.&lt;/p&gt;

&lt;p&gt;The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. &lt;/p&gt;

&lt;h1&gt;📊 Analyzing the appropriate time series&lt;/h1&gt;

&lt;p&gt;The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unmasking forgery through speed analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let’s explain the use of derivatives through an example of &lt;strong&gt;signature forgery&lt;/strong&gt;. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might &lt;strong&gt;meticulously trace the line to be replicated, proceeding slowly and accurately&lt;/strong&gt;, inch by inch. The result would be a slow, nearly constant-speed movement. &lt;strong&gt;The speed time series would exhibit an approximately constant value.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, imagine &lt;strong&gt;someone writing their own signature&lt;/strong&gt;. &lt;strong&gt;The speed can vary significantly&lt;/strong&gt;, but it won’t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature’s image is an exact copy of the genuine one in terms of x-y coordinates, &lt;strong&gt;the speed profiles would look entirely different.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.&lt;/p&gt;

&lt;p&gt;Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.&lt;/p&gt;

&lt;p&gt;In theory, we could &lt;strong&gt;take derivatives of our time series as many times as desired&lt;/strong&gt;. However, there is a practical limit as, &lt;strong&gt;after a certain point, the derivative becomes more noise than meaningful information.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. &lt;strong&gt;When we began using this method, the results demonstrated exceptional accuracy&lt;/strong&gt;.&lt;/p&gt;

&lt;h1&gt;🔍 Describing Time Series with Scalar Values&lt;/h1&gt;

&lt;p&gt;We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, &lt;strong&gt;we employ a straightforward approach: calculating a few statistical characteristics&lt;/strong&gt;. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.&lt;/p&gt;

&lt;p&gt;Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.&lt;/p&gt;

&lt;p&gt;To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.&lt;/p&gt;

&lt;p&gt;Two lesser-known statistical values are skewness and kurtosis. &lt;strong&gt;Skewness measures the asymmetry of a distribution&lt;/strong&gt;. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.&lt;/p&gt;

&lt;p&gt;In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.&lt;/p&gt;

&lt;p&gt;On the other hand, &lt;strong&gt;kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;These are the basic features we utilize for analysis.&lt;/p&gt;

&lt;p&gt;Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! 💬🕺🏽💻&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179u12d,True,,CursorInsight,,0,True,all_ads,False,[],False,,/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,all_ads,False,https://www.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,1209065,1697533471.0,1,,False,,,,,,,,,,5205,792
,datascience,"Hi r/datascience,

From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?

Thanks!",t2_mk6o8gs2,False,,0,False,Repetitive airflow pipeline problems,[],r/datascience,False,6,discussion,0,,,False,t3_179r5li,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697520996.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn&amp;#39;t running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179r5li,True,,dec_dev,,0,True,all_ads,False,[],False,,/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,all_ads,False,https://www.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,1209065,1697520996.0,0,,False,,,,,,,,,,606,101
,datascience,"I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!",t2_a3amxwo,False,,0,False,Cruise Ship Musicians Scheduling,[],r/datascience,False,6,projects,0,,,False,t3_179q91p,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697517644.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,179q91p,True,,SaxTeacher1988,,11,True,all_ads,False,[],False,,/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,all_ads,False,https://www.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,1209066,1697517644.0,0,,False,,,,,,,,,,406,79
,datascience,"Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.
As we can plot univariate time series on plot and train GaN's to complete that plot.

Not so much work is in going on this feild.
Why ?",t2_an5w3ncs,False,,0,False,Time series forcasting,[],r/datascience,False,6,discussion,0,,,False,t3_179q60m,False,dark,0.2,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697517330.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Why we cannot use GAN&amp;#39;s inplace of LSTM for any recurrent neural network for time series forcasting.
As we can plot univariate time series on plot and train GaN&amp;#39;s to complete that plot.&lt;/p&gt;

&lt;p&gt;Not so much work is in going on this feild.
Why ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179q60m,True,,Awkward-Block-5005,,6,True,all_ads,False,[],False,,/r/datascience/comments/179q60m/time_series_forcasting/,all_ads,False,https://www.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/,1209066,1697517330.0,0,,False,,,,,,,,,,236,45
,datascience,"My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.

 Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.

I really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.
How should I approach this? Anything in particular I should show?

I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)",t2_19f7pjd0,False,,0,False,How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?,[],r/datascience,False,6,tooling,0,,,False,t3_179kwrd,False,dark,0.62,,public,3,0,{},,,False,[],,False,False,,{},Tooling,False,3,,False,False,self,False,,[],{},,True,,1697501264.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.&lt;/p&gt;

&lt;p&gt;Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.&lt;/p&gt;

&lt;p&gt;I really do use these tools often and could show real-world cases where it&amp;#39;s helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.
How should I approach this? Anything in particular I should show?&lt;/p&gt;

&lt;p&gt;I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,179kwrd,True,,throwaWayne2,,7,True,all_ads,False,[],False,,/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,all_ads,False,https://www.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,1209066,1697501264.0,0,,False,,,,,,,,,,1039,203
,datascience,"I was wondering if there are other people out there who regret choosing data science as a career path.

For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.

I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).

In the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.

I can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. 

Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.

I'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.",t2_iljnct2d,False,,0,False,Regretting Data Science,[],r/datascience,False,6,discussion,0,,,False,t3_179etbr,False,dark,0.82,,public,25,0,{},,,False,[],,False,False,,{},Discussion,False,25,,False,False,self,1697514908.0,,[],{},,True,,1697485575.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was wondering if there are other people out there who regret choosing data science as a career path.&lt;/p&gt;

&lt;p&gt;For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.&lt;/p&gt;

&lt;p&gt;I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).&lt;/p&gt;

&lt;p&gt;In the fall of the 2nd year of my Master&amp;#39;s I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I&amp;#39;m stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.&lt;/p&gt;

&lt;p&gt;I can&amp;#39;t really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I&amp;#39;m personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. &lt;/p&gt;

&lt;p&gt;Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don&amp;#39;t know if every job feels like this and I have to suck it up, or if I should just leave. I&amp;#39;ve only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I&amp;#39;m having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179etbr,True,,Relative_Practice_93,,30,True,all_ads,False,[],False,,/r/datascience/comments/179etbr/regretting_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/179etbr/regretting_data_science/,1209066,1697485575.0,0,,False,,,,,,,,,,2633,500
,datascience,"**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, ""that is impossible."" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give ""impossible"" tasks.

**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.

**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.

There are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.",t2_4fiyncpa,False,,0,False,Why employers want experience over education,[],r/datascience,False,6,discussion,0,,,False,t3_179ebar,False,dark,0.85,,public,147,0,{},,,False,[],,False,False,,{},Discussion,False,147,,False,False,self,1697484790.0,,[],{},,True,,1697484333.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Creativity&lt;/strong&gt;: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn&amp;#39;t be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, &amp;quot;that is impossible.&amp;quot; How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give &amp;quot;impossible&amp;quot; tasks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dirty Data&lt;/strong&gt;: I understand that provided or toy datasets can sometimes be dirty. They don&amp;#39;t come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don&amp;#39;t link to each other naturally, do regression tests because they don&amp;#39;t update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Being easy to work with&lt;/strong&gt;: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.&lt;/p&gt;

&lt;p&gt;There are many others, but these are three big ones. If you don&amp;#39;t have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won&amp;#39;t be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179ebar,True,,Expendable_0,,79,True,all_ads,False,[],False,,/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,all_ads,False,https://www.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,1209066,1697484333.0,0,,False,,,,,,,,,,3323,600
,datascience,"Hi all,

Building off our last research post, we wanted to figure out ways to quantify ""ambiguity"" and ""uncertainty"" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: ""Structural"" and ""Conceptual"" uncertainty.

In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.

You can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)",t2_9o36o,False,,0,False,Decoding LLM Uncertainties for Better Predictability,[],r/datascience,False,6,projects,0,,,False,t3_1799oao,False,dark,0.78,,public,12,0,{},,,True,[],,False,False,,{},Projects,False,12,,False,False,self,False,,[],{},,True,,1697472672.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;Building off our last research post, we wanted to figure out ways to quantify &amp;quot;ambiguity&amp;quot; and &amp;quot;uncertainty&amp;quot; in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: &amp;quot;Structural&amp;quot; and &amp;quot;Conceptual&amp;quot; uncertainty.&lt;/p&gt;

&lt;p&gt;In a nutshell: Conceptual uncertainty is when the model isn&amp;#39;t sure what to say, and Structural uncertainty is when the model isn&amp;#39;t sure how to say it.&lt;/p&gt;

&lt;p&gt;You can play around with this yourself in the &lt;a href=""https://uncertainty.demos.watchful.io/""&gt;demo&lt;/a&gt; or read about it in more detail in the &lt;a href=""https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability""&gt;blog post&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1799oao,True,,shayanjm,,1,True,all_ads,False,[],False,,/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,all_ads,False,https://www.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,1209066,1697472672.0,0,,False,,,,,,,,,,626,84
,datascience,"I have been working as a ""data scientist"" in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with ""data scientist"" titles in the whole org but they are in a separate silo from me. 

Generally I am tossed tasks that don't make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like ""build us a chatbot"". I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  

Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can't imagine that project was less than a few million as well. 

In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don't even realize the consultants will likely build a very similar model to SAP. 

Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I've worked here. It seems like they have no vision or clue what they are doing.",t2_dbvtg,False,,0,False,How many companies actually have a clear plan for their data?,[],r/datascience,False,6,discussion,0,,,False,t3_179945p,False,dark,0.95,,public,114,0,{},,,False,[],,False,False,,{},Discussion,False,114,,False,False,self,False,,[],{},,True,,1697471271.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been working as a &amp;quot;data scientist&amp;quot; in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with &amp;quot;data scientist&amp;quot; titles in the whole org but they are in a separate silo from me. &lt;/p&gt;

&lt;p&gt;Generally I am tossed tasks that don&amp;#39;t make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like &amp;quot;build us a chatbot&amp;quot;. I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  &lt;/p&gt;

&lt;p&gt;Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can&amp;#39;t imagine that project was less than a few million as well. &lt;/p&gt;

&lt;p&gt;In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don&amp;#39;t even realize the consultants will likely build a very similar model to SAP. &lt;/p&gt;

&lt;p&gt;Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I&amp;#39;ve worked here. It seems like they have no vision or clue what they are doing.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,179945p,True,,MikeyCyrus,,48,True,all_ads,False,[],False,,/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,1209066,1697471271.0,0,,False,,,,,,,,,,1563,293
,datascience,"Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:

\- The law of diminishing returns

\- ROAS and Marginal ROAS

\- Advertisement elasticity on Returns

Hope that it is useful for everybody. Any feedback is welcome.

[https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html](https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html)",t2_47oo16kh,False,,0,False,[Applied Data Science in Marketing] How to measure marginal returns and elasticity of marketing campaigns,[],r/datascience,False,6,projects,0,,,False,t3_1798de7,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697469358.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:&lt;/p&gt;

&lt;p&gt;- The law of diminishing returns&lt;/p&gt;

&lt;p&gt;- ROAS and Marginal ROAS&lt;/p&gt;

&lt;p&gt;- Advertisement elasticity on Returns&lt;/p&gt;

&lt;p&gt;Hope that it is useful for everybody. Any feedback is welcome.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html""&gt;https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1798de7,True,,G4L1C,,1,True,all_ads,False,[],False,,/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,all_ads,False,https://www.reddit.com/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,1209066,1697469358.0,0,,False,,,,,,,,,,510,59
,datascience,"I'm in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? 

Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today's decision",t2_jtjumdnvw,False,,0,False,Sap ui5 fiori vs data science,[],r/datascience,False,6,discussion,0,,,False,t3_1796r9j,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697465111.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? &lt;/p&gt;

&lt;p&gt;Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today&amp;#39;s decision&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1796r9j,True,,Tasty_Potential7670,,5,True,all_ads,False,[],False,,/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,1209066,1697465111.0,0,,False,,,,,,,,,,375,71
,datascience,"Hi everyone, I’m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.

We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.

💻 Code examples and end-to-end deployment blueprints.  
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.  
❤️ Free and open to everyone.  
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace.

Course info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/)

Hope you’ll find the course useful!",t2_ms6x3icc,False,,0,False,Free Open-source ML observability course: starts today 🚀,[],r/datascience,False,6,projects,0,,,False,t3_1796r3n,False,dark,0.87,,public,6,0,{},,,False,[],,False,False,,{},Projects,False,6,,False,False,self,False,,[],{},,True,,1697465098.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I’m one of the people who work on &lt;a href=""https://github.com/evidentlyai/evidently""&gt;Evidently&lt;/a&gt;, an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.&lt;/p&gt;

&lt;p&gt;We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.&lt;/p&gt;

&lt;p&gt;💻 Code examples and end-to-end deployment blueprints.&lt;br/&gt;
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.&lt;br/&gt;
❤️ Free and open to everyone.&lt;br/&gt;
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace.&lt;/p&gt;

&lt;p&gt;Course info and notes: &lt;a href=""https://learn.evidentlyai.com/""&gt;https://learn.evidentlyai.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hope you’ll find the course useful!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1796r3n,True,,dmalyugina,,0,True,all_ads,False,[],False,,/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,all_ads,False,https://www.reddit.com/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,1209066,1697465098.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?auto=webp&amp;s=a4460012747f80368067bbc08cf0bfaf4f04a83b', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd64ef2ff79951860bb08a39d4bb1fc52b1b3235', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2f4805ca7f9815fec0e0fab3beec74eff8e36c1', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa5b0ccd7ceec7492d4dbeff29cd97ffac1bee9e', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1523ca7e3809e3ea9762304b5ec40bc4cd7633aa', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=412fe868629247abf7f561dacacb8742a7bd5897', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7306ec6454df06e21404184bfa2e867ed5a447cc', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'vpmpbE4KKp-X8MJmt4x46ZJk-dHdBfNmLnmk67S6TUc'}], 'enabled': False}",,,,,,,902,131
,datascience,"For my project, I need to identify existing to users to start using a product. 

I have different ideas that I want to try, but I would like to have your input.

&amp;#x200B;

**Idea 1**: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster

&amp;#x200B;

**Idea 2:** Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.

&amp;#x200B;

**Idea 3:** Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.

&amp;#x200B;

Let me know what you think or if I am on the right track!",t2_3mn8s3hq,False,,0,False,Advice on my approach for a project,[],r/datascience,False,6,projects,0,,,False,t3_1796ecp,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697464128.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For my project, I need to identify existing to users to start using a product. &lt;/p&gt;

&lt;p&gt;I have different ideas that I want to try, but I would like to have your input.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Idea 1&lt;/strong&gt;: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Idea 2:&lt;/strong&gt; Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Idea 3:&lt;/strong&gt; Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Let me know what you think or if I am on the right track!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1796ecp,True,,datasciencewithmarco,,2,False,all_ads,False,[],False,,/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,1209066,1697464128.0,0,,False,,,,,,,,,,976,171
,datascience," Sharing is caring - Creators can share your trade diary with your Members any time using [Gorudo.io](https://Gorudo.io)

&amp;#x200B;

https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3",t2_36py9z15,False,,0,False,Sharing is caring - with Gorudo.io,[],r/datascience,False,6,tooling,0,71.0,,False,t3_17961eu,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},Tooling,False,0,,False,False,https://b.thumbs.redditmedia.com/vg2Zv5AzMlOOPvjEGrsTBfgehwy74j9CnqzUjUNbGKQ.jpg,False,,[],{},,True,,1697463079.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sharing is caring - Creators can share your trade diary with your Members any time using &lt;a href=""https://Gorudo.io""&gt;Gorudo.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3""&gt;https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,17961eu,True,,orangepie000,,1,True,all_ads,False,[],False,,/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,all_ads,False,https://www.reddit.com/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,1209066,1697463079.0,0,,False,"{'kyec0yu6hkub1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 55, 'x': 108, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe4f8a3dc8f342ba4e5904a086933f2b8a2b456d'}, {'y': 110, 'x': 216, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4721b634398351ffdbd7a129a8faaefa8b94a9c'}, {'y': 164, 'x': 320, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba02126596107c86d13a5ed94f4b5064d1b7233c'}, {'y': 328, 'x': 640, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ef114dfaa2277834d7137303b660527dda607b4'}, {'y': 493, 'x': 960, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e1663390ec820f2ad40f7849a461ce86a168d35'}, {'y': 554, 'x': 1080, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae2b26ffb57b9e4f3c0acd8c27396b0767157bf6'}], 's': {'y': 1052, 'x': 2048, 'u': 'https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3'}, 'id': 'kyec0yu6hkub1'}}",,,,,,,,,265,19
,datascience,"I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.

The problem is very unbalanced, most people will not concert.

Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.
I.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.

How would you go about solving this?",t2_ao7p8weu,False,,0,False,Interpretation of logistic regression in absolute terms,[],r/datascience,False,6,discussion,0,,,False,t3_17950k5,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697459906.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.&lt;/p&gt;

&lt;p&gt;The problem is very unbalanced, most people will not concert.&lt;/p&gt;

&lt;p&gt;Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.
I.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.&lt;/p&gt;

&lt;p&gt;How would you go about solving this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17950k5,True,,CombinationThese993,,0,True,all_ads,False,[],False,,/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,all_ads,False,https://www.reddit.com/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,1209066,1697459906.0,0,,False,,,,,,,,,,465,75
,datascience,"Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!",t2_a0o64rxa,False,,0,False,What would be a good curriculum for a data scientist to learn about forecasting?,[],r/datascience,False,6,discussion,0,,,False,t3_17941v2,False,dark,0.86,,public,14,0,{},,,False,[],,False,False,,{},Discussion,False,14,,False,False,self,False,,[],{},,True,,1697456671.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17941v2,True,,Illustrious-Class-65,,9,True,all_ads,False,[],False,,/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,1209066,1697456671.0,0,,False,,,,,,,,,,295,52
,datascience,"Hello everyone,

I'm a former data science student who started to work in IT audit but decided to go back to DS.  I am rebuilding my portfolio with new projects. Any great project ideas ?   
Here are some projects i think about, please don't hesitate to give your opinion on which to choose :   


* Credit Card attrition.
* Black&amp;white video/ picture coloring and improving.
* License plate recognition
* Facebook Friend Recommendation
* Quora Question Pair Similarity
* Credit scoring improvement
* Disease Outbreak Prediction
* Product Recommendation system
* Housing Price Predictor
* Sentiment Analysis
* Stock Price Forecasting
* Flight Delay Prediction
* Fire Outbreak Prediction
* Game Outcome Prediction
* Object Detection in Videos
* Influencer Detection

Thank you in advance for your response.

P.S : If anyone has great mentorship platforms or any other way of mentorship please don't hesitate.",t2_fd92duw8,False,,0,False,Data Science Protfolio,[],r/datascience,False,6,projects,0,,,False,t3_17932k1,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1697452955.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a former data science student who started to work in IT audit but decided to go back to DS.  I am rebuilding my portfolio with new projects. Any great project ideas ?&lt;br/&gt;
Here are some projects i think about, please don&amp;#39;t hesitate to give your opinion on which to choose :   &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Credit Card attrition.&lt;/li&gt;
&lt;li&gt;Black&amp;amp;white video/ picture coloring and improving.&lt;/li&gt;
&lt;li&gt;License plate recognition&lt;/li&gt;
&lt;li&gt;Facebook Friend Recommendation&lt;/li&gt;
&lt;li&gt;Quora Question Pair Similarity&lt;/li&gt;
&lt;li&gt;Credit scoring improvement&lt;/li&gt;
&lt;li&gt;Disease Outbreak Prediction&lt;/li&gt;
&lt;li&gt;Product Recommendation system&lt;/li&gt;
&lt;li&gt;Housing Price Predictor&lt;/li&gt;
&lt;li&gt;Sentiment Analysis&lt;/li&gt;
&lt;li&gt;Stock Price Forecasting&lt;/li&gt;
&lt;li&gt;Flight Delay Prediction&lt;/li&gt;
&lt;li&gt;Fire Outbreak Prediction&lt;/li&gt;
&lt;li&gt;Game Outcome Prediction&lt;/li&gt;
&lt;li&gt;Object Detection in Videos&lt;/li&gt;
&lt;li&gt;Influencer Detection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thank you in advance for your response.&lt;/p&gt;

&lt;p&gt;P.S : If anyone has great mentorship platforms or any other way of mentorship please don&amp;#39;t hesitate.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17932k1,True,,Individual-School-07,,3,True,all_ads,False,[],False,,/r/datascience/comments/17932k1/data_science_protfolio/,all_ads,False,https://www.reddit.com/r/datascience/comments/17932k1/data_science_protfolio/,1209066,1697452955.0,0,,False,,,,,,,,,,911,145
,datascience," Source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)

About the dataset: 9,261 jobs crawled from 1605 companies worldwide in June-Sep 2023

https://preview.redd.it/dympbqa3ljub1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=e5db457072a89a08528d73fe0c064adc45372dea",t2_h7ibth00,False,,0,False,Popularity of Data Visualization tools mentioned in data-science/ml job descriptions,[],r/datascience,False,6,tooling,0,78.0,,False,t3_1792wrc,False,dark,0.73,,public,7,0,{},140.0,,False,[],,False,False,,{},Tooling,False,7,,False,False,https://b.thumbs.redditmedia.com/cXMezbFOpJ5gXIat38B9j5PV1q7W7reKi2PW-Lp8E1E.jpg,False,,[],{},,True,,1697452282.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Source: &lt;a href=""https://jobs-in-data.com/blog/machine-learning-vs-data-scientist""&gt;https://jobs-in-data.com/blog/machine-learning-vs-data-scientist&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;About the dataset: 9,261 jobs crawled from 1605 companies worldwide in June-Sep 2023&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/dympbqa3ljub1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e5db457072a89a08528d73fe0c064adc45372dea""&gt;https://preview.redd.it/dympbqa3ljub1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e5db457072a89a08528d73fe0c064adc45372dea&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,1792wrc,True,,pg860,,2,True,all_ads,False,[],False,,/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,all_ads,False,https://www.reddit.com/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,1209066,1697452282.0,0,,False,"{'dympbqa3ljub1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9edfef4f4591f0b4dd89420d28bf2c13c55e537b'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3cda0c5cdac377429b471bd1e95242339aa262ac'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a30f8d2a2e32abc0222921a52edc653263ad4173'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=13c700aae470d5a687116520c85cf0c926c0ecde'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=611070d4be7df86ecf6f74e0b577a391a57e40cd'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=edcd2da0adbe9a30dae5426da05523caf9676d52'}], 's': {'y': 1440, 'x': 2560, 'u': 'https://preview.redd.it/dympbqa3ljub1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=e5db457072a89a08528d73fe0c064adc45372dea'}, 'id': 'dympbqa3ljub1'}}",,,,,,,,,357,16
,datascience,"Hey everyone,
I work actually in a ML project for binary classification problem. When I did the EDA, I found that there are some numerical features highly skewed ( almost close to zero) and we plotted the histogram of each feature by class I have the same distribution... 

Can someone help to solve this problem 🙏🏻",t2_t3gttexz,False,,0,False,How remove highly skewed feature,[],r/datascience,False,6,projects,0,,,False,t3_1792i6s,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697450639.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,
I work actually in a ML project for binary classification problem. When I did the EDA, I found that there are some numerical features highly skewed ( almost close to zero) and we plotted the histogram of each feature by class I have the same distribution... &lt;/p&gt;

&lt;p&gt;Can someone help to solve this problem 🙏🏻&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1792i6s,True,,you_ako,,4,True,all_ads,False,[],False,,/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,all_ads,False,https://www.reddit.com/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,1209066,1697450639.0,0,,False,,,,,,,,,,315,56
,datascience,"I've been job searching for awhile now, and while I understand that the job market in general is rough right now, I have to imagine that struggling to even get initial interviews means that I'm doing something wrong. 

For context, I'm pretty much graduated with a BA in Economics at Boston University. I have some part-time and internship experience: about half a year of working the front desk of a small hotel (I have not put this on my resume since I worked the job for side money, not for work experience), a few months as a Sales Representative, a few months as a Dispute Resolution Analyst for the Better Business Bureau, and a few other internship experiences during my high school years. Obviously, none of my work experience is related to working with data or analysis, other than some of my Economics coursework, completing the Google Data Analytics certificate, and a guided project with Python (NumPy, Pandas, Seaborn) in Exploratory Data Analysis on Coursera. In any case, I know that my work experience is pretty weak/nonexistent and I've been struggling to even get an initial interview for entry-level/no-experience-required roles. So what can I do in terms of job searching/applications? Should I focus more on my resume/work experience by completing my own projects that demonstrate self-taught skills (Excel, SQL, Python, etc.)? Or should I give up on trying to apply for data/analyst roles and instead try to transition in through a different field like Marketing, Consulting, etc? Any and all feedback that can help me get past this current bottleneck would be greatly appreciated!",t2_1hog9fl5,False,,0,False,"Hitting a bottleneck (500+ applications over the past half year with barely any interviews at all). Any advice on job searching, applications, or even transitioning from another field?",[],r/datascience,False,6,discussion,0,,,False,t3_1792cy2,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,False,self,False,,[],{},,True,,1697450080.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been job searching for awhile now, and while I understand that the job market in general is rough right now, I have to imagine that struggling to even get initial interviews means that I&amp;#39;m doing something wrong. &lt;/p&gt;

&lt;p&gt;For context, I&amp;#39;m pretty much graduated with a BA in Economics at Boston University. I have some part-time and internship experience: about half a year of working the front desk of a small hotel (I have not put this on my resume since I worked the job for side money, not for work experience), a few months as a Sales Representative, a few months as a Dispute Resolution Analyst for the Better Business Bureau, and a few other internship experiences during my high school years. Obviously, none of my work experience is related to working with data or analysis, other than some of my Economics coursework, completing the Google Data Analytics certificate, and a guided project with Python (NumPy, Pandas, Seaborn) in Exploratory Data Analysis on Coursera. In any case, I know that my work experience is pretty weak/nonexistent and I&amp;#39;ve been struggling to even get an initial interview for entry-level/no-experience-required roles. So what can I do in terms of job searching/applications? Should I focus more on my resume/work experience by completing my own projects that demonstrate self-taught skills (Excel, SQL, Python, etc.)? Or should I give up on trying to apply for data/analyst roles and instead try to transition in through a different field like Marketing, Consulting, etc? Any and all feedback that can help me get past this current bottleneck would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1792cy2,True,,IGetToSkrtWhenIWant,,12,True,all_ads,False,[],False,,/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,all_ads,False,https://www.reddit.com/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,1209066,1697450080.0,0,,False,,,,,,,,,,1603,264
,datascience,"I'm an MSc graduate with some DS experience and I'm looking to move to a ML Engineering role. Are there any courses you would recommend? My Masters was in applied math and my UG was in mathematics, so I have the maths and stats, and have done a lot of work with neural nets and PyTorch. ",t2_429ud1dq,False,,0,False,ML Engineering Courses/ Certs,[],r/datascience,False,6,tooling,0,,,False,t3_1791y53,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Tooling,False,3,,False,False,self,False,,[],{},,True,,1697448322.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m an MSc graduate with some DS experience and I&amp;#39;m looking to move to a ML Engineering role. Are there any courses you would recommend? My Masters was in applied math and my UG was in mathematics, so I have the maths and stats, and have done a lot of work with neural nets and PyTorch. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,1791y53,True,,getoutofmybus,,2,True,all_ads,False,[],False,,/r/datascience/comments/1791y53/ml_engineering_courses_certs/,all_ads,False,https://www.reddit.com/r/datascience/comments/1791y53/ml_engineering_courses_certs/,1209066,1697448322.0,0,,False,,,,,,,,,,287,56
,datascience," Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. 

I have tried ""[https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)"" but it gives high score even there is no matching between words.

Thank you for your guidance. ",t2_fz8eq8fuz,False,,0,False,Which Model is best for Word Level Embeddings Generation?,[],r/datascience,False,6,discussion,0,,,False,t3_178zw5j,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697439222.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;m currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between &amp;quot;Company City Name&amp;quot; and &amp;quot;Company Country Name&amp;quot; and compare them with &amp;quot;Employee City Name&amp;quot; and &amp;quot;Employee Country Name.&amp;quot; I&amp;#39;m seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. &lt;/p&gt;

&lt;p&gt;I have tried &amp;quot;&lt;a href=""https://tfhub.dev/google/universal-sentence-encoder/4""&gt;https://tfhub.dev/google/universal-sentence-encoder/4&lt;/a&gt;&amp;quot; but it gives high score even there is no matching between words.&lt;/p&gt;

&lt;p&gt;Thank you for your guidance. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178zw5j,True,,Green_Ad6024,,1,True,all_ads,False,[],False,,/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,all_ads,False,https://www.reddit.com/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,1209066,1697439222.0,0,,False,,,,,,,,,,692,87
,datascience,"Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. Thank you for your guidance. ",t2_fz8eq8fuz,False,,0,False,Which Model is best for Word Embedding?,[],r/datascience,False,6,discussion,0,,,False,t3_178ztsj,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,False,,[],{},,True,,1697438925.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;m currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between &amp;quot;Company City Name&amp;quot; and &amp;quot;Company Country Name&amp;quot; and compare them with &amp;quot;Employee City Name&amp;quot; and &amp;quot;Employee Country Name.&amp;quot; I&amp;#39;m seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. Thank you for your guidance. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178ztsj,True,,Green_Ad6024,,1,True,all_ads,False,[],False,,/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,all_ads,False,https://www.reddit.com/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,1209066,1697438925.0,0,,False,,,,,,,,,,497,71
,datascience,"Hi everyone. My friend has a small business (think ecommerce) and asked me if i can help in any way. I have a math background but I'm interested in trying some sort of DS/DA side project. Any ideas on what topics / results i should look for?

Sorry if this is open ended; this kind of project seems very different from college projects where they tell you to do a,b,c and put it in a presentation.

Thanks!",t2_tyt5x,False,,0,False,Data science/analytics project idea for friend's business,[],r/datascience,False,6,projects,0,,,False,t3_178z2x2,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697435726.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone. My friend has a small business (think ecommerce) and asked me if i can help in any way. I have a math background but I&amp;#39;m interested in trying some sort of DS/DA side project. Any ideas on what topics / results i should look for?&lt;/p&gt;

&lt;p&gt;Sorry if this is open ended; this kind of project seems very different from college projects where they tell you to do a,b,c and put it in a presentation.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,178z2x2,True,,gumiho34,,5,True,all_ads,False,[],False,,/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,all_ads,False,https://www.reddit.com/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,1209066,1697435726.0,0,,False,,,,,,,,,,406,77
,datascience,"I'm a software engineer, while building AI side projects I noticed that it takes a while to setup the MLOPs and cloud infra for deploying and building models so, I'm creating a low-code platform for finetuning and deploying ai models (B2B mostly). do you guys think there is a market for this product ?",,False,,0,False,Is my idea worth pursuing ?,[],r/datascience,False,6,projects,0,,,False,t3_178yk7k,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},Projects,False,7,,False,,self,False,,,{},,True,,1697433586.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a software engineer, while building AI side projects I noticed that it takes a while to setup the MLOPs and cloud infra for deploying and building models so, I&amp;#39;m creating a low-code platform for finetuning and deploying ai models (B2B mostly). do you guys think there is a market for this product ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,178yk7k,True,,[deleted],,5,True,all_ads,False,[],,dark,/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,all_ads,False,https://www.reddit.com/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,1209066,1697433586.0,0,,False,,,,,,,,,,302,54
,datascience,"Hello everyone, I have been given a task where I have to find the minimum of a function. I know i can easily do this using Gradient descent but I have been specifically told to use PPO policy network and explore-exploit framework.

Is it even possible? If so then how should I go about achieving this?

link to the function formula is given here: [https://www.sfu.ca/\~ssurjano/holder.html](https://www.sfu.ca/~ssurjano/holder.html)",t2_573xy5ar,False,,0,False,How to use PPO policy network to find global min of a function ?,[],r/datascience,False,6,discussion,0,,,False,t3_178yb8k,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697432589.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I have been given a task where I have to find the minimum of a function. I know i can easily do this using Gradient descent but I have been specifically told to use PPO policy network and explore-exploit framework.&lt;/p&gt;

&lt;p&gt;Is it even possible? If so then how should I go about achieving this?&lt;/p&gt;

&lt;p&gt;link to the function formula is given here: &lt;a href=""https://www.sfu.ca/%7Essurjano/holder.html""&gt;https://www.sfu.ca/~ssurjano/holder.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178yb8k,True,,arya_Kumar,,0,True,all_ads,False,[],False,,/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,all_ads,False,https://www.reddit.com/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,1209066,1697432589.0,0,,False,,,,,,,,,,432,65
,datascience,"It’s been a while and all I really do in my job is NLP and googling. I haven’t used SQL, stats, etc.. in such a long time. I’ve looked at leetcode and interviewquery, but there’s a lot out there.

What would you recommend using? Thanks!",t2_6lukipdd,False,,0,False,What are the best sites to review DS topics/study for interviews?,[],r/datascience,False,6,discussion,0,,,False,t3_178wh2z,False,dark,0.9,,public,24,0,{},,,False,[],,False,False,,{},Discussion,False,24,,False,False,self,False,,[],{},,True,,1697425974.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It’s been a while and all I really do in my job is NLP and googling. I haven’t used SQL, stats, etc.. in such a long time. I’ve looked at leetcode and interviewquery, but there’s a lot out there.&lt;/p&gt;

&lt;p&gt;What would you recommend using? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178wh2z,True,,Much-Focus-1408,,13,True,all_ads,False,[],False,,/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,all_ads,False,https://www.reddit.com/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,1209066,1697425974.0,0,,False,,,,,,,,,,236,45
,datascience,"Anyone else confused where they fit in data science? There's a huge range of backgrounds, from bootcamps to Ph.D.s. I've found DS quite unwelcoming because of this. Everyone is trying to distinguish themselves from the ""fakers,"" while most companies needs are quite basic.

I've been working on a DS master's degree for a year. I certainly know more than the typical data analyst or self-taught MOOCs student, but I'm overwhelmed by the interdisciplinary nature of the field. I've invested countless hours and thousands of dollars, yet there's a lifetime more to learn. This makes me question whether I want to continue in the field. When I talk to computer scientists, they're all very encouraging and emphasize that, although difficult, everyone can learn to code. When I talk to other data scientists, I get an air of elitism.

I think this happens because data science is a relatively new field. Other specialized skills like accounting, law, or finance have had time to settle into a list of requirements and utilize certifications where necessary. Since we have one title to describe a huge population, people end up getting defensive so they're not grouped together with the less qualified. Maybe overtime this resolves itself as data science expands into more titles. For now, I feel caught between both sides of the argument. I have no desire to get a PhD and a lot of imposter syndrome. It leaves me feeling like I should have gone MBA -&gt; product management and called it a day.  On the flip side, when I explain basic stats at work, I'm met with blank stares, leading me to think the push for Ph.Ds is more about ego than practicality. My hope is to see clearer distinction in titles and more encouragement in the field than discouragement. 

For those of you in the middle like me, where have y'all had success? What kinds of industries, companies, or roles do you target?",t2_9zed6pt,False,,0,False,Identity Crisis in Data Science,[],r/datascience,False,6,discussion,0,,,False,t3_178vvrk,False,dark,0.86,,public,73,0,{},,,False,[],,False,False,,{},Discussion,False,73,,False,False,self,False,,[],{},,True,,1697424043.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone else confused where they fit in data science? There&amp;#39;s a huge range of backgrounds, from bootcamps to Ph.D.s. I&amp;#39;ve found DS quite unwelcoming because of this. Everyone is trying to distinguish themselves from the &amp;quot;fakers,&amp;quot; while most companies needs are quite basic.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been working on a DS master&amp;#39;s degree for a year. I certainly know more than the typical data analyst or self-taught MOOCs student, but I&amp;#39;m overwhelmed by the interdisciplinary nature of the field. I&amp;#39;ve invested countless hours and thousands of dollars, yet there&amp;#39;s a lifetime more to learn. This makes me question whether I want to continue in the field. When I talk to computer scientists, they&amp;#39;re all very encouraging and emphasize that, although difficult, everyone can learn to code. When I talk to other data scientists, I get an air of elitism.&lt;/p&gt;

&lt;p&gt;I think this happens because data science is a relatively new field. Other specialized skills like accounting, law, or finance have had time to settle into a list of requirements and utilize certifications where necessary. Since we have one title to describe a huge population, people end up getting defensive so they&amp;#39;re not grouped together with the less qualified. Maybe overtime this resolves itself as data science expands into more titles. For now, I feel caught between both sides of the argument. I have no desire to get a PhD and a lot of imposter syndrome. It leaves me feeling like I should have gone MBA -&amp;gt; product management and called it a day.  On the flip side, when I explain basic stats at work, I&amp;#39;m met with blank stares, leading me to think the push for Ph.Ds is more about ego than practicality. My hope is to see clearer distinction in titles and more encouragement in the field than discouragement. &lt;/p&gt;

&lt;p&gt;For those of you in the middle like me, where have y&amp;#39;all had success? What kinds of industries, companies, or roles do you target?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178vvrk,True,,n96j77,,32,True,all_ads,False,[],False,,/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,all_ads,False,https://www.reddit.com/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,1209066,1697424043.0,0,,False,,,,,,,,,,1887,322
,datascience,"I have a certain data that I measure the uncertainty via Monte Carlo, but I was wondering if there is a practical way to do that using machine learning.",t2_dffbrzoz3,False,,0,False,What is the best tool or way to measure uncertainties using machine learning ?,[],r/datascience,False,6,discussion,0,,,False,t3_178vkg9,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697423059.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a certain data that I measure the uncertainty via Monte Carlo, but I was wondering if there is a practical way to do that using machine learning.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178vkg9,True,,CrazyProfessionalp,,2,True,all_ads,False,[],False,,/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,all_ads,False,https://www.reddit.com/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,1209066,1697423059.0,0,,False,,,,,,,,,,152,29
,datascience,"Hello there. 

I've been thinking a lot recently about ML projects that failed and tried to organize and write up my thoughts. Do y'all see it this way?  

[https://www.kobrosly.net/ML\_failure\_funnel.html](https://www.kobrosly.net/ML_failure_funnel.html)",t2_luqf6xu01,False,,0,False,The ML project failure funnel,[],r/datascience,False,6,discussion,0,,,False,t3_178shmx,False,dark,0.67,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697413509.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been thinking a lot recently about ML projects that failed and tried to organize and write up my thoughts. Do y&amp;#39;all see it this way?  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.kobrosly.net/ML_failure_funnel.html""&gt;https://www.kobrosly.net/ML_failure_funnel.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178shmx,True,,Practical_Laugh6208,,2,True,all_ads,False,[],False,,/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,all_ads,False,https://www.reddit.com/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,1209066,1697413509.0,0,,False,,,,,,,,,,256,29
,datascience," 

\#Apple, #Question, #Data\_Scientists,

What do data scientist do when their data isn't reliable? Looking for answers other than the easily Googled/ChatGPTed validate, clean, imputation, transformation, documentation, source investigation, quality assessment, etc.

\#Context, 

A project my team and I are working on we regularly release builds using Testflight. 

An observation is that Apple has incorrect analytics even within their walled garden from AppStoreConnect to TestFlight.

Specifically, in this screencast/video we can see that the version of the app which the App Store Connect dashboard says I've currently got installed is 1.0.1+26 which was installed today October 15th 2023.  


[https://youtube.com/shorts/Sc2NrvAKFlA?feature=share](https://youtube.com/shorts/Sc2NrvAKFlA?feature=share)

But at the beginning &amp; end of the video, we clearly see that I haven't installed that version yet; I still need to update.

I accept data between differing aggregators being ""off"" no problem. 

\#Unpopular\_Opinion

However seeing this behavior within a platform/company which is the largest, most well-funded, arguably among the most technical in the world makes me doubt the value of data analytics/science.   


How can we be sure of our analysis if we can't be sure of our data? It's disconcerting.

Not trying to flame data scientists here, trying to figure out how to feel cause I do believe we have to have analytics/benchmarks to make informed decisions but this conundrum is causing cognitive dissonance.  


Looking forward to seeing everyones feedback.  
",t2_7w92pawj0,False,,0,False,What do data scientist do when their data isn't reliable?,[],r/datascience,False,6,discussion,0,,,False,t3_178rqxf,False,dark,0.38,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697411282.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;#Apple, #Question, #Data_Scientists,&lt;/p&gt;

&lt;p&gt;What do data scientist do when their data isn&amp;#39;t reliable? Looking for answers other than the easily Googled/ChatGPTed validate, clean, imputation, transformation, documentation, source investigation, quality assessment, etc.&lt;/p&gt;

&lt;p&gt;#Context, &lt;/p&gt;

&lt;p&gt;A project my team and I are working on we regularly release builds using Testflight. &lt;/p&gt;

&lt;p&gt;An observation is that Apple has incorrect analytics even within their walled garden from AppStoreConnect to TestFlight.&lt;/p&gt;

&lt;p&gt;Specifically, in this screencast/video we can see that the version of the app which the App Store Connect dashboard says I&amp;#39;ve currently got installed is 1.0.1+26 which was installed today October 15th 2023.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://youtube.com/shorts/Sc2NrvAKFlA?feature=share""&gt;https://youtube.com/shorts/Sc2NrvAKFlA?feature=share&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But at the beginning &amp;amp; end of the video, we clearly see that I haven&amp;#39;t installed that version yet; I still need to update.&lt;/p&gt;

&lt;p&gt;I accept data between differing aggregators being &amp;quot;off&amp;quot; no problem. &lt;/p&gt;

&lt;p&gt;#Unpopular_Opinion&lt;/p&gt;

&lt;p&gt;However seeing this behavior within a platform/company which is the largest, most well-funded, arguably among the most technical in the world makes me doubt the value of data analytics/science.   &lt;/p&gt;

&lt;p&gt;How can we be sure of our analysis if we can&amp;#39;t be sure of our data? It&amp;#39;s disconcerting.&lt;/p&gt;

&lt;p&gt;Not trying to flame data scientists here, trying to figure out how to feel cause I do believe we have to have analytics/benchmarks to make informed decisions but this conundrum is causing cognitive dissonance.  &lt;/p&gt;

&lt;p&gt;Looking forward to seeing everyones feedback.  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178rqxf,True,,Ordinary_Jelly_6344,,5,True,all_ads,False,[],False,,/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,all_ads,False,https://www.reddit.com/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,1209066,1697411282.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/k8-1zIsM0SRPOV7X8qG4QJCMrNs0QI0-rye7cPAT2PI.jpg?auto=webp&amp;s=a5e3d7afaf20dc95ce1717bf168c34121e0aba01', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/k8-1zIsM0SRPOV7X8qG4QJCMrNs0QI0-rye7cPAT2PI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d55949581d6b1b373784fd51be28c2ed05b9a8d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/k8-1zIsM0SRPOV7X8qG4QJCMrNs0QI0-rye7cPAT2PI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=78869e61d6162b772abf5683dbb805d62fa5f101', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/k8-1zIsM0SRPOV7X8qG4QJCMrNs0QI0-rye7cPAT2PI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec0e96baec73a0514888291f1c782e763ee68e72', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'G3nURuj0Nmb70H_xxCKo8NK7atx3D-alGH14EKfiEaU'}], 'enabled': False}",,,,,,,1582,220
,datascience,"I've been a data scientist with 3 (almost 4) years experience and a Masters. Is there somewhere you guys go to get your resume critiqued or improved? I've tried sending it to a career counselor and she thought it was good. Also, I met someone who works in the industry through a career fair, and he said it is ""impressive"". Nevertheless, I apply to job after job, only to get rejection emails. After 4 months, I've had one interview and that was through a referral. Even the hiring manager said the resume looks good for the job (before interview). This happens even if I tailor my resume, apply to jobs that I feel I'm highly qualified, and am early in applying (within a week of job posting). I feel like I'm wasting time, and this is just the first step. Interviewing is going to be another battle, and at this rate I will never find something!",t2_jnnvdz39c,False,,0,False,Not getting noticed for data science jobs,[],r/datascience,False,6,discussion,0,,,False,t3_178r037,False,dark,0.86,,public,55,0,{},,,False,[],,False,False,,{},Discussion,False,55,,False,False,self,False,,[],{},,True,,1697409160.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been a data scientist with 3 (almost 4) years experience and a Masters. Is there somewhere you guys go to get your resume critiqued or improved? I&amp;#39;ve tried sending it to a career counselor and she thought it was good. Also, I met someone who works in the industry through a career fair, and he said it is &amp;quot;impressive&amp;quot;. Nevertheless, I apply to job after job, only to get rejection emails. After 4 months, I&amp;#39;ve had one interview and that was through a referral. Even the hiring manager said the resume looks good for the job (before interview). This happens even if I tailor my resume, apply to jobs that I feel I&amp;#39;m highly qualified, and am early in applying (within a week of job posting). I feel like I&amp;#39;m wasting time, and this is just the first step. Interviewing is going to be another battle, and at this rate I will never find something!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178r037,True,,daufoi21,,37,True,all_ads,False,[],False,,/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,all_ads,False,https://www.reddit.com/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,1209066,1697409160.0,0,,False,,,,,,,,,,847,156
,datascience,"Apologies if this is the wrong place to ask. I was recently hired as a data scientist in a (motor) finance company. What is your opinion about this industry? Are insurance skills transferable to other industries too and if so, which ones do you think are closest?",t2_yfayr,False,,0,False,Opinions about the insurance industry?,[],r/datascience,False,6,discussion,0,,,False,t3_178oz6c,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,False,,[],{},,True,,1697403727.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Apologies if this is the wrong place to ask. I was recently hired as a data scientist in a (motor) finance company. What is your opinion about this industry? Are insurance skills transferable to other industries too and if so, which ones do you think are closest?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178oz6c,True,,sn9691,,1,True,all_ads,False,[],False,,/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,all_ads,False,https://www.reddit.com/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,1209066,1697403727.0,0,,False,,,,,,,,,,263,47
,datascience,"I'm just starting a PhD in a life science field (at a top university, if it matters). I've been wanting to learn more about the data science field and whether having a PhD in a biology domain would be helpful for data scientists positions within biotech, healthcare, etc. I plan to complete a computational certificate that my program offers, and my thesis project should involve a good amount of data science on top of wet-lab work.

Would this be a good career path? Will not having a degree in computer science, data science, etc. put me at a disadvantage?",t2_v3w0otrg,False,,0,False,Biologist (PhD) --&gt; Data Scientist?,[],r/datascience,False,6,discussion,0,,,False,t3_178nz28,False,dark,0.38,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697400966.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m just starting a PhD in a life science field (at a top university, if it matters). I&amp;#39;ve been wanting to learn more about the data science field and whether having a PhD in a biology domain would be helpful for data scientists positions within biotech, healthcare, etc. I plan to complete a computational certificate that my program offers, and my thesis project should involve a good amount of data science on top of wet-lab work.&lt;/p&gt;

&lt;p&gt;Would this be a good career path? Will not having a degree in computer science, data science, etc. put me at a disadvantage?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178nz28,True,,No-Dot-6385,,4,True,all_ads,False,[],False,,/r/datascience/comments/178nz28/biologist_phd_data_scientist/,all_ads,False,https://www.reddit.com/r/datascience/comments/178nz28/biologist_phd_data_scientist/,1209066,1697400966.0,0,,False,,,,,,,,,,559,99
,datascience,"Has anyone interviewed at c3ai? I've read there are 3 stages of b2b interviews: ML/stats fundamentals, pandas/numpy/python coding, case study. 

What kind of questions are asked, especially in the case study portion? what exactly does the coding part inolve? also for stats - is it enough to cover hypothesis testing, p-values, PCA, etc? 

Any insight is appreciated!",t2_46r0mytx,False,,0,False,c3AI data scientist interview,[],r/datascience,False,6,discussion,0,,,False,t3_178neqa,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697399391.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone interviewed at c3ai? I&amp;#39;ve read there are 3 stages of b2b interviews: ML/stats fundamentals, pandas/numpy/python coding, case study. &lt;/p&gt;

&lt;p&gt;What kind of questions are asked, especially in the case study portion? what exactly does the coding part inolve? also for stats - is it enough to cover hypothesis testing, p-values, PCA, etc? &lt;/p&gt;

&lt;p&gt;Any insight is appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178neqa,True,,hellohibyebye13,,5,True,all_ads,False,[],False,,/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,all_ads,False,https://www.reddit.com/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,1209066,1697399391.0,0,,False,,,,,,,,,,367,57
,datascience,"
For some context, I’m a 24 year old international who recently graduated with a MS in CS in the US. Throughout my bachelors and while applying for internships during my first year, I always wanted to do DS. This was primarily based on a misconception however. 

During my bachelors I was not serious about coursework or coding, not in the slightest. It was only when covid hit and I realized I’ll be going to the US soon, did I start looking into some actual coding stuff. Started off with Python and thought DS was all about pandas, numpy and scikit learn and decided this is what I wanted to do. Obviously as I started grad school and learnt more about the actual nuances of ML and DS, I realized I was nowhere near good enough with my foundations in stats and math. 

I do consider myself to be a problem solver though, so despite not having a great base and starting off with grad level concepts in school, I was able to get upto speed and score a good grade. 

After this, I landed my first internship in “Data Science” at a consulting firm. Through 3 months, all I did was a ton of web scraping and ETL operations. Applying traditional ML in litigation casework is not easy because eventually all cases or most cases end up in front of a jury. So I never got to apply all that math in a professional environment. 

Since then, the world went through a “recession” and I couldn’t even land a single other interview. Did another internship with these guys and switched my focus to development based cases. Started building dashboards in Javascript and backends in C#. The closest DS related work I have done is integrating Azure OpenAI LLM APIs into a VueJs frond end through a .NET backend. Did this for 2 reasons, one, web scraping and ETL was redundant and boring. Two, the manager in charge of those cases is awful, constantly undermining my credentials, never even making eye contact during a conversation, insanely condescending and even told me multiple times that he doesn’t believe I have 2 degrees in CS. 

Anyway, at this point, I have been doing this for about 10 months. Based on my work that has transcended into more software development, do you think I should exclusively apply to SWE jobs to find a way out? What could my options be? Also, does this kind of a resume where you jump from one tech stack to another hurt? I haven’t received any interviews in about a year. Wondering if this is the general state of the world or is something fundamentally wrong with my work exp and if I’m stuck where I am.",t2_i9fgk8dg,False,,0,False,Is my experience not good?,[],r/datascience,False,6,discussion,0,,,False,t3_178lcts,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,1697394042.0,,[],{},,True,,1697393737.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For some context, I’m a 24 year old international who recently graduated with a MS in CS in the US. Throughout my bachelors and while applying for internships during my first year, I always wanted to do DS. This was primarily based on a misconception however. &lt;/p&gt;

&lt;p&gt;During my bachelors I was not serious about coursework or coding, not in the slightest. It was only when covid hit and I realized I’ll be going to the US soon, did I start looking into some actual coding stuff. Started off with Python and thought DS was all about pandas, numpy and scikit learn and decided this is what I wanted to do. Obviously as I started grad school and learnt more about the actual nuances of ML and DS, I realized I was nowhere near good enough with my foundations in stats and math. &lt;/p&gt;

&lt;p&gt;I do consider myself to be a problem solver though, so despite not having a great base and starting off with grad level concepts in school, I was able to get upto speed and score a good grade. &lt;/p&gt;

&lt;p&gt;After this, I landed my first internship in “Data Science” at a consulting firm. Through 3 months, all I did was a ton of web scraping and ETL operations. Applying traditional ML in litigation casework is not easy because eventually all cases or most cases end up in front of a jury. So I never got to apply all that math in a professional environment. &lt;/p&gt;

&lt;p&gt;Since then, the world went through a “recession” and I couldn’t even land a single other interview. Did another internship with these guys and switched my focus to development based cases. Started building dashboards in Javascript and backends in C#. The closest DS related work I have done is integrating Azure OpenAI LLM APIs into a VueJs frond end through a .NET backend. Did this for 2 reasons, one, web scraping and ETL was redundant and boring. Two, the manager in charge of those cases is awful, constantly undermining my credentials, never even making eye contact during a conversation, insanely condescending and even told me multiple times that he doesn’t believe I have 2 degrees in CS. &lt;/p&gt;

&lt;p&gt;Anyway, at this point, I have been doing this for about 10 months. Based on my work that has transcended into more software development, do you think I should exclusively apply to SWE jobs to find a way out? What could my options be? Also, does this kind of a resume where you jump from one tech stack to another hurt? I haven’t received any interviews in about a year. Wondering if this is the general state of the world or is something fundamentally wrong with my work exp and if I’m stuck where I am.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178lcts,True,,Objective-Test5021,,9,True,all_ads,False,[],False,,/r/datascience/comments/178lcts/is_my_experience_not_good/,all_ads,False,https://www.reddit.com/r/datascience/comments/178lcts/is_my_experience_not_good/,1209066,1697393737.0,0,,False,,,,,,,,,,2525,458
,datascience,"Hello wonderful people,
I've been ask to study the effect of price on the final room occupancy rate for the hostels of my company.

So here are the data :
For a date (t), and for a specific room type, I have the occupancy Rate (OR, between 0 and 1), a set of categorical ordinal variables (total of 90 variables) that represent an indexed price of the room at a date (t-z). In other words, I know what was the indexed price of a specific room from the date being analysed back to 90 days before.

As I said, those exogenous variables are categorical ordinal. For example : PRICE1, PRINCE2... PRICE10, with price2 being more expensive than PRICE1. It is an indexed price in the sense that it drives the applied price on different booking network (booking.com, Expedia, our own website...)

How would you approach this subject ? I had in mind to try fitting an ARIMA model and look at the model parameters, but with the categorical ordinal variables, it would mean one-hour encoding and therefore having a huuuge dimensionality...

What do you guys think ? 💪",t2_bl8dhx5v,False,,0,False,Price effect on room occupancy rate,[],r/datascience,False,6,discussion,0,,,False,t3_178l850,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697393383.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello wonderful people,
I&amp;#39;ve been ask to study the effect of price on the final room occupancy rate for the hostels of my company.&lt;/p&gt;

&lt;p&gt;So here are the data :
For a date (t), and for a specific room type, I have the occupancy Rate (OR, between 0 and 1), a set of categorical ordinal variables (total of 90 variables) that represent an indexed price of the room at a date (t-z). In other words, I know what was the indexed price of a specific room from the date being analysed back to 90 days before.&lt;/p&gt;

&lt;p&gt;As I said, those exogenous variables are categorical ordinal. For example : PRICE1, PRINCE2... PRICE10, with price2 being more expensive than PRICE1. It is an indexed price in the sense that it drives the applied price on different booking network (booking.com, Expedia, our own website...)&lt;/p&gt;

&lt;p&gt;How would you approach this subject ? I had in mind to try fitting an ARIMA model and look at the model parameters, but with the categorical ordinal variables, it would mean one-hour encoding and therefore having a huuuge dimensionality...&lt;/p&gt;

&lt;p&gt;What do you guys think ? 💪&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178l850,True,,Zealousideal-Yak5547,,4,True,all_ads,False,[],False,,/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,all_ads,False,https://www.reddit.com/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,1209066,1697393383.0,0,,False,,,,,,,,,,1056,188
,datascience,"Hello!

I’m going back to school full time in the spring. I’m double majoring in data science and interactive media and getting my B.S. in both. I’m projected to be graduated by Spring of 2027. What internships should I start looking into and how far along in school should I start applying? I’m new to this field and have done alot of research into the type of jobs I can get but just wanted outside opinion.",t2_ajtcfpv6,False,,0,False,Going back to school,[],r/datascience,False,6,discussion,0,,,False,t3_178kwzn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697392535.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;I’m going back to school full time in the spring. I’m double majoring in data science and interactive media and getting my B.S. in both. I’m projected to be graduated by Spring of 2027. What internships should I start looking into and how far along in school should I start applying? I’m new to this field and have done alot of research into the type of jobs I can get but just wanted outside opinion.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178kwzn,True,,Humble_Engineer1124,,0,True,all_ads,False,[],False,,/r/datascience/comments/178kwzn/going_back_to_school/,all_ads,False,https://www.reddit.com/r/datascience/comments/178kwzn/going_back_to_school/,1209066,1697392535.0,0,,False,,,,,,,,,,409,76
,datascience,I’m seeing a lot of people recommending people that have a degree in econ/cs/math to get a masters in data science or statistics. Will I need one if my whole bachelors is based in pure data science anyway?,t2_e0veyxtn,False,,0,False,Get masters if my bachelors is in data sci?,[],r/datascience,False,6,discussion,0,,,False,t3_178kwz8,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697392534.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m seeing a lot of people recommending people that have a degree in econ/cs/math to get a masters in data science or statistics. Will I need one if my whole bachelors is based in pure data science anyway?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178kwz8,True,,Patient-Sun-5806,,6,True,all_ads,False,[],False,,/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,all_ads,False,https://www.reddit.com/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,1209066,1697392534.0,0,,False,,,,,,,,,,205,38
,datascience,"I am aware about the experiment design process in simple business model, but experiment design is lot more complicated in two sided or three sided marketplace. Can anyone help me to understand how the experiment design works in three sided marketplace like Uber or Amazon ?",t2_cai0dil0,False,,0,False,Casual Inference,[],r/datascience,False,6,discussion,0,,,False,t3_178kkpc,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,False,,[],{},,True,,1697391557.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am aware about the experiment design process in simple business model, but experiment design is lot more complicated in two sided or three sided marketplace. Can anyone help me to understand how the experiment design works in three sided marketplace like Uber or Amazon ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178kkpc,True,,indiancaptainamerica,,5,True,all_ads,False,[],False,,/r/datascience/comments/178kkpc/casual_inference/,all_ads,False,https://www.reddit.com/r/datascience/comments/178kkpc/casual_inference/,1209066,1697391557.0,0,,False,,,,,,,,,,273,46
,datascience,"I come from more of a engineering(non-software) background and never learned Data Structures and Algorithms. I want to start applying for jobs next year(3 YOE), how often are you asked Leetcode questions in interviews? I'm trying to figure out a plan of action to get prepared.",t2_4d3uhjau,False,,0,False,Do you folks Leetcode?,[],r/datascience,False,6,discussion,0,,,False,t3_178juum,False,dark,0.96,,public,114,0,{},,,False,[],,False,False,,{},Discussion,False,114,,False,False,self,False,,[],{},,True,,1697389501.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I come from more of a engineering(non-software) background and never learned Data Structures and Algorithms. I want to start applying for jobs next year(3 YOE), how often are you asked Leetcode questions in interviews? I&amp;#39;m trying to figure out a plan of action to get prepared.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178juum,True,,Puzzled_Implement_78,,76,True,all_ads,False,[],False,,/r/datascience/comments/178juum/do_you_folks_leetcode/,all_ads,False,https://www.reddit.com/r/datascience/comments/178juum/do_you_folks_leetcode/,1209066,1697389501.0,0,,False,,,,,,,,,,277,46
,datascience,"I am a 27-year-old guy who lives in the Netherlands and has about 2.5 years of experience in data science/software engineering. I've always dreamt of going on an international adventure and working abroad in Europe. Unfortunately, I have not yet been able to or have had the courage to take the leap. Now, with my girlfriend going on an exchange at the start of 2024, it feels like the perfect time to explore the possibilities of finding a job abroad.

I'm looking for tips, help, or experiences on how to tackle this big project. How do you start to look for jobs or projects? I know LinkedIn of course, but I'm wondering if there are also companies hiring people for a fixed-time contract. Or are there any businesses or platforms that connect job seekers with such companies? I'm uncertain about committing to an indefinite job, and I think for example a 6-month project might provide more security.

I'd appreciate any advice or stories that people are willing to share about their experiences working abroad. Thank you in advance for your support and wisdom!",t2_elevuvfh,False,,0,False,Tips on Data Science Jobs Abroad,[],r/datascience,False,6,discussion,0,,,False,t3_178j8v9,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,1697390123.0,,[],{},,True,,1697387734.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a 27-year-old guy who lives in the Netherlands and has about 2.5 years of experience in data science/software engineering. I&amp;#39;ve always dreamt of going on an international adventure and working abroad in Europe. Unfortunately, I have not yet been able to or have had the courage to take the leap. Now, with my girlfriend going on an exchange at the start of 2024, it feels like the perfect time to explore the possibilities of finding a job abroad.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking for tips, help, or experiences on how to tackle this big project. How do you start to look for jobs or projects? I know LinkedIn of course, but I&amp;#39;m wondering if there are also companies hiring people for a fixed-time contract. Or are there any businesses or platforms that connect job seekers with such companies? I&amp;#39;m uncertain about committing to an indefinite job, and I think for example a 6-month project might provide more security.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d appreciate any advice or stories that people are willing to share about their experiences working abroad. Thank you in advance for your support and wisdom!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178j8v9,True,,TheFibonacci1235,,0,True,all_ads,False,[],False,,/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,all_ads,False,https://www.reddit.com/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,1209066,1697387734.0,0,,False,,,,,,,,,,1064,183
,datascience,"Edit: thank you for all of your help!! I spoke with legal and said where I was, where I was going to be, and asked for more time to get the data. The data is slowly coming in; very excited! 

Feeling incredibly anxious since this goes against my ethical morals. 

I trained a model on data that won’t be used anymore; however, they want to use this model for data/KPIs that I’ve never seen before. They overpromised to senior leadership because the company is suffering. And they want me to over-deliver and do the paperwork/put this model into production.

I’ve asked to delay the deadline to get access to the KPIs for the model, but all they did was move the model due date up by…. A month. 

I’m having panic attacks and can’t sleep because this is just setting me up to fail. I’m so burnt out after speaking with management/teams. They just want to push this model into production, no matter what. 

How do you handle that? I’ve escalated the problem to other pp in mgmt and they said to just do it because of how important the model is. I’m 1000% sure that I’ll be seen as a scapegoat because there’s no way you can have a good model if there’s no data to train it/the wrong data.

For example, the OG data was on cats, but now they want me to look at data about ligers. It’s ridiculous and I’m not sure what to do. 

I haven’t been able to deliver the paperwork like they want/legal review because I know that this model isn’t good, but they want this to go into production so badly that the paperwork/things I’m saying aren’t correct. It’s due tomorrow, but there’s no way I can feasibly do that. I’ve tried meds and even thought of taking myself out of office this week to avoid this, but I lack the PTO. I got sick from the lack of sleep and I’m finding myself procrastinating on anything else because this ask seems so unethical. So many people at my company/role are getting laid off, and I should do this, but I just can’t do this. It’s related to my performance goals, too.",t2_6lukipdd,False,,0,False,Mgmt and team want me to put a model in production without data. What do I do?,[],r/datascience,False,6,discussion,0,,,False,t3_178ioxq,False,dark,0.72,,public,9,0,{},,,False,[],,False,False,,{},Discussion,False,9,,False,False,self,1697510944.0,,[],{},,True,,1697386202.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Edit: thank you for all of your help!! I spoke with legal and said where I was, where I was going to be, and asked for more time to get the data. The data is slowly coming in; very excited! &lt;/p&gt;

&lt;p&gt;Feeling incredibly anxious since this goes against my ethical morals. &lt;/p&gt;

&lt;p&gt;I trained a model on data that won’t be used anymore; however, they want to use this model for data/KPIs that I’ve never seen before. They overpromised to senior leadership because the company is suffering. And they want me to over-deliver and do the paperwork/put this model into production.&lt;/p&gt;

&lt;p&gt;I’ve asked to delay the deadline to get access to the KPIs for the model, but all they did was move the model due date up by…. A month. &lt;/p&gt;

&lt;p&gt;I’m having panic attacks and can’t sleep because this is just setting me up to fail. I’m so burnt out after speaking with management/teams. They just want to push this model into production, no matter what. &lt;/p&gt;

&lt;p&gt;How do you handle that? I’ve escalated the problem to other pp in mgmt and they said to just do it because of how important the model is. I’m 1000% sure that I’ll be seen as a scapegoat because there’s no way you can have a good model if there’s no data to train it/the wrong data.&lt;/p&gt;

&lt;p&gt;For example, the OG data was on cats, but now they want me to look at data about ligers. It’s ridiculous and I’m not sure what to do. &lt;/p&gt;

&lt;p&gt;I haven’t been able to deliver the paperwork like they want/legal review because I know that this model isn’t good, but they want this to go into production so badly that the paperwork/things I’m saying aren’t correct. It’s due tomorrow, but there’s no way I can feasibly do that. I’ve tried meds and even thought of taking myself out of office this week to avoid this, but I lack the PTO. I got sick from the lack of sleep and I’m finding myself procrastinating on anything else because this ask seems so unethical. So many people at my company/role are getting laid off, and I should do this, but I just can’t do this. It’s related to my performance goals, too.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178ioxq,True,,Much-Focus-1408,,32,True,all_ads,False,[],False,,/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,1209066,1697386202.0,0,,False,,,,,,,,,,1987,370
,datascience,"Do you use Causal Inference as a data scientist? I wrote an article to reflect why it took so long for data scientists to discover Causal Inference and and tried to give an inspirational overview (just look at the images). 

[http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/](http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/)",t2_7iste,False,,0,False,Causal inference as a blind spot of data scientists,[],r/datascience,False,6,discussion,0,,,False,t3_178ifs7,False,dark,0.88,,public,65,0,{},,,False,[],,False,False,,{},Discussion,False,65,,False,False,self,False,,[],{},,True,,1697385528.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you use Causal Inference as a data scientist? I wrote an article to reflect why it took so long for data scientists to discover Causal Inference and and tried to give an inspirational overview (just look at the images). &lt;/p&gt;

&lt;p&gt;&lt;a href=""http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/""&gt;http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178ifs7,True,,kafka399,,61,True,all_ads,False,[],False,,/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,1209066,1697385528.0,0,,False,,,,,,,,,,329,41
,datascience,"Updated:

Thank you so much for all the suggestions and comments! The community is so supportive and enthusiastic. I read every comments very carefully, probably more than one time for most, and they are very insightful and play a vital role in my decision making, whether thumbs up or down.

I have been thinking about this almost every minutes in the past few days. In the end, I decided to take this offer. For me this decision is very complicated. Actually I am not sure how long I will stay, but it's always important to make my first step.

Thank you again for all the comments! 

\--------------------------------------------------------------------

As a new graduate recently I am getting a data analyst offer from a casino resort. It's a hard time for new grad and after two times of withdrawals of my offers, this is the only one I have in my hands. The job duty is about analyzing campaign performance, analyzing customer patterns, and forecasting business trends.  They are also working on breaking data silos utilizing cloud service so ETL jobs should also be expected.

Overall the project sounds pretty attractive to me. My only concern is the business itself. One of my friends (not in US) gave me a strong suggestion that don't easily go into this industry. He was working in an operation role for company building mobile casinos, and the business logic was so different from other industries that it's hard to get out of this. Many people have a bias toward this career so he had a hard time changing jobs.

I am scared, to be honest. But I am not sure to what extent his thoughts work in my scenario. Casino Resort still looks much different from mobile casinos and his role was not data analyst. I wonder how you guys think about this.  Should I take this offer?",t2_ecmqntuj,False,,0,False,Will being data analyst in casino resort ruin my career?,[],r/datascience,False,6,discussion,0,,,False,t3_178fhbg,False,dark,0.88,,public,211,0,{},,,False,[],,False,False,,{},Discussion,False,211,,False,False,self,1697725332.0,,[],{},,True,,1697376874.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Updated:&lt;/p&gt;

&lt;p&gt;Thank you so much for all the suggestions and comments! The community is so supportive and enthusiastic. I read every comments very carefully, probably more than one time for most, and they are very insightful and play a vital role in my decision making, whether thumbs up or down.&lt;/p&gt;

&lt;p&gt;I have been thinking about this almost every minutes in the past few days. In the end, I decided to take this offer. For me this decision is very complicated. Actually I am not sure how long I will stay, but it&amp;#39;s always important to make my first step.&lt;/p&gt;

&lt;p&gt;Thank you again for all the comments! &lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;As a new graduate recently I am getting a data analyst offer from a casino resort. It&amp;#39;s a hard time for new grad and after two times of withdrawals of my offers, this is the only one I have in my hands. The job duty is about analyzing campaign performance, analyzing customer patterns, and forecasting business trends.  They are also working on breaking data silos utilizing cloud service so ETL jobs should also be expected.&lt;/p&gt;

&lt;p&gt;Overall the project sounds pretty attractive to me. My only concern is the business itself. One of my friends (not in US) gave me a strong suggestion that don&amp;#39;t easily go into this industry. He was working in an operation role for company building mobile casinos, and the business logic was so different from other industries that it&amp;#39;s hard to get out of this. Many people have a bias toward this career so he had a hard time changing jobs.&lt;/p&gt;

&lt;p&gt;I am scared, to be honest. But I am not sure to what extent his thoughts work in my scenario. Casino Resort still looks much different from mobile casinos and his role was not data analyst. I wonder how you guys think about this.  Should I take this offer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178fhbg,True,,BladeClickerQQ,,131,True,all_ads,False,[],False,,/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,all_ads,False,https://www.reddit.com/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,1209066,1697376874.0,0,,False,,,,,,,,,,1783,311
,datascience,"Data analytics leadership and imposter syndrome?

I have found myself in and out of data analytics leadership roles in the past decade, mixed with hands-on data analyst work. I know I have some legit skills (eg, I have lots of experience in inferential statistics, research, can speak to the outcomes well, etc), but I can’t seem to shake the feeling of not deserving to be in a leadership position. For example, I recently hired a data analyst to expand my existing team and going through all the resumes showed me all the things that I can’t do (work in specific coding languages, predictive modeling, just to name a few). At several points, I asked myself why these people shouldn’t be MY boss because they clearly have to teach me lots of valuable skills. 

So please talk to me about the value-add of analytics leadership: what does a good leader bring to the table? Is it okay to not be able to do everything yourself? Is this imposter syndrome and do others recognize it?",t2_a69wz9pgw,False,,0,False,Data analytics leadership and imposter syndrome?,[],r/datascience,False,6,discussion,0,,,False,t3_178eum0,False,dark,0.8,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,False,self,False,,[],{},,True,,1697374785.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data analytics leadership and imposter syndrome?&lt;/p&gt;

&lt;p&gt;I have found myself in and out of data analytics leadership roles in the past decade, mixed with hands-on data analyst work. I know I have some legit skills (eg, I have lots of experience in inferential statistics, research, can speak to the outcomes well, etc), but I can’t seem to shake the feeling of not deserving to be in a leadership position. For example, I recently hired a data analyst to expand my existing team and going through all the resumes showed me all the things that I can’t do (work in specific coding languages, predictive modeling, just to name a few). At several points, I asked myself why these people shouldn’t be MY boss because they clearly have to teach me lots of valuable skills. &lt;/p&gt;

&lt;p&gt;So please talk to me about the value-add of analytics leadership: what does a good leader bring to the table? Is it okay to not be able to do everything yourself? Is this imposter syndrome and do others recognize it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178eum0,True,,Rebec1990,,13,True,all_ads,False,[],False,,/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,all_ads,False,https://www.reddit.com/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,1209066,1697374785.0,0,,False,,,,,,,,,,978,173
,datascience," td/dr: easily build a SaaS with just python + zero front-end knowledge using streamlit.

I wrote this short guide which allows you to create a Data Science micro-SaaS MVP with stripe integration using Streamlit python package. I thought folks here might find it useful. Example of a zillow clone below.

[A Comprehensive Guide to Building and Deploying a Scalable SaaS Web App with Python, Streamlit, MongoDB, and Stripe](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86)

[example of Streamlit SaaS](https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&amp;format=png&amp;auto=webp&amp;s=82643795b248c160de48cdc0f2fee9b0c6ac19ed)",t2_2n4fkzma,False,,0,False,Build a Data Science App with Just Python: A Streamlit Guide,[],r/datascience,False,6,discussion,0,123.0,,False,t3_178eu2m,False,dark,0.91,,public,39,0,{},140.0,,False,[],,False,False,,{},Discussion,False,39,,False,False,https://b.thumbs.redditmedia.com/2oBH3_xUoStl5WNJf3uKpU1T27OHjVamnToqHlrgZDM.jpg,False,,[],{},,True,,1697374730.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;td/dr: easily build a SaaS with just python + zero front-end knowledge using streamlit.&lt;/p&gt;

&lt;p&gt;I wrote this short guide which allows you to create a Data Science micro-SaaS MVP with stripe integration using Streamlit python package. I thought folks here might find it useful. Example of a zillow clone below.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86""&gt;A Comprehensive Guide to Building and Deploying a Scalable SaaS Web App with Python, Streamlit, MongoDB, and Stripe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82643795b248c160de48cdc0f2fee9b0c6ac19ed""&gt;example of Streamlit SaaS&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178eu2m,True,,InterestingBasil,,10,True,all_ads,False,[],False,,/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,1209066,1697374730.0,0,,False,"{'xl4z0dtf6dub1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 94, 'x': 108, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8fd7c8843637e04060d64bdebaa24824fa283707'}, {'y': 189, 'x': 216, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=faafa381d567db593c59b924d1403717621ecbb8'}, {'y': 281, 'x': 320, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0d283ef03505fd2d7d9906360e2eb8793b968a0'}, {'y': 562, 'x': 640, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=21544e2c5baeef7ad4234a113a4cb2094d77e3a6'}, {'y': 843, 'x': 960, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6d355b6c663cc0c12e86f1c7bad5ebea6abf5f4b'}, {'y': 949, 'x': 1080, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bf4544e6e002ac90a6dbbfaf8ab5177cbfef875'}], 's': {'y': 1327, 'x': 1510, 'u': 'https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&amp;format=png&amp;auto=webp&amp;s=82643795b248c160de48cdc0f2fee9b0c6ac19ed'}, 'id': 'xl4z0dtf6dub1'}}",self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?auto=webp&amp;s=953eb6d4175d337d3dafbfe306dbd8403a2e35c1', 'width': 1200, 'height': 686}, 'resolutions': [{'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d2b495c75bd6871ba5a820e37c10e04c1b1470f', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7711309ae7139708e636ba2b320d55fa3557f4b4', 'width': 216, 'height': 123}, {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=318a97842f21b4e4a2d39595f101db5dcd15e074', 'width': 320, 'height': 182}, {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c729e3255f8db519b9b8e7c40885d70b6e437b2e', 'width': 640, 'height': 365}, {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c81179b3d6a73a410dccebfea81b97aaa0b678cc', 'width': 960, 'height': 548}, {'url': 'https://external-preview.redd.it/oMjprobSN8nD1yE5QZvbF-X4Zh_NxHKy4T2UGH3IkRw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bca8e9c3692cf07ce2c879162501c7c88174a89', 'width': 1080, 'height': 617}], 'variants': {}, 'id': 'UJlrdQ1pBJ05jPftv4NELwDGL32Je0EoG5V_BzgyFVU'}], 'enabled': False}",,,,,,,692,72
,datascience,"During my BSc biochemistry degree I realised that I’m much more interested in analytics and data science than pure science. My dissertation was about analysing existing mitochondria proteins databases for which I used R, excel and Prism. I graduated from university as adult (M27) and I’ve been a quality manager in a local coffee shop chain for the last two years. What are my chances to get into data science field without cs/math degree and what would be the best strategy to land a job? For context I live in the UK.",t2_5ojsq5gx,False,,0,False,Finding ds job after life sciences degree,[],r/datascience,False,6,discussion,0,,,False,t3_178e7fp,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697372459.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;During my BSc biochemistry degree I realised that I’m much more interested in analytics and data science than pure science. My dissertation was about analysing existing mitochondria proteins databases for which I used R, excel and Prism. I graduated from university as adult (M27) and I’ve been a quality manager in a local coffee shop chain for the last two years. What are my chances to get into data science field without cs/math degree and what would be the best strategy to land a job? For context I live in the UK.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178e7fp,True,,asatenata,,3,True,all_ads,False,[],False,,/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,all_ads,False,https://www.reddit.com/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,1209066,1697372459.0,0,,False,,,,,,,,,,520,92
,datascience,"Hey Guys , I have my Walmart first round karat interview next week .

Any tips would be helpful:)

Thanks in advance",t2_i3t8l14x8,False,,0,False,Walmart Data Science Internship,[],r/datascience,False,6,discussion,0,,,False,t3_178csio,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697366806.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Guys , I have my Walmart first round karat interview next week .&lt;/p&gt;

&lt;p&gt;Any tips would be helpful:)&lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178csio,True,,Economy_Tap7557,,3,True,all_ads,False,[],False,,/r/datascience/comments/178csio/walmart_data_science_internship/,all_ads,False,https://www.reddit.com/r/datascience/comments/178csio/walmart_data_science_internship/,1209066,1697366806.0,0,,False,,,,,,,,,,116,22
,datascience,"Hi DS community, Was just wondering what are the approaches you guys take reading and comprehending Research papers and the maths behind it. I have developed a keen interest reading research; however, For me digesting the whole research paper takes a lot of time (5-6)hours. Since, I plan to go for PHD, this is the skill I want to polish the most. I was wondering, what approaches you guys take for the following.

*  Maths portion (which I enjoy I must say), here mostly I try to rederive the equations on paper to understand better. 
* The reference papers that I have to revisit to gain praticle insights about the research at hand ( most time I read them Abstract, intro, conclusion and diagrams to extract important insights only and other time I read them end-to-end.

Thanks again.",t2_cb6s1w4f,False,,0,False,Comprehending Research Papers,[],r/datascience,False,6,discussion,0,,,False,t3_178byoc,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697363153.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi DS community, Was just wondering what are the approaches you guys take reading and comprehending Research papers and the maths behind it. I have developed a keen interest reading research; however, For me digesting the whole research paper takes a lot of time (5-6)hours. Since, I plan to go for PHD, this is the skill I want to polish the most. I was wondering, what approaches you guys take for the following.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; Maths portion (which I enjoy I must say), here mostly I try to rederive the equations on paper to understand better. &lt;/li&gt;
&lt;li&gt;The reference papers that I have to revisit to gain praticle insights about the research at hand ( most time I read them Abstract, intro, conclusion and diagrams to extract important insights only and other time I read them end-to-end.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks again.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,178byoc,True,,Informal-Assist2642,,0,True,all_ads,False,[],False,,/r/datascience/comments/178byoc/comprehending_research_papers/,all_ads,False,https://www.reddit.com/r/datascience/comments/178byoc/comprehending_research_papers/,1209066,1697363153.0,0,,False,,,,,,,,,,789,138
,datascience,"Hi, I'm looking for a tool to easily categorize a huge amount of images. Best case would be, if i could use the tool with a python library. Could you recommend anything?",t2_3r6rde6l,False,,0,False,Looking for a tool for image recognition,[],r/datascience,False,6,tooling,0,,,False,t3_178bdnk,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Tooling,False,2,,False,False,self,False,,[],{},,True,,1697360496.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m looking for a tool to easily categorize a huge amount of images. Best case would be, if i could use the tool with a python library. Could you recommend anything?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,178bdnk,True,,xTH13M0x,,0,True,all_ads,False,[],False,,/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,all_ads,False,https://www.reddit.com/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,1209066,1697360496.0,0,,False,,,,,,,,,,169,32
,datascience,"Hey folks,

I developed a research tool [https://demo-idea-factory.ngrok.dev/](https://demo-idea-factory.ngrok.dev/) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.

I would be happy to get your feedback on its usefulness for data science related research problems.

Thank you in advance!",t2_6ghkw2,False,,0,False,AI-based Research tool to help brainstorm novel ideas,[],r/datascience,False,6,tooling,0,,,False,t3_1788uk9,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Tooling,False,1,,False,False,self,1697507767.0,,[],{},,True,,1697349440.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks,&lt;/p&gt;

&lt;p&gt;I developed a research tool &lt;a href=""https://demo-idea-factory.ngrok.dev/""&gt;https://demo-idea-factory.ngrok.dev/&lt;/a&gt; to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.&lt;/p&gt;

&lt;p&gt;I would be happy to get your feedback on its usefulness for data science related research problems.&lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,1788uk9,True,,hassaan84s,,2,True,all_ads,False,[],False,,/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,all_ads,False,https://www.reddit.com/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,1209066,1697349440.0,0,,False,,,,,,,,,,487,66
,datascience,"Say, I have an N group of students. And I have their normalized test scores for 8 subjects from 0 to 1. 

I want to create a model that can put the data points into 2D plot showing which students are similar to each other. I will show the visualization of the data points.

Lastly, if someone gives their data point, I want to show them where they are in the plot, show which students are most similar to the new data point.

Which amongst PCA, tSNE, UMAP is suitable for this? Or are there other options like VAEs for tabular data?

The new data point is a test point and the N group of students are the training points.",t2_yy3f2,False,,0,False,Embed multi-dimensional data points for visualizing and inserting a new data in the plot,[],r/datascience,False,6,discussion,0,,,False,t3_1787v23,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697345478.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Say, I have an N group of students. And I have their normalized test scores for 8 subjects from 0 to 1. &lt;/p&gt;

&lt;p&gt;I want to create a model that can put the data points into 2D plot showing which students are similar to each other. I will show the visualization of the data points.&lt;/p&gt;

&lt;p&gt;Lastly, if someone gives their data point, I want to show them where they are in the plot, show which students are most similar to the new data point.&lt;/p&gt;

&lt;p&gt;Which amongst PCA, tSNE, UMAP is suitable for this? Or are there other options like VAEs for tabular data?&lt;/p&gt;

&lt;p&gt;The new data point is a test point and the N group of students are the training points.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1787v23,True,,sarmientoj24,,0,True,all_ads,False,[],False,,/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,1209066,1697345478.0,0,,False,,,,,,,,,,621,120
,datascience,"Is git copilot going to be a major asset for stats coding, in R for instance?",t2_ub0q7i8l,False,,0,False,What’s the best AI tool for statistical coding?,[],r/datascience,False,6,tooling,0,,,False,t3_178744m,False,dark,0.2,,public,0,0,{},,,False,[],,False,False,,{},Tooling,False,0,,False,False,self,False,,[],{},,True,,1697342616.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is git copilot going to be a major asset for stats coding, in R for instance?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,178744m,True,,leaderdebordel,,4,True,all_ads,False,[],False,,/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,all_ads,False,https://www.reddit.com/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,1209066,1697342616.0,0,,False,,,,,,,,,,77,16
,datascience,"Just wondering how to handle management that thinks ChatGPT is a sentiment being that is going to that is self learning entity that solves every problem. I was asked to give a presentation on how LLMs work and indicated they are  not considered classical A.I. After I was sent crackpot articles on how Chapt is thinking and learning, reading and learning how to talk.  Management literally is asking with every data science  project  if we incorporate ChatGPT A.I.. Im in a leadership role so have to try hard not to poo poo  this enthusiasm but its hard. Thoughts?",t2_72buulaq,False,,0,False,"How to handle ""A.I."" obsessed management?",[],r/datascience,False,6,discussion,0,,,False,t3_1786pqr,False,dark,0.98,,public,158,0,{},,,False,[],,False,False,,{},Discussion,False,158,,False,False,self,False,,[],{},,True,,1697341171.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just wondering how to handle management that thinks ChatGPT is a sentiment being that is going to that is self learning entity that solves every problem. I was asked to give a presentation on how LLMs work and indicated they are  not considered classical A.I. After I was sent crackpot articles on how Chapt is thinking and learning, reading and learning how to talk.  Management literally is asking with every data science  project  if we incorporate ChatGPT A.I.. Im in a leadership role so have to try hard not to poo poo  this enthusiasm but its hard. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1786pqr,True,,Equal_Astronaut_5696,,49,True,all_ads,False,[],False,,/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,all_ads,False,https://www.reddit.com/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,1209066,1697341171.0,0,,False,,,,,,,,,,565,98
,datascience,"I’m planning to live in NY, and wanted to known the best online or live short courses , pos graduation courses and/or masters related with data science , and possibly with sustainability as well?",t2_dffbrzoz3,False,,0,False,What are the best data science courses for curriculum in US?,[],r/datascience,False,6,discussion,0,,,False,t3_1786ftu,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697340226.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m planning to live in NY, and wanted to known the best online or live short courses , pos graduation courses and/or masters related with data science , and possibly with sustainability as well?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1786ftu,True,,CrazyProfessionalp,,0,True,all_ads,False,[],False,,/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,1209066,1697340226.0,0,,False,,,,,,,,,,195,34
,datascience,"Deep reinforcement learning has led to a variety of compelling results.  However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly.  Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.

&amp;#x200B;

https://preview.redd.it/x7050xg2baub1.png?width=1786&amp;format=png&amp;auto=webp&amp;s=14929e5614404808c85d48922e0af947f8d52b90

We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).

&amp;#x200B;

https://preview.redd.it/k1ntxyh3baub1.png?width=1636&amp;format=png&amp;auto=webp&amp;s=bdf0bb030a0a4d38034460d52940593e6a57cb32

However, the benefits of our semantic proxy go well beyond performance.  The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity.  PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false).  We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.

Preprint: [https://arxiv.org/abs/2310.06835](https://arxiv.org/abs/2310.06835)

Video: [https://youtu.be/9e6ZHJEJzgw](https://youtu.be/9e6ZHJEJzgw)

Code for PyReason-as-a-Sim (integration with DQN): [https://github.com/lab-v2/pyreason-rl-sim](https://github.com/lab-v2/pyreason-rl-sim)

Code for PyReason Gym: [https://github.com/lab-v2/pyreason-gym](https://github.com/lab-v2/pyreason-gym)

PyReason home: [https://neurosymbolic.asu.edu/pyreason/](https://neurosymbolic.asu.edu/pyreason/)",t2_u8v5y5z0,False,,0,False,Supercharging Reinforcement Learning with Logic,[],r/datascience,False,6,projects,0,52.0,,False,t3_1786d5a,False,dark,0.76,,public,2,0,{},140.0,,False,[],,False,False,,{},Projects,False,2,,False,False,https://a.thumbs.redditmedia.com/ZV1_IO6OKhoJfGEo2RUHaP5MNorgHILhDR-HZFl2ID0.jpg,False,,[],{},,True,,1697339974.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Deep reinforcement learning has led to a variety of compelling results.  However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly.  Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/x7050xg2baub1.png?width=1786&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=14929e5614404808c85d48922e0af947f8d52b90""&gt;https://preview.redd.it/x7050xg2baub1.png?width=1786&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=14929e5614404808c85d48922e0af947f8d52b90&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/k1ntxyh3baub1.png?width=1636&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdf0bb030a0a4d38034460d52940593e6a57cb32""&gt;https://preview.redd.it/k1ntxyh3baub1.png?width=1636&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdf0bb030a0a4d38034460d52940593e6a57cb32&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, the benefits of our semantic proxy go well beyond performance.  The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity.  PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false).  We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.&lt;/p&gt;

&lt;p&gt;Preprint: &lt;a href=""https://arxiv.org/abs/2310.06835""&gt;https://arxiv.org/abs/2310.06835&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Video: &lt;a href=""https://youtu.be/9e6ZHJEJzgw""&gt;https://youtu.be/9e6ZHJEJzgw&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Code for PyReason-as-a-Sim (integration with DQN): &lt;a href=""https://github.com/lab-v2/pyreason-rl-sim""&gt;https://github.com/lab-v2/pyreason-rl-sim&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Code for PyReason Gym: &lt;a href=""https://github.com/lab-v2/pyreason-gym""&gt;https://github.com/lab-v2/pyreason-gym&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PyReason home: &lt;a href=""https://neurosymbolic.asu.edu/pyreason/""&gt;https://neurosymbolic.asu.edu/pyreason/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1786d5a,True,,Neurosymbolic,,1,True,all_ads,False,[],False,,/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,all_ads,False,https://www.reddit.com/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,1209066,1697339974.0,0,,False,"{'x7050xg2baub1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 40, 'x': 108, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=45deccc736663a44256891b34b62ca15aa8b8ab2'}, {'y': 80, 'x': 216, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=df3edbbb0c0bc139a84bda95b393b6355b184f9c'}, {'y': 119, 'x': 320, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3419064ebc99c1dd8cdff3a2fcd763b1dcab2418'}, {'y': 238, 'x': 640, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9eff5da3fae93c2ad245210fb974933794bb652f'}, {'y': 357, 'x': 960, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1689fc1f3a36ce1604b6ce7eeb130be5764f7a20'}, {'y': 402, 'x': 1080, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bbd2fe355a27dfe41bf65d1d4f1919b5d191c64'}], 's': {'y': 665, 'x': 1786, 'u': 'https://preview.redd.it/x7050xg2baub1.png?width=1786&amp;format=png&amp;auto=webp&amp;s=14929e5614404808c85d48922e0af947f8d52b90'}, 'id': 'x7050xg2baub1'}, 'k1ntxyh3baub1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 28, 'x': 108, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39c581167d62c6fcb09aeae97b4204b57f116aa5'}, {'y': 56, 'x': 216, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0df0c9d774cc6a766bda3ae79c6fce52eb934d2e'}, {'y': 83, 'x': 320, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=83726a6c69aa1cb616bdb1cf2f5787727e7946e8'}, {'y': 167, 'x': 640, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f601d29f8778eca05793d5f772be6efdc8fe47db'}, {'y': 251, 'x': 960, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa315590b03fb61f973a92ecf498992ad690b353'}, {'y': 283, 'x': 1080, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1bde606a2d8c2c4cc3b779a584046d5bc7d55625'}], 's': {'y': 429, 'x': 1636, 'u': 'https://preview.redd.it/k1ntxyh3baub1.png?width=1636&amp;format=png&amp;auto=webp&amp;s=bdf0bb030a0a4d38034460d52940593e6a57cb32'}, 'id': 'k1ntxyh3baub1'}}",,,,,,,,,2240,240
,datascience,"So basically is a data analytics job (SQL and power bi viz) is better than a data scientist job (hands on python, model building and cloud) at a national company ?


Or just joining the big 4 in hopes of getting promoted to a job with more hands on coding is the right way to go?",t2_2jcm7o1m,False,,0,False,Does the big 4 tag really matter?,[],r/datascience,False,6,discussion,0,,,False,t3_1786ci4,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,1697341666.0,,[],{},,True,,1697339911.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So basically is a data analytics job (SQL and power bi viz) is better than a data scientist job (hands on python, model building and cloud) at a national company ?&lt;/p&gt;

&lt;p&gt;Or just joining the big 4 in hopes of getting promoted to a job with more hands on coding is the right way to go?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1786ci4,True,,Talion07,,12,True,all_ads,False,[],False,,/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,all_ads,False,https://www.reddit.com/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,1209066,1697339911.0,0,,False,,,,,,,,,,279,56
,datascience,"I'm your generic mid-career data scientist who sometimes functions as an ML engineer. I've been tasked with advising a team building an LLM application to automate 'data analysis' for non-technical customers. My role is to bring some wisdom and system design expertise to the team. The team is compromised of two people: a young, eager software engineer who calls themselves a ""Langchain Developer"" and a senior technical director who believes in the macro trends around Generative AI and wants to learn more about applying the techonology.

The idea is a customer types a vague question in to a field  *e.g.* ""Is my business meeting my customer retention goals"" and the output would be a visualization of some descriptive metrics and an interpretation of the data.

The design presented to me by the Langchain developer sounds overly complex and a bit unhinged to me. I'm looking for an external opinion to make sure my opinions are well grounded or make sense.

1. This project is my first time using LangChain. From reading through the LangChain code,  and building some basic examples, the library feels over abstracted.  You have to navigate a tangled mess of private variables to even find the prompt the tool is using. I am *really* concerned about putting Langchain code in production since it seems difficult to debug and modify. Why can't we use a DAG or state machine instead?
2. The langchain developer doesn't present any systematic way to deal with hallucination. Generally, the strategy verbalized is too play ""wack a mole"" every time they see or measure a hallucination. If hallucinations are rare, then sure, and I'd be a bit more comfortable with this approach. But I've see no evidence that's the case.
3. The scalable ways to measure hallucination often use an LLM to judge it's own output. Generally, I try to avoid feedback loops between models. Is that too strong of an opinion to have when working with LLMs?

Appreciate the responses!",t2_ebitsu3s,False,,0,False,Company building an LLM App. Need some understanding if my opinions are reasonable.,[],r/datascience,False,6,discussion,0,,,False,t3_1785em4,False,dark,0.94,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,False,self,False,,[],{},,True,,1697336757.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m your generic mid-career data scientist who sometimes functions as an ML engineer. I&amp;#39;ve been tasked with advising a team building an LLM application to automate &amp;#39;data analysis&amp;#39; for non-technical customers. My role is to bring some wisdom and system design expertise to the team. The team is compromised of two people: a young, eager software engineer who calls themselves a &amp;quot;Langchain Developer&amp;quot; and a senior technical director who believes in the macro trends around Generative AI and wants to learn more about applying the techonology.&lt;/p&gt;

&lt;p&gt;The idea is a customer types a vague question in to a field  &lt;em&gt;e.g.&lt;/em&gt; &amp;quot;Is my business meeting my customer retention goals&amp;quot; and the output would be a visualization of some descriptive metrics and an interpretation of the data.&lt;/p&gt;

&lt;p&gt;The design presented to me by the Langchain developer sounds overly complex and a bit unhinged to me. I&amp;#39;m looking for an external opinion to make sure my opinions are well grounded or make sense.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;This project is my first time using LangChain. From reading through the LangChain code,  and building some basic examples, the library feels over abstracted.  You have to navigate a tangled mess of private variables to even find the prompt the tool is using. I am &lt;em&gt;really&lt;/em&gt; concerned about putting Langchain code in production since it seems difficult to debug and modify. Why can&amp;#39;t we use a DAG or state machine instead?&lt;/li&gt;
&lt;li&gt;The langchain developer doesn&amp;#39;t present any systematic way to deal with hallucination. Generally, the strategy verbalized is too play &amp;quot;wack a mole&amp;quot; every time they see or measure a hallucination. If hallucinations are rare, then sure, and I&amp;#39;d be a bit more comfortable with this approach. But I&amp;#39;ve see no evidence that&amp;#39;s the case.&lt;/li&gt;
&lt;li&gt;The scalable ways to measure hallucination often use an LLM to judge it&amp;#39;s own output. Generally, I try to avoid feedback loops between models. Is that too strong of an opinion to have when working with LLMs?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Appreciate the responses!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1785em4,True,,krhymme,,15,True,all_ads,False,[],False,,/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,all_ads,False,https://www.reddit.com/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,1209066,1697336757.0,0,,False,,,,,,,,,,1959,328
,datascience,"As the title suggests I am going to be having 1-on-1 interviews with 3 candidates to replace my previous boss. Others within my team as well as higher ups will also be interviewing them separately. I will be given some instruction and there will be some coordination between all of us involved in this process. As this is a new experience for me (and likely a little unusual for most people to be choosing their boss), I am wondering if anyone has any suggestions as to questions that might be a bit outside of the basics you'd find on any old list of interview questions.   


For context, I have worked as a data analyst/data scientist/statistician (there isn't really a distinction between these roles in my area) for about 4.5 years now and have been in this current job for 2 years. I work in healthcare analytics with some of my work being straightforward research for the purposes of publication and other work with hospitals, governments, etc. trying to leverage their data to improve different aspects of their work and responsibilities. I am based outside of the U.S.A. and this is not for an American company FYI.

Update: Appreciate all the feedback. There were some really great responses in here that I will definitely be using.",t2_ekmq5,False,,0,False,"I am interviewing my future boss, what should I ask them?",[],r/datascience,False,6,discussion,0,,,False,t3_1784jir,False,dark,1.0,,public,35,0,{},,,False,[],,False,False,,{},Discussion,False,35,,False,False,self,1697769719.0,,[],{},,True,,1697333923.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As the title suggests I am going to be having 1-on-1 interviews with 3 candidates to replace my previous boss. Others within my team as well as higher ups will also be interviewing them separately. I will be given some instruction and there will be some coordination between all of us involved in this process. As this is a new experience for me (and likely a little unusual for most people to be choosing their boss), I am wondering if anyone has any suggestions as to questions that might be a bit outside of the basics you&amp;#39;d find on any old list of interview questions.   &lt;/p&gt;

&lt;p&gt;For context, I have worked as a data analyst/data scientist/statistician (there isn&amp;#39;t really a distinction between these roles in my area) for about 4.5 years now and have been in this current job for 2 years. I work in healthcare analytics with some of my work being straightforward research for the purposes of publication and other work with hospitals, governments, etc. trying to leverage their data to improve different aspects of their work and responsibilities. I am based outside of the U.S.A. and this is not for an American company FYI.&lt;/p&gt;

&lt;p&gt;Update: Appreciate all the feedback. There were some really great responses in here that I will definitely be using.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1784jir,True,,maple_enthusiast,,28,True,all_ads,False,[],False,,/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,all_ads,False,https://www.reddit.com/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,1209066,1697333923.0,0,,False,,,,,,,,,,1242,215
,datascience,"Graduated summer of 2022 with a MS in Analytics after discovering the field by accident while exploring possible new fields, as I got burnt out from crazy hours at a previous database engineer role. I kept getting far in interview processes but never the role, although in hindsight I dropped out of a few interview processes that I maybe shouldn't have since I'd be the only analyst in the company. Finally got one this week, albeit as a data engineer/analyst supporting another analyst, right after taking a customer service role as I was giving up and planning on going to grad school next year for something completely different. Still processing this as I can barely believe it.",t2_1nqy26vi,False,,0,False,Took me over a year but I finally got a data analyst job,[],r/datascience,False,6,discussion,0,,,False,t3_1780308,False,dark,0.97,,public,130,0,{},,,False,[],,False,False,,{},Discussion,False,130,,False,False,self,1697326415.0,,[],{},,True,,1697320407.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Graduated summer of 2022 with a MS in Analytics after discovering the field by accident while exploring possible new fields, as I got burnt out from crazy hours at a previous database engineer role. I kept getting far in interview processes but never the role, although in hindsight I dropped out of a few interview processes that I maybe shouldn&amp;#39;t have since I&amp;#39;d be the only analyst in the company. Finally got one this week, albeit as a data engineer/analyst supporting another analyst, right after taking a customer service role as I was giving up and planning on going to grad school next year for something completely different. Still processing this as I can barely believe it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1780308,True,,crattikal,,16,True,all_ads,False,[],False,,/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,1209066,1697320407.0,0,,False,,,,,,,,,,683,117
,datascience,"I have a degree in computer science and 1 year of experience as a data analyst done in the middle of my degree. Looking online a lot of the advice on standing out recommends doing personal projects. However, it also all seems very US-centric. Data analysts from the UK, how important do you feel personal projects are to get hired for beginner roles?",t2_159mpp,False,,0,False,Can I get a UK perspective on how important personal projects are for beginner data analyst roles?,[],r/datascience,False,6,discussion,0,,,False,t3_177zdxe,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697318434.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a degree in computer science and 1 year of experience as a data analyst done in the middle of my degree. Looking online a lot of the advice on standing out recommends doing personal projects. However, it also all seems very US-centric. Data analysts from the UK, how important do you feel personal projects are to get hired for beginner roles?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177zdxe,True,,DansePaladinDanse,,1,True,all_ads,False,[],False,,/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,all_ads,False,https://www.reddit.com/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,1209066,1697318434.0,0,,False,,,,,,,,,,350,63
,datascience,"Im new to the Data science community and just started my first job as a robotics engineer. 

Im wondering how I can take my data science skills to the next level and so Ive made [this showcase](https://visualstudycode.com/stochastic-gradient-descent-for-robotics/) on stochastic gradient descent for robotics, as the first step in visualization and UI experience. Let me know your thoughts!",t2_cj9ow85u,False,,0,False,What is the best UI creator for DS projects?,[],r/datascience,False,6,projects,0,,,False,t3_177yjgm,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697316015.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im new to the Data science community and just started my first job as a robotics engineer. &lt;/p&gt;

&lt;p&gt;Im wondering how I can take my data science skills to the next level and so Ive made &lt;a href=""https://visualstudycode.com/stochastic-gradient-descent-for-robotics/""&gt;this showcase&lt;/a&gt; on stochastic gradient descent for robotics, as the first step in visualization and UI experience. Let me know your thoughts!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,177yjgm,True,,SmokeSlurp,,0,True,all_ads,False,[],False,,/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,all_ads,False,https://www.reddit.com/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,1209066,1697316015.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?auto=webp&amp;s=1b9371cb75f725dae3290d02768282d0f13944a3', 'width': 1200, 'height': 920}, 'resolutions': [{'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b3cd51512e95ce1c18685d7b670579797743610', 'width': 108, 'height': 82}, {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1742e661db6929ed9a1d6f67f39af41e6fe89d37', 'width': 216, 'height': 165}, {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b63a50336c2e363ade5f01761e3578bd1b31546a', 'width': 320, 'height': 245}, {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca57618fc1ee2b9cc413267834e1d9db669dc6ac', 'width': 640, 'height': 490}, {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=86095ed000ad27c01ac68a3f3754ead35b6411be', 'width': 960, 'height': 736}, {'url': 'https://external-preview.redd.it/-WCGvEKw0cQpU33g3tFfObHoQGLaUMKTzY8dSZoPf7w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c63fb2a9b9a300cb7ad2466f2f6ea35f6c18c84e', 'width': 1080, 'height': 828}], 'variants': {}, 'id': 'MQQA88X4HZs7Ce39hFwDUj1uf2bXr2dTQtsIkcyGe9U'}], 'enabled': False}",,,,,,,390,57
,datascience,"Hey there! 

I'm currently transferring to Indiana University Northwest in Spring 2024 from a community college for my Data Science degree and got an internship next summer. 

The thing is I also applied to UIC and got rejected with some weird reasoning but after talking to a faculty member, they were recommending I take a break and apply again in the summer to undecided and then transferring into the Data Science program.

I'm wondering if I should consider transferring to UIC instead and also if that hinders my internship for Summer 2024.",t2_rsz2o,False,,0,False,Question on School options,[],r/datascience,False,6,discussion,0,,,False,t3_177xuon,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697314015.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there! &lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently transferring to Indiana University Northwest in Spring 2024 from a community college for my Data Science degree and got an internship next summer. &lt;/p&gt;

&lt;p&gt;The thing is I also applied to UIC and got rejected with some weird reasoning but after talking to a faculty member, they were recommending I take a break and apply again in the summer to undecided and then transferring into the Data Science program.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m wondering if I should consider transferring to UIC instead and also if that hinders my internship for Summer 2024.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177xuon,True,,lovelylavenderchild,,3,True,all_ads,False,[],False,,/r/datascience/comments/177xuon/question_on_school_options/,all_ads,False,https://www.reddit.com/r/datascience/comments/177xuon/question_on_school_options/,1209066,1697314015.0,0,,False,,,,,,,,,,546,92
,datascience,"Curious because I just took an assessment. Not like I googled the full question. I just had chat gpt fix some syntax issues and googled some functions I couldn’t remember the exact way to write. I think if they asked me about it, I’d just explain that’s what I did — same as when I’m writing code outside an assessment. But I’m curious what’s considered the norm in assessments for jobs.

Edit: there was nothing on the assessment that said either way.",t2_7q4gkyhp,False,,0,False,Do companies consider it cheating to Google/chat gpt stuff on hackerrank tests?,[],r/datascience,False,6,discussion,0,,,False,t3_177w76r,False,dark,0.81,,public,26,0,{},,,False,[],,False,False,,{},Discussion,False,26,,False,False,self,False,,[],{},,True,,1697309272.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Curious because I just took an assessment. Not like I googled the full question. I just had chat gpt fix some syntax issues and googled some functions I couldn’t remember the exact way to write. I think if they asked me about it, I’d just explain that’s what I did — same as when I’m writing code outside an assessment. But I’m curious what’s considered the norm in assessments for jobs.&lt;/p&gt;

&lt;p&gt;Edit: there was nothing on the assessment that said either way.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177w76r,True,,Historical_Leek_9012,,26,True,all_ads,False,[],False,,/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,all_ads,False,https://www.reddit.com/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,1209066,1697309272.0,0,,False,,,,,,,,,,452,82
,datascience,"Very new to the topic.  
I do not understand why we want to maximize the likelihood of the parameter theta: isn't the likelihood we care about just the likelihood of output y? What is the point of maximizing the parameter's likelihood?

Apologies if this is a silly question and thank you so much for your input",t2_lqydu4egc,False,,0,False,Why do we maximize likelihood of theta in logistic regression?,[],r/datascience,False,6,discussion,0,,,False,t3_177rzkj,False,dark,0.75,,public,8,0,{},,,False,[],,False,False,,{},Discussion,False,8,,False,False,self,False,,[],{},,True,,1697297086.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Very new to the topic.&lt;br/&gt;
I do not understand why we want to maximize the likelihood of the parameter theta: isn&amp;#39;t the likelihood we care about just the likelihood of output y? What is the point of maximizing the parameter&amp;#39;s likelihood?&lt;/p&gt;

&lt;p&gt;Apologies if this is a silly question and thank you so much for your input&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177rzkj,True,,Careful_Till8105,,10,True,all_ads,False,[],False,,/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,1209066,1697297086.0,0,,False,,,,,,,,,,311,56
,datascience,"Hi everyone! I work in the consulting arm of a data science software company. I scope data science projects with my clients regularly using the following questions. Would love some feedback if there is anything missing/I should be asking them in a different way:

Questions about client

* What is your project budget?
* Describe your familiarity with data science and data analytics
* Describe the nature of your business (feel free to include any links to your website)

Questions about the project

* What are the main objectives you want to achieve with this project? Try to be as specific as possible, using numbers
* Describe the current situation (without this project)
* Describe the envisioned situation if the project is a success (e.g. how will you use the project output?)
* Who will benefit from the most from this project? Who else will be impacted?

Questions about the data

* Describe the nature of your data in your own words. (prompts include how do you normally access this data? How is it normally used?)
* What data sources do you have for this project? Where do they come from?
* Are there any public data sources that might help?
* In what format is the data available (e.g., CSV, Excel, SQL Database)?
* Would you consider your data structured, semi-structured, or unstructured?
* How much data do you have (e.g. rows, records, or file size)
* Is it possible to collect more data? Would it be difficult to do so?
* Does your data need to be labeled? If so, what is the corresponding effort?
* How would you rate the quality of the available data? Are there any known issues? (missing values, conflicts, outliers, reliability)
* Please send over an example of your data if possible

Other questions

* What is your current technical set-up? Describe the tools you currently use may be relevant to the project
* Do you foresee any technical integration requirements?
* Is there any additional information or specific requirements that have not been covered? (cybersecurity, data privacy, ethical considerations)

&amp;#x200B;",t2_8xwepztbe,False,,0,False,Data Science Scoping Questions (Looking for feedback from DS consultants),[],r/datascience,False,6,discussion,0,,,False,t3_177r3bk,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697294514.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone! I work in the consulting arm of a data science software company. I scope data science projects with my clients regularly using the following questions. Would love some feedback if there is anything missing/I should be asking them in a different way:&lt;/p&gt;

&lt;p&gt;Questions about client&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is your project budget?&lt;/li&gt;
&lt;li&gt;Describe your familiarity with data science and data analytics&lt;/li&gt;
&lt;li&gt;Describe the nature of your business (feel free to include any links to your website)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Questions about the project&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What are the main objectives you want to achieve with this project? Try to be as specific as possible, using numbers&lt;/li&gt;
&lt;li&gt;Describe the current situation (without this project)&lt;/li&gt;
&lt;li&gt;Describe the envisioned situation if the project is a success (e.g. how will you use the project output?)&lt;/li&gt;
&lt;li&gt;Who will benefit from the most from this project? Who else will be impacted?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Questions about the data&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Describe the nature of your data in your own words. (prompts include how do you normally access this data? How is it normally used?)&lt;/li&gt;
&lt;li&gt;What data sources do you have for this project? Where do they come from?&lt;/li&gt;
&lt;li&gt;Are there any public data sources that might help?&lt;/li&gt;
&lt;li&gt;In what format is the data available (e.g., CSV, Excel, SQL Database)?&lt;/li&gt;
&lt;li&gt;Would you consider your data structured, semi-structured, or unstructured?&lt;/li&gt;
&lt;li&gt;How much data do you have (e.g. rows, records, or file size)&lt;/li&gt;
&lt;li&gt;Is it possible to collect more data? Would it be difficult to do so?&lt;/li&gt;
&lt;li&gt;Does your data need to be labeled? If so, what is the corresponding effort?&lt;/li&gt;
&lt;li&gt;How would you rate the quality of the available data? Are there any known issues? (missing values, conflicts, outliers, reliability)&lt;/li&gt;
&lt;li&gt;Please send over an example of your data if possible&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other questions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is your current technical set-up? Describe the tools you currently use may be relevant to the project&lt;/li&gt;
&lt;li&gt;Do you foresee any technical integration requirements?&lt;/li&gt;
&lt;li&gt;Is there any additional information or specific requirements that have not been covered? (cybersecurity, data privacy, ethical considerations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177r3bk,True,,saasthom,,0,True,all_ads,False,[],False,,/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,1209066,1697294514.0,0,,False,,,,,,,,,,2048,348
,datascience,"Hi! I have a Bsc (Honours) in Applied Mathematics, and I have done various courses on Udemy on ML and DL by SuperDataScience. I have also done some self work on Kaggle.
I am currently a Robotics Process Automatiom (RPA) developer. I'd love to move into the DS/ML/DL/AI space. I do of course use some AI tools within my automation solutions. I miss doing the Mathematics though. I really loved studying it.

Anyways, it's been a while since I've done any studying or self-work in the AI space, and I was wondering what your thoughts on the renowned Andrew Ng Deep Learning course are? I know I'd really enjoy doing it, but how much would it help me in getting closer to a job in the AI space?

Note: I haven't done any mathematics for quite a few years, as a I graduated end of 2018, so I would also need to spend sometime relearning some of the work I learnt in my degree. I also do not want to go into academia, despite my love of research, because it often involves lecturing (which I dislike) and it will generally not pay as well - I want to have enough money to live a comfortable life and travel the world.

Thanks",t2_frwys,False,,0,False,How much stock would you put in Andrew Ng's ML/DL course?,[],r/datascience,False,6,discussion,0,,,False,t3_177qw2v,False,dark,0.47,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697293932.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I have a Bsc (Honours) in Applied Mathematics, and I have done various courses on Udemy on ML and DL by SuperDataScience. I have also done some self work on Kaggle.
I am currently a Robotics Process Automatiom (RPA) developer. I&amp;#39;d love to move into the DS/ML/DL/AI space. I do of course use some AI tools within my automation solutions. I miss doing the Mathematics though. I really loved studying it.&lt;/p&gt;

&lt;p&gt;Anyways, it&amp;#39;s been a while since I&amp;#39;ve done any studying or self-work in the AI space, and I was wondering what your thoughts on the renowned Andrew Ng Deep Learning course are? I know I&amp;#39;d really enjoy doing it, but how much would it help me in getting closer to a job in the AI space?&lt;/p&gt;

&lt;p&gt;Note: I haven&amp;#39;t done any mathematics for quite a few years, as a I graduated end of 2018, so I would also need to spend sometime relearning some of the work I learnt in my degree. I also do not want to go into academia, despite my love of research, because it often involves lecturing (which I dislike) and it will generally not pay as well - I want to have enough money to live a comfortable life and travel the world.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177qw2v,True,,fouried96,,7,True,all_ads,False,[],False,,/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,all_ads,False,https://www.reddit.com/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,1209066,1697293932.0,0,,False,,,,,,,,,,1120,211
,datascience,"So I’m in my late 20s, I received a bachelor of science in math and a master of science in data analytics. I have been working as a “Data Science Consultant” for 2 years now. I really just don’t find the work challenging or interesting. My field of interests include NLP, Policy, Media, and International Relations (I know very niche). The data science market is terrible and I’m applying to jobs and getting a few interviews, but not roles I’m really interested in. I think I would really enjoy doing applied data science research, like how can we use data science, statistics, etc. to address this issue. The problem is all of these jobs I see are reserved for PhDs. I just keep going back and forth on whether this should be something I pursue or not. What would you all recommend for someone in my shoes?",t2_d97itlol,False,,0,False,Should I pursue a PhD,[],r/datascience,False,6,discussion,0,,,False,t3_177qnvc,False,dark,0.89,,public,77,0,{},,,False,[],,False,False,,{},Discussion,False,77,,False,False,self,False,,[],{},,True,,1697293280.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I’m in my late 20s, I received a bachelor of science in math and a master of science in data analytics. I have been working as a “Data Science Consultant” for 2 years now. I really just don’t find the work challenging or interesting. My field of interests include NLP, Policy, Media, and International Relations (I know very niche). The data science market is terrible and I’m applying to jobs and getting a few interviews, but not roles I’m really interested in. I think I would really enjoy doing applied data science research, like how can we use data science, statistics, etc. to address this issue. The problem is all of these jobs I see are reserved for PhDs. I just keep going back and forth on whether this should be something I pursue or not. What would you all recommend for someone in my shoes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177qnvc,True,,cptsanderzz,,88,True,all_ads,False,[],False,,/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,all_ads,False,https://www.reddit.com/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,1209066,1697293280.0,0,,False,,,,,,,,,,808,147
,datascience,"Hello everyone,

&amp;#x200B;

I'm relatively new to the field of Data Science, with approximately 6 months of experience. Prior to this role, I worked as a Machine Learning Engineer for a year and a half.

In my current position, I spend a significant portion of my time conducting data analysis, applying basic statistical techniques (hypothesis testing, regression analysis, etc), and developing standard banking models (so far, I've worked in churn rate prediction, client clustering, and currently studying to help building a recommendation system)

I'm currently pursuing a Master's degree in Computer Science, with a research focus on weather forecasting. This research involves the use of time series analysis and machine learning. As we progress in our research, we are also delving into deep learning models, the goal is to build state of art models.

My academic background is in computer science. In both bachelor's and master's I've completed classes in basic linear algebra, three levels of calculus (up to Multivariate Calculus and First Order Differential Equations), discrete mathematics, two statistics courses, one time series analysis course, and several classes focused on machine learning algorithms and artificial intelligence.

While I generally have a good understanding of the mathematical principles behind machine learning models, there are certain areas where I struggle. For instance, I've never fully comprehended why the kernel trick is effective in SVMs (got the intuition, but not the maths)

When it comes to statistics, I feel that my knowledge is lacking. I can effectively work with machine learning frameworks, but there are specific statistical topics where my knowledge is either superficial or non-existent. These include:

&amp;#x200B;

* Post hoc analysis
* Survival analysis
* Multivariate statistics, such as PCA, MANOVA, and Factor analysis
* Markov Processes

Given my current role and academic pursuits, I'm wondering if it's essential to address these knowledge gaps immediately or if it would be more practical to focus on completing my Master's degree first.

I would greatly appreciate any guidance on how to begin studying these statistical concepts effectively.",t2_2d335yx7,False,,0,False,Do I need more statistics?,[],r/datascience,False,6,discussion,0,,,False,t3_177q65k,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,1697292201.0,,[],{},,True,,1697291897.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m relatively new to the field of Data Science, with approximately 6 months of experience. Prior to this role, I worked as a Machine Learning Engineer for a year and a half.&lt;/p&gt;

&lt;p&gt;In my current position, I spend a significant portion of my time conducting data analysis, applying basic statistical techniques (hypothesis testing, regression analysis, etc), and developing standard banking models (so far, I&amp;#39;ve worked in churn rate prediction, client clustering, and currently studying to help building a recommendation system)&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently pursuing a Master&amp;#39;s degree in Computer Science, with a research focus on weather forecasting. This research involves the use of time series analysis and machine learning. As we progress in our research, we are also delving into deep learning models, the goal is to build state of art models.&lt;/p&gt;

&lt;p&gt;My academic background is in computer science. In both bachelor&amp;#39;s and master&amp;#39;s I&amp;#39;ve completed classes in basic linear algebra, three levels of calculus (up to Multivariate Calculus and First Order Differential Equations), discrete mathematics, two statistics courses, one time series analysis course, and several classes focused on machine learning algorithms and artificial intelligence.&lt;/p&gt;

&lt;p&gt;While I generally have a good understanding of the mathematical principles behind machine learning models, there are certain areas where I struggle. For instance, I&amp;#39;ve never fully comprehended why the kernel trick is effective in SVMs (got the intuition, but not the maths)&lt;/p&gt;

&lt;p&gt;When it comes to statistics, I feel that my knowledge is lacking. I can effectively work with machine learning frameworks, but there are specific statistical topics where my knowledge is either superficial or non-existent. These include:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Post hoc analysis&lt;/li&gt;
&lt;li&gt;Survival analysis&lt;/li&gt;
&lt;li&gt;Multivariate statistics, such as PCA, MANOVA, and Factor analysis&lt;/li&gt;
&lt;li&gt;Markov Processes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given my current role and academic pursuits, I&amp;#39;m wondering if it&amp;#39;s essential to address these knowledge gaps immediately or if it would be more practical to focus on completing my Master&amp;#39;s degree first.&lt;/p&gt;

&lt;p&gt;I would greatly appreciate any guidance on how to begin studying these statistical concepts effectively.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177q65k,True,,IcaroRibeiro,,3,True,all_ads,False,[],False,,/r/datascience/comments/177q65k/do_i_need_more_statistics/,all_ads,False,https://www.reddit.com/r/datascience/comments/177q65k/do_i_need_more_statistics/,1209066,1697291897.0,0,,False,,,,,,,,,,2216,335
,datascience,"After spending considerable time researching on the Data Science (DS) field, I've noticed two significant challenges: 

1. The difficulty of breaking into DS as a fresher 
2. The necessity for a specialized niche in a particular domain, such as healthcare or business, which often requires prior field experience or a related bachelor's degree.

I'm a final year bachelor's in Technology student (specialization-Information Technology ) and possess average coding skill. My aspirations involve pursuing higher education and professional opportunities in Europe, particularly in German universities.

Despite some institutions prioritizing revenue generation and offering below average DS programs(as repeatedly mentioned in this sub), low cost German public universities offers numerous DS programs taught in English, welcoming international students. Personally, I'm drawn to the profound impact DS can have on decision-making processes (specifically policy making), which makes it a very rewarding field.

I'm at a crossroads between pursuing a Master's in Computer Science (CS) with a DS track or opting for a specialized Data Science degree. Which academic path would provide more job security and a stronger foothold in the European job market for a background like mine?

There are some courses that have intersection of two disciplines like policy making and DS. Will those courses limit me to certain domain and thus affect my chances of getting jobs? or Will the specialization in a field actually be more beneficial?

Furthermore, I'm curious if I can smoothly transition into DS roles after gaining several years of experience working with other technologies in the IT sector.

Thank you in advance for your time and guidance!",t2_f6c1sc7cd,False,,0,False,Choosing the Right Academic Path for Job Security and Career Growth in Europe,[],r/datascience,False,6,discussion,0,,,False,t3_177q2t2,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697291634.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;After spending considerable time researching on the Data Science (DS) field, I&amp;#39;ve noticed two significant challenges: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The difficulty of breaking into DS as a fresher &lt;/li&gt;
&lt;li&gt;The necessity for a specialized niche in a particular domain, such as healthcare or business, which often requires prior field experience or a related bachelor&amp;#39;s degree.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;#39;m a final year bachelor&amp;#39;s in Technology student (specialization-Information Technology ) and possess average coding skill. My aspirations involve pursuing higher education and professional opportunities in Europe, particularly in German universities.&lt;/p&gt;

&lt;p&gt;Despite some institutions prioritizing revenue generation and offering below average DS programs(as repeatedly mentioned in this sub), low cost German public universities offers numerous DS programs taught in English, welcoming international students. Personally, I&amp;#39;m drawn to the profound impact DS can have on decision-making processes (specifically policy making), which makes it a very rewarding field.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m at a crossroads between pursuing a Master&amp;#39;s in Computer Science (CS) with a DS track or opting for a specialized Data Science degree. Which academic path would provide more job security and a stronger foothold in the European job market for a background like mine?&lt;/p&gt;

&lt;p&gt;There are some courses that have intersection of two disciplines like policy making and DS. Will those courses limit me to certain domain and thus affect my chances of getting jobs? or Will the specialization in a field actually be more beneficial?&lt;/p&gt;

&lt;p&gt;Furthermore, I&amp;#39;m curious if I can smoothly transition into DS roles after gaining several years of experience working with other technologies in the IT sector.&lt;/p&gt;

&lt;p&gt;Thank you in advance for your time and guidance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177q2t2,True,,Final_Teach_5838,,5,True,all_ads,False,[],False,,/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,all_ads,False,https://www.reddit.com/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,1209066,1697291634.0,0,,False,,,,,,,,,,1737,261
,datascience," TL;DR: **Biggest fails and your most loved data science solutions** in **web related applications**, which you have experienced **in your data science career**.

*(Similar posts were previously removed for unclear reasons, so I have reworded the post. Please let me be clear: this is not a homework exercise, nor is it breaking any other rule in my opinion! My last attempt...)*

I  am just curious in your personal data science experience of common web  applications like e-commerce, lead generation, web marketing and so on.

Upper   management often wants solutions or applications which have a positive  imapct in selling products, gaining more customers or at least improve  existing products and services which can be used in marketing. And you  know, sometimes it's all about slapping the ""AI"" label on products.

What  were the worst misconceptions/requirements of senior management?  In  contrast: What unexpectedly  worked well? I.e. Data may be very limited  on training due to data  protection rules, but still lead to ""good""  models which are production  ready.

In  my experience it was not  a big deal to produce a working model. But I  failed to deploy or  integrate the model into an existing solution. The  guys which were  responsible to implement the model api failed to  present the results in a  nice way or the UX was just terrible.

Another  fail requirement: ""generate automatic A/B landing pages in a web  application"". So the requirement was to automatically generate different  versions of landing pages based on the visitor flows (or origin  parameters: organic vs direct hits). It would be technically possible,  but imho at least 2000h of work ot get good results.

I look forward to an exciting exchange of experiences!",t2_a3gidxwy,False,,0,False,"What were the worst misconceptions/requirements of senior management in data science projects in connection with web applications (lead generation &amp; churn, content generation, data driven marketing, etc.)?",[],r/datascience,False,6,discussion,0,,,False,t3_177lhhw,False,dark,0.44,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697274959.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TL;DR: &lt;strong&gt;Biggest fails and your most loved data science solutions&lt;/strong&gt; in &lt;strong&gt;web related applications&lt;/strong&gt;, which you have experienced &lt;strong&gt;in your data science career&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Similar posts were previously removed for unclear reasons, so I have reworded the post. Please let me be clear: this is not a homework exercise, nor is it breaking any other rule in my opinion! My last attempt...)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I  am just curious in your personal data science experience of common web  applications like e-commerce, lead generation, web marketing and so on.&lt;/p&gt;

&lt;p&gt;Upper   management often wants solutions or applications which have a positive  imapct in selling products, gaining more customers or at least improve  existing products and services which can be used in marketing. And you  know, sometimes it&amp;#39;s all about slapping the &amp;quot;AI&amp;quot; label on products.&lt;/p&gt;

&lt;p&gt;What  were the worst misconceptions/requirements of senior management?  In  contrast: What unexpectedly  worked well? I.e. Data may be very limited  on training due to data  protection rules, but still lead to &amp;quot;good&amp;quot;  models which are production  ready.&lt;/p&gt;

&lt;p&gt;In  my experience it was not  a big deal to produce a working model. But I  failed to deploy or  integrate the model into an existing solution. The  guys which were  responsible to implement the model api failed to  present the results in a  nice way or the UX was just terrible.&lt;/p&gt;

&lt;p&gt;Another  fail requirement: &amp;quot;generate automatic A/B landing pages in a web  application&amp;quot;. So the requirement was to automatically generate different  versions of landing pages based on the visitor flows (or origin  parameters: organic vs direct hits). It would be technically possible,  but imho at least 2000h of work ot get good results.&lt;/p&gt;

&lt;p&gt;I look forward to an exciting exchange of experiences!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177lhhw,True,,malirkan,,2,True,all_ads,False,[],False,,/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,1209066,1697274959.0,0,,False,,,,,,,,,,1752,279
,datascience,"I've been working in the role of a data scientist for about 3 years at a large corporate. My training is as a physicist. I'm often involved in early stage proofs-of-concept for different departments so we're often in exchange with ""innovation managers"" whose role is to find use cases for ""AI"", as they call it. As a result, I often get pitched ideas for new projects from those managers.  


Now, upon closer inspection, many of these problems involve, at their technical core, an optimisation problem, where an objective function has to be optimised in the presence of constraints. I find these problems intriguing but I usually feel overwhelmed tackling them, as I lack the training to deal with them and I feel there is no good tooling around to help me model them, not to mention choosing and tuning the solver, benchmarking and then finally bringing them in production. 

As a result (and also for other reasons), those projects usually don't get realised.

I wonder whether others here face the same challenge or whether this is particular to me and if there are others, how you deal with it. Thanks",t2_l56y3hobw,False,,0,False,Do you also often deal with problems that turn out to be some kind of constrained optimisation problems?,[],r/datascience,False,6,discussion,0,,,False,t3_177k8pw,False,dark,0.95,,public,29,0,{},,,False,[],,False,False,,{},Discussion,False,29,,False,False,self,False,,[],{},,True,,1697269478.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been working in the role of a data scientist for about 3 years at a large corporate. My training is as a physicist. I&amp;#39;m often involved in early stage proofs-of-concept for different departments so we&amp;#39;re often in exchange with &amp;quot;innovation managers&amp;quot; whose role is to find use cases for &amp;quot;AI&amp;quot;, as they call it. As a result, I often get pitched ideas for new projects from those managers.  &lt;/p&gt;

&lt;p&gt;Now, upon closer inspection, many of these problems involve, at their technical core, an optimisation problem, where an objective function has to be optimised in the presence of constraints. I find these problems intriguing but I usually feel overwhelmed tackling them, as I lack the training to deal with them and I feel there is no good tooling around to help me model them, not to mention choosing and tuning the solver, benchmarking and then finally bringing them in production. &lt;/p&gt;

&lt;p&gt;As a result (and also for other reasons), those projects usually don&amp;#39;t get realised.&lt;/p&gt;

&lt;p&gt;I wonder whether others here face the same challenge or whether this is particular to me and if there are others, how you deal with it. Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177k8pw,True,,Much-Egg7130,,16,True,all_ads,False,[],False,,/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,all_ads,False,https://www.reddit.com/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,1209066,1697269478.0,0,,False,,,,,,,,,,1106,190
,datascience," 

I work in a large federal government agency, and regrettably, I have an extremely incompetent manager who spent many years working on dashboarding before being promoted to lead our team. My manager lacks any prior experience as a data scientist, data engineer, or machine learning engineer and is unwilling to learn in these areas. Given the nature of government employment, the likelihood of termination or layoffs is exceedingly low. The organization comprises both employees and contractors with the title of ""data scientists,"" but there's no clear plan on how to utilize their skills effectively. Additionally, our data governance and data quality processes are almost nonexistent.

There is a  significant fraud problem resulting in multimillion-dollar losses. One of the major challenges is that there are multiple definitions of fraud within the organization, making it nearly impossible to get straight answers when seeking guidance from supposed subject matter experts. Furthermore, various teams within the agency have different agendas when trying to address the fraud problem.

The CIO has recently directed us, likely influenced by management consultants, to use machine learning to solve the fraud problem. Nevertheless, it's apparent that there are many low-hanging fruit solutions, like process changes, that don't require machine learning and could significantly alleviate the issue.

Now, our manager is pressuring our team to build a machine learning model to supposedly save X millions of dollars. It appears that many people here are more interested in showcasing flashy tools and ideas to the directors and CIO, rather than delving into the details of the problem. Some of the other data scientists are demonstrating the use of complex machine learning techniques without truly understanding the problem statement or the models they are building. To make matters worse, we don't even have a clear, agreed-upon estimate of how much money we are losing.

In this chaotic environment, the manager wants us to build a model simply because someone in another team has done something similar. Our manager is focused on marketing and doesn't seem to care about the necessary details. I've suggested that we should invest time in understanding the data and conduct a feasibility study to determine if machine learning is an appropriate solution before committing to creating elaborate models. However, my manager either doesn't grasp the importance of understanding the data or simply doesn't care. Today he said I want each of you to build a model and compare results.

I know that the right thing to do is to leave the company or the team, and I am actively working on it. In the meantime, how can I handle this situation in the best possible way?",t2_5fbmh3va,False,,0,False,How to handle incompetent manager while looking for another job,[],r/datascience,False,6,discussion,0,,,False,t3_177ifms,False,dark,0.93,,public,29,0,{},,,False,[],,False,False,,{},Discussion,False,29,,False,False,self,1697290127.0,,[],{},,True,,1697261922.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work in a large federal government agency, and regrettably, I have an extremely incompetent manager who spent many years working on dashboarding before being promoted to lead our team. My manager lacks any prior experience as a data scientist, data engineer, or machine learning engineer and is unwilling to learn in these areas. Given the nature of government employment, the likelihood of termination or layoffs is exceedingly low. The organization comprises both employees and contractors with the title of &amp;quot;data scientists,&amp;quot; but there&amp;#39;s no clear plan on how to utilize their skills effectively. Additionally, our data governance and data quality processes are almost nonexistent.&lt;/p&gt;

&lt;p&gt;There is a  significant fraud problem resulting in multimillion-dollar losses. One of the major challenges is that there are multiple definitions of fraud within the organization, making it nearly impossible to get straight answers when seeking guidance from supposed subject matter experts. Furthermore, various teams within the agency have different agendas when trying to address the fraud problem.&lt;/p&gt;

&lt;p&gt;The CIO has recently directed us, likely influenced by management consultants, to use machine learning to solve the fraud problem. Nevertheless, it&amp;#39;s apparent that there are many low-hanging fruit solutions, like process changes, that don&amp;#39;t require machine learning and could significantly alleviate the issue.&lt;/p&gt;

&lt;p&gt;Now, our manager is pressuring our team to build a machine learning model to supposedly save X millions of dollars. It appears that many people here are more interested in showcasing flashy tools and ideas to the directors and CIO, rather than delving into the details of the problem. Some of the other data scientists are demonstrating the use of complex machine learning techniques without truly understanding the problem statement or the models they are building. To make matters worse, we don&amp;#39;t even have a clear, agreed-upon estimate of how much money we are losing.&lt;/p&gt;

&lt;p&gt;In this chaotic environment, the manager wants us to build a model simply because someone in another team has done something similar. Our manager is focused on marketing and doesn&amp;#39;t seem to care about the necessary details. I&amp;#39;ve suggested that we should invest time in understanding the data and conduct a feasibility study to determine if machine learning is an appropriate solution before committing to creating elaborate models. However, my manager either doesn&amp;#39;t grasp the importance of understanding the data or simply doesn&amp;#39;t care. Today he said I want each of you to build a model and compare results.&lt;/p&gt;

&lt;p&gt;I know that the right thing to do is to leave the company or the team, and I am actively working on it. In the meantime, how can I handle this situation in the best possible way?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177ifms,True,,Excellent_Cost170,,21,True,all_ads,False,[],False,,/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,all_ads,False,https://www.reddit.com/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,1209066,1697261922.0,0,,False,,,,,,,,,,2766,438
,datascience,"I hope it's ok for me to ask questions here, please point me elsewhere if that's not the case.

I have a binary classification model for identifying profitable trades, and I have just learned how AUC works (which took my smooth brain a lot longer than perhaps it would for you fine folk).

Anyway, would someone mind providing some pointers about which Classification metrics (Accuracy, AUC are the ones I already know) would be beneficial to understand, when comparing and understanding models? Or is AUC the de-facto standard?

I'm reading books on this topic, but finding that it can be difficult to follow.

Thanks",t2_3juer,False,,0,False,"For binary classification, where the focus is to avoid FP, can you help with which metrics to use?",[],r/datascience,False,6,discussion,0,,,False,t3_177ffq9,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697250944.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I hope it&amp;#39;s ok for me to ask questions here, please point me elsewhere if that&amp;#39;s not the case.&lt;/p&gt;

&lt;p&gt;I have a binary classification model for identifying profitable trades, and I have just learned how AUC works (which took my smooth brain a lot longer than perhaps it would for you fine folk).&lt;/p&gt;

&lt;p&gt;Anyway, would someone mind providing some pointers about which Classification metrics (Accuracy, AUC are the ones I already know) would be beneficial to understand, when comparing and understanding models? Or is AUC the de-facto standard?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m reading books on this topic, but finding that it can be difficult to follow.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177ffq9,True,,CatalystNZ,,8,True,all_ads,False,[],False,,/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,1209066,1697250944.0,0,,False,,,,,,,,,,618,104
,datascience,Does anyone have a good resource to share on long term holdout experiments and what they're used for?,t2_pyf90,False,,0,False,Holdout Experiments,[],r/datascience,False,6,projects,0,,,False,t3_177dgos,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697244620.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have a good resource to share on long term holdout experiments and what they&amp;#39;re used for?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,177dgos,True,,Dr_Rhombus,,0,True,all_ads,False,[],False,,/r/datascience/comments/177dgos/holdout_experiments/,all_ads,False,https://www.reddit.com/r/datascience/comments/177dgos/holdout_experiments/,1209066,1697244620.0,0,,False,,,,,,,,,,101,18
,datascience,"Does anyone have a good resource to share that lays out customer growth accounting framework (churn, resurrections, etc), and how it's used?",t2_pyf90,False,,0,False,"Customer Growth Accounting (churn, resurrections, etc) framework",[],r/datascience,False,6,projects,0,,,False,t3_177dfyv,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1697244557.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have a good resource to share that lays out customer growth accounting framework (churn, resurrections, etc), and how it&amp;#39;s used?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,177dfyv,True,,Dr_Rhombus,,0,True,all_ads,False,[],False,,/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,all_ads,False,https://www.reddit.com/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,1209066,1697244557.0,0,,False,,,,,,,,,,140,22
,datascience,"I got contacted by a recruiter today for an immediate hire for an ""Intermediate level data scientist"" at an energy company in Calgary. This would be a contract position for one year, full-time, hybrid (2 days from home per week), and required 5 years of experience.

The salary was 46.5 CAD/hour, no benefits and required you as a contractor to be incorporated.

I have a PhD, a completed post doctoral position, over 3 years of work experience as an independent contractor in a variety of industries as a data scientist and was honestly surprised by the low hourly rate. The majority of my clients have not been from the energy sector though, so maybe this is why?

After mentioning that this was below the hourly rate that I would consider a position, comparing this to a base salary of a full time employee coming with benefits such as healthcare, pension plan, paid time off, etc, while also not requiring the overhead of costs you have as a incorporated business in regards to bookkeeping, invoicing, taxes, etc, the rate was increased to 47 CAD/hour. 

I thought I'd throw it on here to keep these kind of salaries transparent and see if other Calgary/Canada-based data scientists have had similar experiences in this job market.",t2_lpsceo37l,False,,0,False,Hourly salary Data Scientist Canada,[],r/datascience,False,6,discussion,0,,,False,t3_177cfpy,False,dark,0.86,,public,25,0,{},,,False,[],,False,False,,{},Discussion,False,25,,False,False,self,False,,[],{},,True,,1697241463.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I got contacted by a recruiter today for an immediate hire for an &amp;quot;Intermediate level data scientist&amp;quot; at an energy company in Calgary. This would be a contract position for one year, full-time, hybrid (2 days from home per week), and required 5 years of experience.&lt;/p&gt;

&lt;p&gt;The salary was 46.5 CAD/hour, no benefits and required you as a contractor to be incorporated.&lt;/p&gt;

&lt;p&gt;I have a PhD, a completed post doctoral position, over 3 years of work experience as an independent contractor in a variety of industries as a data scientist and was honestly surprised by the low hourly rate. The majority of my clients have not been from the energy sector though, so maybe this is why?&lt;/p&gt;

&lt;p&gt;After mentioning that this was below the hourly rate that I would consider a position, comparing this to a base salary of a full time employee coming with benefits such as healthcare, pension plan, paid time off, etc, while also not requiring the overhead of costs you have as a incorporated business in regards to bookkeeping, invoicing, taxes, etc, the rate was increased to 47 CAD/hour. &lt;/p&gt;

&lt;p&gt;I thought I&amp;#39;d throw it on here to keep these kind of salaries transparent and see if other Calgary/Canada-based data scientists have had similar experiences in this job market.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177cfpy,True,,Dataman-Calgary,,13,True,all_ads,False,[],False,,/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,all_ads,False,https://www.reddit.com/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,1209066,1697241463.0,0,,False,,,,,,,,,,1235,212
,datascience,"Hello guys,  im kinda new in the data science area,  i was wondering what might be the best approach to tacle a demand forecasting  per sku project for the next 6 months in an fmcg distribution company , i have the sales per customer per sku per salesman for the last 2 years ( daily) but i prefer to give more weight to the last year data since its very different fot the previous one.

Ps: the customer data is not always accurate since the salesman can sometimes close a sale with partner A and pass it as its customer B , so the sale quantity per sku is always correct, the customer not always (75% accurate)

Thaanks in advance!!",t2_d8zcy4hv,False,,0,False,Demand forecasting FMCG company,[],r/datascience,False,6,projects,0,,,False,t3_177b4po,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1697237609.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys,  im kinda new in the data science area,  i was wondering what might be the best approach to tacle a demand forecasting  per sku project for the next 6 months in an fmcg distribution company , i have the sales per customer per sku per salesman for the last 2 years ( daily) but i prefer to give more weight to the last year data since its very different fot the previous one.&lt;/p&gt;

&lt;p&gt;Ps: the customer data is not always accurate since the salesman can sometimes close a sale with partner A and pass it as its customer B , so the sale quantity per sku is always correct, the customer not always (75% accurate)&lt;/p&gt;

&lt;p&gt;Thaanks in advance!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,177b4po,True,,RaccoonFew5715,,19,True,all_ads,False,[],False,,/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,all_ads,False,https://www.reddit.com/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,1209066,1697237609.0,0,,False,,,,,,,,,,634,120
,datascience,"I teach data science at a university (going anonymous for obvious reasons). I won't mention the institution name or location, though I think this is something typical across all non-prestigious universities. Basically, master's courses in data science, especially those of 1 year and marketed to international students, are a scam. 

Essentially, because there is pressure to pass all the students, we cannot give any material that is too challenging. I don't want to put challenging material in the course because I want them to fail--I put it because challenge is how students **grow** and **learn**. Aside from being a data analyst, being even an entry-level data scientist requires being good at a lot of things, and knowing the material deeply, not just superficially. Likewise, data engineers have to be good software engineers.

But apparently, asking the students to implement a trivial function in Python is too much. Just working with high-level libraries won't be enough to get my students a job in the field. OK, maybe you don’t have to implement algorithms from scratch, but you have to at least wrangle data. The theoretical content is OK, but the practical element is far from sufficient.

It is my belief that only one of my students, a software developer, will go on to get a high-paying job in the data field. Some might become data analysts (which pays thousands less), and likely a few will never get into a data career.

Universities write all sorts of crap in their marketing spiel that bears no resemblance to reality. And students, nor parents, don’t know any better, because how many people are actually qualified to judge whether a DS curriculum is good? Nor is it enough to see the topics, you have to see the *assignments*. If a DS course doesn’t have at least one serious course in statistics, any SQL, and doesn’t make you solve real programming problems, it's no good.",t2_sz964gnb,False,,0,False,Warning to would be master’s graduates in “data science”,[],r/datascience,False,6,discussion,0,,,False,t3_17798wz,False,dark,0.96,,public,632,0,{},,,False,[],,False,False,,{},Discussion,False,632,,False,False,self,1697238048.0,,[],{},,True,,1697232528.0,text,6,,,text,self.datascience,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I teach data science at a university (going anonymous for obvious reasons). I won&amp;#39;t mention the institution name or location, though I think this is something typical across all non-prestigious universities. Basically, master&amp;#39;s courses in data science, especially those of 1 year and marketed to international students, are a scam. &lt;/p&gt;

&lt;p&gt;Essentially, because there is pressure to pass all the students, we cannot give any material that is too challenging. I don&amp;#39;t want to put challenging material in the course because I want them to fail--I put it because challenge is how students &lt;strong&gt;grow&lt;/strong&gt; and &lt;strong&gt;learn&lt;/strong&gt;. Aside from being a data analyst, being even an entry-level data scientist requires being good at a lot of things, and knowing the material deeply, not just superficially. Likewise, data engineers have to be good software engineers.&lt;/p&gt;

&lt;p&gt;But apparently, asking the students to implement a trivial function in Python is too much. Just working with high-level libraries won&amp;#39;t be enough to get my students a job in the field. OK, maybe you don’t have to implement algorithms from scratch, but you have to at least wrangle data. The theoretical content is OK, but the practical element is far from sufficient.&lt;/p&gt;

&lt;p&gt;It is my belief that only one of my students, a software developer, will go on to get a high-paying job in the data field. Some might become data analysts (which pays thousands less), and likely a few will never get into a data career.&lt;/p&gt;

&lt;p&gt;Universities write all sorts of crap in their marketing spiel that bears no resemblance to reality. And students, nor parents, don’t know any better, because how many people are actually qualified to judge whether a DS curriculum is good? Nor is it enough to see the topics, you have to see the &lt;em&gt;assignments&lt;/em&gt;. If a DS course doesn’t have at least one serious course in statistics, any SQL, and doesn’t make you solve real programming problems, it&amp;#39;s no good.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17798wz,True,,anon_throwaway09557,,302,True,all_ads,False,[],False,,/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,1209066,1697232528.0,0,,False,,,,,,,,,,1899,319
,datascience,"While I understand that some industries have a pretty shallow pool of ideas, what do those with a lot of ideas use to organize them into a way that allows project tracking and or understanding relationships between them?",t2_5bfewy53,False,,0,False,How does your team organize ideas?,[],r/datascience,False,6,discussion,0,,,False,t3_1778xvq,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697231748.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;While I understand that some industries have a pretty shallow pool of ideas, what do those with a lot of ideas use to organize them into a way that allows project tracking and or understanding relationships between them?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1778xvq,True,,hownottopetacat,,3,True,all_ads,False,[],False,,/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,all_ads,False,https://www.reddit.com/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,1209066,1697231748.0,0,,False,,,,True,,,,,,220,38
,datascience,"Not many people pay attention to this even though most people know that when you are interviewing for your next data scientist roles, you are also interviewing your next boss!

You've done a great job answering all the technical questions, but asking good questions are also critical but not much effort was put into this is what I've seen typically. 

So what are some good questions to ask your next prospect boss?

As a hiring manager myself, here are some of my favorite questions from my best candidates:

**To learn more about the day-to-day:**

* What's the day-to-day like for you (or for a data scientist on your team)?
* What percentage of your time (a DS on the team) is spent on coding?
* What percentage for other tasks? And what are those tasks?

**To learn more about ownership:**

* How are projects assigned across the team?
* How do team members collaborate?
* How is the scope of a project typically determined? 

**There are more you can ask to learn more about scope of projects and to learn more about room for adaptability:**

More detailed questions here:

[https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview](https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview)

What did you ask that got you great insights about your interviewer? 

&amp;#x200B;",t2_c4ul3bfy,False,,0,False,What are good questions to ask in interviews to validate the quality of your future boss?,[],r/datascience,False,6,discussion,0,,,False,t3_1778u49,False,dark,0.97,,public,90,0,{},,,False,[],,False,False,,{},Discussion,False,90,,False,False,self,False,,[],{},,True,,1697231474.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not many people pay attention to this even though most people know that when you are interviewing for your next data scientist roles, you are also interviewing your next boss!&lt;/p&gt;

&lt;p&gt;You&amp;#39;ve done a great job answering all the technical questions, but asking good questions are also critical but not much effort was put into this is what I&amp;#39;ve seen typically. &lt;/p&gt;

&lt;p&gt;So what are some good questions to ask your next prospect boss?&lt;/p&gt;

&lt;p&gt;As a hiring manager myself, here are some of my favorite questions from my best candidates:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To learn more about the day-to-day:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What&amp;#39;s the day-to-day like for you (or for a data scientist on your team)?&lt;/li&gt;
&lt;li&gt;What percentage of your time (a DS on the team) is spent on coding?&lt;/li&gt;
&lt;li&gt;What percentage for other tasks? And what are those tasks?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;To learn more about ownership:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How are projects assigned across the team?&lt;/li&gt;
&lt;li&gt;How do team members collaborate?&lt;/li&gt;
&lt;li&gt;How is the scope of a project typically determined? &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;There are more you can ask to learn more about scope of projects and to learn more about room for adaptability:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;More detailed questions here:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview""&gt;https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What did you ask that got you great insights about your interviewer? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1778u49,True,,linamagr,,31,True,all_ads,False,[],False,,/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,1209066,1697231474.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?auto=webp&amp;s=4c2bb5152387c17b258e1ff1b491770f0768d5d7', 'width': 1100, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4785b224ae9dbf033e77ea73bfc37cd09dfd981', 'width': 108, 'height': 58}, {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=536720e8e3a9632038fcd6516929b6732db16ce5', 'width': 216, 'height': 117}, {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3928ebbe80d890d99ad63e863723351b2c6c8bff', 'width': 320, 'height': 174}, {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=91d7bea93720b6e29d5097e885ff11036812c2a1', 'width': 640, 'height': 349}, {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=42ef75911686647d0818fb2672e8cf2fd558faf8', 'width': 960, 'height': 523}, {'url': 'https://external-preview.redd.it/vR9QFVrK2TDtj0eh6IRbZoJXD8jDKl-o2XYui3knDKY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f213ecc2ca36bfa498655f03b9a4248d4cd03d24', 'width': 1080, 'height': 589}], 'variants': {}, 'id': '86_A-18OAYiexWyy2hT0Q-fbAm6ddnuNJhaJBGboSJo'}], 'enabled': False}",,,,,,,1326,203
,datascience,What do you think guys -&gt; [https://twitter.com/Cesar\_Ges/status/1712541730053173280](https://twitter.com/Cesar_Ges/status/1712541730053173280),t2_8c394a76,False,,0,False,Ocean protocol,[],r/datascience,False,6,discussion,0,,,False,t3_1777d0q,False,dark,0.2,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697227436.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What do you think guys -&amp;gt; &lt;a href=""https://twitter.com/Cesar_Ges/status/1712541730053173280""&gt;https://twitter.com/Cesar_Ges/status/1712541730053173280&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1777d0q,True,,Zestyclose-Ad-7154,,0,True,all_ads,False,[],False,,/r/datascience/comments/1777d0q/ocean_protocol/,all_ads,False,https://www.reddit.com/r/datascience/comments/1777d0q/ocean_protocol/,1209066,1697227436.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/uaEkxKfEEmqieWhWWYlaJEtsm0vSmO6L4p4Jli39lJk.jpg?auto=webp&amp;s=7d6a9495d1d18aa744a3f7b0413cc6702b568e59', 'width': 140, 'height': 140}, 'resolutions': [{'url': 'https://external-preview.redd.it/uaEkxKfEEmqieWhWWYlaJEtsm0vSmO6L4p4Jli39lJk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e961ddc1f4365d14ad3a194c6482f2ca52f4639', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'yaJVivp8wwvjPUGEALqrUqrUgnEbxZzurDNhAzOTvD4'}], 'enabled': False}",,,,,,,146,7
,datascience,I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I'd preferably like to use an offline language model or one that would be safe to put in our code,t2_9e4tgkg2,False,,0,False,Guidance on Language Model,[],r/datascience,False,6,projects,0,,,False,t3_1775rtq,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697222961.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I&amp;#39;d preferably like to use an offline language model or one that would be safe to put in our code&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1775rtq,True,,Aggravating_Sand352,,5,True,all_ads,False,[],False,,/r/datascience/comments/1775rtq/guidance_on_language_model/,all_ads,False,https://www.reddit.com/r/datascience/comments/1775rtq/guidance_on_language_model/,1209066,1697222961.0,0,,False,,,,,,,,,,310,62
,datascience,"I'm implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as ""created by"" and ""last modified by."" For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I'm aware of CloudTrail's Lookup Events API, but I'm looking for an alternative approach to retrieve this information from the server-side without using a client library.",t2_a6jhwhs16,False,,0,False,Fetching User Details for Triggered AWS Glue Job,[],r/datascience,False,6,discussion,0,,,False,t3_1775qrn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697222881.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as &amp;quot;created by&amp;quot; and &amp;quot;last modified by.&amp;quot; For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I&amp;#39;m aware of CloudTrail&amp;#39;s Lookup Events API, but I&amp;#39;m looking for an alternative approach to retrieve this information from the server-side without using a client library.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1775qrn,True,,TechSavvyGal,,0,True,all_ads,False,[],False,,/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,1209066,1697222881.0,0,,False,,,,,,,,,,543,92
,datascience,Can't wait to read your comment!,t2_nk2pd,False,,0,False,"In your time working with data science at a corporation, what cool things did you pick up / learn that school didn't teach you?",[],r/datascience,False,6,discussion,0,,,False,t3_1775fq0,False,dark,0.99,,public,107,0,{},,,False,[],,False,False,,{},Discussion,False,107,,False,False,self,False,,[],{},,True,,1697222068.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can&amp;#39;t wait to read your comment!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1775fq0,True,,TheEnlightenedMan,,64,True,all_ads,False,[],False,,/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,1209066,1697222068.0,0,,False,,,,,,,,,,32,6
,datascience,"Two months ago, I was laid off from my role as a data scientist after 2 years. It was ""reduction in force"" and my role was affected. 

Some background:

* Previous Role: Data Scientist 1
* 2 yrs of xp, master's in statistics
* Had a big tech company as long term client at previous role (13 months)
* I was in top 10% of performers (98% billable hours and internal recognition for innovation)
* Was confirmed for promotion.

It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I'm laid off. What should I do about this market? I barely see any positions open for someone like my self.",t2_7p8ba,False,,0,False,It's been two months since I was laid off as a DS. Any advice on how to deal with current market.,[],r/datascience,False,6,discussion,0,,,False,t3_177479m,False,dark,0.92,,public,126,0,{},,,False,[],,False,False,,{},Discussion,False,126,,False,False,self,False,,[],{},,True,,1697218719.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Two months ago, I was laid off from my role as a data scientist after 2 years. It was &amp;quot;reduction in force&amp;quot; and my role was affected. &lt;/p&gt;

&lt;p&gt;Some background:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Previous Role: Data Scientist 1&lt;/li&gt;
&lt;li&gt;2 yrs of xp, master&amp;#39;s in statistics&lt;/li&gt;
&lt;li&gt;Had a big tech company as long term client at previous role (13 months)&lt;/li&gt;
&lt;li&gt;I was in top 10% of performers (98% billable hours and internal recognition for innovation)&lt;/li&gt;
&lt;li&gt;Was confirmed for promotion.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I&amp;#39;m laid off. What should I do about this market? I barely see any positions open for someone like my self.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,177479m,True,,VodkaRain,,86,True,all_ads,False,[],False,,/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,all_ads,False,https://www.reddit.com/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,1209066,1697218719.0,0,,False,,,,,,,,,,683,130
,datascience,"Hi everyone,



First time posting here so not sure this is where it belongs.



I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I've not had much experience in SQL or Power BI, neither of which the internship need either.



I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?



Nothing to publish, solely extra academic learning I can play with. Thanks !",t2_31tuq20y,False,,0,False,I want to improve more!,[],r/datascience,False,6,projects,0,,,False,t3_1773x9b,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Projects,False,3,,False,False,self,False,,[],{},,True,,1697217932.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;First time posting here so not sure this is where it belongs.&lt;/p&gt;

&lt;p&gt;I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I&amp;#39;ve not had much experience in SQL or Power BI, neither of which the internship need either.&lt;/p&gt;

&lt;p&gt;I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?&lt;/p&gt;

&lt;p&gt;Nothing to publish, solely extra academic learning I can play with. Thanks !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1773x9b,True,,RebeccaMayy,,1,True,all_ads,False,[],False,,/r/datascience/comments/1773x9b/i_want_to_improve_more/,all_ads,False,https://www.reddit.com/r/datascience/comments/1773x9b/i_want_to_improve_more/,1209066,1697217932.0,0,,False,,,,,,,,,,535,96
,datascience,"https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;format=png&amp;auto=webp&amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df

&amp;#x200B;",t2_c5tc2ovi,False,,0,False,Fraud Detection Machine learning project,[],r/datascience,False,6,projects,0,31.0,,False,t3_1772in6,False,dark,0.75,,public,2,0,{},140.0,,False,[],,False,False,,{},Projects,False,2,,False,False,https://a.thumbs.redditmedia.com/JQeeWPbpqA_pqiWH-L5lR8yEG3tB9PvhiW-ILwsdJ00.jpg,False,,[],{},,True,,1697214034.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df""&gt;https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1772in6,True,,ResearchShort4056,,1,True,all_ads,False,[],False,,/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,1209066,1697214034.0,0,,False,"{'ha6kw13ewztb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 24, 'x': 108, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f1e6a41af2baa0371f3cc4f840b570b3b8d7ae5'}, {'y': 48, 'x': 216, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2789925ee4b5d0b334949045fb55ff624f412b13'}, {'y': 71, 'x': 320, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a5401b76f38d9f72b43aaa3c85adbe90552075f5'}, {'y': 143, 'x': 640, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=832a5553038634938362db66d7039620eb026e65'}, {'y': 214, 'x': 960, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e07c357093312ce4b83cc36e3cfef19898f7f8e'}], 's': {'y': 216, 'x': 966, 'u': 'https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;format=png&amp;auto=webp&amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df'}, 'id': 'ha6kw13ewztb1'}}",,,,,,,,,141,2
,datascience,"Hi All, 

I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).

I have store sales &amp; customer but need the traffic data. 

How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).

I tried government data and websites and the information is available but not to the public and it isn't quite the information needed. 

Welcoming all suggestions, thanks everyone!",t2_hqo0dh0zu,False,,0,False,Traffic Data Source for Senior Project,[],r/datascience,False,6,projects,0,,,False,t3_1771jsh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697211429.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All, &lt;/p&gt;

&lt;p&gt;I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).&lt;/p&gt;

&lt;p&gt;I have store sales &amp;amp; customer but need the traffic data. &lt;/p&gt;

&lt;p&gt;How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).&lt;/p&gt;

&lt;p&gt;I tried government data and websites and the information is available but not to the public and it isn&amp;#39;t quite the information needed. &lt;/p&gt;

&lt;p&gt;Welcoming all suggestions, thanks everyone!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1771jsh,True,,Purple_Bite_9579,,2,True,all_ads,False,[],False,,/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,1209066,1697211429.0,0,,False,,,,,,,,,,751,132
,datascience,My experience as a candidate wasn't always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate's technical aptitude and work ethic on the job.,t2_75rv6bzh,False,,0,False,What are the best practices for interviewing data science candidates?,[],r/datascience,False,6,discussion,0,,,False,t3_1771460,False,dark,0.75,,public,6,0,{},,,False,[],,False,False,,{},Discussion,False,6,,False,False,self,False,,[],{},,True,,1697210273.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My experience as a candidate wasn&amp;#39;t always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate&amp;#39;s technical aptitude and work ethic on the job.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1771460,True,,Born_Buy7037,,6,False,all_ads,False,[],False,,/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,1209066,1697210273.0,0,,False,,,,,,,,,,253,42
,datascience,"Hello guys and girls,

I'm a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.

All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.

But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. 

So, I have this database with data not audited and data audited with it's outcomes: data needed to be corrected and don't.

We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc

So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it's not representative as it's not a random sample, so how to look to it? 

Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.

Thanks in advance.",t2_2oa2pvy7,False,,0,False,Guidance to analyze data reliability and variables related,[],r/datascience,False,6,projects,0,,,False,t3_176yuks,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,1697204435.0,,[],{},,True,,1697203951.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys and girls,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.&lt;/p&gt;

&lt;p&gt;All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.&lt;/p&gt;

&lt;p&gt;But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. &lt;/p&gt;

&lt;p&gt;So, I have this database with data not audited and data audited with it&amp;#39;s outcomes: data needed to be corrected and don&amp;#39;t.&lt;/p&gt;

&lt;p&gt;We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc&lt;/p&gt;

&lt;p&gt;So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it&amp;#39;s not representative as it&amp;#39;s not a random sample, so how to look to it? &lt;/p&gt;

&lt;p&gt;Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,176yuks,True,,lfelipecl,,1,True,all_ads,False,[],False,,/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,1209065,1697203951.0,0,,False,,,,,,,,,,1444,245
,datascience,"During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field's ""Discovering Statistics Using R"" book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.

  
Several years later, I've left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field's ""Discovering Statistics Using R"", which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.

  
As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don't know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?",t2_vje69p4l,False,,0,False,Guides that explore statistical theory and concepts through analysis in R using tidyverse,[],r/datascience,False,6,discussion,0,,,False,t3_176uhmx,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697188094.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field&amp;#39;s &amp;quot;Discovering Statistics Using R&amp;quot; book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.&lt;/p&gt;

&lt;p&gt;Several years later, I&amp;#39;ve left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field&amp;#39;s &amp;quot;Discovering Statistics Using R&amp;quot;, which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.&lt;/p&gt;

&lt;p&gt;As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don&amp;#39;t know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176uhmx,True,,FrancisGrant1,,1,True,all_ads,False,[],False,,/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,all_ads,False,https://www.reddit.com/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,1209065,1697188094.0,0,,False,,,,,,,,,,1204,198
,datascience,"Recently i was in conversation with professor Rob Hyndman and he told how TimeGPT was a promising model that could be used for prediction tasks. For those who don't know this is an excerpt from the company website:-

TimeGPT, developed by Nixtla, is a generative pre-trained transformer model specialized in prediction tasks. TimeGPT was trained on the largest collection of data in history – over 100 billion rows of financial, weather, energy, and web data – and democratizes the power of time-series analysis.

So what are your thoughts on such models and where do you think the future lies for forecasting tasks when compared to statistical models like ARIMA or state space models.",t2_vt5r7wi2,False,,0,False,What are your thoughts on time series analysis and forecasting with Generative models like TimeGPT,[],r/datascience,False,6,discussion,0,,,False,t3_176tmht,False,dark,0.36,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,1697209194.0,,[],{},,True,,1697184311.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently i was in conversation with professor Rob Hyndman and he told how TimeGPT was a promising model that could be used for prediction tasks. For those who don&amp;#39;t know this is an excerpt from the company website:-&lt;/p&gt;

&lt;p&gt;TimeGPT, developed by Nixtla, is a generative pre-trained transformer model specialized in prediction tasks. TimeGPT was trained on the largest collection of data in history – over 100 billion rows of financial, weather, energy, and web data – and democratizes the power of time-series analysis.&lt;/p&gt;

&lt;p&gt;So what are your thoughts on such models and where do you think the future lies for forecasting tasks when compared to statistical models like ARIMA or state space models.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176tmht,True,,Additional_Guide5439,,3,True,all_ads,False,[],False,,/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,all_ads,False,https://www.reddit.com/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,1209065,1697184311.0,0,,False,,,,,,,,,,685,113
,datascience,"I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \~ 150k stores in the dataset.

I can distribute these into \~21k regions with varying number of stores (max \~5k) and search locally within and that aligns with the problem statement.

My current method involves:  
Loop for region  
Calculate distance of first store from all other stores  
Loop for each store  
dist col = dist col - dist store(current loop iteration)  
filter for dist col &lt;= 150m

store\_ref = current loop iteration

check if dist (store\_ref and store in iteration &lt;=100m)

if yes,

check similarity,

if similarity&gt;threshold, add to list/dataframe

&amp;#x200B;

&amp;#x200B;

This is a 3 level loop of max \~21k \* 5k \* 600 iterations and is taking too long. 

I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  
",t2_15nser,False,,0,False,Alphanumeric Search Algorithm?,[],r/datascience,False,6,discussion,0,,,False,t3_176tcyw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697183133.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are ~ 150k stores in the dataset.&lt;/p&gt;

&lt;p&gt;I can distribute these into ~21k regions with varying number of stores (max ~5k) and search locally within and that aligns with the problem statement.&lt;/p&gt;

&lt;p&gt;My current method involves:&lt;br/&gt;
Loop for region&lt;br/&gt;
Calculate distance of first store from all other stores&lt;br/&gt;
Loop for each store&lt;br/&gt;
dist col = dist col - dist store(current loop iteration)&lt;br/&gt;
filter for dist col &amp;lt;= 150m&lt;/p&gt;

&lt;p&gt;store_ref = current loop iteration&lt;/p&gt;

&lt;p&gt;check if dist (store_ref and store in iteration &amp;lt;=100m)&lt;/p&gt;

&lt;p&gt;if yes,&lt;/p&gt;

&lt;p&gt;check similarity,&lt;/p&gt;

&lt;p&gt;if similarity&amp;gt;threshold, add to list/dataframe&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This is a 3 level loop of max ~21k * 5k * 600 iterations and is taking too long. &lt;/p&gt;

&lt;p&gt;I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176tcyw,True,,sarafpiyush98,,2,True,all_ads,False,[],False,,/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,all_ads,False,https://www.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,1209065,1697183133.0,0,,False,,,,,,,,,,1005,166
,datascience,"Hello everyone,

I recently completed **Hyndman, R.J., &amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?",t2_vt5r7wi2,False,,0,False,Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications,[],r/datascience,False,6,discussion,0,,,False,t3_176t8at,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697182542.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I recently completed &lt;strong&gt;Hyndman, R.J., &amp;amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition&lt;/strong&gt;. It&amp;#39;s a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I&amp;#39;m looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any &lt;strong&gt;books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)&lt;/strong&gt;? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176t8at,True,,Additional_Guide5439,,3,True,all_ads,False,[],False,,/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,all_ads,False,https://www.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,1209065,1697182542.0,0,,False,,,,,,,,,,945,136
,datascience," I've been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?

I've heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it's all about the work, and personal connections might be secondary.

I'd love to hear your thoughts and experiences on this matter:

1. Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?
2. Conversely, have you been on a high-performance team where personal relationships weren't a focal point, yet it still excelled in achieving its goals?
3. What are your thoughts on the balance between personal connections and professional performance within a team?
4. Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?

Feel free to share your insights, anecdotes, or opinions. I'm genuinely curious to see the various perspectives on this topic. Let's have a meaningful discussion!

 ",t2_e2ahk9usw,False,,0,False,High Performance Teams: Is the Balance of Personal and Professional Connections Vital for Team Synergy? Should you really KNOW and CARE about your colleagues?,[],r/datascience,False,6,discussion,0,,,False,t3_176rwg6,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697177100.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it&amp;#39;s all about the work, and personal connections might be secondary.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d love to hear your thoughts and experiences on this matter:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?&lt;/li&gt;
&lt;li&gt;Conversely, have you been on a high-performance team where personal relationships weren&amp;#39;t a focal point, yet it still excelled in achieving its goals?&lt;/li&gt;
&lt;li&gt;What are your thoughts on the balance between personal connections and professional performance within a team?&lt;/li&gt;
&lt;li&gt;Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Feel free to share your insights, anecdotes, or opinions. I&amp;#39;m genuinely curious to see the various perspectives on this topic. Let&amp;#39;s have a meaningful discussion!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176rwg6,True,,Active_Cranberry7606,,3,True,all_ads,False,[],False,,/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,all_ads,False,https://www.reddit.com/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,1209065,1697177100.0,0,,False,,,,,,,,,,1262,203
,datascience,"Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).

The problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.

(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:

&gt;data = {'User': \['User1', 'User2', 'User3'\],'Hobbies': \[\['Soccer', 'Swimming', 'Hiking'\],\['Swimming', 'Cycling'\],\['Soccer', 'Hiking'\]\]}

)

I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.

The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.

How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.

&amp;#x200B;",t2_34cofh7h,False,,0,False,On handling multi-label/multi-value categorical features and high cardinality.,[],r/datascience,False,6,discussion,0,,,False,t3_176ojaz,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697164921.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m working on a binary classification problem with all input features being categorical (and nominal).&lt;/p&gt;

&lt;p&gt;The problem I&amp;#39;m facing is that each input example can contain multiple values of a feature and there are too many different values.&lt;/p&gt;

&lt;p&gt;(For example, multi-value feature being a &amp;#39;Hobbies&amp;#39; feature that contains a list of strings:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;data = {&amp;#39;User&amp;#39;: [&amp;#39;User1&amp;#39;, &amp;#39;User2&amp;#39;, &amp;#39;User3&amp;#39;],&amp;#39;Hobbies&amp;#39;: [[&amp;#39;Soccer&amp;#39;, &amp;#39;Swimming&amp;#39;, &amp;#39;Hiking&amp;#39;],[&amp;#39;Swimming&amp;#39;, &amp;#39;Cycling&amp;#39;],[&amp;#39;Soccer&amp;#39;, &amp;#39;Hiking&amp;#39;]]}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;)&lt;/p&gt;

&lt;p&gt;I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0&amp;#39;s.  I searched for other suggestions that address this issue and &lt;a href=""https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4""&gt;this article&lt;/a&gt; stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.&lt;/p&gt;

&lt;p&gt;The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I&amp;#39;m not sure about this approach.&lt;/p&gt;

&lt;p&gt;How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I&amp;#39;m new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn&amp;#39;t address the multiple-value nature of the features.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176ojaz,True,,CheapBanana1050,,3,True,all_ads,False,[],False,,/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,all_ads,False,https://www.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,1209065,1697164921.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?auto=webp&amp;s=e4c05efb8e7eabb8fe5be7950cbdf8b7574039d0', 'width': 1200, 'height': 848}, 'resolutions': [{'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2bcbbcf5c954a81d766f837557ab8538d04464d', 'width': 108, 'height': 76}, {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=719c3a6e89b80326515907eec8208713517d44fd', 'width': 216, 'height': 152}, {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9c755cb79167278a421677a8ac39c82174e97aa', 'width': 320, 'height': 226}, {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31105cf933cfdaef26002492c8d5111b5e2c7334', 'width': 640, 'height': 452}, {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=39339c6e244f4e1d9d334aeb2ecc02c6574a2e87', 'width': 960, 'height': 678}, {'url': 'https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f16efceb0e9e91b01f70242ea1cbfe247ab124a', 'width': 1080, 'height': 763}], 'variants': {}, 'id': 'Vju-ktydPGpaa_K21sWwaMhKZihatZsNz7OW0Ec8tNQ'}], 'enabled': False}",,,,,,,1741,255
,datascience,"I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a ""reorganization"" by a higher up and that my role had been eliminated.

Anyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.

Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.

Some other key details below:

- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).
- Worked for over a year and have 2.5 years of experience in data science.
- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.
- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.

I'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn.",t2_lnimx58p7,False,,0,False,"Got hit with a layoff today but they offered to shop me around internally, any advice?",[],r/datascience,False,6,discussion,0,,,False,t3_176nzqe,False,dark,0.9,,public,81,0,{},,,False,[],,False,False,,{},Discussion,False,81,,False,False,self,False,,[],{},,True,,1697163196.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a &amp;quot;reorganization&amp;quot; by a higher up and that my role had been eliminated.&lt;/p&gt;

&lt;p&gt;Anyways, they offered to help shop me around to some other internal teams and I&amp;#39;ll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I&amp;#39;d really appreciate it.&lt;/p&gt;

&lt;p&gt;Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there&amp;#39;s no training period, I&amp;#39;m already familiar with all the datasets and industry. I&amp;#39;m going to spend tomorrow trying to summarize all the work I&amp;#39;ve done at the company since I got hired.&lt;/p&gt;

&lt;p&gt;Some other key details below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Was told I was rehire eligible. They specifically said that severance wouldn&amp;#39;t be impacted if I boomeranged unless I switched teams before final date (1 month).&lt;/li&gt;
&lt;li&gt;Worked for over a year and have 2.5 years of experience in data science.&lt;/li&gt;
&lt;li&gt;Probably was on the bottom half of performers, but I wasn&amp;#39;t the worst. I was the most recent hire though. My boss&amp;#39;s boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.&lt;/li&gt;
&lt;li&gt;The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m going to keep the ranting to a minimum because this post is pretty identifiable, but I&amp;#39;m honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that&amp;#39;s life but god damn.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176nzqe,True,,Smart_Donut_9558,,45,True,all_ads,False,[],False,,/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,all_ads,False,https://www.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,1209065,1697163196.0,0,,False,,,,,,,,,,1985,376
,datascience,I'm autistic. I have really bad social anxiety. Is networking key in getting a job? I am just getting started in school.. i've been a stay at home mom for the last 9 years. Am i wasting my time?,t2_gnpttzu4r,False,,0,False,Is networking key?,[],r/datascience,False,6,discussion,0,,,False,t3_176n9lw,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697160879.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m autistic. I have really bad social anxiety. Is networking key in getting a job? I am just getting started in school.. i&amp;#39;ve been a stay at home mom for the last 9 years. Am i wasting my time?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176n9lw,True,,are-you-kittenme,,7,True,all_ads,False,[],False,,/r/datascience/comments/176n9lw/is_networking_key/,all_ads,False,https://www.reddit.com/r/datascience/comments/176n9lw/is_networking_key/,1209065,1697160879.0,0,,False,,,,,,,,,,194,39
,datascience,"Hi all,

I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.

Thanks! Any advice would be appreciated.",t2_ds90qagip,False,,0,False,Resources on Monte Carlo Simulations (Python),[],r/datascience,False,6,discussion,0,,,False,t3_176h4n3,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697143923.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.&lt;/p&gt;

&lt;p&gt;Thanks! Any advice would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176h4n3,True,,Reasonable-Farmer186,,4,True,all_ads,False,[],False,,/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,all_ads,False,https://www.reddit.com/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,1209065,1697143923.0,0,,False,,,,,,,,,,388,67
,datascience,"\`cp.norm(weights, 1).is\_dcp()\` returns true. Then why this code works:

&amp;#x200B;

    import cvxpy as cp
    import numpy as np
    inputs = np.random.normal(0, 1, (100, 300))
    inputs_mean = inputs.mean(axis=1) # shape (features,)
    inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)
    weights = cp.Variable(len(inputs))
    risk = cp.quad_form(weights, inputs_cov)
    constraints = [
    # cp.norm(weights, 1) == 1.,
    cp.sum(weights) == 1.,
    ]
    problem = cp.Problem(cp.Minimize(risk), constraints)
    problem.solve(verbose=True)
    weights.value

But if you use the first constraint (\`cp.norm\`) instead of the second, it does not:

&amp;#x200B;

    DCPError: Problem does not follow DCP rules. Specifically:
    The following constraints are not DCP:
    norm1(var456) == 1.0 , because the following subexpressions are not:
    |-- norm1(var456) == 1.0

&amp;#x200B;

Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.

&amp;#x200B;",t2_j34wfzb7,False,,0,False,CVXPY: Why Norm constraint is not DCP?,[],r/datascience,False,6,discussion,0,,,False,t3_176fpo0,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697140219.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;`cp.norm(weights, 1).is_dcp()` returns true. Then why this code works:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import cvxpy as cp
import numpy as np
inputs = np.random.normal(0, 1, (100, 300))
inputs_mean = inputs.mean(axis=1) # shape (features,)
inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)
weights = cp.Variable(len(inputs))
risk = cp.quad_form(weights, inputs_cov)
constraints = [
# cp.norm(weights, 1) == 1.,
cp.sum(weights) == 1.,
]
problem = cp.Problem(cp.Minimize(risk), constraints)
problem.solve(verbose=True)
weights.value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But if you use the first constraint (`cp.norm`) instead of the second, it does not:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DCPError: Problem does not follow DCP rules. Specifically:
The following constraints are not DCP:
norm1(var456) == 1.0 , because the following subexpressions are not:
|-- norm1(var456) == 1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176fpo0,True,,FierceTeletubby,,6,True,all_ads,False,[],False,,/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,all_ads,False,https://www.reddit.com/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,1209065,1697140219.0,0,,False,,,,,,,,,,1088,138
,datascience,"For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. 

Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. 

However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. 

Things like SHAP values of LIME are okay in some instances with a stable model, but we've seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. 

This blog post summarizes most of my thoughts clearly: https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/

Anyways, I guess what I'm asking is are there practicioners out there that hold a different view? Are there advancements in this space that I'm unaware of? I know there's a lot of effort going into the explainable AI space right now, but I'm pessimistic that it's even possible for us to have a good explaination for many models. Thoughts?",t2_2x1e09nw,False,,0,False,Explainable AI Scepticism,[],r/datascience,False,6,discussion,0,,,False,t3_176drw8,False,dark,0.84,,public,8,0,{},,,False,[],,False,False,,{},Discussion,False,8,,False,False,self,False,,[],{},,True,,1697135053.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. &lt;/p&gt;

&lt;p&gt;Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. &lt;/p&gt;

&lt;p&gt;However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. &lt;/p&gt;

&lt;p&gt;Things like SHAP values of LIME are okay in some instances with a stable model, but we&amp;#39;ve seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. &lt;/p&gt;

&lt;p&gt;This blog post summarizes most of my thoughts clearly: &lt;a href=""https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/""&gt;https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Anyways, I guess what I&amp;#39;m asking is are there practicioners out there that hold a different view? Are there advancements in this space that I&amp;#39;m unaware of? I know there&amp;#39;s a lot of effort going into the explainable AI space right now, but I&amp;#39;m pessimistic that it&amp;#39;s even possible for us to have a good explaination for many models. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176drw8,True,,a157reverse,,6,True,all_ads,False,[],False,,/r/datascience/comments/176drw8/explainable_ai_scepticism/,all_ads,False,https://www.reddit.com/r/datascience/comments/176drw8/explainable_ai_scepticism/,1209065,1697135053.0,0,,False,,,,,,,,,,1774,285
,datascience," Hi guys, i'm doing research on Pandas, and I've read various posts here and there on the web, but i haven't reached a definitive conclusion regarding the question i posed. I'd like to understand how Pandas stores indices and what the time complexity of lookup operations performed with **loc** is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, [https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas](https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas), which discusses the topic, but there's no concrete evidence that this is true. Can anyone help me? Thanks a lot.",t2_dlj2dqhje,False,,0,False,What's Pandas .loc time complexity?,[],r/datascience,False,6,discussion,0,,,False,t3_176di2y,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697134354.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, i&amp;#39;m doing research on Pandas, and I&amp;#39;ve read various posts here and there on the web, but i haven&amp;#39;t reached a definitive conclusion regarding the question i posed. I&amp;#39;d like to understand how Pandas stores indices and what the time complexity of lookup operations performed with &lt;strong&gt;loc&lt;/strong&gt; is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, &lt;a href=""https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas""&gt;https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas&lt;/a&gt;, which discusses the topic, but there&amp;#39;s no concrete evidence that this is true. Can anyone help me? Thanks a lot.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176di2y,True,,AlternativeSea4330,,5,True,all_ads,False,[],False,,/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,all_ads,False,https://www.reddit.com/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,1209065,1697134354.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,,765,94
,datascience,"This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.


For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it's likely the cheapest price in the interval that I should place the order.


I'm currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don't usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!",t2_81jpdz5w,False,,0,False,What is a personal side project that you have worked on that has increased your efficiency or has saved you money?,[],r/datascience,False,6,projects,0,,,False,t3_176de18,False,dark,0.95,,public,56,0,{},,,False,[],,False,False,,{},Projects,False,56,,False,False,self,False,,[],{},,True,,1697134067.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.&lt;/p&gt;

&lt;p&gt;For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it&amp;#39;s likely the cheapest price in the interval that I should place the order.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don&amp;#39;t usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,176de18,True,,OutcomeSerious,,38,True,all_ads,False,[],False,,/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,all_ads,False,https://www.reddit.com/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,1209065,1697134067.0,0,,False,,,,,,,,,,883,159
,datascience,Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?,t2_62sz58k,False,,0,False,What to do when looking for a job,[],r/datascience,False,6,discussion,0,,,False,t3_176c3gh,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697130763.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176c3gh,True,,mangos5,,3,True,all_ads,False,[],False,,/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,1209065,1697130763.0,0,,False,,,,,,,,,,98,16
,datascience,"I'm a beginner in data science, Can someone recommend some good Data Science courses? ",t2_70rifmy3,False,,0,False,Recommend data science course,[],r/datascience,False,6,discussion,0,,,False,t3_176bn2q,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697129582.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a beginner in data science, Can someone recommend some good Data Science courses? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,176bn2q,True,,Ashfan007,,2,True,all_ads,False,[],False,,/r/datascience/comments/176bn2q/recommend_data_science_course/,all_ads,False,https://www.reddit.com/r/datascience/comments/176bn2q/recommend_data_science_course/,1209065,1697129582.0,0,,False,,,,,,,,,,86,14
,datascience,"I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!",t2_spw388k1,False,,0,False,Need problem statements for a project,[],r/datascience,False,6,projects,0,,,False,t3_176aamb,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1697126138.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to make a project in which I&amp;#39;m thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn&amp;#39;t already a solution however I&amp;#39;m not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y&amp;#39;all have any suggestions please let me know it&amp;#39;ll be genuinely appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,176aamb,True,,emotional-Limit-2000,,5,True,all_ads,False,[],False,,/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,all_ads,False,https://www.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,1209065,1697126138.0,0,,False,,,,,,,,,,369,70
,datascience,"I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.

I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?

How did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?",t2_8cg2z0mf,False,,0,False,can any research scientists share their experience?,[],r/datascience,False,6,discussion,0,,,False,t3_1769z7v,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697125314.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.&lt;/p&gt;

&lt;p&gt;I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?&lt;/p&gt;

&lt;p&gt;How did you get the role? If I&amp;#39;m interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1769z7v,True,,Legitimate_Ebb3623,,2,True,all_ads,False,[],False,,/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,all_ads,False,https://www.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,1209065,1697125314.0,0,,False,,,,,,,,,,642,125
,datascience,"Hi, I’m writing this post hoping to get some advice from everyone. I’m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.

However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :(",t2_ctixwjk2,False,,0,False,I feel like I’m stuck with my scientific research,[],r/datascience,False,6,discussion,0,,,False,t3_1769vr7,False,dark,0.7,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697125064.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I’m writing this post hoping to get some advice from everyone. I’m studying for a Master&amp;#39;s degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I&amp;#39;ve completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.&lt;/p&gt;

&lt;p&gt;However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I&amp;#39;m stuck at this stage; one month has passed, and I haven&amp;#39;t been able to discover anything new beyond what they have pointed out. I&amp;#39;m really worried that I might disappoint my mentors, as they&amp;#39;ve been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I&amp;#39;m afraid that I might be slowing down the whole team :(&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1769vr7,True,,ma-d-ghost,,7,True,all_ads,False,[],False,,/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,all_ads,False,https://www.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,1209065,1697125064.0,0,,False,,,,,,,,,,955,162
,datascience,"I have been working as a ""Data Scientist"" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. 

In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.

I'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?",t2_8cg2z0mf,False,,0,False,Coding sometimes scares me. Is this the wrong field for me?,[],r/datascience,False,6,discussion,0,,,False,t3_1769ler,False,dark,0.73,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,False,self,False,,[],{},,True,,1697124321.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been working as a &amp;quot;Data Scientist&amp;quot; for a little over 2 years but in my company I&amp;#39;m primarily tasked with developing MVPs with the company&amp;#39;s  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company&amp;#39;s technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. &lt;/p&gt;

&lt;p&gt;In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1769ler,True,,Legitimate_Ebb3623,,27,True,all_ads,False,[],False,,/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,all_ads,False,https://www.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,1209065,1697124321.0,0,,False,,,,,,,,,,904,161
,datascience,What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?,t2_7zmoi25a,False,,0,False,DS exits or pivots,[],r/datascience,False,6,discussion,0,,,False,t3_1769fk8,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697123889.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What&amp;#39;s the most creative exit or pivot you have done (or seen others do) after being a DS for some time?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1769fk8,True,,ergodym,,0,True,all_ads,False,[],False,,/r/datascience/comments/1769fk8/ds_exits_or_pivots/,all_ads,False,https://www.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/,1209065,1697123889.0,0,,False,,,,,,,,,,104,21
,datascience,"Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?",t2_7wg5m7r,False,,0,False,Career planning,[],r/datascience,False,6,discussion,0,,,False,t3_17686qn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1697120602.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17686qn,True,,Kenny9184,,1,True,all_ads,False,[],False,,/r/datascience/comments/17686qn/career_planning/,all_ads,False,https://www.reddit.com/r/datascience/comments/17686qn/career_planning/,1209065,1697120602.0,0,,False,,,,,,,,,,679,132
,datascience," If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? ",t2_5fbmh3va,False,,0,False,How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote),[],r/datascience,False,6,discussion,0,,,False,t3_17666j9,False,dark,0.88,,public,301,0,{},,,False,[],,False,False,,{},Discussion,False,301,,False,False,self,False,,[],{},,True,,1697114881.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17666j9,True,,Excellent_Cost170,,121,True,all_ads,False,[],False,,/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,all_ads,False,https://www.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,1209065,1697114881.0,0,,False,,,,,,,,,,148,27
,datascience,"I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things ""AI"").

Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.

If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.

My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.

I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like ""Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?""

Basically, all this is a very long-winded, rambling way to get to three questions:

1. Are there any examples of converting a remotely complex RDMS into a vector database?

2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?

3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?",t2_32ls6,False,,0,False,Existing relational database to new vector database?,[],r/datascience,False,6,discussion,0,,,False,t3_1761n34,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1697098022.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things &amp;quot;AI&amp;quot;).&lt;/p&gt;

&lt;p&gt;Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.&lt;/p&gt;

&lt;p&gt;If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.&lt;/p&gt;

&lt;p&gt;My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I&amp;#39;m not sure where to start, and I&amp;#39;m getting hung up on that there doesn&amp;#39;t seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.&lt;/p&gt;

&lt;p&gt;I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I&amp;#39;d equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That&amp;#39;s half of it. But I&amp;#39;m not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I&amp;#39;m most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like &amp;quot;Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?&amp;quot;&lt;/p&gt;

&lt;p&gt;Basically, all this is a very long-winded, rambling way to get to three questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Are there any examples of converting a remotely complex RDMS into a vector database?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How much massaging beyond basic denormalization and pre-aggregation do I need to do?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1761n34,True,,ZebZ,,1,True,all_ads,False,[],False,,/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,all_ads,False,https://www.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,1209065,1697098022.0,0,,False,,,,,,,,,,2872,480
,datascience,"Hi Guys,

Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. 

&amp;#x200B;

Thanks. ",t2_gqmgvnn0,False,,0,False,SHAP Deep Reinforcement Learning,[],r/datascience,False,6,discussion,0,,,False,t3_175x92z,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697081538.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;

&lt;p&gt;Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175x92z,True,,ProductOk7316,,0,True,all_ads,False,[],False,,/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,all_ads,False,https://www.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,1209065,1697081538.0,0,,False,,,,,,,,,,253,46
,datascience,"I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. 

I work on a team of \~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. 

I think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.

When you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?",t2_c9pbqokh,False,,0,False,Predicting what features lead to long wait times,[],r/datascience,False,6,tooling,0,,,False,t3_175qvkx,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Tooling,False,3,,False,False,self,False,,[],{},,True,,1697063226.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. &lt;/p&gt;

&lt;p&gt;I work on a team of ~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. &lt;/p&gt;

&lt;p&gt;I think there&amp;#39;s a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.&lt;/p&gt;

&lt;p&gt;When you have one value (duration) that you&amp;#39;re trying to make predictions about, but you don&amp;#39;t have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,175qvkx,True,,Bulky_Gap_7072,,4,True,all_ads,False,[],False,,/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,all_ads,False,https://www.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,1209065,1697063226.0,0,,False,,,,,,,,,,1154,207
,datascience,&amp;#x200B;,t2_3vtdvu7m,False,,0,False,Is fitting functions to data (with chi2 and all that) data analysis or data science?,[],r/datascience,False,6,discussion,0,,,False,t3_175qent,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,1697072739.0,,[],{},,True,,1697062044.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175qent,True,,Silly_Valley,,52,True,all_ads,False,[],False,,/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,all_ads,False,https://www.reddit.com/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,1209065,1697062044.0,0,,False,,,,,,,,,,12,1
,datascience,"I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.

I would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.

My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet.",t2_c4tdx,False,,0,False,Security measures at my workplace,[],r/datascience,False,6,discussion,0,,,False,t3_175q00o,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,False,self,False,,[],{},,True,,1697061027.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work for a pretty big Aerospace manufacturing company where my job title is &amp;#39;Digital Engineer&amp;#39;. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can&amp;#39;t disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.&lt;/p&gt;

&lt;p&gt;I would of course like to use Python&amp;#39;s Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.&lt;/p&gt;

&lt;p&gt;My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven&amp;#39;t really been exposed to it yet.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175q00o,True,,EncryptedMyst,,7,True,all_ads,False,[],False,,/r/datascience/comments/175q00o/security_measures_at_my_workplace/,all_ads,False,https://www.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/,1209065,1697061027.0,0,,False,,,,,,,,,,999,172
,datascience,"Hi everyone,

I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around £5,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. 

Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. ",t2_caxt5,False,,0,False,Where to spend £5k budget for professional development in Data Science,[],r/datascience,False,6,discussion,0,,,False,t3_175ptfa,False,dark,0.84,,public,13,0,{},,,False,[],,False,False,,{},Discussion,False,13,,False,False,self,False,,[],{},,True,,1697060557.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around £5,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. &lt;/p&gt;

&lt;p&gt;Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175ptfa,True,,greathassan,,24,True,all_ads,False,[],False,,/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,all_ads,False,https://www.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,1209065,1697060557.0,0,,False,,,,,,,,,,715,127
,datascience,"[https://github.com/jinyus/related\_post\_gen](https://github.com/jinyus/related_post_gen)

https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f",t2_6dtot6beo,False,,0,False,"Julia leads Rust, Zig, Go and Java in data processing benchmark",[],r/datascience,False,6,discussion,0,140.0,,False,t3_175oh0k,False,dark,0.79,,public,5,0,{},140.0,,False,[],,False,False,,{},Discussion,False,5,,False,False,https://b.thumbs.redditmedia.com/W2Naxk_8dd2GS0UHXIBaEkjm_3OxA5-KTZjS66eWAIs.jpg,False,,[],{},,True,,1697057221.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/jinyus/related_post_gen""&gt;https://github.com/jinyus/related_post_gen&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f""&gt;https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175oh0k,True,,Fincho64,,0,True,all_ads,False,[],False,,/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,1209065,1697057221.0,0,,False,"{'ii0dm13dymtb1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 111, 'x': 108, 'u': 'https://preview.redd.it/ii0dm13dymtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29389ec319b46acce2f70256fb514f3b12ac60af'}, {'y': 223, 'x': 216, 'u': 'https://preview.redd.it/ii0dm13dymtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=edef1a8be72ea4a5076387fd93b5a248f708a697'}, {'y': 331, 'x': 320, 'u': 'https://preview.redd.it/ii0dm13dymtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3945a0f9a2a5d58f5286afb0c20ee19e015e331'}, {'y': 663, 'x': 640, 'u': 'https://preview.redd.it/ii0dm13dymtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=04f3394bfbd28c4fab37f8d5091932b4e8a4c804'}], 's': {'y': 880, 'x': 849, 'u': 'https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f'}, 'id': 'ii0dm13dymtb1'}}",,,,,,,,,219,2
,datascience,"Hello.

I have to do a project for my thesis.
I have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it’s being laundered.

What do you say about it?
 How should I approach this topic and how to do it?
Any ideas? Thanks.",t2_5gw1p7y,False,,0,False,Fraud Detection Thesis,[],r/datascience,False,6,projects,0,,,False,t3_175nces,False,dark,0.27,,public,0,0,{},,,False,[],,False,False,,{},Projects,False,0,,False,False,self,False,,[],{},,True,,1697054438.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello.&lt;/p&gt;

&lt;p&gt;I have to do a project for my thesis.
I have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it’s being laundered.&lt;/p&gt;

&lt;p&gt;What do you say about it?
 How should I approach this topic and how to do it?
Any ideas? Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,175nces,True,,philemil,,12,True,all_ads,False,[],False,,/r/datascience/comments/175nces/fraud_detection_thesis/,all_ads,False,https://www.reddit.com/r/datascience/comments/175nces/fraud_detection_thesis/,1209065,1697054438.0,0,,False,,,,,,,,,,267,54
,datascience,"I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.

I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?

What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?

I'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get.",t2_pxn8nina,False,,0,False,Any value to an unrelated advanced degree to get into DS?,[],r/datascience,False,6,discussion,0,,,False,t3_175nbtg,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,False,self,False,,[],{},,True,,1697054404.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.&lt;/p&gt;

&lt;p&gt;I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don&amp;#39;t care about non-CS scientific education ?&lt;/p&gt;

&lt;p&gt;What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m interested in Data Science and I&amp;#39;m looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn&amp;#39;t want to pursue more formal education if it doesn&amp;#39;t really give me more options other than a false hope and wasted time applying for DS positions I can&amp;#39;t get.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175nbtg,True,,childofaether,,14,True,all_ads,False,[],False,,/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,all_ads,False,https://www.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,1209065,1697054404.0,0,,False,,,,,,,,,,1135,200
,datascience,"I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!

Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?

P.S. i sadly mustn't split the dataset. 

Thanks a lot, i wish you nothing but simple datasets. ",t2_3x05wl5n,False,,0,False,R-SESSION CRASHING-PHOBIA,[],r/datascience,False,6,discussion,0,,,False,t3_175mipy,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1697052333.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I&amp;#39;d say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE &amp;#39;&amp;#39;SESSION CRASHED&amp;#39;&amp;#39;!&lt;/p&gt;

&lt;p&gt;Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?&lt;/p&gt;

&lt;p&gt;P.S. i sadly mustn&amp;#39;t split the dataset. &lt;/p&gt;

&lt;p&gt;Thanks a lot, i wish you nothing but simple datasets. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175mipy,True,,aesthetic-mango,,9,True,all_ads,False,[],False,,/r/datascience/comments/175mipy/rsession_crashingphobia/,all_ads,False,https://www.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/,1209065,1697052333.0,0,,False,,,,,,,,,,821,158
,datascience,"Let’s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?


How would you store/archive this project?
Committing Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that’s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?

What tool / workflow am I missing here?

I keep hearning notebooks are great for experiments but I don’t see what the workflow is like for these experiments…

EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..",t2_13hucc,False,,0,False,How do you store your ad hoc experiments?,[],r/datascience,False,6,discussion,0,,,False,t3_175jep1,False,dark,0.95,,public,48,0,{},,,False,[],,False,False,,{},Discussion,False,48,,False,False,self,1697083575.0,,[],{},,True,,1697044442.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let’s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?&lt;/p&gt;

&lt;p&gt;How would you store/archive this project?
Committing Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that’s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?&lt;/p&gt;

&lt;p&gt;What tool / workflow am I missing here?&lt;/p&gt;

&lt;p&gt;I keep hearning notebooks are great for experiments but I don’t see what the workflow is like for these experiments…&lt;/p&gt;

&lt;p&gt;EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175jep1,True,,every_other_freackle,,30,True,all_ads,False,[],False,,/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,all_ads,False,https://www.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,1209065,1697044442.0,0,,False,,,,,,,,,,1270,239
,datascience,Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.,t2_hf2e17ayz,False,,0,False,What are grid search alternatives?,[],r/datascience,False,6,discussion,0,,,False,t3_175gyx0,False,dark,0.83,,public,24,0,{},,,False,[],,False,False,,{},Discussion,False,24,,False,False,self,False,,[],{},,True,,1697038513.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175gyx0,True,,Pineapple_throw_105,,38,True,all_ads,False,[],False,,/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,all_ads,False,https://www.reddit.com/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,1209065,1697038513.0,0,,False,,,,,,,,,,161,28
,datascience,"I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? 

For example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? 

Any suggestions are appreciated.",t2_28h3sgt7,False,,0,False,Predicted raw probabilities or threshold-adjusted ones?,[],r/datascience,False,6,discussion,0,,,False,t3_175errf,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1697032992.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? &lt;/p&gt;

&lt;p&gt;For example, suppose I get a probability as 0.55. Which means, in face value, that there&amp;#39;s more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I&amp;#39;m concerned with ONLY the probability, isnt that deceiving or wrong? &lt;/p&gt;

&lt;p&gt;Any suggestions are appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175errf,True,,oblivious_horizon,,5,True,all_ads,False,[],False,,/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,all_ads,False,https://www.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,1209065,1697032992.0,0,,False,,,,,,,,,,756,125
,datascience,"My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.

I am the “lead”/senior data scientist in an R&amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.

  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.

I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.",t2_91esrqhf,False,,0,False,How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?,[],r/datascience,False,6,discussion,0,,,False,t3_175caah,False,dark,0.86,,public,74,0,{},,,False,[],,False,False,,{},Discussion,False,74,,False,False,self,False,,[],{},,True,,1697025555.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.&lt;/p&gt;

&lt;p&gt;I am the “lead”/senior data scientist in an R&amp;amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.&lt;/p&gt;

&lt;p&gt;I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.&lt;/p&gt;

&lt;p&gt;I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,175caah,True,,Diligent_Trust2569,,81,True,all_ads,False,[],False,,/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,all_ads,False,https://www.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,1209065,1697025555.0,0,,False,,,,,,,,,,1165,210
,datascience,"Hi Everyone

I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. 

I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). 

My question is beyond a refresher training I wanted to make a map for the ~~lazy~~ some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.",t2_8o2bbpliq,False,,0,False,Creating a Visualizations Map,[],r/datascience,False,6,projects,0,,,False,t3_17578q8,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1697004961.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Everyone&lt;/p&gt;

&lt;p&gt;I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. &lt;/p&gt;

&lt;p&gt;I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). &lt;/p&gt;

&lt;p&gt;My question is beyond a refresher training I wanted to make a map for the &lt;del&gt;lazy&lt;/del&gt; some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17578q8,True,,Prestigious_Virus_33,,2,True,all_ads,False,[],False,,/r/datascience/comments/17578q8/creating_a_visualizations_map/,all_ads,False,https://www.reddit.com/r/datascience/comments/17578q8/creating_a_visualizations_map/,1209065,1697004961.0,0,,False,,,,,,,,,,688,116
,datascience,"I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is ‘attractive’, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.

If I want to do A/B test on this to see if this ‘attractive’ indication makes those items sell at a higher rate, how would you design the test? Would you:
1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?
2. Identify those items and only show the ‘attractive’ indicator to half of the users. Meaning that half the users will see the existing experience (no ‘attractive’ indicator at all) and half will see the ‘attractive’ indicator on all 500 items, then compare how they sell by user group?

Intuitively #1 makes more sense to me, but I’m not finding a lot of literature to support this methodology. How would you design such a test and what’s your rationale?

Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.

Thanks",t2_82f9k6td,False,,0,False,A/B Testing Product or User Split,[],r/datascience,False,6,discussion,0,,,False,t3_1756hae,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1697002012.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is ‘attractive’, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.&lt;/p&gt;

&lt;p&gt;If I want to do A/B test on this to see if this ‘attractive’ indication makes those items sell at a higher rate, how would you design the test? Would you:
1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?
2. Identify those items and only show the ‘attractive’ indicator to half of the users. Meaning that half the users will see the existing experience (no ‘attractive’ indicator at all) and half will see the ‘attractive’ indicator on all 500 items, then compare how they sell by user group?&lt;/p&gt;

&lt;p&gt;Intuitively #1 makes more sense to me, but I’m not finding a lot of literature to support this methodology. How would you design such a test and what’s your rationale?&lt;/p&gt;

&lt;p&gt;Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1756hae,True,,DboS3dan,,5,True,all_ads,False,[],False,,/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,all_ads,False,https://www.reddit.com/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,1209065,1697002012.0,0,,False,,,,,,,,,,1259,227
,datascience,Hey! Has anyone used Comet (https://www.comet.com) for their experiment tracking? I’m looking into the product and am curious if anyone here has enjoyed using it,t2_nm4npbzv,False,,0,False,Has anyone used Comet for experiment tracking?,[],r/datascience,False,6,tooling,0,,,False,t3_1755h3b,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Tooling,False,2,,False,False,self,False,,[],{},,True,,1696998190.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey! Has anyone used Comet (&lt;a href=""https://www.comet.com""&gt;https://www.comet.com&lt;/a&gt;) for their experiment tracking? I’m looking into the product and am curious if anyone here has enjoyed using it&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,1755h3b,True,,jacobwlyman,,2,True,all_ads,False,[],False,,/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,all_ads,False,https://www.reddit.com/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,1209065,1696998190.0,0,,False,,,,,,,,,,161,25
,datascience,"I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I’m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company’s CRM data and my company’s product offering is price benchmarking.",t2_8felv1zi,False,,0,False,Data Science for Sales,[],r/datascience,False,6,discussion,0,,,False,t3_1754v9n,False,dark,0.78,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,False,self,False,,[],{},,True,,1696996136.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I’m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company’s CRM data and my company’s product offering is price benchmarking.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1754v9n,True,,DapperAd8264,,21,True,all_ads,False,[],False,,/r/datascience/comments/1754v9n/data_science_for_sales/,all_ads,False,https://www.reddit.com/r/datascience/comments/1754v9n/data_science_for_sales/,1209065,1696996136.0,0,,False,,,,,,,,,,659,117
,datascience,I'm trying to build something similar where websites can be crawled and refresh daily,t2_8es0n3vl,False,,0,False,"How does SEMRUSH, and other big analytic crawler works?",[],r/datascience,False,6,discussion,0,,,False,t3_1752wat,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,False,self,False,,[],{},,True,,1696990173.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to build something similar where websites can be crawled and refresh daily&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1752wat,True,,Breadskinjinhojiak,,2,True,all_ads,False,[],False,,/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,all_ads,False,https://www.reddit.com/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,1209065,1696990173.0,0,,False,,,,,,,,,,85,14
,datascience,"Got into my first job about 10 months ago. I study a master’s on data science and I’m about to finish school in 2-3 months. I’m doing okay, my lowest score is B+ and I’m working on a churn project. 

I got my job through a friend, the company knew I was recently starting my master’s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I’d bring a new perspective to the team. 

Things started ok and I’m doing pretty good on every day tasks, but whenever I’m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. 

It’s not that I’m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.

I’m starting to feel like I’m wasting company’s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.",t2_m826ekr,False,,0,False,Sucking at my job?,[],r/datascience,False,6,discussion,0,,,False,t3_174wmnk,False,dark,0.94,,public,145,0,{},,,False,[],,False,False,,{},Discussion,False,145,,False,False,self,False,,[],{},,True,,1696973097.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Got into my first job about 10 months ago. I study a master’s on data science and I’m about to finish school in 2-3 months. I’m doing okay, my lowest score is B+ and I’m working on a churn project. &lt;/p&gt;

&lt;p&gt;I got my job through a friend, the company knew I was recently starting my master’s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I’d bring a new perspective to the team. &lt;/p&gt;

&lt;p&gt;Things started ok and I’m doing pretty good on every day tasks, but whenever I’m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. &lt;/p&gt;

&lt;p&gt;It’s not that I’m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.&lt;/p&gt;

&lt;p&gt;I’m starting to feel like I’m wasting company’s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174wmnk,True,,Utterizi,,40,True,all_ads,False,[],False,,/r/datascience/comments/174wmnk/sucking_at_my_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/174wmnk/sucking_at_my_job/,1209065,1696973097.0,1,,False,,,,,,,,,,1216,227
,datascience,"I'm working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?",t2_mzobbzq,False,,0,False,Question animal tracking data and filling in periods of sleep?,[],r/datascience,False,6,discussion,0,,,False,t3_174wama,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,False,self,False,,[],{},,True,,1696972280.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174wama,True,,HyenaJack94,,0,True,all_ads,False,[],False,,/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,all_ads,False,https://www.reddit.com/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,1209065,1696972280.0,0,,False,,,,,,,,,,603,107
,datascience,"I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.

What are the top 5 or 10 DS hubs in the US, and then what's 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I'm assuming is Chicago)?",t2_4ckw169q,False,,0,False,[US] What are some hubs for data science or data analytics?,[],r/datascience,False,6,discussion,0,,,False,t3_174sfb2,False,dark,0.59,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,False,self,False,,[],{},,True,,1696962814.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.&lt;/p&gt;

&lt;p&gt;What are the top 5 or 10 DS hubs in the US, and then what&amp;#39;s 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I&amp;#39;m assuming is Chicago)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174sfb2,True,,valkaress,,14,True,all_ads,False,[],False,,/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,1209065,1696962814.0,0,,False,,,,,,,,,,318,64
,datascience,"One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You're just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...


And recently I've been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don't understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I'm not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. 


So how would you explain what a tensor is in real world terms?",t2_hdeet8zsc,False,,0,False,"Can anyone provide an easy to understand real world example of tensors, and how they are used?",[],r/datascience,False,6,discussion,0,,,False,t3_174pvw9,False,dark,0.85,,public,70,0,{},,,False,[],,False,False,,{},Discussion,False,70,,False,False,self,False,,[],{},,True,,1696956432.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You&amp;#39;re just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...&lt;/p&gt;

&lt;p&gt;And recently I&amp;#39;ve been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don&amp;#39;t understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I&amp;#39;m not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. &lt;/p&gt;

&lt;p&gt;So how would you explain what a tensor is in real world terms?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174pvw9,True,,databro92,,63,True,all_ads,False,[],False,,/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,all_ads,False,https://www.reddit.com/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,1209065,1696956432.0,0,,False,,,,,,,,,,887,155
,datascience,"Hi everyone!

Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I'm currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it's very time-consuming and tedious.  Is there a better way?

I've used Langchain and OpenAI to build ""Chat with your document"" apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don't think this solution will work.

&amp;#x200B;

Thank you for your input,

Data Scallion",t2_dffy2296,False,,0,False,Advancements in extracting tabular data from PDFs?,[],r/datascience,False,6,projects,0,,,False,t3_174pkt1,False,dark,0.84,,public,8,0,{},,,False,[],,False,False,,{},Projects,False,8,,False,False,self,False,,[],{},,True,,1696955619.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;

&lt;p&gt;Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I&amp;#39;m currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it&amp;#39;s very time-consuming and tedious.  Is there a better way?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve used Langchain and OpenAI to build &amp;quot;Chat with your document&amp;quot; apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don&amp;#39;t think this solution will work.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you for your input,&lt;/p&gt;

&lt;p&gt;Data Scallion&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,174pkt1,True,,data_scallion,,9,True,all_ads,False,[],False,,/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,all_ads,False,https://www.reddit.com/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,1209065,1696955619.0,0,,False,,,,,,,,,,624,107
,datascience,"How soon would you expect a new Senior Data Scientist to start churning out models, analysis, reports, experiments, etc? What would you think dictates this expectation?",t2_bhwy8,False,,0,False,How quickly should you be expected to start producing?,[],r/datascience,False,6,discussion,0,,,False,t3_174n6w2,False,dark,0.9,,public,50,0,{},,,False,[],,False,False,,{},Discussion,False,50,,False,False,self,False,,[],{},,True,,1696949594.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How soon would you expect a new Senior Data Scientist to start churning out models, analysis, reports, experiments, etc? What would you think dictates this expectation?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174n6w2,True,,timusw,,33,True,all_ads,False,[],False,,/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,all_ads,False,https://www.reddit.com/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,1209065,1696949594.0,0,,False,,,,,,,,,,168,26
,datascience,"Hi Everyone - Just a quick note to let you know that we just released v.1.4.0 of the [Highcharts for Python Toolkit](https://core-docs.highchartspython.com/) (Highcharts Core for Python, Highcharts Stock for Python, Highcharts Maps for Python, and Highcharts Gantt for Python).

While technically this is a minor release since everything remains backwards compatible and new functionality is purely additive, it still brings a ton of significant improvements across all libraries in the toolkit:

**Performance Improvements**

* 50 - 90% faster when rendering a chart in Jupyter (or when serializing it from Python to JS object literal notation)
* 30 - 90% faster when serializing a chart configuration from Python to JSON

Both major performance improvements depend somewhat on the chart configuration, but in any case it should be quite significant.

**Usability / Quality of Life Improvements**

* **Support for NumPy**

  Now we can create charts and data series directly from NumPy arrays.

* **Simpler API / Reduced Verbosity**

  While the toolkit still supports the full power of Highcharts (JS), the Python toolkit now supports ""naive"" usage and smart defaults. The toolkit will attempt to assemble charts and data series for you as best it can based on your data, even without an explicit configuration. Great for quick-and-dirty experimentation!

* **Python to JavaScript Conversion**

  Now we can write our Highcharts formatter or callback functions in Python, rather than JavaScript. With one method call, we can convert a Python callable/function into its JavaScript equivalent. This relies on integration with either OpenAI's GPT models or Anthropic's Claude model, so you will need to have an account with one (or both) of them to use the functionality. Because AI is generating the JavaScript code, best practice is to review the generated JS code before including it in any production application, but for quick data science work, or to streamline the development / configuration of visualizations, it can be super useful. [We even have a tutorial on how to use this feature here.](https://core-docs.highchartspython.com/en/latest/tutorials/callbacks.html)

* **Series-first Visualization**

  We no longer have to combine series objects and charts to produce a visualization. Now, we can visualize individual series directly with one method call, no need to assemble them into a chart object.

* **Data and Property Propagation**

  When configuring our data points, we no longer have to adjust each data point individually. To set the same property value on all data points, just set the property on the series and it will get automatically propagated across all data points.

* **Series Type Conversion**

  We can now convert one series to a different series type with one method call.

**Bug Fixes**

* Fixed a bug causing a conflict in certain circumstances where Jupyter Notebook uses RequireJS.
* Fixed a bug preventing certain chart-specific required Highcharts (JS) modules from loading correctly in Jupyter Notebook/Labs.

We're already hard at work on the next release, with more improvements coming, but while we work on it, if you're looking for high-end data visualization you'll find the Highcharts for Python Toolkit useful.

Here are all the more detailed links:

* [Highcharts for Python on Github](https://github.com/highcharts-for-python)
* [Highcharts for Python Website](https://highchartspython.com)
* Highcharts Core for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-core)
  * [PyPi](https://pypi.org/project/highcharts-core/)
  * [Documentation](https://core-docs.highchartspython.com)

* Highcharts Stock for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-stock)
  * [PyPi](https://pypi.org/project/highcharts-stock/)
  * [Documentation](https://stock-docs.highchartspython.com)

* Highcharts Maps for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-maps)
  * [PyPi](https://pypi.org/project/highcharts-maps/)
  * [Documentation](https://maps-docs.highchartspython.com)

* Highcharts Gantt for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-gantt)
  * [PyPi](https://pypi.org/project/highcharts-gantt/)
  * [Documentation](https://gantt-docs.highchartspython.com)

Please let us know what you think!",t2_dq0xmlp,False,,0,False,Highcharts for Python v.1.4.0 Released,[],r/datascience,False,6,tooling,0,,,False,t3_174ml3k,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},Tooling,False,2,,False,False,self,False,,[],{},,True,,1696948004.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Everyone - Just a quick note to let you know that we just released v.1.4.0 of the &lt;a href=""https://core-docs.highchartspython.com/""&gt;Highcharts for Python Toolkit&lt;/a&gt; (Highcharts Core for Python, Highcharts Stock for Python, Highcharts Maps for Python, and Highcharts Gantt for Python).&lt;/p&gt;

&lt;p&gt;While technically this is a minor release since everything remains backwards compatible and new functionality is purely additive, it still brings a ton of significant improvements across all libraries in the toolkit:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Performance Improvements&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;50 - 90% faster when rendering a chart in Jupyter (or when serializing it from Python to JS object literal notation)&lt;/li&gt;
&lt;li&gt;30 - 90% faster when serializing a chart configuration from Python to JSON&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both major performance improvements depend somewhat on the chart configuration, but in any case it should be quite significant.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Usability / Quality of Life Improvements&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Support for NumPy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now we can create charts and data series directly from NumPy arrays.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Simpler API / Reduced Verbosity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While the toolkit still supports the full power of Highcharts (JS), the Python toolkit now supports &amp;quot;naive&amp;quot; usage and smart defaults. The toolkit will attempt to assemble charts and data series for you as best it can based on your data, even without an explicit configuration. Great for quick-and-dirty experimentation!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Python to JavaScript Conversion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now we can write our Highcharts formatter or callback functions in Python, rather than JavaScript. With one method call, we can convert a Python callable/function into its JavaScript equivalent. This relies on integration with either OpenAI&amp;#39;s GPT models or Anthropic&amp;#39;s Claude model, so you will need to have an account with one (or both) of them to use the functionality. Because AI is generating the JavaScript code, best practice is to review the generated JS code before including it in any production application, but for quick data science work, or to streamline the development / configuration of visualizations, it can be super useful. &lt;a href=""https://core-docs.highchartspython.com/en/latest/tutorials/callbacks.html""&gt;We even have a tutorial on how to use this feature here.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Series-first Visualization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We no longer have to combine series objects and charts to produce a visualization. Now, we can visualize individual series directly with one method call, no need to assemble them into a chart object.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data and Property Propagation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When configuring our data points, we no longer have to adjust each data point individually. To set the same property value on all data points, just set the property on the series and it will get automatically propagated across all data points.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Series Type Conversion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can now convert one series to a different series type with one method call.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fixed a bug causing a conflict in certain circumstances where Jupyter Notebook uses RequireJS.&lt;/li&gt;
&lt;li&gt;Fixed a bug preventing certain chart-specific required Highcharts (JS) modules from loading correctly in Jupyter Notebook/Labs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;#39;re already hard at work on the next release, with more improvements coming, but while we work on it, if you&amp;#39;re looking for high-end data visualization you&amp;#39;ll find the Highcharts for Python Toolkit useful.&lt;/p&gt;

&lt;p&gt;Here are all the more detailed links:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/highcharts-for-python""&gt;Highcharts for Python on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://highchartspython.com""&gt;Highcharts for Python Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Highcharts Core for Python&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/highcharts-for-python/highcharts-core""&gt;Source Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://pypi.org/project/highcharts-core/""&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://core-docs.highchartspython.com""&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Highcharts Stock for Python&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/highcharts-for-python/highcharts-stock""&gt;Source Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://pypi.org/project/highcharts-stock/""&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://stock-docs.highchartspython.com""&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Highcharts Maps for Python&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/highcharts-for-python/highcharts-maps""&gt;Source Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://pypi.org/project/highcharts-maps/""&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://maps-docs.highchartspython.com""&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Highcharts Gantt for Python&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/highcharts-for-python/highcharts-gantt""&gt;Source Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://pypi.org/project/highcharts-gantt/""&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://gantt-docs.highchartspython.com""&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please let us know what you think!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,174ml3k,True,,InsightIndustry,,2,True,all_ads,False,[],False,,/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,all_ads,False,https://www.reddit.com/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,1209065,1696948004.0,0,,False,,,,,,,,,,4369,570
,datascience,"I see a lot of data scientists in this subreddit describing their work as using different types of methods to, in the end, improve company performance and/or profits.

I was wondering, if you have examples for how data science is used for social benefit instead of the bottom line of profits?",t2_tf1f2,False,,0,False,"How can data science be used to ""make the world a better place""?",[],r/datascience,False,6,discussion,0,,,False,t3_174gxvo,False,dark,0.89,,public,130,0,{},,,False,[],,False,False,,{},Discussion,False,130,,False,False,self,1696936462.0,,[],{},,True,,1696930199.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see a lot of data scientists in this subreddit describing their work as using different types of methods to, in the end, improve company performance and/or profits.&lt;/p&gt;

&lt;p&gt;I was wondering, if you have examples for how data science is used for social benefit instead of the bottom line of profits?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174gxvo,True,,Fluxan,,100,True,all_ads,False,[],False,,/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,all_ads,False,https://www.reddit.com/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,1209065,1696930199.0,0,,False,,,,,,,,,,292,51
,datascience,"Asides from skill issue

Is there any benefit to using Tableu/BI over streamlit given that coding isn't the issue? ",t2_uhv4bci5,False,,0,False,Why would I use Tableu/BI over Streamlit? Is there any advantage?,[],r/datascience,False,6,tooling,0,,,False,t3_174f1cc,False,dark,0.65,,public,7,0,{},,,False,[],,False,False,,{},Tooling,False,7,,False,False,self,False,,[],{},,True,,1696922002.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Asides from skill issue&lt;/p&gt;

&lt;p&gt;Is there any benefit to using Tableu/BI over streamlit given that coding isn&amp;#39;t the issue? &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,174f1cc,True,,Salt-Page1396,,28,True,all_ads,False,[],False,,/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,all_ads,False,https://www.reddit.com/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,1209065,1696922002.0,0,,False,,,,,,,,,,115,19
,datascience,Just curious how many people out there favor explainable boosting machines over bread and butter methods like lgbm or xgbm. Should I learn this or is it a fad?,t2_fzrh3,False,,0,False,Explainable boosting machines,[],r/datascience,False,6,discussion,0,,,False,t3_174dzeb,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,False,,[],{},,True,,1696917692.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just curious how many people out there favor explainable boosting machines over bread and butter methods like lgbm or xgbm. Should I learn this or is it a fad?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,174dzeb,True,,mingzhouren,,13,True,all_ads,False,[],False,,/r/datascience/comments/174dzeb/explainable_boosting_machines/,all_ads,False,https://www.reddit.com/r/datascience/comments/174dzeb/explainable_boosting_machines/,1209065,1696917692.0,0,,False,,,,,,,,,,159,29
,datascience,"
Hey everyone,

I recently joined a company as a data scientist and found that their data warehouse is in dire shape. It seems they haven't invested enough time in validating their data, resulting in most tables being unreliable for modeling or reporting. The analysts are reporting incorrect data and the upper management knows it. To add to the challenge, there's only one overburdened data engineer here, so I'm pretty much on my own in navigating this.

I've been identifying and communicating these data issues to upper management, but I also need to produce some models. The warehouse is poorly built, many tables with no data, a lot of columns in one table meaning they didn't bother creating more dimension tables. And worst of all, the data in tables is simply wrong. My current thought is to pivot temporarily:

1. Use existing, validated CSVs and Excel files to begin my analyses and model building.
2. Parallelly, work on gradually rectifying the data warehouse issues.
3. Eventually, transition the models to source data directly from the fixed warehouse.

Has anyone faced a similar situation? How did you handle it? Any advice or alternative approaches would be greatly appreciated!",t2_7bhaubdp,False,,0,False,Tough spot,[],r/datascience,False,6,discussion,0,,,False,t3_1748bph,False,dark,0.91,,public,24,0,{},,,False,[],,False,False,,{},Discussion,False,24,,False,False,self,False,,[],{},,True,,1696899397.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;I recently joined a company as a data scientist and found that their data warehouse is in dire shape. It seems they haven&amp;#39;t invested enough time in validating their data, resulting in most tables being unreliable for modeling or reporting. The analysts are reporting incorrect data and the upper management knows it. To add to the challenge, there&amp;#39;s only one overburdened data engineer here, so I&amp;#39;m pretty much on my own in navigating this.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been identifying and communicating these data issues to upper management, but I also need to produce some models. The warehouse is poorly built, many tables with no data, a lot of columns in one table meaning they didn&amp;#39;t bother creating more dimension tables. And worst of all, the data in tables is simply wrong. My current thought is to pivot temporarily:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Use existing, validated CSVs and Excel files to begin my analyses and model building.&lt;/li&gt;
&lt;li&gt;Parallelly, work on gradually rectifying the data warehouse issues.&lt;/li&gt;
&lt;li&gt;Eventually, transition the models to source data directly from the fixed warehouse.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Has anyone faced a similar situation? How did you handle it? Any advice or alternative approaches would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1748bph,True,,AbramoNauseus,,17,True,all_ads,False,[],False,,/r/datascience/comments/1748bph/tough_spot/,all_ads,False,https://www.reddit.com/r/datascience/comments/1748bph/tough_spot/,1209065,1696899397.0,0,,False,,,,,,,,,,1197,196
,datascience,"Hi all, I’m in the midst of a job search and one question I’ve been asked a few times is how I work with product managers. 

In truth, I’ve worked with product managers very little, and when I did, the partnerships were not fruitful. They generally wanted me to do exactly what they asked with minimal input from me on whether that task was worthwhile. In the worst cases, it felt like my entire job was just to keep the PM happy. This is quite different from my interactions with other stakeholders like managers, execs, etc, who have typically valued a more collaborative approach. I don’t know if this is typical—just my experience. 

Rather than ask for interview advice, I’m hoping I can prompt a more interesting discussion here on how to work well with product managers. What makes a good product manager? When is it worth pushing back on requests, and when should we just put our heads down and do what is asked? How do you balance the needs of PMs with those of other stakeholders?",t2_9h21e3hr,False,,0,False,How to work with product managers,[],r/datascience,False,6,discussion,0,,,False,t3_1740tx7,False,dark,0.93,,public,22,0,{},,,False,[],,False,False,,{},Discussion,False,22,,False,False,self,1696880385.0,,[],{},,True,,1696880200.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I’m in the midst of a job search and one question I’ve been asked a few times is how I work with product managers. &lt;/p&gt;

&lt;p&gt;In truth, I’ve worked with product managers very little, and when I did, the partnerships were not fruitful. They generally wanted me to do exactly what they asked with minimal input from me on whether that task was worthwhile. In the worst cases, it felt like my entire job was just to keep the PM happy. This is quite different from my interactions with other stakeholders like managers, execs, etc, who have typically valued a more collaborative approach. I don’t know if this is typical—just my experience. &lt;/p&gt;

&lt;p&gt;Rather than ask for interview advice, I’m hoping I can prompt a more interesting discussion here on how to work well with product managers. What makes a good product manager? When is it worth pushing back on requests, and when should we just put our heads down and do what is asked? How do you balance the needs of PMs with those of other stakeholders?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1740tx7,True,,career-throwaway-oof,,14,True,all_ads,False,[],False,,/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,all_ads,False,https://www.reddit.com/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,1209065,1696880200.0,0,,False,,,,,,,,,,990,178
,datascience,"I see so many complaints of people who hate their job or can't find one. I am starting to wonder if this industry is awful and I have just been lucky, or if the negatives just pop up more.

How happy are you with your job?",t2_4fiyncpa,False,,0,False,Are you happy with your job?,[],r/datascience,False,6,discussion,0,,,False,t3_17404sl,False,dark,0.87,,public,38,0,{},,,False,[],,False,False,,{},Discussion,False,38,,False,False,self,False,,[],{},,True,,1696878494.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see so many complaints of people who hate their job or can&amp;#39;t find one. I am starting to wonder if this industry is awful and I have just been lucky, or if the negatives just pop up more.&lt;/p&gt;

&lt;p&gt;How happy are you with your job?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17404sl,True,,Expendable_0,,46,True,all_ads,False,[],False,,/r/datascience/comments/17404sl/are_you_happy_with_your_job/,all_ads,False,https://www.reddit.com/r/datascience/comments/17404sl/are_you_happy_with_your_job/,1209065,1696878494.0,0,,False,,,,,,,,,,222,46
,datascience,Working on a deep learning project with some friends. They really want to build something with SD. Will I be able to use these skills in industry?,t2_a6j22bnv,False,,0,False,Is there a good industry use of stable diffusion that I'm not aware of?,[],r/datascience,False,6,projects,0,,,False,t3_173yyz7,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Projects,False,1,,False,False,self,False,,[],{},,True,,1696875735.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Working on a deep learning project with some friends. They really want to build something with SD. Will I be able to use these skills in industry?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,173yyz7,True,,Candid-Translator-89,,3,True,all_ads,False,[],False,,/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,all_ads,False,https://www.reddit.com/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,1209065,1696875735.0,0,,False,,,,,,,,,,146,27
,datascience,"(Previous post was removed for unclear reason)

I'm curious to hear about the impactful data science projects you've had the opportunity to work on in the corporate world. Whether it's in healthcare, finance, e-commerce, or any other industry, I'd love to know about the projects that made a significant difference.

I understand it may not be possible to go into details, but please share your experiences:

1. The industry or sector you were working in.
2. A brief description of the project.
3. The impact or results the project had on the company. 

Just to clarify, when I say “valuable” I mean from the company’s perspective.",t2_e2jh8y8b,False,,0,False,Most valuable data science project you've worked on for a company?,[],r/datascience,False,6,discussion,0,,,False,t3_173l7aj,False,dark,0.97,,public,60,0,{},,,False,[],,False,False,,{},Discussion,False,60,,False,False,self,False,,[],{},,True,,1696833786.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;(Previous post was removed for unclear reason)&lt;/p&gt;

&lt;p&gt;I&amp;#39;m curious to hear about the impactful data science projects you&amp;#39;ve had the opportunity to work on in the corporate world. Whether it&amp;#39;s in healthcare, finance, e-commerce, or any other industry, I&amp;#39;d love to know about the projects that made a significant difference.&lt;/p&gt;

&lt;p&gt;I understand it may not be possible to go into details, but please share your experiences:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The industry or sector you were working in.&lt;/li&gt;
&lt;li&gt;A brief description of the project.&lt;/li&gt;
&lt;li&gt;The impact or results the project had on the company. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Just to clarify, when I say “valuable” I mean from the company’s perspective.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,173l7aj,True,,foreignparent,,34,True,all_ads,False,[],False,,/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,all_ads,False,https://www.reddit.com/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,1209065,1696833786.0,0,,False,,,,,,,,,,631,106
,datascience,"I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?",t2_96pe53q5,False,,0,False,What is the best package /approach for matching text in python?,[],r/datascience,False,6,discussion,0,,,False,t3_173izkk,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,False,self,False,,[],{},,True,,1696825392.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,173izkk,True,,Ok_Waltz_5145,,2,True,all_ads,False,[],False,,/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,all_ads,False,https://www.reddit.com/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,1209065,1696825392.0,0,,False,,,,,,,,,,304,53
,datascience,"Data Science community, I've got a question for you:

Which data science tools do you find most user-friendly?

I just went live with a project I've been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I'm working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you're able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn't mind a few people ripping everything that sucks with the user experience.

Anyways, I'd love to learn about everyone's favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.

Project link: [https://www.burla.dev/](https://www.burla.dev/)",t2_7iyeps3c,False,,0,False,What data science tools have the best user experience?,[],r/datascience,False,6,projects,0,,,False,t3_173hmq4,False,dark,0.78,,public,22,0,{},,,False,[],,False,False,,{},Projects,False,22,,False,False,self,1696822436.0,,[],{},,True,,1696820819.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data Science community, I&amp;#39;ve got a question for you:&lt;/p&gt;

&lt;p&gt;Which data science tools do you find most user-friendly?&lt;/p&gt;

&lt;p&gt;I just went live with a project I&amp;#39;ve been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I&amp;#39;m working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you&amp;#39;re able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn&amp;#39;t mind a few people ripping everything that sucks with the user experience.&lt;/p&gt;

&lt;p&gt;Anyways, I&amp;#39;d love to learn about everyone&amp;#39;s favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.&lt;/p&gt;

&lt;p&gt;Project link: &lt;a href=""https://www.burla.dev/""&gt;https://www.burla.dev/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,173hmq4,True,,Ok_Post_149,,18,True,all_ads,False,[],False,,/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,all_ads,False,https://www.reddit.com/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,1209065,1696820819.0,0,,False,,self,"{'images': [{'source': {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?auto=webp&amp;s=dc8c6771b845e644cd666eb595201de88230f142', 'width': 1709, 'height': 1121}, 'resolutions': [{'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=496107537c7f02d11ba32280e55d89e56a5848d8', 'width': 108, 'height': 70}, {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ea8dc399ca823ce42caad20fe9c4f25f2be15cd', 'width': 216, 'height': 141}, {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3b10d6ba51982b5f955f301a6d0e6b2db776f20', 'width': 320, 'height': 209}, {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e99df4cf576fa238ed3e8c93013053c3dfa877d4', 'width': 640, 'height': 419}, {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1082634e72898dc2bea9d09182c55d9fd9fa9778', 'width': 960, 'height': 629}, {'url': 'https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e2dd0e6cd4a758bad26ffe4422e54719d529be1', 'width': 1080, 'height': 708}], 'variants': {}, 'id': '87w8QKwoshM83mfexlzDzg8Xw1B52-C16nqklM-GBsc'}], 'enabled': False}",,,,,,,1131,195
,datascience,"Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn't there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?

Shit, like I'm playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn't be that hard for a machine to do right? I can't imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account ",t2_vkzi7izo,False,,0,False,Why aren't there more decision support algos for doctors for differential diagnosing?,[],r/datascience,False,6,discussion,0,,,False,t3_173hj19,False,dark,0.91,,public,46,0,{},,,False,[],,False,False,,{},Discussion,False,46,,False,False,self,False,,[],{},,True,,1696820501.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn&amp;#39;t there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?&lt;/p&gt;

&lt;p&gt;Shit, like I&amp;#39;m playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn&amp;#39;t be that hard for a machine to do right? I can&amp;#39;t imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,173hj19,True,,derpgod123,,52,True,all_ads,False,[],False,,/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,all_ads,False,https://www.reddit.com/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,1209065,1696820501.0,0,,False,,,,,,,,,,731,119
,datascience,"I'm starting out on a team that is very collaborative and I've realized that while I've worked with other people before, I'm not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. 

Does anyone have advice for dealing with what almost feels like getting territorial over a model? It's nothing against the people on my team - they've all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like ""I built that."" It also almost feels like it's my fault for not being able to do all of the work myself, like if I was a better worker I'd be able to get more of the work done and people wouldn't have to pick up my slack.

Is this something that just goes away with time if you continue working on a team that works in this way? I didn't expect there to be an emotional challenge component to this and I'm struggling to know what to do and how to adapt, especially because this doesn't feel like the kind of thing you can really share/get support from coworkers on, because they're the ones working on it with me if that makes sense.",,False,,0,False,What advice would you give someone starting out on learning to collaborate on large projects and not be the sole person responsible for a model build?,[],r/datascience,False,6,discussion,0,,,False,t3_173dd6h,False,dark,1.0,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,,self,False,,,{},,True,,1696808065.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m starting out on a team that is very collaborative and I&amp;#39;ve realized that while I&amp;#39;ve worked with other people before, I&amp;#39;m not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. &lt;/p&gt;

&lt;p&gt;Does anyone have advice for dealing with what almost feels like getting territorial over a model? It&amp;#39;s nothing against the people on my team - they&amp;#39;ve all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like &amp;quot;I built that.&amp;quot; It also almost feels like it&amp;#39;s my fault for not being able to do all of the work myself, like if I was a better worker I&amp;#39;d be able to get more of the work done and people wouldn&amp;#39;t have to pick up my slack.&lt;/p&gt;

&lt;p&gt;Is this something that just goes away with time if you continue working on a team that works in this way? I didn&amp;#39;t expect there to be an emotional challenge component to this and I&amp;#39;m struggling to know what to do and how to adapt, especially because this doesn&amp;#39;t feel like the kind of thing you can really share/get support from coworkers on, because they&amp;#39;re the ones working on it with me if that makes sense.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,173dd6h,True,,[deleted],,3,True,all_ads,False,[],,dark,/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,all_ads,False,https://www.reddit.com/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,1209065,1696808065.0,0,,False,,,,,,,,,,1256,248
,datascience,"A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.

This seems like a problem for NLP but I'm unsure of where to start or just not confident. It's been at least 7 years since I've done any real 'data science' stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you've used that you like and could share.

Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?

I'm really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I'm not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?

Thanks for your thoughtfulness on this :)",,False,,0,False,Is it possible to automate the labeling of strings of text?,[],r/datascience,False,6,projects,0,,,False,t3_173cl4s,False,dark,0.9,,public,14,0,{},,,False,[],,False,False,,{},Projects,False,14,,False,,self,False,,,{},,True,,1696805952.0,text,6,,,,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.&lt;/p&gt;

&lt;p&gt;This seems like a problem for NLP but I&amp;#39;m unsure of where to start or just not confident. It&amp;#39;s been at least 7 years since I&amp;#39;ve done any real &amp;#39;data science&amp;#39; stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you&amp;#39;ve used that you like and could share.&lt;/p&gt;

&lt;p&gt;Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I&amp;#39;m not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?&lt;/p&gt;

&lt;p&gt;Thanks for your thoughtfulness on this :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,173cl4s,True,,[deleted],,22,True,all_ads,False,[],,dark,/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,all_ads,False,https://www.reddit.com/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,1209065,1696805952.0,0,,False,,,,,,,,,,1415,259
,datascience,"I'm an SWE (**not a data scientist**) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.

I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don't think they solve the issue of validating *changes in data* (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.

What I'm looking for is a tool that validates changes in data by comparing the previous value with the new value.

In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there's obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).

This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.

And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I'm just brainstorming here.

Would highly appreciate some recommendations/tips for tackling this problem. Thank you!",t2_mxg44sgb,False,,0,False,How to validate data?,[],r/datascience,False,6,discussion,0,,,False,t3_173broc,False,dark,0.9,,public,52,0,{},,,False,[],,False,False,,{},Discussion,False,52,,False,False,self,1696808736.0,,[],{},,True,,1696803736.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m an SWE (&lt;strong&gt;not a data scientist&lt;/strong&gt;) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.&lt;/p&gt;

&lt;p&gt;I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don&amp;#39;t think they solve the issue of validating &lt;em&gt;changes in data&lt;/em&gt; (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.&lt;/p&gt;

&lt;p&gt;What I&amp;#39;m looking for is a tool that validates changes in data by comparing the previous value with the new value.&lt;/p&gt;

&lt;p&gt;In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there&amp;#39;s obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).&lt;/p&gt;

&lt;p&gt;This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.&lt;/p&gt;

&lt;p&gt;And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I&amp;#39;m just brainstorming here.&lt;/p&gt;

&lt;p&gt;Would highly appreciate some recommendations/tips for tackling this problem. Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,173broc,True,,Sensitive-Main-6700,,26,True,all_ads,False,[],False,,/r/datascience/comments/173broc/how_to_validate_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/173broc/how_to_validate_data/,1209065,1696803736.0,0,,False,,,,,,,,,,1425,250
,datascience,Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!,t2_cjm93tal,False,,0,False,Running ARIMA Models,[],r/datascience,False,6,discussion,0,,,False,t3_17369yn,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,False,self,False,,[],{},,True,,1696789910.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,17369yn,True,,fhckgkgkgjdh,,3,True,all_ads,False,[],False,,/r/datascience/comments/17369yn/running_arima_models/,all_ads,False,https://www.reddit.com/r/datascience/comments/17369yn/running_arima_models/,1209065,1696789910.0,0,,False,,,,,,,,,,182,35
,datascience,"So I've been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don't think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?

The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don't know how much I'm up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let's say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).

Is there even any method to do that? Or should I just insist that it is not feasible?  
Thanks",t2_3hqmko1r,False,,0,False,Automation of insights extraction from Clustering,[],r/datascience,False,6,projects,0,,,False,t3_1731r1r,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1696778383.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;ve been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don&amp;#39;t think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?&lt;/p&gt;

&lt;p&gt;The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don&amp;#39;t know how much I&amp;#39;m up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let&amp;#39;s say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).&lt;/p&gt;

&lt;p&gt;Is there even any method to do that? Or should I just insist that it is not feasible?&lt;br/&gt;
Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1731r1r,True,,nuriel8833,,0,True,all_ads,False,[],False,,/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,all_ads,False,https://www.reddit.com/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,1209065,1696778383.0,0,,False,,,,,,,,,,1101,209
,datascience,"I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. 

I don't know how will i link the annotated JSON file of the images when training. Does anyone know how?",t2_okaww79i,False,,0,False,Image Detection with CNN Model,[],r/datascience,False,6,projects,0,,,False,t3_17316vc,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Projects,False,2,,False,False,self,False,,[],{},,True,,1696777078.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know how will i link the annotated JSON file of the images when training. Does anyone know how?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,17316vc,True,,AutomaticResearch337,,9,True,all_ads,False,[],False,,/r/datascience/comments/17316vc/image_detection_with_cnn_model/,all_ads,False,https://www.reddit.com/r/datascience/comments/17316vc/image_detection_with_cnn_model/,1209065,1696777078.0,2,,False,,,,,,,,,,383,74
,datascience,"As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?

Some of my thoughts:

1. As a manager, I can support my DSs by **NOT** micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.

2. I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. 

3. There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. 

4. The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team’s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. 

5. Some managers think PD is solely the DS’s responsibility. Thoughts?

6. How do you deal with HR when there are no clear DS role descriptions?

Not a simple optimization problem!",t2_7ilx2oko,False,,0,False,How do data scientist managers manage data scientists?,[],r/datascience,False,6,discussion,0,,,False,t3_172zdgx,False,dark,0.95,,public,121,0,{},,,False,[],,False,False,,{},Discussion,False,121,,False,False,self,False,,[],{},,True,,1696772308.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?&lt;/p&gt;

&lt;p&gt;Some of my thoughts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;As a manager, I can support my DSs by &lt;strong&gt;NOT&lt;/strong&gt; micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team’s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some managers think PD is solely the DS’s responsibility. Thoughts?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How do you deal with HR when there are no clear DS role descriptions?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Not a simple optimization problem!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,172zdgx,True,,cazzobomba,,56,True,all_ads,False,[],False,,/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,1209065,1696772308.0,0,,False,,,,,,,,,,1854,316
,datascience,"Are there any industry standard frameworks for data cleaning and wrangling? Naming conventions, order of operations (when to do imputation, detecting careless cases, etc.) that companies and researchers use to make shareable uniform datasets?",t2_okwnq,False,,0,False,Data Cleaning &amp; Wrangling Standards?,[],r/datascience,False,6,discussion,0,,,False,t3_172ko0y,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,False,self,False,,[],{},,True,,1696722713.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are there any industry standard frameworks for data cleaning and wrangling? Naming conventions, order of operations (when to do imputation, detecting careless cases, etc.) that companies and researchers use to make shareable uniform datasets?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,True,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,172ko0y,True,,jrdubbleu,,4,True,all_ads,False,[],False,,/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,all_ads,False,https://www.reddit.com/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,1209065,1696722713.0,0,,False,,,,,,,,,,242,34
,datascience,"So I had an argument with an interviewer who asked me why I didn't just use a non-linear classification model on the linearly separable data that I had in one of my projects that I described to him, even though I had no computational constraints. I told him that it was because, irrespective of computational cost, a linear model is always preferable if you have linear data because it is simpler and captures general pattern while non-linear models might overfit on  local patterns. But he kept disagreeing and saying that the only advantage that a linear model would have is computational cost and explainability even though I was actually getting better results with a logistic regression.

Who do you think was missing something here and why?",t2_4s456zpp,False,,0,False,"Should we use non-linear models for ""linear"" data?",[],r/datascience,False,6,discussion,0,,,False,t3_172gy7a,False,dark,0.95,,public,164,0,{},,,False,[],,False,False,,{},Discussion,False,164,,False,False,self,False,,[],{},,True,,1696712928.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I had an argument with an interviewer who asked me why I didn&amp;#39;t just use a non-linear classification model on the linearly separable data that I had in one of my projects that I described to him, even though I had no computational constraints. I told him that it was because, irrespective of computational cost, a linear model is always preferable if you have linear data because it is simpler and captures general pattern while non-linear models might overfit on  local patterns. But he kept disagreeing and saying that the only advantage that a linear model would have is computational cost and explainability even though I was actually getting better results with a logistic regression.&lt;/p&gt;

&lt;p&gt;Who do you think was missing something here and why?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,172gy7a,True,,dopplegangery,,123,True,all_ads,False,[],False,,/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,all_ads,False,https://www.reddit.com/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,1209065,1696712928.0,0,,False,,,,,,,,,,746,126
,datascience,"Hi all! 

I'm attempting to add some value at work. For context, I'm a Data Analytics Consultant at a small consulting firm where most of the data-related work is done by the DA team based out of India. The issue is that they just blew $10 million on a low-code app to streamline some of our company's offerings. Bottom line, it doesn't work and when it does it only works for cookie cutter cases. Regardless, they're the ones who get the funding and I'm the only Data Analyst in the US, where I was told they don't see the value in true DA/DS. What I would like to do is use open-source tools to recreate what the team in India was trying to do. Some of the base features would be being able to allow clients to fill out a survey of questions, read that to a SQL server I'll have to build, and publish multiple different dashboards (we currently use Tableau, but I figure I will need a web-based dashboard, such as Dash). 

When I was researching tools, they all read like ads, so I wanted to see what open-source tools others recommend from experience. For programming, I mainly use Python, though I am family with R as well. I'm also fine upskilling where needed, within reason (the bottleneck is time due to required chargeability at work and Master's coursework load).

Thanks in advance!

Edit: UI/UX will be pretty important since it is client work.",t2_6y3brbks,False,,0,False,Web-based App Recommendations,[],r/datascience,False,6,projects,0,,,False,t3_1729cnh,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Projects,False,3,,False,False,self,1696693907.0,,[],{},,True,,1696693354.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all! &lt;/p&gt;

&lt;p&gt;I&amp;#39;m attempting to add some value at work. For context, I&amp;#39;m a Data Analytics Consultant at a small consulting firm where most of the data-related work is done by the DA team based out of India. The issue is that they just blew $10 million on a low-code app to streamline some of our company&amp;#39;s offerings. Bottom line, it doesn&amp;#39;t work and when it does it only works for cookie cutter cases. Regardless, they&amp;#39;re the ones who get the funding and I&amp;#39;m the only Data Analyst in the US, where I was told they don&amp;#39;t see the value in true DA/DS. What I would like to do is use open-source tools to recreate what the team in India was trying to do. Some of the base features would be being able to allow clients to fill out a survey of questions, read that to a SQL server I&amp;#39;ll have to build, and publish multiple different dashboards (we currently use Tableau, but I figure I will need a web-based dashboard, such as Dash). &lt;/p&gt;

&lt;p&gt;When I was researching tools, they all read like ads, so I wanted to see what open-source tools others recommend from experience. For programming, I mainly use Python, though I am family with R as well. I&amp;#39;m also fine upskilling where needed, within reason (the bottleneck is time due to required chargeability at work and Master&amp;#39;s coursework load).&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;

&lt;p&gt;Edit: UI/UX will be pretty important since it is client work.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,937a6f50-d780-11e7-826d-0ed1beddcc82,False,False,False,,[],False,,,,t5_2sptq,False,,,,1729cnh,True,,Aislin777,,9,True,all_ads,False,[],False,,/r/datascience/comments/1729cnh/webbased_app_recommendations/,all_ads,False,https://www.reddit.com/r/datascience/comments/1729cnh/webbased_app_recommendations/,1209065,1696693354.0,0,,False,,,,,,,,,,1356,246
,datascience,"Topic might be a bit confusing, let me elaborate. For example let's say I'm working on a time series forecasting problem and I found that temperature is highly correlated with my target. But I also know it's a time series problem, so I want to boost my model by giving it probable temperature for the target dates. How do I do that? I can't wrap my head around it",t2_6o57z4ff,False,,0,False,How do I make use of other parameters' forecasts for time series forecasting?,[],r/datascience,False,6,discussion,0,,,False,t3_1726i2h,False,dark,0.8,,public,8,0,{},,,False,[],,False,False,,{},Discussion,False,8,,False,False,self,False,,[],{},,True,,1696685591.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Topic might be a bit confusing, let me elaborate. For example let&amp;#39;s say I&amp;#39;m working on a time series forecasting problem and I found that temperature is highly correlated with my target. But I also know it&amp;#39;s a time series problem, so I want to boost my model by giving it probable temperature for the target dates. How do I do that? I can&amp;#39;t wrap my head around it&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,4fad7108-d77d-11e7-b0c6-0ee69f155af2,False,False,False,,[],False,,,,t5_2sptq,False,,,,1726i2h,True,,Skilinger,,15,True,all_ads,False,[],False,,/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,all_ads,False,https://www.reddit.com/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,1209065,1696685591.0,0,,False,,,,,,,,,,363,69
,datascience,"Does anyone know of any half decent graph/network visualisation programs? Gephi is very frustrating to use (can only view up to 20 attribute columns at once, can't inspect node/edge attributes from the graph view, attribute values only allow you to copy the abbreviated scientific notation form etc.)

This is what I am trying to do... I have a graph (heterogenous but I can compress it to homogenous if absolutely necessary) and I want to be able to interactively visualise said graph. If I click on a node or edge, I wish to be able to see the attributes of that node or edge. Preferably, I'd also be able to colour nodes and edges by attribute.

There seems to be a few small bespoke projects but from the few I've tried, none have achieved what I have outlined above - what I would have thought to be the bare minimum for a graph visualisation application.

&amp;#x200B;

**EDIT**

Cytoscape standalone is definitely the way to go for me. Would highly recommend over Gephi. Still had to flatten my heterogenous graph, appending all attributes across all types, but with a specified `TYPE` attribute you can conditionally colour within Cytoscape so it gets you there in the end (bit annoying that every node/edge has redundant attributes from other node/edge types but it's not the end of the world.) Thanks for all the suggestions.",t2_xfx8ms4,False,,0,False,Why are there no good graph visualisation programs?,[],r/datascience,False,6,tooling,0,,,False,t3_17212yf,False,dark,0.9,,public,78,0,{},,,False,[],,False,False,,{},Tooling,False,78,,False,False,self,1696733213.0,,[],{},,True,,1696666749.0,text,6,,,text,self.datascience,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone know of any half decent graph/network visualisation programs? Gephi is very frustrating to use (can only view up to 20 attribute columns at once, can&amp;#39;t inspect node/edge attributes from the graph view, attribute values only allow you to copy the abbreviated scientific notation form etc.)&lt;/p&gt;

&lt;p&gt;This is what I am trying to do... I have a graph (heterogenous but I can compress it to homogenous if absolutely necessary) and I want to be able to interactively visualise said graph. If I click on a node or edge, I wish to be able to see the attributes of that node or edge. Preferably, I&amp;#39;d also be able to colour nodes and edges by attribute.&lt;/p&gt;

&lt;p&gt;There seems to be a few small bespoke projects but from the few I&amp;#39;ve tried, none have achieved what I have outlined above - what I would have thought to be the bare minimum for a graph visualisation application.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cytoscape standalone is definitely the way to go for me. Would highly recommend over Gephi. Still had to flatten my heterogenous graph, appending all attributes across all types, but with a specified &lt;code&gt;TYPE&lt;/code&gt; attribute you can conditionally colour within Cytoscape so it gets you there in the end (bit annoying that every node/edge has redundant attributes from other node/edge types but it&amp;#39;s not the end of the world.) Thanks for all the suggestions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,confidence,,,False,False,False,False,False,[],[],False,aaf5d8cc-d780-11e7-a4a5-0e68d01eab56,False,False,False,,[],False,,,,t5_2sptq,False,,,,17212yf,True,,HStuart18,,40,True,all_ads,False,[],False,,/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,all_ads,False,https://www.reddit.com/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,1209065,1696666749.0,0,,False,,,,,,,,,,1335,229
